{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from OSLPPWEIGHTED import *\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from collections import Counter\n",
    "import os\n",
    "import pandas as pd\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('small_datasets.pkl', 'rb') as f:\n",
    "    config = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_abbrev(source, target): return source[0].upper() + target[0].upper()\n",
    "def fmeasures(d): return ' '.join([f'{k}={v*100:.2f}' for (k,v) in d.items()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeaturesDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, features, labels):\n",
    "        self.features = features\n",
    "        self.labels = labels\n",
    "    def __len__(self): return len(self.labels)\n",
    "    def __getitem__(self, i): return self.features[i], self.labels[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _create_balanced_sampler(ds:FeaturesDataset):\n",
    "    freq2 = Counter(ds.labels.tolist())\n",
    "    class_weight = {x: 1.0 / freq2[x] for x in freq2}\n",
    "    source_weights = [class_weight[x] for x in ds.labels.tolist()]\n",
    "    sampler = torch.utils.data.WeightedRandomSampler(source_weights, len(ds.labels.tolist()))\n",
    "    return sampler\n",
    "\n",
    "def _create_trn_dataloader(ds, batch_size, balanced):\n",
    "    if balanced: return torch.utils.data.DataLoader(ds, batch_size=batch_size, sampler=_create_balanced_sampler(ds), drop_last=True)\n",
    "    else: torch.utils.data.DataLoader(ds, batch_size=batch_size, shuffle=True, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_initial_NN(feats_S, lbls_S, num_epochs, params, balanced, lr):\n",
    "    num_src_classes = params.num_common + params.num_src_priv\n",
    "    assert (lbls_S.unique() == torch.arange(num_src_classes)).all()\n",
    "    model = nn.Sequential(nn.Linear(params.pca_dim, params.proj_dim), nn.ReLU(), nn.Linear(params.proj_dim, num_src_classes)).cuda().train()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "#     scheduler = StepLR(optimizer, step_size=10, gamma=0.7)\n",
    "    loss_fn = nn.CrossEntropyLoss().cuda()\n",
    "    ds = FeaturesDataset(feats_S, lbls_S)\n",
    "    dl = _create_trn_dataloader(ds, 32, balanced)\n",
    "    for ep in range(num_epochs):\n",
    "        avg_loss = 0\n",
    "        for f,l in dl:\n",
    "            optimizer.zero_grad()\n",
    "            loss = loss_fn(model(f.cuda()), l.cuda())\n",
    "            loss.backward()\n",
    "            \n",
    "            avg_loss += loss.item()\n",
    "            optimizer.step()\n",
    "        print('Loss:', avg_loss / len(dl))\n",
    "#         scheduler.step()\n",
    "    return model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def entropy_loss(logits):\n",
    "    probs = F.softmax(logits, dim=1)\n",
    "    entropy =  - probs * probs.log()\n",
    "    entropy = entropy.sum(dim=1)\n",
    "    return entropy.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_NN(feats, lbls, num_epochs, params, balanced, lr):\n",
    "    num_src_classes = params.num_common + params.num_src_priv\n",
    "    # feats, lbls = torch.tensor(feats), torch.tensor(lbls)\n",
    "    # lbls[lbls == -2] = num_src_classes\n",
    "    feats, lbls = feats[lbls >= 0], lbls[lbls >= 0]\n",
    "    feats, lbls = feats[lbls < num_src_classes], lbls[lbls < num_src_classes]\n",
    "    model = nn.Sequential(nn.Linear(params.pca_dim, params.proj_dim), nn.ReLU(), nn.Linear(params.proj_dim, num_src_classes)).cuda().train()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "#     scheduler = StepLR(optimizer, step_size=10, gamma=0.7)\n",
    "    loss_fn = nn.CrossEntropyLoss().cuda()\n",
    "    ds = FeaturesDataset(feats, lbls)\n",
    "    dl = _create_trn_dataloader(ds, 32, balanced)\n",
    "    for ep in range(num_epochs):\n",
    "        avg_loss = 0\n",
    "        for f,l in dl:\n",
    "            optimizer.zero_grad()\n",
    "            loss = loss_fn(model(f.cuda()), l.cuda())\n",
    "            loss.backward()\n",
    "            \n",
    "            avg_loss += loss.item()\n",
    "            optimizer.step()\n",
    "        print('Loss:', avg_loss / len(dl))\n",
    "#         scheduler.step()\n",
    "    return model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_NN(model, feats, lbls):\n",
    "    ds = FeaturesDataset(feats, lbls)\n",
    "    dl = torch.utils.data.DataLoader(ds, batch_size=32, shuffle=False)\n",
    "    model = model.eval()\n",
    "    feats = []\n",
    "    preds = []\n",
    "    with torch.no_grad():\n",
    "        for f,l in dl:\n",
    "            out = model(f.cuda())\n",
    "            preds.append(F.softmax(out, dim=1).detach().cpu())\n",
    "            feats.append(f.detach())\n",
    "    feats = torch.cat(feats, dim=0)\n",
    "    preds = torch.cat(preds, dim=0)\n",
    "    return feats, preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sources = ['art', 'clipart', 'product', 'real_world']\n",
    "# targets = ['art', 'clipart', 'product', 'real_world']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sources = ['amazon', 'dslr', 'webcam']\n",
    "# targets = ['amazon', 'dslr', 'webcam']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sources = ['painting_train', 'real_train', 'sketch_train']\n",
    "# targets = ['painting_train', 'real_train', 'sketch_train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sources = ['train'] \n",
    "# targets = ['validation']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed:int):\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "painting -> sketch lr= 0.001 seed= 0\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19]\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20]\n",
      "Loss: 2.562207261721293\n",
      "Loss: 1.2393408083411122\n",
      "Loss: 0.7387420686464461\n",
      "Loss: 0.564478018454143\n",
      "Loss: 0.5006312367619661\n",
      "Loss: 0.4301535349201273\n",
      "Loss: 0.38650771423622415\n",
      "Loss: 0.35652905312322436\n",
      "Loss: 0.32989208191317854\n",
      "Loss: 0.2757383891277843\n",
      "tensor(True) tensor(True)\n",
      "______\n",
      "Iteration t=1\n",
      "all:  cs/acc_i=52.23 cs/acc_c=53.77 os/recall_knw=95.06 os/recall_unk=18.72 total/acc_i=39.30 total/acc_c=51.13 total/h_score=27.63\n",
      "selected:  cs/acc_i=63.07 cs/acc_c=64.16 os/recall_knw=76.05 os/recall_unk=82.66 total/acc_i=67.53 total/acc_c=60.48 total/h_score=69.11\n",
      "Loss: 2.474956455183964\n",
      "Loss: 1.0758645984472013\n",
      "Loss: 0.6366970372550628\n",
      "Loss: 0.5238751575496852\n",
      "Loss: 0.431535816952294\n",
      "Loss: 0.3821670485331732\n",
      "Loss: 0.3484044816052797\n",
      "Loss: 0.2945105408263557\n",
      "Loss: 0.278670582208125\n",
      "Loss: 0.25479272973961103\n",
      "______\n",
      "Iteration t=2\n",
      "all:  cs/acc_i=50.08 cs/acc_c=51.72 os/recall_knw=64.91 os/recall_unk=63.15 total/acc_i=48.13 total/acc_c=42.11 total/h_score=49.76\n",
      "selected:  cs/acc_i=47.15 cs/acc_c=49.04 os/recall_knw=45.39 os/recall_unk=85.63 total/acc_i=52.54 total/acc_c=34.96 total/h_score=47.04\n",
      "Loss: 2.4102033004848233\n",
      "Loss: 0.952316156631216\n",
      "Loss: 0.588902381035166\n",
      "Loss: 0.44875072988621684\n",
      "Loss: 0.3766961358829376\n",
      "Loss: 0.35577315310819435\n",
      "Loss: 0.31139696201463357\n",
      "Loss: 0.27884759374578066\n",
      "Loss: 0.26280805663368023\n",
      "Loss: 0.23015724795810674\n",
      "______\n",
      "Iteration t=3\n",
      "all:  cs/acc_i=49.89 cs/acc_c=51.51 os/recall_knw=59.36 os/recall_unk=70.29 total/acc_i=49.38 total/acc_c=40.26 total/h_score=49.97\n",
      "selected:  cs/acc_i=47.99 cs/acc_c=49.79 os/recall_knw=50.21 os/recall_unk=81.00 total/acc_i=50.99 total/acc_c=36.56 total/h_score=48.23\n",
      "Loss: 2.3634982945083025\n",
      "Loss: 0.8905465802847049\n",
      "Loss: 0.5459312301177484\n",
      "Loss: 0.4355951828228963\n",
      "Loss: 0.37779778848478807\n",
      "Loss: 0.31437957886751594\n",
      "Loss: 0.27517812537811537\n",
      "Loss: 0.25605491905178857\n",
      "Loss: 0.24356313317498088\n",
      "Loss: 0.2111954875129126\n",
      "______\n",
      "Iteration t=4\n",
      "all:  cs/acc_i=50.87 cs/acc_c=52.56 os/recall_knw=59.02 os/recall_unk=70.68 total/acc_i=49.43 total/acc_c=40.12 total/h_score=49.92\n",
      "selected:  cs/acc_i=49.42 cs/acc_c=51.55 os/recall_knw=54.75 os/recall_unk=75.21 total/acc_i=49.61 total/acc_c=38.06 total/h_score=48.88\n",
      "Loss: 2.3105053080562734\n",
      "Loss: 0.8604955670744552\n",
      "Loss: 0.5155186014427684\n",
      "Loss: 0.41304748279672443\n",
      "Loss: 0.35334579921733295\n",
      "Loss: 0.312757854423335\n",
      "Loss: 0.2658715174838715\n",
      "Loss: 0.24424737623865675\n",
      "Loss: 0.21182596408356275\n",
      "Loss: 0.20097641875635044\n",
      "______\n",
      "Iteration t=5\n",
      "all:  cs/acc_i=50.49 cs/acc_c=52.12 os/recall_knw=58.75 os/recall_unk=71.14 total/acc_i=49.50 total/acc_c=39.98 total/h_score=49.90\n",
      "selected:  cs/acc_i=49.43 cs/acc_c=51.50 os/recall_knw=57.29 os/recall_unk=72.71 total/acc_i=49.21 total/acc_c=38.97 total/h_score=49.29\n",
      "Loss: 2.296375814945467\n",
      "Loss: 0.8532410730277339\n",
      "Loss: 0.5115363004827692\n",
      "Loss: 0.4076488527559465\n",
      "Loss: 0.34674697705814916\n",
      "Loss: 0.3002062194169529\n",
      "Loss: 0.25782635803484627\n",
      "Loss: 0.23047186960015567\n",
      "Loss: 0.216930887286341\n",
      "Loss: 0.1934655626725045\n",
      "______\n",
      "Iteration t=6\n",
      "all:  cs/acc_i=50.75 cs/acc_c=52.46 os/recall_knw=58.57 os/recall_unk=71.40 total/acc_i=49.55 total/acc_c=39.93 total/h_score=49.90\n",
      "selected:  cs/acc_i=50.51 cs/acc_c=52.32 os/recall_knw=58.30 os/recall_unk=71.68 total/acc_i=49.46 total/acc_c=39.73 total/h_score=49.78\n",
      "Loss: 2.290953193187714\n",
      "Loss: 0.822188250541687\n",
      "Loss: 0.5078168556094169\n",
      "Loss: 0.38944302639365197\n",
      "Loss: 0.32876738280057904\n",
      "Loss: 0.30552829667925835\n",
      "Loss: 0.25866219015419484\n",
      "Loss: 0.2338382915109396\n",
      "Loss: 0.2152141140848398\n",
      "Loss: 0.1969838996231556\n",
      "______\n",
      "Iteration t=7\n",
      "all:  cs/acc_i=51.17 cs/acc_c=52.85 os/recall_knw=58.53 os/recall_unk=71.40 total/acc_i=49.55 total/acc_c=39.93 total/h_score=49.90\n",
      "selected:  cs/acc_i=51.13 cs/acc_c=52.83 os/recall_knw=58.50 os/recall_unk=71.40 total/acc_i=49.52 total/acc_c=39.89 total/h_score=49.87\n",
      "Loss: 2.2837106872839756\n",
      "Loss: 0.8206999987007613\n",
      "Loss: 0.49139764198506497\n",
      "Loss: 0.38910543384305035\n",
      "Loss: 0.329822302873866\n",
      "Loss: 0.28972230634960044\n",
      "Loss: 0.25977654795188354\n",
      "Loss: 0.24112797525536966\n",
      "Loss: 0.21070996550212343\n",
      "Loss: 0.19975800580712427\n",
      "______\n",
      "Iteration t=8\n",
      "all:  cs/acc_i=51.02 cs/acc_c=52.78 os/recall_knw=58.53 os/recall_unk=71.40 total/acc_i=49.55 total/acc_c=39.93 total/h_score=49.90\n",
      "selected:  cs/acc_i=51.02 cs/acc_c=52.78 os/recall_knw=58.53 os/recall_unk=71.40 total/acc_i=49.55 total/acc_c=39.93 total/h_score=49.90\n",
      "Loss: 2.2951538420293436\n",
      "Loss: 0.8049171410233851\n",
      "Loss: 0.5031417603511734\n",
      "Loss: 0.4049652547119148\n",
      "Loss: 0.3425207250265486\n",
      "Loss: 0.29081175850325847\n",
      "Loss: 0.24214096354001546\n",
      "Loss: 0.23850924397013576\n",
      "Loss: 0.20279731485710675\n",
      "Loss: 0.1908264008621533\n",
      "______\n",
      "Iteration t=9\n",
      "all:  cs/acc_i=50.87 cs/acc_c=52.71 os/recall_knw=58.53 os/recall_unk=71.40 total/acc_i=49.55 total/acc_c=39.93 total/h_score=49.90\n",
      "selected:  cs/acc_i=50.87 cs/acc_c=52.71 os/recall_knw=58.53 os/recall_unk=71.40 total/acc_i=49.55 total/acc_c=39.93 total/h_score=49.90\n",
      "tensor(0)\n",
      "all:  cs/acc_i=50.87 cs/acc_c=52.71 os/recall_knw=58.53 os/recall_unk=71.40 total/acc_i=49.55 total/acc_c=39.93 total/h_score=49.90\n",
      "painting -> sketch lr= 0.001 seed= 1\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19]\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20]\n",
      "Loss: 2.5593216873350597\n",
      "Loss: 1.1921095248883364\n",
      "Loss: 0.7526759953095169\n",
      "Loss: 0.5735803963961424\n",
      "Loss: 0.49312210445681576\n",
      "Loss: 0.4299184090245968\n",
      "Loss: 0.3770721490105624\n",
      "Loss: 0.3368780842376134\n",
      "Loss: 0.31393267226124566\n",
      "Loss: 0.29438852573986407\n",
      "tensor(True) tensor(True)\n",
      "______\n",
      "Iteration t=1\n",
      "all:  cs/acc_i=49.81 cs/acc_c=51.32 os/recall_knw=93.28 os/recall_unk=15.64 total/acc_i=36.52 total/acc_c=48.41 total/h_score=23.83\n",
      "selected:  cs/acc_i=54.84 cs/acc_c=55.74 os/recall_knw=69.20 os/recall_unk=76.85 total/acc_i=58.83 total/acc_c=51.56 total/h_score=60.80\n",
      "Loss: 2.473687489827474\n",
      "Loss: 1.0716573496659596\n",
      "Loss: 0.6336884442351612\n",
      "Loss: 0.4840567953446332\n",
      "Loss: 0.41169848081235794\n",
      "Loss: 0.3761965443617573\n",
      "Loss: 0.3361026620236682\n",
      "Loss: 0.29738006455933347\n",
      "Loss: 0.2736305443241316\n",
      "Loss: 0.2599552413266079\n",
      "______\n",
      "Iteration t=2\n",
      "all:  cs/acc_i=50.87 cs/acc_c=52.57 os/recall_knw=59.09 os/recall_unk=70.22 total/acc_i=49.59 total/acc_c=40.51 total/h_score=50.17\n",
      "selected:  cs/acc_i=47.76 cs/acc_c=49.57 os/recall_knw=41.50 os/recall_unk=86.53 total/acc_i=52.02 total/acc_c=33.15 total/h_score=45.08\n",
      "Loss: 2.4192138183007548\n",
      "Loss: 1.0016799897228905\n",
      "Loss: 0.5795499475313983\n",
      "Loss: 0.45398796773558364\n",
      "Loss: 0.3803000615550837\n",
      "Loss: 0.33730058929105416\n",
      "Loss: 0.3056956640350709\n",
      "Loss: 0.2842871531707431\n",
      "Loss: 0.2508090346744028\n",
      "Loss: 0.22901631797740765\n",
      "______\n",
      "Iteration t=3\n",
      "all:  cs/acc_i=50.34 cs/acc_c=51.97 os/recall_knw=55.40 os/recall_unk=74.67 total/acc_i=50.10 total/acc_c=39.02 total/h_score=49.69\n",
      "selected:  cs/acc_i=48.23 cs/acc_c=50.22 os/recall_knw=47.02 os/recall_unk=81.85 total/acc_i=50.62 total/acc_c=35.22 total/h_score=46.92\n",
      "Loss: 2.364983011328656\n",
      "Loss: 0.9389551756174668\n",
      "Loss: 0.5544097520734953\n",
      "Loss: 0.4210973697512046\n",
      "Loss: 0.38480414657489115\n",
      "Loss: 0.31983590563354286\n",
      "Loss: 0.27821739712811033\n",
      "Loss: 0.2473333859735209\n",
      "Loss: 0.23376064488421316\n",
      "Loss: 0.20686456556229488\n",
      "______\n",
      "Iteration t=4\n",
      "all:  cs/acc_i=50.60 cs/acc_c=52.34 os/recall_knw=55.25 os/recall_unk=74.80 total/acc_i=50.07 total/acc_c=38.91 total/h_score=49.61\n",
      "selected:  cs/acc_i=48.86 cs/acc_c=51.14 os/recall_knw=51.63 os/recall_unk=78.13 total/acc_i=49.78 total/acc_c=36.85 total/h_score=48.14\n",
      "Loss: 2.3368074145775957\n",
      "Loss: 0.8798534054636457\n",
      "Loss: 0.5298781556439699\n",
      "Loss: 0.39695565745421535\n",
      "Loss: 0.355365874689992\n",
      "Loss: 0.3019321049294711\n",
      "Loss: 0.2624959616949119\n",
      "Loss: 0.24814734629756735\n",
      "Loss: 0.22458759643854456\n",
      "Loss: 0.2078711270943097\n",
      "______\n",
      "Iteration t=5\n",
      "all:  cs/acc_i=50.42 cs/acc_c=51.87 os/recall_knw=55.21 os/recall_unk=75.07 total/acc_i=50.14 total/acc_c=38.88 total/h_score=49.64\n",
      "selected:  cs/acc_i=49.47 cs/acc_c=51.31 os/recall_knw=53.72 os/recall_unk=75.91 total/acc_i=49.75 total/acc_c=37.99 total/h_score=48.93\n",
      "Loss: 2.2987174207781567\n",
      "Loss: 0.853927069976006\n",
      "Loss: 0.5329145218241852\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.4054354298016662\n",
      "Loss: 0.35515543242050296\n",
      "Loss: 0.3062824573475147\n",
      "Loss: 0.2746727056648015\n",
      "Loss: 0.2497996680223893\n",
      "Loss: 0.21698428258115862\n",
      "Loss: 0.2058340051046615\n",
      "______\n",
      "Iteration t=6\n",
      "all:  cs/acc_i=51.02 cs/acc_c=52.72 os/recall_knw=55.09 os/recall_unk=75.07 total/acc_i=50.12 total/acc_c=38.84 total/h_score=49.60\n",
      "selected:  cs/acc_i=50.87 cs/acc_c=52.67 os/recall_knw=54.86 os/recall_unk=75.31 total/acc_i=50.08 total/acc_c=38.73 total/h_score=49.53\n",
      "Loss: 2.3243443549163945\n",
      "Loss: 0.8537590163267725\n",
      "Loss: 0.5044855126520482\n",
      "Loss: 0.4155593864256289\n",
      "Loss: 0.3402286485988435\n",
      "Loss: 0.29660773213680197\n",
      "Loss: 0.2571634112637702\n",
      "Loss: 0.24337227739454284\n",
      "Loss: 0.22500657909587632\n",
      "Loss: 0.19784034023863997\n",
      "______\n",
      "Iteration t=7\n",
      "all:  cs/acc_i=51.13 cs/acc_c=52.77 os/recall_knw=55.09 os/recall_unk=75.13 total/acc_i=50.14 total/acc_c=38.85 total/h_score=49.61\n",
      "selected:  cs/acc_i=51.11 cs/acc_c=52.76 os/recall_knw=55.08 os/recall_unk=75.13 total/acc_i=50.13 total/acc_c=38.83 total/h_score=49.60\n",
      "Loss: 2.3047852385334853\n",
      "Loss: 0.8411051265107907\n",
      "Loss: 0.5024283655532976\n",
      "Loss: 0.39815749839796283\n",
      "Loss: 0.3516658196543775\n",
      "Loss: 0.2962841138364823\n",
      "Loss: 0.2867396857316901\n",
      "Loss: 0.23834762970606485\n",
      "Loss: 0.21926204728462348\n",
      "Loss: 0.20322848473319677\n",
      "______\n",
      "Iteration t=8\n",
      "all:  cs/acc_i=51.40 cs/acc_c=53.02 os/recall_knw=55.09 os/recall_unk=75.13 total/acc_i=50.14 total/acc_c=38.85 total/h_score=49.61\n",
      "selected:  cs/acc_i=51.40 cs/acc_c=53.02 os/recall_knw=55.09 os/recall_unk=75.13 total/acc_i=50.14 total/acc_c=38.85 total/h_score=49.61\n",
      "Loss: 2.3054593714625247\n",
      "Loss: 0.8339505424866309\n",
      "Loss: 0.5058768812099449\n",
      "Loss: 0.4100979137034551\n",
      "Loss: 0.3440943704503268\n",
      "Loss: 0.2980345222752104\n",
      "Loss: 0.2687515880656146\n",
      "Loss: 0.2406999410435497\n",
      "Loss: 0.21665415903817303\n",
      "Loss: 0.20241694615377107\n",
      "______\n",
      "Iteration t=9\n",
      "all:  cs/acc_i=51.02 cs/acc_c=52.77 os/recall_knw=55.09 os/recall_unk=75.13 total/acc_i=50.14 total/acc_c=38.85 total/h_score=49.61\n",
      "selected:  cs/acc_i=51.02 cs/acc_c=52.77 os/recall_knw=55.09 os/recall_unk=75.13 total/acc_i=50.14 total/acc_c=38.85 total/h_score=49.61\n",
      "tensor(0)\n",
      "all:  cs/acc_i=51.02 cs/acc_c=52.77 os/recall_knw=55.09 os/recall_unk=75.13 total/acc_i=50.14 total/acc_c=38.85 total/h_score=49.61\n",
      "painting -> sketch lr= 0.001 seed= 2\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19]\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20]\n",
      "Loss: 2.5659425624463923\n",
      "Loss: 1.2379117106634474\n",
      "Loss: 0.7070422317615892\n",
      "Loss: 0.5786564112024963\n",
      "Loss: 0.476149216530815\n",
      "Loss: 0.42248003539584933\n",
      "Loss: 0.37903194732609247\n",
      "Loss: 0.3434457548711666\n",
      "Loss: 0.30182612915991475\n",
      "Loss: 0.2849869960672641\n",
      "tensor(True) tensor(True)\n",
      "______\n",
      "Iteration t=1\n",
      "all:  cs/acc_i=49.89 cs/acc_c=51.47 os/recall_knw=93.51 os/recall_unk=16.03 total/acc_i=36.67 total/acc_c=48.50 total/h_score=24.30\n",
      "selected:  cs/acc_i=55.84 cs/acc_c=57.64 os/recall_knw=70.45 os/recall_unk=79.80 total/acc_i=60.18 total/acc_c=52.74 total/h_score=62.52\n",
      "Loss: 2.469692472149344\n",
      "Loss: 1.0649535634061869\n",
      "Loss: 0.6643449613714919\n",
      "Loss: 0.5074054135703573\n",
      "Loss: 0.44603463897810264\n",
      "Loss: 0.38404105947005984\n",
      "Loss: 0.3367896258977114\n",
      "Loss: 0.2947816056948082\n",
      "Loss: 0.2793809365225481\n",
      "Loss: 0.2585441692202699\n",
      "______\n",
      "Iteration t=2\n",
      "all:  cs/acc_i=49.81 cs/acc_c=51.41 os/recall_knw=63.51 os/recall_unk=63.94 total/acc_i=47.97 total/acc_c=41.35 total/h_score=49.38\n",
      "selected:  cs/acc_i=46.96 cs/acc_c=48.92 os/recall_knw=44.62 os/recall_unk=86.08 total/acc_i=52.20 total/acc_c=34.41 total/h_score=46.47\n",
      "Loss: 2.4185325060415703\n",
      "Loss: 0.9878182300460447\n",
      "Loss: 0.5923532123139145\n",
      "Loss: 0.46048747966869163\n",
      "Loss: 0.37540383404548017\n",
      "Loss: 0.354661019467706\n",
      "Loss: 0.2965086810974353\n",
      "Loss: 0.2743428640682763\n",
      "Loss: 0.2595298588959449\n",
      "Loss: 0.23884011787969037\n",
      "______\n",
      "Iteration t=3\n",
      "all:  cs/acc_i=49.96 cs/acc_c=51.61 os/recall_knw=62.49 os/recall_unk=65.97 total/acc_i=48.42 total/acc_c=40.96 total/h_score=49.58\n",
      "selected:  cs/acc_i=48.32 cs/acc_c=50.41 os/recall_knw=52.17 os/recall_unk=80.13 total/acc_i=51.05 total/acc_c=37.40 total/h_score=48.97\n",
      "Loss: 2.352171524778589\n",
      "Loss: 0.8888823798982612\n",
      "Loss: 0.533962089132953\n",
      "Loss: 0.433607439071069\n",
      "Loss: 0.37212876827169805\n",
      "Loss: 0.31701357591719853\n",
      "Loss: 0.2853105188028895\n",
      "Loss: 0.25625987641223064\n",
      "Loss: 0.2298773265891261\n",
      "Loss: 0.20872441937268038\n",
      "______\n",
      "Iteration t=4\n",
      "all:  cs/acc_i=49.62 cs/acc_c=51.05 os/recall_knw=60.60 os/recall_unk=68.06 total/acc_i=48.61 total/acc_c=40.15 total/h_score=49.39\n",
      "selected:  cs/acc_i=48.28 cs/acc_c=50.11 os/recall_knw=55.59 os/recall_unk=74.55 total/acc_i=49.41 total/acc_c=38.19 total/h_score=48.89\n",
      "Loss: 2.337809408848711\n",
      "Loss: 0.863267071885192\n",
      "Loss: 0.5250798463821411\n",
      "Loss: 0.42835149787273646\n",
      "Loss: 0.3450026217214299\n",
      "Loss: 0.3050043308388643\n",
      "Loss: 0.276399164371718\n",
      "Loss: 0.23953761780224894\n",
      "Loss: 0.21367272428580833\n",
      "Loss: 0.19686919021037605\n",
      "______\n",
      "Iteration t=5\n",
      "all:  cs/acc_i=50.26 cs/acc_c=52.04 os/recall_knw=59.43 os/recall_unk=68.91 total/acc_i=48.54 total/acc_c=39.62 total/h_score=49.12\n",
      "selected:  cs/acc_i=49.35 cs/acc_c=51.62 os/recall_knw=57.63 os/recall_unk=71.10 total/acc_i=48.48 total/acc_c=38.77 total/h_score=48.80\n",
      "Loss: 2.3012434989213943\n",
      "Loss: 0.8342841019433352\n",
      "Loss: 0.48623198264789197\n",
      "Loss: 0.3940648566330633\n",
      "Loss: 0.33745910395537654\n",
      "Loss: 0.3056922865911357\n",
      "Loss: 0.2683306744382266\n",
      "Loss: 0.24311288196833863\n",
      "Loss: 0.21567591470516018\n",
      "Loss: 0.1845249037348455\n",
      "______\n",
      "Iteration t=6\n",
      "all:  cs/acc_i=50.87 cs/acc_c=52.42 os/recall_knw=59.32 os/recall_unk=68.91 total/acc_i=48.47 total/acc_c=39.51 total/h_score=49.02\n",
      "selected:  cs/acc_i=50.48 cs/acc_c=52.19 os/recall_knw=58.81 os/recall_unk=69.28 total/acc_i=48.30 total/acc_c=39.14 total/h_score=48.77\n",
      "Loss: 2.2759411372835676\n",
      "Loss: 0.8389955133436218\n",
      "Loss: 0.49039815904365647\n",
      "Loss: 0.3943549302657918\n",
      "Loss: 0.33476681788525886\n",
      "Loss: 0.2973470997715753\n",
      "Loss: 0.25806986782995484\n",
      "Loss: 0.24026396582346587\n",
      "Loss: 0.20860996422550035\n",
      "Loss: 0.1858462546508582\n",
      "______\n",
      "Iteration t=7\n",
      "all:  cs/acc_i=50.26 cs/acc_c=51.81 os/recall_knw=59.32 os/recall_unk=68.98 total/acc_i=48.49 total/acc_c=39.51 total/h_score=49.03\n",
      "selected:  cs/acc_i=50.21 cs/acc_c=51.77 os/recall_knw=59.27 os/recall_unk=69.02 total/acc_i=48.47 total/acc_c=39.46 total/h_score=49.00\n",
      "Loss: 2.2920074194316338\n",
      "Loss: 0.8302577869458632\n",
      "Loss: 0.5165987570766404\n",
      "Loss: 0.3875823366076579\n",
      "Loss: 0.32886911784353934\n",
      "Loss: 0.2898878752890783\n",
      "Loss: 0.2614024770795828\n",
      "Loss: 0.2188885436934445\n",
      "Loss: 0.21767656316634695\n",
      "Loss: 0.17924249861315777\n",
      "______\n",
      "Iteration t=8\n",
      "all:  cs/acc_i=50.64 cs/acc_c=52.29 os/recall_knw=59.32 os/recall_unk=68.98 total/acc_i=48.49 total/acc_c=39.51 total/h_score=49.03\n",
      "selected:  cs/acc_i=50.64 cs/acc_c=52.29 os/recall_knw=59.32 os/recall_unk=68.98 total/acc_i=48.49 total/acc_c=39.51 total/h_score=49.03\n",
      "Loss: 2.2891205139310933\n",
      "Loss: 0.8368848922695566\n",
      "Loss: 0.5059525059028105\n",
      "Loss: 0.3908345138308088\n",
      "Loss: 0.32579798699014273\n",
      "Loss: 0.3049321700579564\n",
      "Loss: 0.27123773654576816\n",
      "Loss: 0.23573794779864696\n",
      "Loss: 0.20887593213807454\n",
      "Loss: 0.18757572141383946\n",
      "______\n",
      "Iteration t=9\n",
      "all:  cs/acc_i=50.38 cs/acc_c=51.95 os/recall_knw=59.32 os/recall_unk=68.98 total/acc_i=48.49 total/acc_c=39.51 total/h_score=49.03\n",
      "selected:  cs/acc_i=50.38 cs/acc_c=51.95 os/recall_knw=59.32 os/recall_unk=68.98 total/acc_i=48.49 total/acc_c=39.51 total/h_score=49.03\n",
      "tensor(0)\n",
      "all:  cs/acc_i=50.38 cs/acc_c=51.95 os/recall_knw=59.32 os/recall_unk=68.98 total/acc_i=48.49 total/acc_c=39.51 total/h_score=49.03\n",
      "painting -> sketch lr= 0.001 seed= 3\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19]\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20]\n",
      "Loss: 2.559281372519397\n",
      "Loss: 1.2287024511862052\n",
      "Loss: 0.7317007644466622\n",
      "Loss: 0.5555807023294388\n",
      "Loss: 0.5076605450539362\n",
      "Loss: 0.42242088811422784\n",
      "Loss: 0.3826259314698517\n",
      "Loss: 0.3510699357305254\n",
      "Loss: 0.30365148801652214\n",
      "Loss: 0.288082973824607\n",
      "tensor(True) tensor(True)\n",
      "______\n",
      "Iteration t=1\n",
      "all:  cs/acc_i=50.72 cs/acc_c=51.97 os/recall_knw=93.81 os/recall_unk=16.56 total/acc_i=37.17 total/acc_c=48.72 total/h_score=24.92\n",
      "selected:  cs/acc_i=59.13 cs/acc_c=60.57 os/recall_knw=71.48 os/recall_unk=80.32 total/acc_i=61.69 total/acc_c=54.74 total/h_score=64.19\n",
      "Loss: 2.4735532899697623\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 1.053973794275639\n",
      "Loss: 0.6383561838199111\n",
      "Loss: 0.4825239023741554\n",
      "Loss: 0.41764359716691224\n",
      "Loss: 0.36435126129756956\n",
      "Loss: 0.3376537155652163\n",
      "Loss: 0.31094812594500243\n",
      "Loss: 0.2907656703655626\n",
      "Loss: 0.26059987828792897\n",
      "______\n",
      "Iteration t=2\n",
      "all:  cs/acc_i=51.09 cs/acc_c=52.55 os/recall_knw=65.92 os/recall_unk=64.01 total/acc_i=49.11 total/acc_c=43.01 total/h_score=50.69\n",
      "selected:  cs/acc_i=49.01 cs/acc_c=50.64 os/recall_knw=46.03 os/recall_unk=85.27 total/acc_i=53.83 total/acc_c=36.18 total/h_score=48.33\n",
      "Loss: 2.419768670830158\n",
      "Loss: 0.9737176080362513\n",
      "Loss: 0.5894018302953571\n",
      "Loss: 0.4795452101378266\n",
      "Loss: 0.39787495635244824\n",
      "Loss: 0.3366119257012092\n",
      "Loss: 0.3030413058031043\n",
      "Loss: 0.2655369353335385\n",
      "Loss: 0.24452268607367617\n",
      "Loss: 0.23520932449113338\n",
      "______\n",
      "Iteration t=3\n",
      "all:  cs/acc_i=50.91 cs/acc_c=52.58 os/recall_knw=61.77 os/recall_unk=67.47 total/acc_i=49.21 total/acc_c=41.36 total/h_score=50.27\n",
      "selected:  cs/acc_i=49.43 cs/acc_c=51.59 os/recall_knw=51.72 os/recall_unk=79.61 total/acc_i=51.40 total/acc_c=37.84 total/h_score=49.35\n",
      "Loss: 2.3551011973129206\n",
      "Loss: 0.8959180810750821\n",
      "Loss: 0.5462435443938036\n",
      "Loss: 0.42477030026448237\n",
      "Loss: 0.3731326356014132\n",
      "Loss: 0.3176776909337931\n",
      "Loss: 0.2876142980571175\n",
      "Loss: 0.24682270193641836\n",
      "Loss: 0.23689588768915695\n",
      "Loss: 0.206274955303638\n",
      "______\n",
      "Iteration t=4\n",
      "all:  cs/acc_i=51.02 cs/acc_c=52.64 os/recall_knw=60.15 os/recall_unk=69.70 total/acc_i=49.69 total/acc_c=40.94 total/h_score=50.43\n",
      "selected:  cs/acc_i=50.28 cs/acc_c=52.34 os/recall_knw=55.16 os/recall_unk=75.85 total/acc_i=50.76 total/acc_c=39.46 total/h_score=50.31\n",
      "Loss: 2.336315562327703\n",
      "Loss: 0.8798542520652215\n",
      "Loss: 0.5272176111117005\n",
      "Loss: 0.4047188291947047\n",
      "Loss: 0.33818642493958273\n",
      "Loss: 0.3001941763795912\n",
      "Loss: 0.27268199184909464\n",
      "Loss: 0.24616928404817978\n",
      "Loss: 0.21301123783923687\n",
      "Loss: 0.20133097044502696\n",
      "______\n",
      "Iteration t=5\n",
      "all:  cs/acc_i=51.13 cs/acc_c=52.85 os/recall_knw=59.66 os/recall_unk=70.09 total/acc_i=49.64 total/acc_c=40.66 total/h_score=50.27\n",
      "selected:  cs/acc_i=50.16 cs/acc_c=52.19 os/recall_knw=58.08 os/recall_unk=71.78 total/acc_i=49.43 total/acc_c=39.66 total/h_score=49.74\n",
      "Loss: 2.3170580133315055\n",
      "Loss: 0.8574294589700238\n",
      "Loss: 0.4961748873033831\n",
      "Loss: 0.41258665006006917\n",
      "Loss: 0.3285441007765551\n",
      "Loss: 0.2920267360525266\n",
      "Loss: 0.27855818230478513\n",
      "Loss: 0.23352527232359974\n",
      "Loss: 0.20934556798648932\n",
      "Loss: 0.20027982386490029\n",
      "______\n",
      "Iteration t=6\n",
      "all:  cs/acc_i=50.72 cs/acc_c=52.27 os/recall_knw=59.62 os/recall_unk=70.16 total/acc_i=49.64 total/acc_c=40.64 total/h_score=50.26\n",
      "selected:  cs/acc_i=50.25 cs/acc_c=51.97 os/recall_knw=59.18 os/recall_unk=70.71 total/acc_i=49.48 total/acc_c=40.25 total/h_score=50.04\n",
      "Loss: 2.293234794738283\n",
      "Loss: 0.8237241106441772\n",
      "Loss: 0.5006228827266579\n",
      "Loss: 0.39430919847640383\n",
      "Loss: 0.3482730865656617\n",
      "Loss: 0.30219431252652906\n",
      "Loss: 0.2662054028703397\n",
      "Loss: 0.24325930027372808\n",
      "Loss: 0.21011039300031395\n",
      "Loss: 0.19952335357072343\n",
      "______\n",
      "Iteration t=7\n",
      "all:  cs/acc_i=50.87 cs/acc_c=52.53 os/recall_knw=59.62 os/recall_unk=70.22 total/acc_i=49.66 total/acc_c=40.64 total/h_score=50.28\n",
      "selected:  cs/acc_i=50.78 cs/acc_c=52.47 os/recall_knw=59.52 os/recall_unk=70.31 total/acc_i=49.63 total/acc_c=40.56 total/h_score=50.23\n",
      "Loss: 2.2870269867162856\n",
      "Loss: 0.8322624309904991\n",
      "Loss: 0.49228028024709414\n",
      "Loss: 0.4075288987230687\n",
      "Loss: 0.32834118433178416\n",
      "Loss: 0.2956692709454468\n",
      "Loss: 0.2713117713315619\n",
      "Loss: 0.22747652800310225\n",
      "Loss: 0.21034737448725435\n",
      "Loss: 0.18741899013282762\n",
      "______\n",
      "Iteration t=8\n",
      "all:  cs/acc_i=51.28 cs/acc_c=52.87 os/recall_knw=59.62 os/recall_unk=70.22 total/acc_i=49.66 total/acc_c=40.64 total/h_score=50.28\n",
      "selected:  cs/acc_i=51.28 cs/acc_c=52.87 os/recall_knw=59.62 os/recall_unk=70.22 total/acc_i=49.66 total/acc_c=40.64 total/h_score=50.28\n",
      "Loss: 2.310277402636562\n",
      "Loss: 0.8321675785445413\n",
      "Loss: 0.49475391951238684\n",
      "Loss: 0.39850523785168945\n",
      "Loss: 0.3372145642051584\n",
      "Loss: 0.28714869389303116\n",
      "Loss: 0.2545802568346851\n",
      "Loss: 0.22654492621541966\n",
      "Loss: 0.2020863488669923\n",
      "Loss: 0.19983943968481227\n",
      "______\n",
      "Iteration t=9\n",
      "all:  cs/acc_i=51.70 cs/acc_c=53.25 os/recall_knw=59.62 os/recall_unk=70.22 total/acc_i=49.66 total/acc_c=40.64 total/h_score=50.28\n",
      "selected:  cs/acc_i=51.70 cs/acc_c=53.25 os/recall_knw=59.62 os/recall_unk=70.22 total/acc_i=49.66 total/acc_c=40.64 total/h_score=50.28\n",
      "tensor(0)\n",
      "all:  cs/acc_i=51.70 cs/acc_c=53.25 os/recall_knw=59.62 os/recall_unk=70.22 total/acc_i=49.66 total/acc_c=40.64 total/h_score=50.28\n",
      "painting -> sketch lr= 0.001 seed= 4\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19]\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20]\n",
      "Loss: 2.5840553770620356\n",
      "Loss: 1.2237796360853488\n",
      "Loss: 0.7482658487463755\n",
      "Loss: 0.5755815917537326\n",
      "Loss: 0.4885492592103898\n",
      "Loss: 0.4218252872821515\n",
      "Loss: 0.3950935697587079\n",
      "Loss: 0.35439022492479394\n",
      "Loss: 0.3091622264612289\n",
      "Loss: 0.2946784983945902\n",
      "tensor(True) tensor(True)\n",
      "______\n",
      "Iteration t=1\n",
      "all:  cs/acc_i=50.75 cs/acc_c=52.31 os/recall_knw=93.40 os/recall_unk=15.84 total/acc_i=36.84 total/acc_c=48.87 total/h_score=24.12\n",
      "selected:  cs/acc_i=59.52 cs/acc_c=61.91 os/recall_knw=69.72 os/recall_unk=77.07 total/acc_i=60.31 total/acc_c=54.87 total/h_score=63.34\n",
      "Loss: 2.480014789922565\n",
      "Loss: 1.0493492434422176\n",
      "Loss: 0.6305694252106488\n",
      "Loss: 0.5044847397389365\n",
      "Loss: 0.4350815470166066\n",
      "Loss: 0.3939860623841192\n",
      "Loss: 0.3410323310789524\n",
      "Loss: 0.302986055283862\n",
      "Loss: 0.2820034717373988\n",
      "Loss: 0.2417126604374133\n",
      "______\n",
      "Iteration t=2\n",
      "all:  cs/acc_i=50.75 cs/acc_c=52.36 os/recall_knw=65.62 os/recall_unk=60.60 total/acc_i=47.65 total/acc_c=42.49 total/h_score=49.32\n",
      "selected:  cs/acc_i=48.00 cs/acc_c=49.80 os/recall_knw=45.74 os/recall_unk=84.64 total/acc_i=52.36 total/acc_c=35.69 total/h_score=47.73\n",
      "Loss: 2.423106729437452\n",
      "Loss: 0.9981743933957651\n",
      "Loss: 0.5872208603888477\n",
      "Loss: 0.4680765339540779\n",
      "Loss: 0.3843693580102483\n",
      "Loss: 0.34907165692623604\n",
      "Loss: 0.30625489419069857\n",
      "Loss: 0.2781849081089737\n",
      "Loss: 0.23853550567676168\n",
      "Loss: 0.22995114015466575\n",
      "______\n",
      "Iteration t=3\n",
      "all:  cs/acc_i=50.19 cs/acc_c=51.70 os/recall_knw=58.38 os/recall_unk=69.11 total/acc_i=48.61 total/acc_c=39.56 total/h_score=49.11\n",
      "selected:  cs/acc_i=48.43 cs/acc_c=50.24 os/recall_knw=49.17 os/recall_unk=79.58 total/acc_i=50.10 total/acc_c=35.89 total/h_score=47.36\n",
      "Loss: 2.3559808132452367\n",
      "Loss: 0.9073064187904457\n",
      "Loss: 0.5534291597026767\n",
      "Loss: 0.42837065635692506\n",
      "Loss: 0.3685100217918297\n",
      "Loss: 0.31979977307252555\n",
      "Loss: 0.2856215573040954\n",
      "Loss: 0.25543846955998634\n",
      "Loss: 0.2276291535175466\n",
      "Loss: 0.19852259505169217\n",
      "______\n",
      "Iteration t=4\n",
      "all:  cs/acc_i=49.36 cs/acc_c=50.99 os/recall_knw=58.00 os/recall_unk=69.63 total/acc_i=48.71 total/acc_c=39.45 total/h_score=49.12\n",
      "selected:  cs/acc_i=47.50 cs/acc_c=49.57 os/recall_knw=53.25 os/recall_unk=75.57 total/acc_i=49.04 total/acc_c=37.12 total/h_score=48.02\n",
      "Loss: 2.3273610794394584\n",
      "Loss: 0.8584439275653791\n",
      "Loss: 0.5211412974605999\n",
      "Loss: 0.4164185651176644\n",
      "Loss: 0.35775512837216444\n",
      "Loss: 0.3023437796215133\n",
      "Loss: 0.2813488122184905\n",
      "Loss: 0.24876248202126894\n",
      "Loss: 0.21498585195440378\n",
      "Loss: 0.20478633922138972\n",
      "______\n",
      "Iteration t=5\n",
      "all:  cs/acc_i=50.75 cs/acc_c=52.35 os/recall_knw=57.81 os/recall_unk=69.76 total/acc_i=48.76 total/acc_c=39.45 total/h_score=49.15\n",
      "selected:  cs/acc_i=49.90 cs/acc_c=51.83 os/recall_knw=55.93 os/recall_unk=72.32 total/acc_i=48.82 total/acc_c=38.53 total/h_score=48.82\n",
      "Loss: 2.310237909720196\n",
      "Loss: 0.8266120915248142\n",
      "Loss: 0.5172215018088255\n",
      "Loss: 0.40399999116978996\n",
      "Loss: 0.34779497611571136\n",
      "Loss: 0.2850709750309465\n",
      "Loss: 0.26017393654863524\n",
      "Loss: 0.2436901134234376\n",
      "Loss: 0.21641916999729668\n",
      "Loss: 0.19292723441996226\n",
      "______\n",
      "Iteration t=6\n",
      "all:  cs/acc_i=50.87 cs/acc_c=52.45 os/recall_knw=57.58 os/recall_unk=70.03 total/acc_i=48.76 total/acc_c=39.32 total/h_score=49.08\n",
      "selected:  cs/acc_i=50.55 cs/acc_c=52.26 os/recall_knw=57.25 os/recall_unk=70.39 total/acc_i=48.64 total/acc_c=39.07 total/h_score=48.94\n",
      "Loss: 2.2985331196784973\n",
      "Loss: 0.8458789047002793\n",
      "Loss: 0.5144252431988716\n",
      "Loss: 0.40538831597566605\n",
      "Loss: 0.32880869662761686\n",
      "Loss: 0.2876614526510239\n",
      "Loss: 0.26949170273542405\n",
      "Loss: 0.2519372149258852\n",
      "Loss: 0.21943381437659262\n",
      "Loss: 0.18547114410996438\n",
      "______\n",
      "Iteration t=7\n",
      "all:  cs/acc_i=51.32 cs/acc_c=52.89 os/recall_knw=57.58 os/recall_unk=70.03 total/acc_i=48.76 total/acc_c=39.32 total/h_score=49.08\n",
      "selected:  cs/acc_i=51.32 cs/acc_c=52.89 os/recall_knw=57.58 os/recall_unk=70.03 total/acc_i=48.76 total/acc_c=39.32 total/h_score=49.08\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 2.30148971270755\n",
      "Loss: 0.8292469562762287\n",
      "Loss: 0.5240442064178892\n",
      "Loss: 0.38935063286606536\n",
      "Loss: 0.32923208663900533\n",
      "Loss: 0.2788081255507659\n",
      "Loss: 0.26206825461342514\n",
      "Loss: 0.22687526519198817\n",
      "Loss: 0.22941539725993734\n",
      "Loss: 0.1921249508145321\n",
      "______\n",
      "Iteration t=8\n",
      "all:  cs/acc_i=50.45 cs/acc_c=52.14 os/recall_knw=57.58 os/recall_unk=70.03 total/acc_i=48.76 total/acc_c=39.32 total/h_score=49.08\n",
      "selected:  cs/acc_i=50.45 cs/acc_c=52.14 os/recall_knw=57.58 os/recall_unk=70.03 total/acc_i=48.76 total/acc_c=39.32 total/h_score=49.08\n",
      "Loss: 2.301852303434653\n",
      "Loss: 0.8259137815450767\n",
      "Loss: 0.4998835156638309\n",
      "Loss: 0.4021817652055942\n",
      "Loss: 0.3268264917382206\n",
      "Loss: 0.2970372977187909\n",
      "Loss: 0.27160371284917056\n",
      "Loss: 0.21796611846383823\n",
      "Loss: 0.20975740963363076\n",
      "Loss: 0.19640479555939774\n",
      "______\n",
      "Iteration t=9\n",
      "all:  cs/acc_i=51.06 cs/acc_c=52.63 os/recall_knw=57.58 os/recall_unk=70.03 total/acc_i=48.76 total/acc_c=39.32 total/h_score=49.08\n",
      "selected:  cs/acc_i=51.06 cs/acc_c=52.63 os/recall_knw=57.58 os/recall_unk=70.03 total/acc_i=48.76 total/acc_c=39.32 total/h_score=49.08\n",
      "tensor(0)\n",
      "all:  cs/acc_i=51.06 cs/acc_c=52.63 os/recall_knw=57.58 os/recall_unk=70.03 total/acc_i=48.76 total/acc_c=39.32 total/h_score=49.08\n",
      "painting -> sketch lr= 0.001 seed= 0\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19]\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20]\n",
      "Loss: 2.5638115929548073\n",
      "Loss: 1.2401268567357744\n",
      "Loss: 0.7377197827611651\n",
      "Loss: 0.5635843721647111\n",
      "Loss: 0.49965413726826824\n",
      "Loss: 0.4291945453043337\n",
      "Loss: 0.3864954619338273\n",
      "Loss: 0.3561507217073567\n",
      "Loss: 0.32947712265467516\n",
      "Loss: 0.27496728230090367\n",
      "tensor(True) tensor(True)\n",
      "______\n",
      "Iteration t=1\n",
      "all:  cs/acc_i=51.58 cs/acc_c=53.09 os/recall_knw=94.42 os/recall_unk=17.60 total/acc_i=38.42 total/acc_c=50.32 total/h_score=26.30\n",
      "selected:  cs/acc_i=62.16 cs/acc_c=63.47 os/recall_knw=73.33 os/recall_unk=80.54 total/acc_i=65.58 total/acc_c=59.24 total/h_score=67.56\n",
      "Loss: 2.4847358915151334\n",
      "Loss: 1.081217719497634\n",
      "Loss: 0.6372438574246332\n",
      "Loss: 0.5043233931064606\n",
      "Loss: 0.4321428600187395\n",
      "Loss: 0.3957475095476006\n",
      "Loss: 0.3413979514848952\n",
      "Loss: 0.30408602719213446\n",
      "Loss: 0.2792159327689339\n",
      "Loss: 0.2458086313095455\n",
      "______\n",
      "Iteration t=2\n",
      "all:  cs/acc_i=50.23 cs/acc_c=51.93 os/recall_knw=65.85 os/recall_unk=61.71 total/acc_i=48.11 total/acc_c=42.68 total/h_score=49.79\n",
      "selected:  cs/acc_i=47.32 cs/acc_c=49.37 os/recall_knw=46.00 os/recall_unk=84.88 total/acc_i=52.82 total/acc_c=35.79 total/h_score=47.87\n",
      "Loss: 2.4288726006079155\n",
      "Loss: 0.9646616989592893\n",
      "Loss: 0.5750449084497373\n",
      "Loss: 0.4680879988938297\n",
      "Loss: 0.3881340666306675\n",
      "Loss: 0.34842484034256105\n",
      "Loss: 0.3153250274000638\n",
      "Loss: 0.28177446188456423\n",
      "Loss: 0.25429902570920254\n",
      "Loss: 0.2343418805971058\n",
      "______\n",
      "Iteration t=3\n",
      "all:  cs/acc_i=50.15 cs/acc_c=51.73 os/recall_knw=62.87 os/recall_unk=65.12 total/acc_i=48.59 total/acc_c=41.59 total/h_score=49.88\n",
      "selected:  cs/acc_i=48.06 cs/acc_c=49.88 os/recall_knw=52.37 os/recall_unk=78.78 total/acc_i=50.89 total/acc_c=37.68 total/h_score=49.07\n",
      "Loss: 2.3658069005776277\n",
      "Loss: 0.9158841908236086\n",
      "Loss: 0.5423462321231891\n",
      "Loss: 0.43468929472423734\n",
      "Loss: 0.3567990336841319\n",
      "Loss: 0.32486374173071475\n",
      "Loss: 0.29027960494612204\n",
      "Loss: 0.2612403129021843\n",
      "Loss: 0.23141879762534973\n",
      "Loss: 0.20356749796441623\n",
      "______\n",
      "Iteration t=4\n",
      "all:  cs/acc_i=50.26 cs/acc_c=51.88 os/recall_knw=60.98 os/recall_unk=67.93 total/acc_i=49.09 total/acc_c=40.87 total/h_score=49.97\n",
      "selected:  cs/acc_i=48.87 cs/acc_c=50.94 os/recall_knw=55.79 os/recall_unk=73.83 total/acc_i=49.72 total/acc_c=38.82 total/h_score=49.35\n",
      "Loss: 2.311053372517661\n",
      "Loss: 0.8600468941001971\n",
      "Loss: 0.5099224250964604\n",
      "Loss: 0.4010360475892348\n",
      "Loss: 0.34100628233054864\n",
      "Loss: 0.30302340101404307\n",
      "Loss: 0.26696951232881466\n",
      "Loss: 0.24064607490085962\n",
      "Loss: 0.2243563600533731\n",
      "Loss: 0.19770083262650798\n",
      "______\n",
      "Iteration t=5\n",
      "all:  cs/acc_i=49.92 cs/acc_c=51.44 os/recall_knw=60.38 os/recall_unk=68.32 total/acc_i=48.95 total/acc_c=40.44 total/h_score=49.69\n",
      "selected:  cs/acc_i=48.56 cs/acc_c=50.50 os/recall_knw=58.48 os/recall_unk=69.88 total/acc_i=48.47 total/acc_c=39.13 total/h_score=48.89\n",
      "Loss: 2.3106619603183853\n",
      "Loss: 0.8489026940730681\n",
      "Loss: 0.5220568913771925\n",
      "Loss: 0.3982413242380303\n",
      "Loss: 0.33792086310654756\n",
      "Loss: 0.2836933324195774\n",
      "Loss: 0.257884494631166\n",
      "Loss: 0.2314428345685503\n",
      "Loss: 0.2153698051101472\n",
      "Loss: 0.20576671092026683\n",
      "______\n",
      "Iteration t=6\n",
      "all:  cs/acc_i=50.15 cs/acc_c=51.65 os/recall_knw=60.30 os/recall_unk=68.39 total/acc_i=48.97 total/acc_c=40.44 total/h_score=49.71\n",
      "selected:  cs/acc_i=49.83 cs/acc_c=51.53 os/recall_knw=59.83 os/recall_unk=68.75 total/acc_i=48.85 total/acc_c=40.20 total/h_score=49.58\n",
      "Loss: 2.2780679695219863\n",
      "Loss: 0.8065085411071777\n",
      "Loss: 0.4962978707000672\n",
      "Loss: 0.3939189738317912\n",
      "Loss: 0.3342045063498934\n",
      "Loss: 0.2929845170482345\n",
      "Loss: 0.26073418731392606\n",
      "Loss: 0.23256303822040086\n",
      "Loss: 0.20941092497982056\n",
      "Loss: 0.18716914599886525\n",
      "______\n",
      "Iteration t=7\n",
      "all:  cs/acc_i=50.64 cs/acc_c=52.19 os/recall_knw=60.30 os/recall_unk=68.39 total/acc_i=48.97 total/acc_c=40.44 total/h_score=49.71\n",
      "selected:  cs/acc_i=50.59 cs/acc_c=52.17 os/recall_knw=60.23 os/recall_unk=68.52 total/acc_i=48.97 total/acc_c=40.41 total/h_score=49.71\n",
      "Loss: 2.280010063347854\n",
      "Loss: 0.8148403114925219\n",
      "Loss: 0.5058015641265028\n",
      "Loss: 0.3954175273616483\n",
      "Loss: 0.3403678504148806\n",
      "Loss: 0.28553432930172895\n",
      "Loss: 0.24880146651756108\n",
      "Loss: 0.22593133821790143\n",
      "Loss: 0.19612950850718133\n",
      "Loss: 0.19917021221004602\n",
      "______\n",
      "Iteration t=8\n",
      "all:  cs/acc_i=50.64 cs/acc_c=52.33 os/recall_knw=60.30 os/recall_unk=68.39 total/acc_i=48.97 total/acc_c=40.44 total/h_score=49.71\n",
      "selected:  cs/acc_i=50.64 cs/acc_c=52.33 os/recall_knw=60.30 os/recall_unk=68.39 total/acc_i=48.97 total/acc_c=40.44 total/h_score=49.71\n",
      "Loss: 2.2781259675664227\n",
      "Loss: 0.814962445046958\n",
      "Loss: 0.49992843171742957\n",
      "Loss: 0.3847114055996805\n",
      "Loss: 0.3306966520493894\n",
      "Loss: 0.28062725351668716\n",
      "Loss: 0.27404816498554596\n",
      "Loss: 0.245922881831217\n",
      "Loss: 0.2054721835531353\n",
      "Loss: 0.18856776442642756\n",
      "______\n",
      "Iteration t=9\n",
      "all:  cs/acc_i=50.11 cs/acc_c=51.80 os/recall_knw=60.30 os/recall_unk=68.39 total/acc_i=48.97 total/acc_c=40.44 total/h_score=49.71\n",
      "selected:  cs/acc_i=50.11 cs/acc_c=51.80 os/recall_knw=60.30 os/recall_unk=68.39 total/acc_i=48.97 total/acc_c=40.44 total/h_score=49.71\n",
      "tensor(0)\n",
      "all:  cs/acc_i=50.11 cs/acc_c=51.80 os/recall_knw=60.30 os/recall_unk=68.39 total/acc_i=48.97 total/acc_c=40.44 total/h_score=49.71\n",
      "painting -> sketch lr= 0.001 seed= 1\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19]\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20]\n",
      "Loss: 2.5579803746844094\n",
      "Loss: 1.192579170698842\n",
      "Loss: 0.7541898749177418\n",
      "Loss: 0.5751834104143122\n",
      "Loss: 0.4934751381949773\n",
      "Loss: 0.43055586272446567\n",
      "Loss: 0.3774884951020044\n",
      "Loss: 0.33713330911896217\n",
      "Loss: 0.313660570001476\n",
      "Loss: 0.29521354145946954\n",
      "tensor(True) tensor(True)\n",
      "______\n",
      "Iteration t=1\n",
      "all:  cs/acc_i=49.81 cs/acc_c=51.23 os/recall_knw=92.94 os/recall_unk=15.05 total/acc_i=36.14 total/acc_c=48.12 total/h_score=23.11\n",
      "selected:  cs/acc_i=55.08 cs/acc_c=55.64 os/recall_knw=68.31 os/recall_unk=76.16 total/acc_i=57.74 total/acc_c=50.75 total/h_score=59.99\n",
      "Loss: 2.466896306650311\n",
      "Loss: 1.0444192699357575\n",
      "Loss: 0.6273651589073387\n",
      "Loss: 0.47397824427952956\n",
      "Loss: 0.41296377690399394\n",
      "Loss: 0.3746817830730887\n",
      "Loss: 0.34662384569060567\n",
      "Loss: 0.30978341974025847\n",
      "Loss: 0.2632405406740658\n",
      "Loss: 0.2563603363712044\n",
      "______\n",
      "Iteration t=2\n",
      "all:  cs/acc_i=51.21 cs/acc_c=52.82 os/recall_knw=61.06 os/recall_unk=67.47 total/acc_i=49.43 total/acc_c=41.73 total/h_score=50.57\n",
      "selected:  cs/acc_i=47.92 cs/acc_c=49.63 os/recall_knw=42.70 os/recall_unk=85.85 total/acc_i=52.33 total/acc_c=34.23 total/h_score=46.25\n",
      "Loss: 2.4161061436758127\n",
      "Loss: 0.9891795010194866\n",
      "Loss: 0.5565808496070564\n",
      "Loss: 0.4486030610534576\n",
      "Loss: 0.38452823924908947\n",
      "Loss: 0.3509612240649145\n",
      "Loss: 0.3191674675348155\n",
      "Loss: 0.27703397560420384\n",
      "Loss: 0.24073401910312678\n",
      "Loss: 0.2443908052775291\n",
      "______\n",
      "Iteration t=3\n",
      "all:  cs/acc_i=50.94 cs/acc_c=52.48 os/recall_knw=56.26 os/recall_unk=73.63 total/acc_i=50.17 total/acc_c=39.68 total/h_score=50.11\n",
      "selected:  cs/acc_i=48.66 cs/acc_c=50.61 os/recall_knw=48.21 os/recall_unk=81.58 total/acc_i=50.73 total/acc_c=35.84 total/h_score=47.55\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 2.3604359270690325\n",
      "Loss: 0.8931303446169023\n",
      "Loss: 0.5361167096988463\n",
      "Loss: 0.44004737927671117\n",
      "Loss: 0.35809902308178154\n",
      "Loss: 0.3172650226589405\n",
      "Loss: 0.2831554764083454\n",
      "Loss: 0.263930600571942\n",
      "Loss: 0.23675711993208695\n",
      "Loss: 0.20705559530428477\n",
      "______\n",
      "Iteration t=4\n",
      "all:  cs/acc_i=49.89 cs/acc_c=51.46 os/recall_knw=55.81 os/recall_unk=73.89 total/acc_i=50.05 total/acc_c=39.36 total/h_score=49.87\n",
      "selected:  cs/acc_i=47.47 cs/acc_c=49.41 os/recall_knw=51.87 os/recall_unk=77.01 total/acc_i=49.35 total/acc_c=36.52 total/h_score=47.65\n",
      "Loss: 2.3448159330559575\n",
      "Loss: 0.8845957248280737\n",
      "Loss: 0.5223249349135235\n",
      "Loss: 0.4009253408245462\n",
      "Loss: 0.3409267184499916\n",
      "Loss: 0.31828785534932524\n",
      "Loss: 0.25917279904232865\n",
      "Loss: 0.2672267162930766\n",
      "Loss: 0.2292583823889868\n",
      "Loss: 0.20797931772333308\n",
      "______\n",
      "Iteration t=5\n",
      "all:  cs/acc_i=49.89 cs/acc_c=51.39 os/recall_knw=55.74 os/recall_unk=73.95 total/acc_i=50.05 total/acc_c=39.33 total/h_score=49.85\n",
      "selected:  cs/acc_i=48.40 cs/acc_c=50.31 os/recall_knw=54.22 os/recall_unk=74.98 total/acc_i=49.37 total/acc_c=37.95 total/h_score=48.74\n",
      "Loss: 2.326192990189693\n",
      "Loss: 0.8596630946534579\n",
      "Loss: 0.5045612815950737\n",
      "Loss: 0.4128621975417997\n",
      "Loss: 0.349810248149223\n",
      "Loss: 0.30915785055668626\n",
      "Loss: 0.2694169877127546\n",
      "Loss: 0.23909862637214485\n",
      "Loss: 0.22581297869137565\n",
      "Loss: 0.20219783437606254\n",
      "______\n",
      "Iteration t=6\n",
      "all:  cs/acc_i=51.43 cs/acc_c=53.16 os/recall_knw=55.70 os/recall_unk=73.95 total/acc_i=50.05 total/acc_c=39.33 total/h_score=49.85\n",
      "selected:  cs/acc_i=50.99 cs/acc_c=52.87 os/recall_knw=55.26 os/recall_unk=74.44 total/acc_i=49.88 total/acc_c=38.97 total/h_score=49.60\n",
      "Loss: 2.2969023061961664\n",
      "Loss: 0.8317381910434584\n",
      "Loss: 0.49940896512773947\n",
      "Loss: 0.4179894185163141\n",
      "Loss: 0.35917999559059377\n",
      "Loss: 0.29172971357053856\n",
      "Loss: 0.26809868006020543\n",
      "Loss: 0.24350305767805597\n",
      "Loss: 0.20602519787484552\n",
      "Loss: 0.20557792415100384\n",
      "______\n",
      "Iteration t=7\n",
      "all:  cs/acc_i=51.09 cs/acc_c=52.63 os/recall_knw=55.70 os/recall_unk=74.02 total/acc_i=50.07 total/acc_c=39.33 total/h_score=49.87\n",
      "selected:  cs/acc_i=51.04 cs/acc_c=52.59 os/recall_knw=55.65 os/recall_unk=74.02 total/acc_i=50.04 total/acc_c=39.29 total/h_score=49.82\n",
      "Loss: 2.296529016996685\n",
      "Loss: 0.856611719739582\n",
      "Loss: 0.5146916112919085\n",
      "Loss: 0.39790029160165596\n",
      "Loss: 0.3424223897307508\n",
      "Loss: 0.29358496366121506\n",
      "Loss: 0.2668910101056099\n",
      "Loss: 0.23775838390897644\n",
      "Loss: 0.2245679760449811\n",
      "Loss: 0.20603873684761012\n",
      "______\n",
      "Iteration t=8\n",
      "all:  cs/acc_i=52.34 cs/acc_c=53.99 os/recall_knw=55.70 os/recall_unk=74.02 total/acc_i=50.07 total/acc_c=39.33 total/h_score=49.87\n",
      "selected:  cs/acc_i=52.34 cs/acc_c=53.99 os/recall_knw=55.70 os/recall_unk=74.02 total/acc_i=50.07 total/acc_c=39.33 total/h_score=49.87\n",
      "Loss: 2.303624988563599\n",
      "Loss: 0.8352032999598211\n",
      "Loss: 0.5076619233455388\n",
      "Loss: 0.39746564127985506\n",
      "Loss: 0.3355545935731742\n",
      "Loss: 0.2941854242535849\n",
      "Loss: 0.2835211339256456\n",
      "Loss: 0.23052411822361812\n",
      "Loss: 0.22311961436043343\n",
      "Loss: 0.19024311883314962\n",
      "______\n",
      "Iteration t=9\n",
      "all:  cs/acc_i=51.25 cs/acc_c=52.92 os/recall_knw=55.70 os/recall_unk=74.02 total/acc_i=50.07 total/acc_c=39.33 total/h_score=49.87\n",
      "selected:  cs/acc_i=51.25 cs/acc_c=52.92 os/recall_knw=55.70 os/recall_unk=74.02 total/acc_i=50.07 total/acc_c=39.33 total/h_score=49.87\n",
      "tensor(0)\n",
      "all:  cs/acc_i=51.25 cs/acc_c=52.92 os/recall_knw=55.70 os/recall_unk=74.02 total/acc_i=50.07 total/acc_c=39.33 total/h_score=49.87\n",
      "painting -> sketch lr= 0.001 seed= 2\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19]\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20]\n",
      "Loss: 2.5671704238053983\n",
      "Loss: 1.2368916907007732\n",
      "Loss: 0.7059576874056821\n",
      "Loss: 0.5781367708135534\n",
      "Loss: 0.4752812090689543\n",
      "Loss: 0.4222791156677342\n",
      "Loss: 0.37875047322145844\n",
      "Loss: 0.3436401591256813\n",
      "Loss: 0.3023128983362642\n",
      "Loss: 0.284940596807886\n",
      "tensor(True) tensor(True)\n",
      "______\n",
      "Iteration t=1\n",
      "all:  cs/acc_i=50.34 cs/acc_c=51.98 os/recall_knw=93.77 os/recall_unk=16.49 total/acc_i=36.91 total/acc_c=48.70 total/h_score=24.84\n",
      "selected:  cs/acc_i=57.75 cs/acc_c=59.91 os/recall_knw=70.95 os/recall_unk=79.00 total/acc_i=60.43 total/acc_c=53.02 total/h_score=62.51\n",
      "Loss: 2.467523277974596\n",
      "Loss: 1.073165130089311\n",
      "Loss: 0.6443601142542035\n",
      "Loss: 0.5091257476631332\n",
      "Loss: 0.43862000735951406\n",
      "Loss: 0.38803739107999147\n",
      "Loss: 0.3370723680903514\n",
      "Loss: 0.30604174703943965\n",
      "Loss: 0.2823630061146675\n",
      "Loss: 0.2554392836184478\n",
      "______\n",
      "Iteration t=2\n",
      "all:  cs/acc_i=50.30 cs/acc_c=51.91 os/recall_knw=62.64 os/recall_unk=68.59 total/acc_i=49.90 total/acc_c=41.93 total/h_score=51.00\n",
      "selected:  cs/acc_i=47.57 cs/acc_c=49.08 os/recall_knw=44.00 os/recall_unk=86.83 total/acc_i=53.55 total/acc_c=34.95 total/h_score=47.14\n",
      "Loss: 2.4204451452701465\n",
      "Loss: 0.9793562694973902\n",
      "Loss: 0.5786840267684481\n",
      "Loss: 0.4644480544492739\n",
      "Loss: 0.39063847444336347\n",
      "Loss: 0.34191440216718466\n",
      "Loss: 0.312916897032239\n",
      "Loss: 0.27618417852993954\n",
      "Loss: 0.25688526928083066\n",
      "Loss: 0.230083215810837\n",
      "______\n",
      "Iteration t=3\n",
      "all:  cs/acc_i=50.00 cs/acc_c=51.57 os/recall_knw=61.02 os/recall_unk=70.03 total/acc_i=50.02 total/acc_c=41.36 total/h_score=50.86\n",
      "selected:  cs/acc_i=48.07 cs/acc_c=49.75 os/recall_knw=50.83 os/recall_unk=81.62 total/acc_i=52.02 total/acc_c=37.55 total/h_score=49.32\n",
      "Loss: 2.3673872755921406\n",
      "Loss: 0.9145726595235908\n",
      "Loss: 0.5355629746032797\n",
      "Loss: 0.4268734416883925\n",
      "Loss: 0.36456483903786413\n",
      "Loss: 0.33477629507365436\n",
      "Loss: 0.28965749199623647\n",
      "Loss: 0.2543573423086301\n",
      "Loss: 0.2309379927975976\n",
      "Loss: 0.21679341362222382\n",
      "______\n",
      "Iteration t=4\n",
      "all:  cs/acc_i=50.49 cs/acc_c=52.05 os/recall_knw=59.40 os/recall_unk=71.47 total/acc_i=50.05 total/acc_c=40.64 total/h_score=50.55\n",
      "selected:  cs/acc_i=48.87 cs/acc_c=50.85 os/recall_knw=55.05 os/recall_unk=76.20 total/acc_i=50.25 total/acc_c=38.48 total/h_score=49.45\n",
      "Loss: 2.311442180787874\n",
      "Loss: 0.8253465155100921\n",
      "Loss: 0.5211467365135296\n",
      "Loss: 0.41568200967247554\n",
      "Loss: 0.3412257361523343\n",
      "Loss: 0.3125353737799953\n",
      "Loss: 0.26859366791747913\n",
      "Loss: 0.24818384968888216\n",
      "Loss: 0.21402777472503204\n",
      "Loss: 0.20246377568769258\n",
      "______\n",
      "Iteration t=5\n",
      "all:  cs/acc_i=50.79 cs/acc_c=52.59 os/recall_knw=59.13 os/recall_unk=71.99 total/acc_i=50.12 total/acc_c=40.50 total/h_score=50.53\n",
      "selected:  cs/acc_i=49.82 cs/acc_c=51.98 os/recall_knw=57.18 os/recall_unk=73.58 total/acc_i=49.90 total/acc_c=39.44 total/h_score=49.88\n",
      "Loss: 2.2908526876194757\n",
      "Loss: 0.819940145561087\n",
      "Loss: 0.48572337072387883\n",
      "Loss: 0.41761701107628435\n",
      "Loss: 0.3598169592107356\n",
      "Loss: 0.2967559726916344\n",
      "Loss: 0.2792738356932937\n",
      "Loss: 0.24555523304442162\n",
      "Loss: 0.20460301421974836\n",
      "Loss: 0.1858688324146908\n",
      "______\n",
      "Iteration t=6\n",
      "all:  cs/acc_i=50.64 cs/acc_c=52.19 os/recall_knw=59.06 os/recall_unk=71.99 total/acc_i=50.10 total/acc_c=40.47 total/h_score=50.50\n",
      "selected:  cs/acc_i=50.19 cs/acc_c=51.95 os/recall_knw=58.46 os/recall_unk=72.37 total/acc_i=49.90 total/acc_c=40.09 total/h_score=50.24\n",
      "Loss: 2.2843810334205625\n",
      "Loss: 0.8260442538261413\n",
      "Loss: 0.49404284012317656\n",
      "Loss: 0.39794511246681213\n",
      "Loss: 0.3352123386263847\n",
      "Loss: 0.29241757917404176\n",
      "Loss: 0.2653007501512766\n",
      "Loss: 0.22151700867712498\n",
      "Loss: 0.20937296362221242\n",
      "Loss: 0.19202603590488435\n",
      "______\n",
      "Iteration t=7\n",
      "all:  cs/acc_i=50.26 cs/acc_c=51.86 os/recall_knw=59.02 os/recall_unk=71.99 total/acc_i=50.10 total/acc_c=40.47 total/h_score=50.50\n",
      "selected:  cs/acc_i=50.23 cs/acc_c=51.83 os/recall_knw=58.99 os/recall_unk=71.99 total/acc_i=50.07 total/acc_c=40.43 total/h_score=50.47\n",
      "Loss: 2.280515477476842\n",
      "Loss: 0.826226946485945\n",
      "Loss: 0.5030153808721983\n",
      "Loss: 0.3948390382041494\n",
      "Loss: 0.341968685536983\n",
      "Loss: 0.30381012138023794\n",
      "Loss: 0.2687582625187488\n",
      "Loss: 0.23008333878272558\n",
      "Loss: 0.2222122743992929\n",
      "Loss: 0.2071181139741761\n",
      "______\n",
      "Iteration t=8\n",
      "all:  cs/acc_i=50.72 cs/acc_c=52.46 os/recall_knw=59.02 os/recall_unk=71.99 total/acc_i=50.10 total/acc_c=40.47 total/h_score=50.50\n",
      "selected:  cs/acc_i=50.72 cs/acc_c=52.46 os/recall_knw=59.02 os/recall_unk=71.99 total/acc_i=50.10 total/acc_c=40.47 total/h_score=50.50\n",
      "Loss: 2.3149321763164017\n",
      "Loss: 0.8382338201144777\n",
      "Loss: 0.5057754299317698\n",
      "Loss: 0.4014360153105154\n",
      "Loss: 0.32821073400903034\n",
      "Loss: 0.2985748696730906\n",
      "Loss: 0.254586123790874\n",
      "Loss: 0.23318067525487496\n",
      "Loss: 0.21650335867981987\n",
      "Loss: 0.1837682302937327\n",
      "______\n",
      "Iteration t=9\n",
      "all:  cs/acc_i=51.02 cs/acc_c=52.83 os/recall_knw=59.02 os/recall_unk=71.99 total/acc_i=50.10 total/acc_c=40.47 total/h_score=50.50\n",
      "selected:  cs/acc_i=51.02 cs/acc_c=52.83 os/recall_knw=59.02 os/recall_unk=71.99 total/acc_i=50.10 total/acc_c=40.47 total/h_score=50.50\n",
      "tensor(0)\n",
      "all:  cs/acc_i=51.02 cs/acc_c=52.83 os/recall_knw=59.02 os/recall_unk=71.99 total/acc_i=50.10 total/acc_c=40.47 total/h_score=50.50\n",
      "painting -> sketch lr= 0.001 seed= 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19]\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20]\n",
      "Loss: 2.5592495373317172\n",
      "Loss: 1.22829593016357\n",
      "Loss: 0.7313372197920683\n",
      "Loss: 0.5557754443436073\n",
      "Loss: 0.5082891309072101\n",
      "Loss: 0.42276810898036554\n",
      "Loss: 0.38351779356204646\n",
      "Loss: 0.35219004182588487\n",
      "Loss: 0.3047249781943503\n",
      "Loss: 0.28878488750369463\n",
      "tensor(True) tensor(True)\n",
      "______\n",
      "Iteration t=1\n",
      "all:  cs/acc_i=50.15 cs/acc_c=51.43 os/recall_knw=93.55 os/recall_unk=16.10 total/acc_i=36.84 total/acc_c=48.43 total/h_score=24.36\n",
      "selected:  cs/acc_i=56.83 cs/acc_c=58.49 os/recall_knw=70.82 os/recall_unk=80.66 total/acc_i=60.94 total/acc_c=53.65 total/h_score=63.45\n",
      "Loss: 2.4845438219752967\n",
      "Loss: 1.0473455136605339\n",
      "Loss: 0.6353871106517082\n",
      "Loss: 0.4999825548307568\n",
      "Loss: 0.42151569392459065\n",
      "Loss: 0.3730839365253262\n",
      "Loss: 0.33394753242678504\n",
      "Loss: 0.29713553489715444\n",
      "Loss: 0.2786844521395716\n",
      "Loss: 0.24508883619644478\n",
      "______\n",
      "Iteration t=2\n",
      "all:  cs/acc_i=51.28 cs/acc_c=52.88 os/recall_knw=65.92 os/recall_unk=61.85 total/acc_i=48.59 total/acc_c=43.33 total/h_score=50.31\n",
      "selected:  cs/acc_i=48.68 cs/acc_c=50.61 os/recall_knw=45.93 os/recall_unk=84.91 total/acc_i=53.32 total/acc_c=36.38 total/h_score=48.50\n",
      "Loss: 2.4186975529434482\n",
      "Loss: 0.9682429933219875\n",
      "Loss: 0.6057615299290473\n",
      "Loss: 0.447825559372202\n",
      "Loss: 0.3932166781720765\n",
      "Loss: 0.3347919793850785\n",
      "Loss: 0.3028630452965378\n",
      "Loss: 0.264224718743508\n",
      "Loss: 0.2683724523137469\n",
      "Loss: 0.2302632014002275\n",
      "______\n",
      "Iteration t=3\n",
      "all:  cs/acc_i=50.38 cs/acc_c=51.97 os/recall_knw=63.09 os/recall_unk=64.92 total/acc_i=48.61 total/acc_c=41.79 total/h_score=49.98\n",
      "selected:  cs/acc_i=48.21 cs/acc_c=50.17 os/recall_knw=52.57 os/recall_unk=78.86 total/acc_i=50.90 total/acc_c=37.77 total/h_score=49.16\n",
      "Loss: 2.36258145947477\n",
      "Loss: 0.9126538249837371\n",
      "Loss: 0.5591676891237111\n",
      "Loss: 0.422360305662279\n",
      "Loss: 0.37357527756200726\n",
      "Loss: 0.3104908778231381\n",
      "Loss: 0.27867482367145036\n",
      "Loss: 0.24313492552091032\n",
      "Loss: 0.24226207149041679\n",
      "Loss: 0.20534587058025006\n",
      "______\n",
      "Iteration t=4\n",
      "all:  cs/acc_i=50.34 cs/acc_c=51.89 os/recall_knw=60.64 os/recall_unk=68.13 total/acc_i=49.14 total/acc_c=40.93 total/h_score=50.06\n",
      "selected:  cs/acc_i=49.36 cs/acc_c=51.13 os/recall_knw=55.27 os/recall_unk=74.62 total/acc_i=50.17 total/acc_c=39.06 total/h_score=49.72\n",
      "Loss: 2.3375457738836607\n",
      "Loss: 0.8618076346814633\n",
      "Loss: 0.5291023734336098\n",
      "Loss: 0.39245751562217873\n",
      "Loss: 0.33976750432824093\n",
      "Loss: 0.3057125776385268\n",
      "Loss: 0.2723699671216309\n",
      "Loss: 0.2359998341028889\n",
      "Loss: 0.2163299524380515\n",
      "Loss: 0.19196511483751239\n",
      "______\n",
      "Iteration t=5\n",
      "all:  cs/acc_i=50.49 cs/acc_c=52.16 os/recall_knw=59.92 os/recall_unk=68.59 total/acc_i=49.07 total/acc_c=40.57 total/h_score=49.86\n",
      "selected:  cs/acc_i=49.39 cs/acc_c=51.33 os/recall_knw=58.11 os/recall_unk=70.76 total/acc_i=48.90 total/acc_c=39.36 total/h_score=49.26\n",
      "Loss: 2.2928769435269767\n",
      "Loss: 0.8556322473359396\n",
      "Loss: 0.5037178277490608\n",
      "Loss: 0.4078014264384427\n",
      "Loss: 0.3531680749841483\n",
      "Loss: 0.28512398734030475\n",
      "Loss: 0.2780675978276385\n",
      "Loss: 0.23434130290904678\n",
      "Loss: 0.20978579873660483\n",
      "Loss: 0.18930703172662172\n",
      "______\n",
      "Iteration t=6\n",
      "all:  cs/acc_i=50.94 cs/acc_c=52.49 os/recall_knw=59.89 os/recall_unk=68.65 total/acc_i=49.07 total/acc_c=40.53 total/h_score=49.85\n",
      "selected:  cs/acc_i=50.63 cs/acc_c=52.30 os/recall_knw=59.60 os/recall_unk=69.20 total/acc_i=49.00 total/acc_c=40.29 total/h_score=49.75\n",
      "Loss: 2.3053268491043877\n",
      "Loss: 0.8232314618444254\n",
      "Loss: 0.5169973404039978\n",
      "Loss: 0.4059281175433411\n",
      "Loss: 0.32846533480604645\n",
      "Loss: 0.2943874032277128\n",
      "Loss: 0.25730912679651746\n",
      "Loss: 0.24410975980664432\n",
      "Loss: 0.20620516818679369\n",
      "Loss: 0.19273208682480536\n",
      "______\n",
      "Iteration t=7\n",
      "all:  cs/acc_i=51.70 cs/acc_c=53.31 os/recall_knw=59.81 os/recall_unk=68.65 total/acc_i=49.02 total/acc_c=40.47 total/h_score=49.79\n",
      "selected:  cs/acc_i=51.68 cs/acc_c=53.30 os/recall_knw=59.80 os/recall_unk=68.65 total/acc_i=49.01 total/acc_c=40.45 total/h_score=49.77\n",
      "Loss: 2.292361842784957\n",
      "Loss: 0.8304339090119237\n",
      "Loss: 0.5108727980625959\n",
      "Loss: 0.3910775098640457\n",
      "Loss: 0.3446104812468936\n",
      "Loss: 0.3063931791737617\n",
      "Loss: 0.2502699374210222\n",
      "Loss: 0.22650910049617998\n",
      "Loss: 0.20870474924741997\n",
      "Loss: 0.18717414348316286\n",
      "______\n",
      "Iteration t=8\n",
      "all:  cs/acc_i=50.83 cs/acc_c=52.45 os/recall_knw=59.81 os/recall_unk=68.65 total/acc_i=49.02 total/acc_c=40.47 total/h_score=49.79\n",
      "selected:  cs/acc_i=50.83 cs/acc_c=52.45 os/recall_knw=59.81 os/recall_unk=68.65 total/acc_i=49.02 total/acc_c=40.47 total/h_score=49.79\n",
      "Loss: 2.2983684990349715\n",
      "Loss: 0.8389024874122124\n",
      "Loss: 0.5018584672508277\n",
      "Loss: 0.3943478199909991\n",
      "Loss: 0.32980095442589813\n",
      "Loss: 0.28939053254920666\n",
      "Loss: 0.26031211498156775\n",
      "Loss: 0.23890948013996516\n",
      "Loss: 0.20986509628183259\n",
      "Loss: 0.20007729487801632\n",
      "______\n",
      "Iteration t=9\n",
      "all:  cs/acc_i=51.40 cs/acc_c=53.09 os/recall_knw=59.81 os/recall_unk=68.65 total/acc_i=49.02 total/acc_c=40.47 total/h_score=49.79\n",
      "selected:  cs/acc_i=51.40 cs/acc_c=53.09 os/recall_knw=59.81 os/recall_unk=68.65 total/acc_i=49.02 total/acc_c=40.47 total/h_score=49.79\n",
      "tensor(0)\n",
      "all:  cs/acc_i=51.40 cs/acc_c=53.09 os/recall_knw=59.81 os/recall_unk=68.65 total/acc_i=49.02 total/acc_c=40.47 total/h_score=49.79\n",
      "painting -> sketch lr= 0.001 seed= 4\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19]\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20]\n",
      "Loss: 2.5825838462385553\n",
      "Loss: 1.2210098527095936\n",
      "Loss: 0.7460639694380382\n",
      "Loss: 0.5739395616861879\n",
      "Loss: 0.48816827633393506\n",
      "Loss: 0.4212392175166064\n",
      "Loss: 0.39408461938774775\n",
      "Loss: 0.3533905432337806\n",
      "Loss: 0.30863836667840444\n",
      "Loss: 0.2940530500241688\n",
      "tensor(True) tensor(True)\n",
      "______\n",
      "Iteration t=1\n",
      "all:  cs/acc_i=50.64 cs/acc_c=52.20 os/recall_knw=93.06 os/recall_unk=15.25 total/acc_i=36.64 total/acc_c=48.91 total/h_score=23.43\n",
      "selected:  cs/acc_i=57.39 cs/acc_c=60.28 os/recall_knw=68.76 os/recall_unk=77.41 total/acc_i=59.21 total/acc_c=54.08 total/h_score=62.86\n",
      "Loss: 2.4849985732751736\n",
      "Loss: 1.0571443546636432\n",
      "Loss: 0.6384299419382039\n",
      "Loss: 0.5014121975822776\n",
      "Loss: 0.43164697735040797\n",
      "Loss: 0.3775925212631039\n",
      "Loss: 0.3445989239741774\n",
      "Loss: 0.29663752085145784\n",
      "Loss: 0.2811480290895584\n",
      "Loss: 0.25766392972539454\n",
      "______\n",
      "Iteration t=2\n",
      "all:  cs/acc_i=50.57 cs/acc_c=52.23 os/recall_knw=65.55 os/recall_unk=63.02 total/acc_i=48.73 total/acc_c=43.00 total/h_score=50.41\n",
      "selected:  cs/acc_i=48.19 cs/acc_c=49.96 os/recall_knw=45.69 os/recall_unk=85.15 total/acc_i=53.56 total/acc_c=36.57 total/h_score=48.74\n",
      "Loss: 2.40558170998862\n",
      "Loss: 0.9771244808894779\n",
      "Loss: 0.5828189046011059\n",
      "Loss: 0.4462327864191948\n",
      "Loss: 0.3695170687631183\n",
      "Loss: 0.3533384151278286\n",
      "Loss: 0.310789278135934\n",
      "Loss: 0.2676865552816916\n",
      "Loss: 0.2599971706919167\n",
      "Loss: 0.23093420501217382\n",
      "______\n",
      "Iteration t=3\n",
      "all:  cs/acc_i=50.57 cs/acc_c=52.09 os/recall_knw=58.45 os/recall_unk=71.14 total/acc_i=49.83 total/acc_c=40.45 total/h_score=50.31\n",
      "selected:  cs/acc_i=48.50 cs/acc_c=50.37 os/recall_knw=49.05 os/recall_unk=80.58 total/acc_i=51.00 total/acc_c=36.62 total/h_score=48.24\n",
      "Loss: 2.368429638510165\n",
      "Loss: 0.905197421234587\n",
      "Loss: 0.5451541847508886\n",
      "Loss: 0.4245413548272589\n",
      "Loss: 0.3655437439032223\n",
      "Loss: 0.3059891542662745\n",
      "Loss: 0.29936899353304636\n",
      "Loss: 0.2586904628769211\n",
      "Loss: 0.2380899612346421\n",
      "Loss: 0.20953001336235066\n",
      "______\n",
      "Iteration t=4\n",
      "all:  cs/acc_i=50.19 cs/acc_c=51.64 os/recall_knw=57.77 os/recall_unk=71.66 total/acc_i=49.71 total/acc_c=39.99 total/h_score=50.01\n",
      "selected:  cs/acc_i=48.51 cs/acc_c=50.43 os/recall_knw=53.08 os/recall_unk=76.47 total/acc_i=49.88 total/acc_c=37.83 total/h_score=48.86\n",
      "Loss: 2.344712002008031\n",
      "Loss: 0.8734355622505044\n",
      "Loss: 0.5406584997805591\n",
      "Loss: 0.42014301091307876\n",
      "Loss: 0.35084295462988413\n",
      "Loss: 0.3156815743907725\n",
      "Loss: 0.28093069346005944\n",
      "Loss: 0.2520758472538892\n",
      "Loss: 0.21474422991400482\n",
      "Loss: 0.19984753568613878\n",
      "______\n",
      "Iteration t=5\n",
      "all:  cs/acc_i=51.17 cs/acc_c=52.69 os/recall_knw=57.58 os/recall_unk=71.99 total/acc_i=49.81 total/acc_c=39.97 total/h_score=50.06\n",
      "selected:  cs/acc_i=50.41 cs/acc_c=52.23 os/recall_knw=55.97 os/recall_unk=73.14 total/acc_i=49.59 total/acc_c=39.13 total/h_score=49.52\n",
      "Loss: 2.303869652069681\n",
      "Loss: 0.8378259105895592\n",
      "Loss: 0.5281563753156158\n",
      "Loss: 0.41137822447874683\n",
      "Loss: 0.3342168822399969\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.29960483621533324\n",
      "Loss: 0.2581818054422615\n",
      "Loss: 0.23484002618588568\n",
      "Loss: 0.21736799642383084\n",
      "Loss: 0.20251161538488496\n",
      "______\n",
      "Iteration t=6\n",
      "all:  cs/acc_i=50.19 cs/acc_c=51.77 os/recall_knw=57.47 os/recall_unk=71.99 total/acc_i=49.74 total/acc_c=39.84 total/h_score=49.95\n",
      "selected:  cs/acc_i=49.75 cs/acc_c=51.47 os/recall_knw=56.97 os/recall_unk=72.18 total/acc_i=49.51 total/acc_c=39.45 total/h_score=49.62\n",
      "Loss: 2.3190746192472527\n",
      "Loss: 0.8571292504249327\n",
      "Loss: 0.520269567648091\n",
      "Loss: 0.4046208525158794\n",
      "Loss: 0.3249882042378067\n",
      "Loss: 0.28082580660959805\n",
      "Loss: 0.26849123684457504\n",
      "Loss: 0.23634595913161716\n",
      "Loss: 0.21575164646807923\n",
      "Loss: 0.18406565759675092\n",
      "______\n",
      "Iteration t=7\n",
      "all:  cs/acc_i=50.79 cs/acc_c=52.39 os/recall_knw=57.47 os/recall_unk=71.99 total/acc_i=49.74 total/acc_c=39.84 total/h_score=49.95\n",
      "selected:  cs/acc_i=50.79 cs/acc_c=52.40 os/recall_knw=57.44 os/recall_unk=71.99 total/acc_i=49.74 total/acc_c=39.84 total/h_score=49.94\n",
      "Loss: 2.294226768016815\n",
      "Loss: 0.8313663811683655\n",
      "Loss: 0.5015620772242546\n",
      "Loss: 0.3998534911870956\n",
      "Loss: 0.3406180818676949\n",
      "Loss: 0.2966692197620869\n",
      "Loss: 0.267908243983984\n",
      "Loss: 0.2298817091435194\n",
      "Loss: 0.21814718779921533\n",
      "Loss: 0.1949914086908102\n",
      "______\n",
      "Iteration t=8\n",
      "all:  cs/acc_i=49.77 cs/acc_c=51.38 os/recall_knw=57.47 os/recall_unk=71.99 total/acc_i=49.74 total/acc_c=39.84 total/h_score=49.95\n",
      "selected:  cs/acc_i=49.77 cs/acc_c=51.38 os/recall_knw=57.47 os/recall_unk=71.99 total/acc_i=49.74 total/acc_c=39.84 total/h_score=49.95\n",
      "Loss: 2.3041436500549315\n",
      "Loss: 0.8270677012205124\n",
      "Loss: 0.5096116021871567\n",
      "Loss: 0.3986490542292595\n",
      "Loss: 0.3280297709703445\n",
      "Loss: 0.299019543081522\n",
      "Loss: 0.270236604809761\n",
      "Loss: 0.23704918719828127\n",
      "Loss: 0.2299495680332184\n",
      "Loss: 0.20040941332280635\n",
      "______\n",
      "Iteration t=9\n",
      "all:  cs/acc_i=51.58 cs/acc_c=53.35 os/recall_knw=57.47 os/recall_unk=71.99 total/acc_i=49.74 total/acc_c=39.84 total/h_score=49.95\n",
      "selected:  cs/acc_i=51.58 cs/acc_c=53.35 os/recall_knw=57.47 os/recall_unk=71.99 total/acc_i=49.74 total/acc_c=39.84 total/h_score=49.95\n",
      "tensor(0)\n",
      "all:  cs/acc_i=51.58 cs/acc_c=53.35 os/recall_knw=57.47 os/recall_unk=71.99 total/acc_i=49.74 total/acc_c=39.84 total/h_score=49.95\n",
      "painting -> sketch lr= 0.001 seed= 0\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19]\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20]\n",
      "Loss: 2.5623855483595026\n",
      "Loss: 1.239760539519093\n",
      "Loss: 0.7382783796736803\n",
      "Loss: 0.564532313555006\n",
      "Loss: 0.500314025099946\n",
      "Loss: 0.42990866855338766\n",
      "Loss: 0.3870363842557978\n",
      "Loss: 0.35700254678410825\n",
      "Loss: 0.32991153147643204\n",
      "Loss: 0.27621023270188183\n",
      "tensor(True) tensor(True)\n",
      "______\n",
      "Iteration t=1\n",
      "all:  cs/acc_i=52.00 cs/acc_c=53.49 os/recall_knw=94.49 os/recall_unk=17.74 total/acc_i=38.54 total/acc_c=50.40 total/h_score=26.45\n",
      "selected:  cs/acc_i=62.97 cs/acc_c=64.29 os/recall_knw=73.88 os/recall_unk=81.87 total/acc_i=65.62 total/acc_c=58.89 total/h_score=67.72\n",
      "Loss: 2.473692384420657\n",
      "Loss: 1.0829554495273852\n",
      "Loss: 0.6367922308398228\n",
      "Loss: 0.5053905602909771\n",
      "Loss: 0.43994910299193624\n",
      "Loss: 0.386135970844942\n",
      "Loss: 0.3478807248175144\n",
      "Loss: 0.30763832348234516\n",
      "Loss: 0.28871920083959896\n",
      "Loss: 0.2463245948630513\n",
      "______\n",
      "Iteration t=2\n",
      "all:  cs/acc_i=49.40 cs/acc_c=50.95 os/recall_knw=60.91 os/recall_unk=66.49 total/acc_i=47.94 total/acc_c=39.93 total/h_score=48.85\n",
      "selected:  cs/acc_i=46.32 cs/acc_c=48.24 os/recall_knw=42.73 os/recall_unk=86.03 total/acc_i=51.24 total/acc_c=32.76 total/h_score=44.59\n",
      "Loss: 2.434049574607009\n",
      "Loss: 0.9682352526472249\n",
      "Loss: 0.5813820827581467\n",
      "Loss: 0.46101876348257065\n",
      "Loss: 0.3812646245874396\n",
      "Loss: 0.34315612683192304\n",
      "Loss: 0.3138146479058703\n",
      "Loss: 0.27690307997645586\n",
      "Loss: 0.2528585939915902\n",
      "Loss: 0.22948996095550717\n",
      "______\n",
      "Iteration t=3\n",
      "all:  cs/acc_i=50.26 cs/acc_c=51.71 os/recall_knw=58.72 os/recall_unk=68.98 total/acc_i=48.28 total/acc_c=39.09 total/h_score=48.67\n",
      "selected:  cs/acc_i=49.05 cs/acc_c=50.68 os/recall_knw=49.52 os/recall_unk=81.08 total/acc_i=50.42 total/acc_c=35.89 total/h_score=47.54\n",
      "Loss: 2.360348039606343\n",
      "Loss: 0.8985192364972571\n",
      "Loss: 0.569090692245442\n",
      "Loss: 0.4344461948327396\n",
      "Loss: 0.3657309434660103\n",
      "Loss: 0.32205204707772833\n",
      "Loss: 0.28721183768433073\n",
      "Loss: 0.2603411431221858\n",
      "Loss: 0.2351671087677064\n",
      "Loss: 0.21163593874839337\n",
      "______\n",
      "Iteration t=4\n",
      "all:  cs/acc_i=50.72 cs/acc_c=52.18 os/recall_knw=57.85 os/recall_unk=69.96 total/acc_i=48.42 total/acc_c=38.79 total/h_score=48.60\n",
      "selected:  cs/acc_i=49.60 cs/acc_c=51.50 os/recall_knw=53.32 os/recall_unk=75.87 total/acc_i=49.08 total/acc_c=37.02 total/h_score=47.97\n",
      "Loss: 2.3184204762180647\n",
      "Loss: 0.8586034288009008\n",
      "Loss: 0.5120816408966978\n",
      "Loss: 0.40863375905901195\n",
      "Loss: 0.35358042530715467\n",
      "Loss: 0.30771634853444996\n",
      "Loss: 0.2752386924500267\n",
      "Loss: 0.23969712289981543\n",
      "Loss: 0.2168662374994407\n",
      "Loss: 0.20211200579069555\n",
      "______\n",
      "Iteration t=5\n",
      "all:  cs/acc_i=50.08 cs/acc_c=51.42 os/recall_knw=56.87 os/recall_unk=70.94 total/acc_i=48.49 total/acc_c=38.40 total/h_score=48.43\n",
      "selected:  cs/acc_i=49.26 cs/acc_c=51.03 os/recall_knw=55.53 os/recall_unk=72.80 total/acc_i=48.41 total/acc_c=37.63 total/h_score=48.06\n",
      "Loss: 2.3111594978386796\n",
      "Loss: 0.8383466264581293\n",
      "Loss: 0.5125980876325592\n",
      "Loss: 0.38743934753101045\n",
      "Loss: 0.3414013797068984\n",
      "Loss: 0.2856396559656151\n",
      "Loss: 0.2642587256443694\n",
      "Loss: 0.23962072631329057\n",
      "Loss: 0.22402080363495563\n",
      "Loss: 0.19596642391317018\n",
      "______\n",
      "Iteration t=6\n",
      "all:  cs/acc_i=50.72 cs/acc_c=52.21 os/recall_knw=56.75 os/recall_unk=70.94 total/acc_i=48.47 total/acc_c=38.36 total/h_score=48.40\n",
      "selected:  cs/acc_i=50.49 cs/acc_c=52.11 os/recall_knw=56.43 os/recall_unk=71.41 total/acc_i=48.43 total/acc_c=38.18 total/h_score=48.32\n",
      "Loss: 2.310814085255665\n",
      "Loss: 0.8465462482597933\n",
      "Loss: 0.5034062953658373\n",
      "Loss: 0.40425010007548046\n",
      "Loss: 0.3251432776750331\n",
      "Loss: 0.3016128414665839\n",
      "Loss: 0.2565268324949895\n",
      "Loss: 0.24317669753269497\n",
      "Loss: 0.20754065966031637\n",
      "Loss: 0.1955702904776397\n",
      "______\n",
      "Iteration t=7\n",
      "all:  cs/acc_i=50.15 cs/acc_c=51.76 os/recall_knw=56.75 os/recall_unk=70.94 total/acc_i=48.47 total/acc_c=38.36 total/h_score=48.40\n",
      "selected:  cs/acc_i=50.15 cs/acc_c=51.76 os/recall_knw=56.75 os/recall_unk=70.94 total/acc_i=48.47 total/acc_c=38.36 total/h_score=48.40\n",
      "Loss: 2.2916480436325073\n",
      "Loss: 0.820811172246933\n",
      "Loss: 0.4989629379510879\n",
      "Loss: 0.38729613295197485\n",
      "Loss: 0.33183800330758095\n",
      "Loss: 0.28983218763768676\n",
      "Loss: 0.2623660730421543\n",
      "Loss: 0.24430020856857299\n",
      "Loss: 0.20926358339190482\n",
      "Loss: 0.191600140966475\n",
      "______\n",
      "Iteration t=8\n",
      "all:  cs/acc_i=49.96 cs/acc_c=51.46 os/recall_knw=56.75 os/recall_unk=70.94 total/acc_i=48.47 total/acc_c=38.36 total/h_score=48.40\n",
      "selected:  cs/acc_i=49.96 cs/acc_c=51.46 os/recall_knw=56.75 os/recall_unk=70.94 total/acc_i=48.47 total/acc_c=38.36 total/h_score=48.40\n",
      "Loss: 2.301647842884064\n",
      "Loss: 0.8284053148031235\n",
      "Loss: 0.511890815615654\n",
      "Loss: 0.4183179801106453\n",
      "Loss: 0.34506843096017836\n",
      "Loss: 0.28919449359178545\n",
      "Loss: 0.2698332915008068\n",
      "Loss: 0.23952331970632076\n",
      "Loss: 0.2046208673864603\n",
      "Loss: 0.19108313500881194\n",
      "______\n",
      "Iteration t=9\n",
      "all:  cs/acc_i=49.89 cs/acc_c=51.41 os/recall_knw=56.75 os/recall_unk=70.94 total/acc_i=48.47 total/acc_c=38.36 total/h_score=48.40\n",
      "selected:  cs/acc_i=49.89 cs/acc_c=51.41 os/recall_knw=56.75 os/recall_unk=70.94 total/acc_i=48.47 total/acc_c=38.36 total/h_score=48.40\n",
      "tensor(0)\n",
      "all:  cs/acc_i=49.89 cs/acc_c=51.41 os/recall_knw=56.75 os/recall_unk=70.94 total/acc_i=48.47 total/acc_c=38.36 total/h_score=48.40\n",
      "painting -> sketch lr= 0.001 seed= 1\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19]\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20]\n",
      "Loss: 2.5555783642662897\n",
      "Loss: 1.1907508092582542\n",
      "Loss: 0.7530392624398388\n",
      "Loss: 0.5743571321169535\n",
      "Loss: 0.49295997611744696\n",
      "Loss: 0.4305124404253783\n",
      "Loss: 0.377337904991927\n",
      "Loss: 0.3370462860222216\n",
      "Loss: 0.3138263937499788\n",
      "Loss: 0.29435343157362054\n",
      "tensor(True) tensor(True)\n",
      "______\n",
      "Iteration t=1\n",
      "all:  cs/acc_i=49.89 cs/acc_c=51.32 os/recall_knw=93.40 os/recall_unk=15.84 total/acc_i=36.67 total/acc_c=48.50 total/h_score=24.07\n",
      "selected:  cs/acc_i=54.39 cs/acc_c=56.03 os/recall_knw=69.88 os/recall_unk=78.06 total/acc_i=59.03 total/acc_c=52.12 total/h_score=61.56\n",
      "Loss: 2.466830440011679\n",
      "Loss: 1.0646368108835875\n",
      "Loss: 0.6169257418197744\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.49861179438291814\n",
      "Loss: 0.42456481459678386\n",
      "Loss: 0.3712895526459404\n",
      "Loss: 0.3185566832110578\n",
      "Loss: 0.30759280405062084\n",
      "Loss: 0.2782007672403957\n",
      "Loss: 0.24218732560528258\n",
      "______\n",
      "Iteration t=2\n",
      "all:  cs/acc_i=50.98 cs/acc_c=52.55 os/recall_knw=63.77 os/recall_unk=64.73 total/acc_i=49.16 total/acc_c=42.69 total/h_score=50.64\n",
      "selected:  cs/acc_i=47.75 cs/acc_c=49.46 os/recall_knw=44.57 os/recall_unk=85.70 total/acc_i=53.01 total/acc_c=35.35 total/h_score=47.48\n",
      "Loss: 2.4090984578526347\n",
      "Loss: 0.9762246863010826\n",
      "Loss: 0.5801598158998227\n",
      "Loss: 0.46094998689966465\n",
      "Loss: 0.395664923371525\n",
      "Loss: 0.36388732287861886\n",
      "Loss: 0.30935649491778205\n",
      "Loss: 0.2659264517554996\n",
      "Loss: 0.24864730614861216\n",
      "Loss: 0.2277069939898515\n",
      "______\n",
      "Iteration t=3\n",
      "all:  cs/acc_i=51.43 cs/acc_c=53.00 os/recall_knw=61.32 os/recall_unk=68.00 total/acc_i=49.71 total/acc_c=41.82 total/h_score=50.77\n",
      "selected:  cs/acc_i=49.81 cs/acc_c=51.63 os/recall_knw=51.10 os/recall_unk=80.29 total/acc_i=51.86 total/acc_c=38.18 total/h_score=49.78\n",
      "Loss: 2.3533042912897857\n",
      "Loss: 0.8968943261581919\n",
      "Loss: 0.5613002151250839\n",
      "Loss: 0.43395566830168597\n",
      "Loss: 0.36171010972365086\n",
      "Loss: 0.3153763476597226\n",
      "Loss: 0.2836615257936975\n",
      "Loss: 0.25303093076724076\n",
      "Loss: 0.23976098329800627\n",
      "Loss: 0.2174778580179681\n",
      "______\n",
      "Iteration t=4\n",
      "all:  cs/acc_i=50.72 cs/acc_c=52.30 os/recall_knw=60.49 os/recall_unk=68.91 total/acc_i=49.83 total/acc_c=41.51 total/h_score=50.73\n",
      "selected:  cs/acc_i=48.64 cs/acc_c=50.78 os/recall_knw=55.60 os/recall_unk=74.47 total/acc_i=49.97 total/acc_c=39.03 total/h_score=49.67\n",
      "Loss: 2.3194742519331175\n",
      "Loss: 0.8518845131041103\n",
      "Loss: 0.5344354211047477\n",
      "Loss: 0.4073460074875859\n",
      "Loss: 0.34579560145179267\n",
      "Loss: 0.3006768840600841\n",
      "Loss: 0.2785714538883866\n",
      "Loss: 0.24095275334982952\n",
      "Loss: 0.21536009905558404\n",
      "Loss: 0.20201469843442016\n",
      "______\n",
      "Iteration t=5\n",
      "all:  cs/acc_i=51.58 cs/acc_c=53.10 os/recall_knw=59.77 os/recall_unk=69.11 total/acc_i=49.59 total/acc_c=41.07 total/h_score=50.40\n",
      "selected:  cs/acc_i=50.57 cs/acc_c=52.48 os/recall_knw=57.75 os/recall_unk=71.40 total/acc_i=49.50 total/acc_c=40.05 total/h_score=50.01\n",
      "Loss: 2.3009388754444737\n",
      "Loss: 0.8591628894209862\n",
      "Loss: 0.5289081756265894\n",
      "Loss: 0.4019464566822975\n",
      "Loss: 0.3397307151087349\n",
      "Loss: 0.2959230380252965\n",
      "Loss: 0.2631538651823517\n",
      "Loss: 0.2333539148732539\n",
      "Loss: 0.20488685180222796\n",
      "Loss: 0.19107836219031485\n",
      "______\n",
      "Iteration t=6\n",
      "all:  cs/acc_i=50.75 cs/acc_c=52.32 os/recall_knw=59.51 os/recall_unk=69.24 total/acc_i=49.52 total/acc_c=40.89 total/h_score=50.28\n",
      "selected:  cs/acc_i=50.35 cs/acc_c=52.07 os/recall_knw=58.86 os/recall_unk=69.70 total/acc_i=49.37 total/acc_c=40.53 total/h_score=50.07\n",
      "Loss: 2.2960661179515944\n",
      "Loss: 0.8268429615583078\n",
      "Loss: 0.5062242383026032\n",
      "Loss: 0.38359694865595295\n",
      "Loss: 0.33248510829124794\n",
      "Loss: 0.3015337380398792\n",
      "Loss: 0.26400638730877424\n",
      "Loss: 0.2280338873782481\n",
      "Loss: 0.21527488351580631\n",
      "Loss: 0.18964490721900149\n",
      "______\n",
      "Iteration t=7\n",
      "all:  cs/acc_i=51.17 cs/acc_c=52.69 os/recall_knw=59.51 os/recall_unk=69.24 total/acc_i=49.52 total/acc_c=40.89 total/h_score=50.28\n",
      "selected:  cs/acc_i=51.21 cs/acc_c=52.73 os/recall_knw=59.48 os/recall_unk=69.29 total/acc_i=49.56 total/acc_c=40.92 total/h_score=50.32\n",
      "Loss: 2.3043884872919014\n",
      "Loss: 0.823689461461169\n",
      "Loss: 0.5221307512092968\n",
      "Loss: 0.4026670341670749\n",
      "Loss: 0.33469209313510434\n",
      "Loss: 0.29697138932441536\n",
      "Loss: 0.2583113008955486\n",
      "Loss: 0.2287261892007038\n",
      "Loss: 0.21338012752679025\n",
      "Loss: 0.1945327921612225\n",
      "______\n",
      "Iteration t=8\n",
      "all:  cs/acc_i=52.00 cs/acc_c=53.50 os/recall_knw=59.51 os/recall_unk=69.24 total/acc_i=49.52 total/acc_c=40.89 total/h_score=50.28\n",
      "selected:  cs/acc_i=52.00 cs/acc_c=53.50 os/recall_knw=59.51 os/recall_unk=69.24 total/acc_i=49.52 total/acc_c=40.89 total/h_score=50.28\n",
      "Loss: 2.2918978352320525\n",
      "Loss: 0.8493174253245116\n",
      "Loss: 0.49866977010084235\n",
      "Loss: 0.3891687233575248\n",
      "Loss: 0.3351949889787101\n",
      "Loss: 0.3049308614945223\n",
      "Loss: 0.26302177252858994\n",
      "Loss: 0.23987702249361592\n",
      "Loss: 0.21306469454890184\n",
      "Loss: 0.18814056047161107\n",
      "______\n",
      "Iteration t=9\n",
      "all:  cs/acc_i=51.85 cs/acc_c=53.47 os/recall_knw=59.51 os/recall_unk=69.24 total/acc_i=49.52 total/acc_c=40.89 total/h_score=50.28\n",
      "selected:  cs/acc_i=51.85 cs/acc_c=53.47 os/recall_knw=59.51 os/recall_unk=69.24 total/acc_i=49.52 total/acc_c=40.89 total/h_score=50.28\n",
      "tensor(0)\n",
      "all:  cs/acc_i=51.85 cs/acc_c=53.47 os/recall_knw=59.51 os/recall_unk=69.24 total/acc_i=49.52 total/acc_c=40.89 total/h_score=50.28\n",
      "painting -> sketch lr= 0.001 seed= 2\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19]\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20]\n",
      "Loss: 2.5668644223894392\n",
      "Loss: 1.2395638091854317\n",
      "Loss: 0.7070231893390575\n",
      "Loss: 0.5784787846305383\n",
      "Loss: 0.475624387541776\n",
      "Loss: 0.42236028899433753\n",
      "Loss: 0.37846792205458596\n",
      "Loss: 0.34299717382306144\n",
      "Loss: 0.3019538801261988\n",
      "Loss: 0.284409393275541\n",
      "tensor(True) tensor(True)\n",
      "______\n",
      "Iteration t=1\n",
      "all:  cs/acc_i=50.26 cs/acc_c=51.92 os/recall_knw=93.62 os/recall_unk=16.23 total/acc_i=36.96 total/acc_c=48.87 total/h_score=24.57\n",
      "selected:  cs/acc_i=56.42 cs/acc_c=58.73 os/recall_knw=70.66 os/recall_unk=79.23 total/acc_i=60.40 total/acc_c=53.48 total/h_score=62.93\n",
      "Loss: 2.4701065234109465\n",
      "Loss: 1.0782384831531375\n",
      "Loss: 0.6301257157442617\n",
      "Loss: 0.5070031448906543\n",
      "Loss: 0.43005043436207024\n",
      "Loss: 0.374861203061015\n",
      "Loss: 0.3382266874187717\n",
      "Loss: 0.30866900955637294\n",
      "Loss: 0.28136324853289363\n",
      "Loss: 0.2490887363240415\n",
      "______\n",
      "Iteration t=2\n",
      "all:  cs/acc_i=49.81 cs/acc_c=51.32 os/recall_knw=65.85 os/recall_unk=61.98 total/acc_i=47.61 total/acc_c=41.84 total/h_score=49.23\n",
      "selected:  cs/acc_i=47.47 cs/acc_c=49.16 os/recall_knw=46.10 os/recall_unk=85.39 total/acc_i=52.58 total/acc_c=35.15 total/h_score=47.23\n",
      "Loss: 2.41155834318301\n",
      "Loss: 0.9740633133354537\n",
      "Loss: 0.5755536051791742\n",
      "Loss: 0.45978906989917845\n",
      "Loss: 0.3839641914386815\n",
      "Loss: 0.3428018025609605\n",
      "Loss: 0.2994408195308589\n",
      "Loss: 0.2840470954126448\n",
      "Loss: 0.2623779309247065\n",
      "Loss: 0.22620588095021357\n",
      "______\n",
      "Iteration t=3\n",
      "all:  cs/acc_i=50.87 cs/acc_c=52.35 os/recall_knw=60.72 os/recall_unk=69.37 total/acc_i=49.21 total/acc_c=40.43 total/h_score=49.91\n",
      "selected:  cs/acc_i=50.00 cs/acc_c=51.56 os/recall_knw=50.48 os/recall_unk=80.85 total/acc_i=51.54 total/acc_c=37.13 total/h_score=48.80\n",
      "Loss: 2.363792273272639\n",
      "Loss: 0.9080729234477748\n",
      "Loss: 0.5347008504945299\n",
      "Loss: 0.43713679657034255\n",
      "Loss: 0.3673210774426875\n",
      "Loss: 0.30665425366681553\n",
      "Loss: 0.29572589630665985\n",
      "Loss: 0.24984603274775588\n",
      "Loss: 0.23552567840594313\n",
      "Loss: 0.21013162411425423\n",
      "______\n",
      "Iteration t=4\n",
      "all:  cs/acc_i=50.19 cs/acc_c=51.71 os/recall_knw=59.77 os/recall_unk=70.09 total/acc_i=49.11 total/acc_c=39.88 total/h_score=49.59\n",
      "selected:  cs/acc_i=48.48 cs/acc_c=50.54 os/recall_knw=55.02 os/recall_unk=74.58 total/acc_i=49.16 total/acc_c=37.52 total/h_score=48.25\n",
      "Loss: 2.3146318721573382\n",
      "Loss: 0.857584205653163\n",
      "Loss: 0.5211013771315334\n",
      "Loss: 0.429088065300245\n",
      "Loss: 0.35241507256550414\n",
      "Loss: 0.2943057829660993\n",
      "Loss: 0.26843963081163985\n",
      "Loss: 0.24858426145003545\n",
      "Loss: 0.22149759815441622\n",
      "Loss: 0.19712473566477723\n",
      "______\n",
      "Iteration t=5\n",
      "all:  cs/acc_i=50.08 cs/acc_c=51.69 os/recall_knw=59.74 os/recall_unk=70.09 total/acc_i=49.11 total/acc_c=39.88 total/h_score=49.59\n",
      "selected:  cs/acc_i=49.01 cs/acc_c=51.07 os/recall_knw=57.86 os/recall_unk=71.73 total/acc_i=48.84 total/acc_c=38.78 total/h_score=48.94\n",
      "Loss: 2.308023844034441\n",
      "Loss: 0.8263240431345278\n",
      "Loss: 0.49147037608969596\n",
      "Loss: 0.4051169161234171\n",
      "Loss: 0.33356286245848865\n",
      "Loss: 0.3012168967435437\n",
      "Loss: 0.2572716295178379\n",
      "Loss: 0.23662645269125218\n",
      "Loss: 0.20732209975680999\n",
      "Loss: 0.18042100504821829\n",
      "______\n",
      "Iteration t=6\n",
      "all:  cs/acc_i=51.13 cs/acc_c=52.82 os/recall_knw=59.21 os/recall_unk=70.62 total/acc_i=49.19 total/acc_c=39.72 total/h_score=49.56\n",
      "selected:  cs/acc_i=50.95 cs/acc_c=52.72 os/recall_knw=58.99 os/recall_unk=70.71 total/acc_i=49.09 total/acc_c=39.56 total/h_score=49.43\n",
      "Loss: 2.2737510246889934\n",
      "Loss: 0.8089135323488523\n",
      "Loss: 0.4863882081376182\n",
      "Loss: 0.3864494137288559\n",
      "Loss: 0.32623589641991113\n",
      "Loss: 0.30257600974587223\n",
      "Loss: 0.2761472777448713\n",
      "Loss: 0.2265895005345108\n",
      "Loss: 0.2110373517941861\n",
      "Loss: 0.1842687109721795\n",
      "______\n",
      "Iteration t=7\n",
      "all:  cs/acc_i=50.26 cs/acc_c=52.03 os/recall_knw=59.21 os/recall_unk=70.62 total/acc_i=49.19 total/acc_c=39.72 total/h_score=49.56\n",
      "selected:  cs/acc_i=50.25 cs/acc_c=52.02 os/recall_knw=59.19 os/recall_unk=70.62 total/acc_i=49.17 total/acc_c=39.71 total/h_score=49.55\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 2.270412498996371\n",
      "Loss: 0.8274123274854251\n",
      "Loss: 0.5072741237069879\n",
      "Loss: 0.4031823020251024\n",
      "Loss: 0.3276799213259466\n",
      "Loss: 0.28900389793136766\n",
      "Loss: 0.25010956043288823\n",
      "Loss: 0.22326025885662862\n",
      "Loss: 0.20059519751913965\n",
      "Loss: 0.19364497538596864\n",
      "______\n",
      "Iteration t=8\n",
      "all:  cs/acc_i=50.68 cs/acc_c=52.43 os/recall_knw=59.21 os/recall_unk=70.62 total/acc_i=49.19 total/acc_c=39.72 total/h_score=49.56\n",
      "selected:  cs/acc_i=50.68 cs/acc_c=52.43 os/recall_knw=59.21 os/recall_unk=70.62 total/acc_i=49.19 total/acc_c=39.72 total/h_score=49.56\n",
      "Loss: 2.2897775627317882\n",
      "Loss: 0.8292877879880723\n",
      "Loss: 0.4942903279785126\n",
      "Loss: 0.3889988290057296\n",
      "Loss: 0.33655781479227165\n",
      "Loss: 0.28940303203841994\n",
      "Loss: 0.24865066357666538\n",
      "Loss: 0.23304124653989833\n",
      "Loss: 0.21222350588216196\n",
      "Loss: 0.18463187630007427\n",
      "______\n",
      "Iteration t=9\n",
      "all:  cs/acc_i=52.04 cs/acc_c=53.58 os/recall_knw=59.21 os/recall_unk=70.62 total/acc_i=49.19 total/acc_c=39.72 total/h_score=49.56\n",
      "selected:  cs/acc_i=52.04 cs/acc_c=53.58 os/recall_knw=59.21 os/recall_unk=70.62 total/acc_i=49.19 total/acc_c=39.72 total/h_score=49.56\n",
      "tensor(0)\n",
      "all:  cs/acc_i=52.04 cs/acc_c=53.58 os/recall_knw=59.21 os/recall_unk=70.62 total/acc_i=49.19 total/acc_c=39.72 total/h_score=49.56\n",
      "painting -> sketch lr= 0.001 seed= 3\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19]\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20]\n",
      "Loss: 2.558762755343523\n",
      "Loss: 1.2293929779340351\n",
      "Loss: 0.7319963088742009\n",
      "Loss: 0.5561701333712018\n",
      "Loss: 0.5085188421622786\n",
      "Loss: 0.4234611157071653\n",
      "Loss: 0.3834109294509131\n",
      "Loss: 0.3524206541675739\n",
      "Loss: 0.3045602486956687\n",
      "Loss: 0.2883744614307212\n",
      "tensor(True) tensor(True)\n",
      "______\n",
      "Iteration t=1\n",
      "all:  cs/acc_i=50.53 cs/acc_c=51.81 os/recall_knw=93.81 os/recall_unk=16.56 total/acc_i=37.17 total/acc_c=48.71 total/h_score=24.92\n",
      "selected:  cs/acc_i=58.20 cs/acc_c=59.57 os/recall_knw=71.68 os/recall_unk=80.83 total/acc_i=61.77 total/acc_c=54.42 total/h_score=64.10\n",
      "Loss: 2.4771967208852956\n",
      "Loss: 1.0699578523635864\n",
      "Loss: 0.6423636753769482\n",
      "Loss: 0.4976627025388035\n",
      "Loss: 0.4251009269672282\n",
      "Loss: 0.38022517968042224\n",
      "Loss: 0.33698732420509936\n",
      "Loss: 0.30597410741828235\n",
      "Loss: 0.27420128458270837\n",
      "Loss: 0.2726166681660449\n",
      "______\n",
      "Iteration t=2\n",
      "all:  cs/acc_i=50.79 cs/acc_c=52.03 os/recall_knw=67.36 os/recall_unk=60.73 total/acc_i=48.04 total/acc_c=42.94 total/h_score=49.69\n",
      "selected:  cs/acc_i=48.93 cs/acc_c=50.24 os/recall_knw=47.29 os/recall_unk=85.22 total/acc_i=53.63 total/acc_c=36.65 total/h_score=48.83\n",
      "Loss: 2.4235786205038017\n",
      "Loss: 0.9872273346152874\n",
      "Loss: 0.5697459776740555\n",
      "Loss: 0.4528624273221427\n",
      "Loss: 0.39422409479087644\n",
      "Loss: 0.35988701760358766\n",
      "Loss: 0.30161141669121355\n",
      "Loss: 0.2687454950918845\n",
      "Loss: 0.25020233666473024\n",
      "Loss: 0.23507077810824464\n",
      "______\n",
      "Iteration t=3\n",
      "all:  cs/acc_i=50.53 cs/acc_c=52.02 os/recall_knw=60.64 os/recall_unk=67.80 total/acc_i=48.97 total/acc_c=40.68 total/h_score=49.78\n",
      "selected:  cs/acc_i=48.67 cs/acc_c=50.55 os/recall_knw=50.43 os/recall_unk=79.45 total/acc_i=50.79 total/acc_c=36.85 total/h_score=48.33\n",
      "Loss: 2.358204404513041\n",
      "Loss: 0.8831448103442336\n",
      "Loss: 0.5240770392603689\n",
      "Loss: 0.42251384235692746\n",
      "Loss: 0.36202606845856744\n",
      "Loss: 0.3155173182616502\n",
      "Loss: 0.28663883877523016\n",
      "Loss: 0.2536153812848386\n",
      "Loss: 0.2224982553585009\n",
      "Loss: 0.20986896895226978\n",
      "______\n",
      "Iteration t=4\n",
      "all:  cs/acc_i=50.23 cs/acc_c=51.75 os/recall_knw=60.49 os/recall_unk=68.00 total/acc_i=48.99 total/acc_c=40.62 total/h_score=49.77\n",
      "selected:  cs/acc_i=48.65 cs/acc_c=50.65 os/recall_knw=54.97 os/recall_unk=73.95 total/acc_i=49.52 total/acc_c=38.33 total/h_score=48.92\n",
      "Loss: 2.3382329245408378\n",
      "Loss: 0.8714110106229782\n",
      "Loss: 0.5237640388930838\n",
      "Loss: 0.3926446329181393\n",
      "Loss: 0.34959816417346395\n",
      "Loss: 0.29491086533914007\n",
      "Loss: 0.29384884775305786\n",
      "Loss: 0.25007065311074256\n",
      "Loss: 0.22479129154235125\n",
      "Loss: 0.19587904628521452\n",
      "______\n",
      "Iteration t=5\n",
      "all:  cs/acc_i=50.42 cs/acc_c=52.09 os/recall_knw=60.30 os/recall_unk=68.32 total/acc_i=49.07 total/acc_c=40.57 total/h_score=49.80\n",
      "selected:  cs/acc_i=49.34 cs/acc_c=51.53 os/recall_knw=58.00 os/recall_unk=70.16 total/acc_i=48.84 total/acc_c=39.46 total/h_score=49.24\n",
      "Loss: 2.3064549464371895\n",
      "Loss: 0.8515174043995719\n",
      "Loss: 0.5167964832076142\n",
      "Loss: 0.4102292670718124\n",
      "Loss: 0.33593465141471357\n",
      "Loss: 0.2729790335701358\n",
      "Loss: 0.2542666831624604\n",
      "Loss: 0.24795645132901206\n",
      "Loss: 0.21337172363494192\n",
      "Loss: 0.18854736176229292\n",
      "______\n",
      "Iteration t=6\n",
      "all:  cs/acc_i=50.57 cs/acc_c=52.06 os/recall_knw=60.23 os/recall_unk=68.32 total/acc_i=49.04 total/acc_c=40.53 total/h_score=49.77\n",
      "selected:  cs/acc_i=50.17 cs/acc_c=51.90 os/recall_knw=59.60 os/recall_unk=68.82 total/acc_i=48.91 total/acc_c=40.22 total/h_score=49.62\n",
      "Loss: 2.2953435452211473\n",
      "Loss: 0.8281530371261021\n",
      "Loss: 0.5152434013074353\n",
      "Loss: 0.3870806299327385\n",
      "Loss: 0.3275449698761342\n",
      "Loss: 0.30419885812120306\n",
      "Loss: 0.2672612824669433\n",
      "Loss: 0.24342700392599143\n",
      "Loss: 0.20864502526819706\n",
      "Loss: 0.19706060596933914\n",
      "______\n",
      "Iteration t=7\n",
      "all:  cs/acc_i=51.55 cs/acc_c=53.08 os/recall_knw=60.19 os/recall_unk=68.39 total/acc_i=49.07 total/acc_c=40.53 total/h_score=49.78\n",
      "selected:  cs/acc_i=51.59 cs/acc_c=53.13 os/recall_knw=60.13 os/recall_unk=68.43 total/acc_i=49.10 total/acc_c=40.57 total/h_score=49.83\n",
      "Loss: 2.2721138845278523\n",
      "Loss: 0.8152556505024903\n",
      "Loss: 0.5128505703971142\n",
      "Loss: 0.39211140966086877\n",
      "Loss: 0.34107375593753314\n",
      "Loss: 0.29366220759711864\n",
      "Loss: 0.2696275835578132\n",
      "Loss: 0.23874884628228785\n",
      "Loss: 0.2099701788745762\n",
      "Loss: 0.18781670542272527\n",
      "______\n",
      "Iteration t=8\n",
      "all:  cs/acc_i=50.79 cs/acc_c=52.24 os/recall_knw=60.19 os/recall_unk=68.39 total/acc_i=49.07 total/acc_c=40.53 total/h_score=49.78\n",
      "selected:  cs/acc_i=50.79 cs/acc_c=52.24 os/recall_knw=60.19 os/recall_unk=68.39 total/acc_i=49.07 total/acc_c=40.53 total/h_score=49.78\n",
      "Loss: 2.287149189494726\n",
      "Loss: 0.8193913336813919\n",
      "Loss: 0.4981388491908396\n",
      "Loss: 0.4091359233469006\n",
      "Loss: 0.339898142259656\n",
      "Loss: 0.30274248926892994\n",
      "Loss: 0.2589770989917864\n",
      "Loss: 0.2262217953771822\n",
      "Loss: 0.21605886438289496\n",
      "Loss: 0.1934753753039546\n",
      "______\n",
      "Iteration t=9\n",
      "all:  cs/acc_i=50.79 cs/acc_c=52.41 os/recall_knw=60.19 os/recall_unk=68.39 total/acc_i=49.07 total/acc_c=40.53 total/h_score=49.78\n",
      "selected:  cs/acc_i=50.79 cs/acc_c=52.41 os/recall_knw=60.19 os/recall_unk=68.39 total/acc_i=49.07 total/acc_c=40.53 total/h_score=49.78\n",
      "tensor(0)\n",
      "all:  cs/acc_i=50.79 cs/acc_c=52.41 os/recall_knw=60.19 os/recall_unk=68.39 total/acc_i=49.07 total/acc_c=40.53 total/h_score=49.78\n",
      "painting -> sketch lr= 0.001 seed= 4\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19]\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20]\n",
      "Loss: 2.586253943266692\n",
      "Loss: 1.2237069417559912\n",
      "Loss: 0.7467817760333813\n",
      "Loss: 0.5753164028049146\n",
      "Loss: 0.48887335284361766\n",
      "Loss: 0.42108471257976754\n",
      "Loss: 0.39450488826900565\n",
      "Loss: 0.3534147031802349\n",
      "Loss: 0.309058334698122\n",
      "Loss: 0.29496634629353014\n",
      "tensor(True) tensor(True)\n",
      "______\n",
      "Iteration t=1\n",
      "all:  cs/acc_i=50.53 cs/acc_c=52.02 os/recall_knw=93.21 os/recall_unk=15.51 total/acc_i=36.69 total/acc_c=48.82 total/h_score=23.73\n",
      "selected:  cs/acc_i=57.95 cs/acc_c=61.40 os/recall_knw=69.23 os/recall_unk=77.45 total/acc_i=59.82 total/acc_c=55.17 total/h_score=63.67\n",
      "Loss: 2.485499991505754\n",
      "Loss: 1.0811840871385499\n",
      "Loss: 0.6529570668935776\n",
      "Loss: 0.5011495423375392\n",
      "Loss: 0.4356957866134597\n",
      "Loss: 0.39924609997108873\n",
      "Loss: 0.33460158905854415\n",
      "Loss: 0.30541676060095724\n",
      "Loss: 0.273054276392156\n",
      "Loss: 0.24837847612798214\n",
      "______\n",
      "Iteration t=2\n",
      "all:  cs/acc_i=50.57 cs/acc_c=52.01 os/recall_knw=68.42 os/recall_unk=59.03 total/acc_i=47.63 total/acc_c=43.17 total/h_score=49.34\n",
      "selected:  cs/acc_i=48.48 cs/acc_c=50.14 os/recall_knw=47.98 os/recall_unk=84.62 total/acc_i=53.46 total/acc_c=36.73 total/h_score=48.85\n",
      "Loss: 2.404216914001955\n",
      "Loss: 0.9953085856700162\n",
      "Loss: 0.5877162239967136\n",
      "Loss: 0.46342413715266306\n",
      "Loss: 0.3865117653520829\n",
      "Loss: 0.3451897873107446\n",
      "Loss: 0.30062817385710705\n",
      "Loss: 0.2799422372850256\n",
      "Loss: 0.251333521405628\n",
      "Loss: 0.2308826566665271\n",
      "______\n",
      "Iteration t=3\n",
      "all:  cs/acc_i=50.60 cs/acc_c=52.08 os/recall_knw=58.91 os/recall_unk=69.70 total/acc_i=49.23 total/acc_c=40.11 total/h_score=49.71\n",
      "selected:  cs/acc_i=49.10 cs/acc_c=50.97 os/recall_knw=49.61 os/recall_unk=79.66 total/acc_i=50.80 total/acc_c=36.67 total/h_score=48.16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 2.3578204917701293\n",
      "Loss: 0.9085808179595254\n",
      "Loss: 0.543587350290575\n",
      "Loss: 0.4237955433207673\n",
      "Loss: 0.35773288197331615\n",
      "Loss: 0.3024011503147098\n",
      "Loss: 0.27845899559138143\n",
      "Loss: 0.259097023459869\n",
      "Loss: 0.2319188236190385\n",
      "Loss: 0.2066170731922249\n",
      "______\n",
      "Iteration t=4\n",
      "all:  cs/acc_i=50.19 cs/acc_c=51.67 os/recall_knw=58.75 os/recall_unk=69.90 total/acc_i=49.31 total/acc_c=40.12 total/h_score=49.76\n",
      "selected:  cs/acc_i=48.36 cs/acc_c=50.27 os/recall_knw=54.08 os/recall_unk=74.43 total/acc_i=49.31 total/acc_c=37.80 total/h_score=48.50\n",
      "Loss: 2.3315697329667593\n",
      "Loss: 0.8643299827189861\n",
      "Loss: 0.5221421944278899\n",
      "Loss: 0.4048183151362348\n",
      "Loss: 0.3392392988026884\n",
      "Loss: 0.30651239624161936\n",
      "Loss: 0.2683153066521364\n",
      "Loss: 0.23764984761036284\n",
      "Loss: 0.21723622437643808\n",
      "Loss: 0.19649168369804676\n",
      "______\n",
      "Iteration t=5\n",
      "all:  cs/acc_i=51.02 cs/acc_c=52.67 os/recall_knw=58.26 os/recall_unk=70.09 total/acc_i=49.26 total/acc_c=39.98 total/h_score=49.68\n",
      "selected:  cs/acc_i=50.16 cs/acc_c=52.20 os/recall_knw=56.49 os/recall_unk=71.83 total/acc_i=49.12 total/acc_c=39.13 total/h_score=49.27\n",
      "Loss: 2.296742698441633\n",
      "Loss: 0.8334950822808964\n",
      "Loss: 0.5169732580904053\n",
      "Loss: 0.4071778681596764\n",
      "Loss: 0.3340387538920047\n",
      "Loss: 0.29349335038710217\n",
      "Loss: 0.26589697143930174\n",
      "Loss: 0.24267141002151166\n",
      "Loss: 0.2147353431624681\n",
      "Loss: 0.19248103655060292\n",
      "______\n",
      "Iteration t=6\n",
      "all:  cs/acc_i=51.70 cs/acc_c=53.28 os/recall_knw=58.11 os/recall_unk=70.22 total/acc_i=49.28 total/acc_c=39.96 total/h_score=49.69\n",
      "selected:  cs/acc_i=51.17 cs/acc_c=52.97 os/recall_knw=57.49 os/recall_unk=71.01 total/acc_i=49.13 total/acc_c=39.55 total/h_score=49.49\n",
      "Loss: 2.2902195472717284\n",
      "Loss: 0.8319453517198563\n",
      "Loss: 0.5180053328871727\n",
      "Loss: 0.41517860746383667\n",
      "Loss: 0.33775450015068054\n",
      "Loss: 0.29474703496694565\n",
      "Loss: 0.2639920745790005\n",
      "Loss: 0.23932562324404716\n",
      "Loss: 0.2090515081882477\n",
      "Loss: 0.19846566402912139\n",
      "______\n",
      "Iteration t=7\n",
      "all:  cs/acc_i=50.04 cs/acc_c=51.62 os/recall_knw=58.00 os/recall_unk=70.29 total/acc_i=49.23 total/acc_c=39.86 total/h_score=49.62\n",
      "selected:  cs/acc_i=50.04 cs/acc_c=51.62 os/recall_knw=58.00 os/recall_unk=70.38 total/acc_i=49.26 total/acc_c=39.87 total/h_score=49.64\n",
      "Loss: 2.293045851338907\n",
      "Loss: 0.8356262728037587\n",
      "Loss: 0.5159216688804893\n",
      "Loss: 0.3793784494834592\n",
      "Loss: 0.3212938867657783\n",
      "Loss: 0.2867406565710843\n",
      "Loss: 0.25683103270264734\n",
      "Loss: 0.237329906245983\n",
      "Loss: 0.2151085713588859\n",
      "Loss: 0.18950557385931213\n",
      "______\n",
      "Iteration t=8\n",
      "all:  cs/acc_i=50.98 cs/acc_c=52.58 os/recall_knw=58.00 os/recall_unk=70.29 total/acc_i=49.23 total/acc_c=39.86 total/h_score=49.62\n",
      "selected:  cs/acc_i=50.98 cs/acc_c=52.58 os/recall_knw=58.00 os/recall_unk=70.29 total/acc_i=49.23 total/acc_c=39.86 total/h_score=49.62\n",
      "Loss: 2.312119256452735\n",
      "Loss: 0.8318443561930106\n",
      "Loss: 0.5036868970113921\n",
      "Loss: 0.3978219513161724\n",
      "Loss: 0.32542920652851165\n",
      "Loss: 0.2981091125968443\n",
      "Loss: 0.2520558967058402\n",
      "Loss: 0.23706081940002174\n",
      "Loss: 0.2142614571162429\n",
      "Loss: 0.19497132728774233\n",
      "______\n",
      "Iteration t=9\n",
      "all:  cs/acc_i=51.06 cs/acc_c=52.76 os/recall_knw=58.00 os/recall_unk=70.29 total/acc_i=49.23 total/acc_c=39.86 total/h_score=49.62\n",
      "selected:  cs/acc_i=51.06 cs/acc_c=52.76 os/recall_knw=58.00 os/recall_unk=70.29 total/acc_i=49.23 total/acc_c=39.86 total/h_score=49.62\n",
      "tensor(0)\n",
      "all:  cs/acc_i=51.06 cs/acc_c=52.76 os/recall_knw=58.00 os/recall_unk=70.29 total/acc_i=49.23 total/acc_c=39.86 total/h_score=49.62\n",
      "painting -> sketch lr= 0.001 seed= 0\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19]\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20]\n",
      "Loss: 2.562185294413693\n",
      "Loss: 1.2391435724717599\n",
      "Loss: 0.737465520069082\n",
      "Loss: 0.5634288067224795\n",
      "Loss: 0.49935011967780096\n",
      "Loss: 0.4284557397403414\n",
      "Loss: 0.3857264881805768\n",
      "Loss: 0.35486517988500144\n",
      "Loss: 0.3285166914500887\n",
      "Loss: 0.27480438808915475\n",
      "tensor(True) tensor(True)\n",
      "______\n",
      "Iteration t=1\n",
      "all:  cs/acc_i=51.74 cs/acc_c=53.20 os/recall_knw=94.79 os/recall_unk=18.26 total/acc_i=38.92 total/acc_c=50.71 total/h_score=27.07\n",
      "selected:  cs/acc_i=61.18 cs/acc_c=62.95 os/recall_knw=75.31 os/recall_unk=83.78 total/acc_i=66.93 total/acc_c=59.93 total/h_score=69.06\n",
      "Loss: 2.4738332243526684\n",
      "Loss: 1.0739056193361096\n",
      "Loss: 0.6293202321611199\n",
      "Loss: 0.516608948874123\n",
      "Loss: 0.4286814126021722\n",
      "Loss: 0.3821355535411367\n",
      "Loss: 0.34093289479028943\n",
      "Loss: 0.30037079729578076\n",
      "Loss: 0.28858640065014945\n",
      "Loss: 0.24417634125725896\n",
      "______\n",
      "Iteration t=2\n",
      "all:  cs/acc_i=50.72 cs/acc_c=52.30 os/recall_knw=69.77 os/recall_unk=57.59 total/acc_i=47.89 total/acc_c=44.60 total/h_score=49.85\n",
      "selected:  cs/acc_i=48.41 cs/acc_c=50.08 os/recall_knw=49.11 os/recall_unk=84.21 total/acc_i=54.18 total/acc_c=38.18 total/h_score=50.32\n",
      "Loss: 2.42566957440945\n",
      "Loss: 0.9839385467658349\n",
      "Loss: 0.5860366325039382\n",
      "Loss: 0.45452263260926673\n",
      "Loss: 0.3795197415720979\n",
      "Loss: 0.3258461380428677\n",
      "Loss: 0.3026636019690868\n",
      "Loss: 0.2654152925066445\n",
      "Loss: 0.2459604200146614\n",
      "Loss: 0.23982222949009424\n",
      "______\n",
      "Iteration t=3\n",
      "all:  cs/acc_i=50.60 cs/acc_c=52.11 os/recall_knw=65.77 os/recall_unk=63.29 total/acc_i=48.97 total/acc_c=43.24 total/h_score=50.66\n",
      "selected:  cs/acc_i=49.20 cs/acc_c=50.75 os/recall_knw=54.51 os/recall_unk=78.36 total/acc_i=52.23 total/acc_c=39.60 total/h_score=50.88\n",
      "Loss: 2.3536640751413453\n",
      "Loss: 0.8920331957278314\n",
      "Loss: 0.5430692354321995\n",
      "Loss: 0.421454732648996\n",
      "Loss: 0.3603616189453509\n",
      "Loss: 0.31935101089539464\n",
      "Loss: 0.29239976164195447\n",
      "Loss: 0.25661508776086234\n",
      "Loss: 0.22210241357485452\n",
      "Loss: 0.21046648180975028\n",
      "______\n",
      "Iteration t=4\n",
      "all:  cs/acc_i=50.72 cs/acc_c=52.34 os/recall_knw=62.79 os/recall_unk=66.95 total/acc_i=49.59 total/acc_c=42.32 total/h_score=50.92\n",
      "selected:  cs/acc_i=49.34 cs/acc_c=51.38 os/recall_knw=57.81 os/recall_unk=74.02 total/acc_i=50.58 total/acc_c=40.41 total/h_score=50.85\n",
      "Loss: 2.3117207791194443\n",
      "Loss: 0.8830441415063606\n",
      "Loss: 0.5228416589666004\n",
      "Loss: 0.406704720571514\n",
      "Loss: 0.339401025509785\n",
      "Loss: 0.3006383291761245\n",
      "Loss: 0.2697010003953926\n",
      "Loss: 0.2395199618864158\n",
      "Loss: 0.22816000355422988\n",
      "Loss: 0.2059874284612246\n",
      "______\n",
      "Iteration t=5\n",
      "all:  cs/acc_i=50.00 cs/acc_c=51.55 os/recall_knw=62.45 os/recall_unk=67.28 total/acc_i=49.62 total/acc_c=42.18 total/h_score=50.89\n",
      "selected:  cs/acc_i=48.61 cs/acc_c=50.49 os/recall_knw=60.42 os/recall_unk=69.60 total/acc_i=49.36 total/acc_c=40.81 total/h_score=50.29\n",
      "Loss: 2.276969532567666\n",
      "Loss: 0.835974781043026\n",
      "Loss: 0.49722808059230744\n",
      "Loss: 0.38175626063489343\n",
      "Loss: 0.3355578165278729\n",
      "Loss: 0.2963840080447406\n",
      "Loss: 0.24586017043942\n",
      "Loss: 0.23972101888036823\n",
      "Loss: 0.21667907237116085\n",
      "Loss: 0.20335203113843245\n",
      "______\n",
      "Iteration t=6\n",
      "all:  cs/acc_i=50.00 cs/acc_c=51.58 os/recall_knw=62.38 os/recall_unk=67.47 total/acc_i=49.69 total/acc_c=42.19 total/h_score=50.95\n",
      "selected:  cs/acc_i=49.19 cs/acc_c=51.06 os/recall_knw=61.51 os/recall_unk=68.23 total/acc_i=49.38 total/acc_c=41.57 total/h_score=50.62\n",
      "Loss: 2.2849971501846014\n",
      "Loss: 0.8163746988444817\n",
      "Loss: 0.4892808012957648\n",
      "Loss: 0.37334027780791906\n",
      "Loss: 0.3209044615056102\n",
      "Loss: 0.28698090807072757\n",
      "Loss: 0.25877076968198687\n",
      "Loss: 0.21764026239045023\n",
      "Loss: 0.21090521079700764\n",
      "Loss: 0.1895593025054284\n",
      "______\n",
      "Iteration t=7\n",
      "all:  cs/acc_i=51.51 cs/acc_c=53.08 os/recall_knw=62.38 os/recall_unk=67.47 total/acc_i=49.69 total/acc_c=42.19 total/h_score=50.95\n",
      "selected:  cs/acc_i=51.38 cs/acc_c=53.00 os/recall_knw=62.25 os/recall_unk=67.56 total/acc_i=49.63 total/acc_c=42.09 total/h_score=50.89\n",
      "Loss: 2.274145151488483\n",
      "Loss: 0.8156185584375635\n",
      "Loss: 0.5136988842277788\n",
      "Loss: 0.3971478777821176\n",
      "Loss: 0.3312944429926574\n",
      "Loss: 0.2807049982075114\n",
      "Loss: 0.26184263272443786\n",
      "Loss: 0.24193508707685396\n",
      "Loss: 0.2099400940205669\n",
      "Loss: 0.18508486906648614\n",
      "______\n",
      "Iteration t=8\n",
      "all:  cs/acc_i=50.64 cs/acc_c=52.37 os/recall_knw=62.38 os/recall_unk=67.47 total/acc_i=49.66 total/acc_c=42.16 total/h_score=50.93\n",
      "selected:  cs/acc_i=50.64 cs/acc_c=52.37 os/recall_knw=62.38 os/recall_unk=67.47 total/acc_i=49.66 total/acc_c=42.16 total/h_score=50.93\n",
      "Loss: 2.294862607959658\n",
      "Loss: 0.8001947794109583\n",
      "Loss: 0.4921945314272307\n",
      "Loss: 0.39043719781329855\n",
      "Loss: 0.32639458565972745\n",
      "Loss: 0.2735431047331076\n",
      "Loss: 0.2528222387918504\n",
      "Loss: 0.2214937722819741\n",
      "Loss: 0.20437619907897897\n",
      "Loss: 0.18810512688651215\n",
      "______\n",
      "Iteration t=9\n",
      "all:  cs/acc_i=51.51 cs/acc_c=53.08 os/recall_knw=62.38 os/recall_unk=67.47 total/acc_i=49.66 total/acc_c=42.16 total/h_score=50.93\n",
      "selected:  cs/acc_i=51.51 cs/acc_c=53.08 os/recall_knw=62.38 os/recall_unk=67.47 total/acc_i=49.66 total/acc_c=42.16 total/h_score=50.93\n",
      "tensor(0)\n",
      "all:  cs/acc_i=51.51 cs/acc_c=53.08 os/recall_knw=62.38 os/recall_unk=67.47 total/acc_i=49.66 total/acc_c=42.16 total/h_score=50.93\n",
      "painting -> sketch lr= 0.001 seed= 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19]\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20]\n",
      "Loss: 2.5568915542471347\n",
      "Loss: 1.1907231205354922\n",
      "Loss: 0.7529492189013769\n",
      "Loss: 0.5739526587030875\n",
      "Loss: 0.49307521271011817\n",
      "Loss: 0.42986587730665055\n",
      "Loss: 0.3767766358045043\n",
      "Loss: 0.3366951968461748\n",
      "Loss: 0.3135499755541484\n",
      "Loss: 0.2941078679665687\n",
      "tensor(True) tensor(True)\n",
      "______\n",
      "Iteration t=1\n",
      "all:  cs/acc_i=49.70 cs/acc_c=51.18 os/recall_knw=93.43 os/recall_unk=15.90 total/acc_i=36.43 total/acc_c=48.13 total/h_score=24.10\n",
      "selected:  cs/acc_i=55.61 cs/acc_c=57.43 os/recall_knw=69.95 os/recall_unk=77.88 total/acc_i=59.15 total/acc_c=52.42 total/h_score=61.75\n",
      "Loss: 2.4622244303132974\n",
      "Loss: 1.0625326551643073\n",
      "Loss: 0.6240640640550968\n",
      "Loss: 0.482632785012909\n",
      "Loss: 0.42089775438402216\n",
      "Loss: 0.38379804563580777\n",
      "Loss: 0.3408938870199171\n",
      "Loss: 0.3012451360951744\n",
      "Loss: 0.27480598462416844\n",
      "Loss: 0.25353210381067853\n",
      "______\n",
      "Iteration t=2\n",
      "all:  cs/acc_i=51.66 cs/acc_c=53.25 os/recall_knw=64.57 os/recall_unk=64.01 total/acc_i=49.09 total/acc_c=43.01 total/h_score=50.69\n",
      "selected:  cs/acc_i=49.21 cs/acc_c=50.83 os/recall_knw=45.38 os/recall_unk=86.02 total/acc_i=53.50 total/acc_c=36.20 total/h_score=48.44\n",
      "Loss: 2.420238825706167\n",
      "Loss: 1.0057732477920864\n",
      "Loss: 0.576715272911098\n",
      "Loss: 0.46203170450182135\n",
      "Loss: 0.37709113900814584\n",
      "Loss: 0.3508114380368946\n",
      "Loss: 0.3060417563201637\n",
      "Loss: 0.2697042827964376\n",
      "Loss: 0.26535771814508174\n",
      "Loss: 0.2119651997820773\n",
      "______\n",
      "Iteration t=3\n",
      "all:  cs/acc_i=50.42 cs/acc_c=52.02 os/recall_knw=60.79 os/recall_unk=68.26 total/acc_i=49.38 total/acc_c=41.26 total/h_score=50.37\n",
      "selected:  cs/acc_i=48.24 cs/acc_c=49.93 os/recall_knw=51.15 os/recall_unk=79.80 total/acc_i=51.05 total/acc_c=37.23 total/h_score=48.75\n",
      "Loss: 2.3720351622734235\n",
      "Loss: 0.907177039942184\n",
      "Loss: 0.5445832795911021\n",
      "Loss: 0.43072905201158485\n",
      "Loss: 0.3639666060413117\n",
      "Loss: 0.31852680470520284\n",
      "Loss: 0.2849865659458555\n",
      "Loss: 0.2686178966453581\n",
      "Loss: 0.2215675384419047\n",
      "Loss: 0.20846813107594783\n",
      "______\n",
      "Iteration t=4\n",
      "all:  cs/acc_i=50.23 cs/acc_c=51.82 os/recall_knw=59.43 os/recall_unk=69.50 total/acc_i=49.40 total/acc_c=40.65 total/h_score=50.13\n",
      "selected:  cs/acc_i=48.52 cs/acc_c=50.40 os/recall_knw=54.64 os/recall_unk=75.43 total/acc_i=49.84 total/acc_c=38.41 total/h_score=49.25\n",
      "Loss: 2.328897214929263\n",
      "Loss: 0.8625178970396519\n",
      "Loss: 0.5225525754814346\n",
      "Loss: 0.40657014946142833\n",
      "Loss: 0.3432035137278338\n",
      "Loss: 0.3034044495162865\n",
      "Loss: 0.2765314026114841\n",
      "Loss: 0.24435094747071465\n",
      "Loss: 0.2187020087847486\n",
      "Loss: 0.2082164089505871\n",
      "______\n",
      "Iteration t=5\n",
      "all:  cs/acc_i=50.91 cs/acc_c=52.47 os/recall_knw=58.91 os/recall_unk=70.16 total/acc_i=49.47 total/acc_c=40.43 total/h_score=50.08\n",
      "selected:  cs/acc_i=49.90 cs/acc_c=51.74 os/recall_knw=57.44 os/recall_unk=71.37 total/acc_i=49.13 total/acc_c=39.44 total/h_score=49.46\n",
      "Loss: 2.314619017224158\n",
      "Loss: 0.8284210750172215\n",
      "Loss: 0.5143116118326303\n",
      "Loss: 0.39841387562093233\n",
      "Loss: 0.3421752095042217\n",
      "Loss: 0.3099433051482324\n",
      "Loss: 0.263779045953866\n",
      "Loss: 0.22964132390916348\n",
      "Loss: 0.2087710155925203\n",
      "Loss: 0.18732325764252775\n",
      "______\n",
      "Iteration t=6\n",
      "all:  cs/acc_i=51.32 cs/acc_c=53.07 os/recall_knw=58.64 os/recall_unk=70.29 total/acc_i=49.40 total/acc_c=40.24 total/h_score=49.95\n",
      "selected:  cs/acc_i=51.08 cs/acc_c=52.97 os/recall_knw=58.28 os/recall_unk=70.52 total/acc_i=49.30 total/acc_c=40.04 total/h_score=49.82\n",
      "Loss: 2.3011905239872723\n",
      "Loss: 0.8347023165083501\n",
      "Loss: 0.48794225855652557\n",
      "Loss: 0.3970916783548446\n",
      "Loss: 0.34083034899605225\n",
      "Loss: 0.28836848129670456\n",
      "Loss: 0.2603421590895767\n",
      "Loss: 0.2169646135275345\n",
      "Loss: 0.22137664400961293\n",
      "Loss: 0.19272802124519747\n",
      "______\n",
      "Iteration t=7\n",
      "all:  cs/acc_i=51.70 cs/acc_c=53.31 os/recall_knw=58.60 os/recall_unk=70.29 total/acc_i=49.38 total/acc_c=40.20 total/h_score=49.92\n",
      "selected:  cs/acc_i=51.72 cs/acc_c=53.33 os/recall_knw=58.59 os/recall_unk=70.29 total/acc_i=49.39 total/acc_c=40.22 total/h_score=49.93\n",
      "Loss: 2.3062961882068995\n",
      "Loss: 0.8203476322075677\n",
      "Loss: 0.5052318034309243\n",
      "Loss: 0.40707547063865357\n",
      "Loss: 0.31497331862411804\n",
      "Loss: 0.29518310552729027\n",
      "Loss: 0.2712566176251996\n",
      "Loss: 0.2245213302325398\n",
      "Loss: 0.2192489822942113\n",
      "Loss: 0.1831890706135522\n",
      "______\n",
      "Iteration t=8\n",
      "all:  cs/acc_i=51.17 cs/acc_c=52.75 os/recall_knw=58.60 os/recall_unk=70.29 total/acc_i=49.38 total/acc_c=40.20 total/h_score=49.92\n",
      "selected:  cs/acc_i=51.17 cs/acc_c=52.75 os/recall_knw=58.60 os/recall_unk=70.29 total/acc_i=49.38 total/acc_c=40.20 total/h_score=49.92\n",
      "Loss: 2.2876476664391774\n",
      "Loss: 0.8557787049147818\n",
      "Loss: 0.5070188308637293\n",
      "Loss: 0.38915848986260476\n",
      "Loss: 0.32903856450011804\n",
      "Loss: 0.29046800697133657\n",
      "Loss: 0.260994535885633\n",
      "Loss: 0.2287496831711559\n",
      "Loss: 0.21314388166166962\n",
      "Loss: 0.1881842839915956\n",
      "______\n",
      "Iteration t=9\n",
      "all:  cs/acc_i=51.40 cs/acc_c=53.07 os/recall_knw=58.60 os/recall_unk=70.29 total/acc_i=49.38 total/acc_c=40.20 total/h_score=49.92\n",
      "selected:  cs/acc_i=51.40 cs/acc_c=53.07 os/recall_knw=58.60 os/recall_unk=70.29 total/acc_i=49.38 total/acc_c=40.20 total/h_score=49.92\n",
      "tensor(0)\n",
      "all:  cs/acc_i=51.40 cs/acc_c=53.07 os/recall_knw=58.60 os/recall_unk=70.29 total/acc_i=49.38 total/acc_c=40.20 total/h_score=49.92\n",
      "painting -> sketch lr= 0.001 seed= 2\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19]\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20]\n",
      "Loss: 2.5674283435105014\n",
      "Loss: 1.2376821242943012\n",
      "Loss: 0.7064563110076562\n",
      "Loss: 0.5787383041999958\n",
      "Loss: 0.47562234434816575\n",
      "Loss: 0.4229282886578292\n",
      "Loss: 0.3789292455665649\n",
      "Loss: 0.3437526259551603\n",
      "Loss: 0.3024895889339624\n",
      "Loss: 0.2853596146617617\n",
      "tensor(True) tensor(True)\n",
      "______\n",
      "Iteration t=1\n",
      "all:  cs/acc_i=50.19 cs/acc_c=51.80 os/recall_knw=93.81 os/recall_unk=16.56 total/acc_i=37.03 total/acc_c=48.79 total/h_score=24.93\n",
      "selected:  cs/acc_i=56.64 cs/acc_c=58.93 os/recall_knw=71.33 os/recall_unk=79.56 total/acc_i=60.79 total/acc_c=53.95 total/h_score=63.38\n",
      "Loss: 2.4660240066986456\n",
      "Loss: 1.0710800725455378\n",
      "Loss: 0.6531813168058208\n",
      "Loss: 0.5099537652351108\n",
      "Loss: 0.42748119112323313\n",
      "Loss: 0.38022865581454013\n",
      "Loss: 0.3415558624501322\n",
      "Loss: 0.3011627745832883\n",
      "Loss: 0.27994649915718567\n",
      "Loss: 0.25204918303472157\n",
      "______\n",
      "Iteration t=2\n",
      "all:  cs/acc_i=51.06 cs/acc_c=52.46 os/recall_knw=65.02 os/recall_unk=64.14 total/acc_i=49.09 total/acc_c=42.93 total/h_score=50.67\n",
      "selected:  cs/acc_i=48.08 cs/acc_c=49.71 os/recall_knw=45.31 os/recall_unk=85.29 total/acc_i=53.20 total/acc_c=35.60 total/h_score=47.71\n",
      "Loss: 2.4077843903401575\n",
      "Loss: 0.9730214975569227\n",
      "Loss: 0.5726029484643849\n",
      "Loss: 0.44555772164272606\n",
      "Loss: 0.37398291150227597\n",
      "Loss: 0.3454555813735778\n",
      "Loss: 0.3110209807685209\n",
      "Loss: 0.27422303019450345\n",
      "Loss: 0.2503024043703298\n",
      "Loss: 0.20928019056216293\n",
      "______\n",
      "Iteration t=3\n",
      "all:  cs/acc_i=51.58 cs/acc_c=53.12 os/recall_knw=59.21 os/recall_unk=71.34 total/acc_i=50.53 total/acc_c=41.30 total/h_score=51.10\n",
      "selected:  cs/acc_i=49.72 cs/acc_c=51.71 os/recall_knw=49.58 os/recall_unk=80.38 total/acc_i=51.71 total/acc_c=37.50 total/h_score=49.11\n",
      "Loss: 2.3631053868826335\n",
      "Loss: 0.8974741198025741\n",
      "Loss: 0.5419864159770859\n",
      "Loss: 0.4309806114796436\n",
      "Loss: 0.3799041002924308\n",
      "Loss: 0.323375837659681\n",
      "Loss: 0.29109645302677567\n",
      "Loss: 0.2606675834495784\n",
      "Loss: 0.23462617145730302\n",
      "Loss: 0.20788281981821183\n",
      "______\n",
      "Iteration t=4\n",
      "all:  cs/acc_i=50.94 cs/acc_c=52.38 os/recall_knw=58.26 os/recall_unk=71.99 total/acc_i=50.36 total/acc_c=40.72 total/h_score=50.72\n",
      "selected:  cs/acc_i=48.94 cs/acc_c=50.83 os/recall_knw=54.05 os/recall_unk=75.97 total/acc_i=50.12 total/acc_c=38.28 total/h_score=49.22\n",
      "Loss: 2.3224432141949034\n",
      "Loss: 0.8727547400225247\n",
      "Loss: 0.5223980281981195\n",
      "Loss: 0.41757509180371694\n",
      "Loss: 0.3640851192640071\n",
      "Loss: 0.3087559827135806\n",
      "Loss: 0.2726407272439775\n",
      "Loss: 0.24965972267864156\n",
      "Loss: 0.22299750957684397\n",
      "Loss: 0.19244086173560115\n",
      "______\n",
      "Iteration t=5\n",
      "all:  cs/acc_i=50.34 cs/acc_c=51.91 os/recall_knw=58.26 os/recall_unk=72.12 total/acc_i=50.41 total/acc_c=40.73 total/h_score=50.76\n",
      "selected:  cs/acc_i=48.86 cs/acc_c=50.87 os/recall_knw=56.63 os/recall_unk=73.42 total/acc_i=49.81 total/acc_c=39.40 total/h_score=49.82\n",
      "Loss: 2.3164841568904366\n",
      "Loss: 0.8232084915705538\n",
      "Loss: 0.5012391840036099\n",
      "Loss: 0.41686452864876644\n",
      "Loss: 0.34663296128936144\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.30385877198053274\n",
      "Loss: 0.26980318367360573\n",
      "Loss: 0.22329192536954695\n",
      "Loss: 0.212637059300052\n",
      "Loss: 0.19209236582281136\n",
      "______\n",
      "Iteration t=6\n",
      "all:  cs/acc_i=50.64 cs/acc_c=52.19 os/recall_knw=58.15 os/recall_unk=72.25 total/acc_i=50.43 total/acc_c=40.69 total/h_score=50.75\n",
      "selected:  cs/acc_i=50.13 cs/acc_c=51.90 os/recall_knw=57.56 os/recall_unk=72.58 total/acc_i=50.19 total/acc_c=40.28 total/h_score=50.46\n",
      "Loss: 2.2932097217644074\n",
      "Loss: 0.8389960107315018\n",
      "Loss: 0.5033925621504765\n",
      "Loss: 0.40432140051600446\n",
      "Loss: 0.3420107688111474\n",
      "Loss: 0.2990867959477576\n",
      "Loss: 0.2545259237349273\n",
      "Loss: 0.2177886770492098\n",
      "Loss: 0.21709640012926845\n",
      "Loss: 0.18729490719466324\n",
      "______\n",
      "Iteration t=7\n",
      "all:  cs/acc_i=51.02 cs/acc_c=52.67 os/recall_knw=58.11 os/recall_unk=72.25 total/acc_i=50.41 total/acc_c=40.66 total/h_score=50.72\n",
      "selected:  cs/acc_i=51.02 cs/acc_c=52.67 os/recall_knw=58.11 os/recall_unk=72.25 total/acc_i=50.41 total/acc_c=40.66 total/h_score=50.72\n",
      "Loss: 2.3062595353126527\n",
      "Loss: 0.8405897624492645\n",
      "Loss: 0.5113624913692474\n",
      "Loss: 0.39334326654672624\n",
      "Loss: 0.33891526553034784\n",
      "Loss: 0.2876198980212212\n",
      "Loss: 0.2639604347795248\n",
      "Loss: 0.23060117823630571\n",
      "Loss: 0.20489855711162092\n",
      "Loss: 0.1941169586405158\n",
      "______\n",
      "Iteration t=8\n",
      "all:  cs/acc_i=51.32 cs/acc_c=52.88 os/recall_knw=58.11 os/recall_unk=72.25 total/acc_i=50.41 total/acc_c=40.66 total/h_score=50.72\n",
      "selected:  cs/acc_i=51.32 cs/acc_c=52.88 os/recall_knw=58.11 os/recall_unk=72.25 total/acc_i=50.41 total/acc_c=40.66 total/h_score=50.72\n",
      "Loss: 2.298973058223724\n",
      "Loss: 0.831928807258606\n",
      "Loss: 0.5227908816933632\n",
      "Loss: 0.4077626259922981\n",
      "Loss: 0.34079399111866954\n",
      "Loss: 0.29768731927871706\n",
      "Loss: 0.25839730809628964\n",
      "Loss: 0.22655998043715952\n",
      "Loss: 0.21410329669713973\n",
      "Loss: 0.1901979623362422\n",
      "______\n",
      "Iteration t=9\n",
      "all:  cs/acc_i=51.43 cs/acc_c=52.94 os/recall_knw=58.11 os/recall_unk=72.25 total/acc_i=50.41 total/acc_c=40.66 total/h_score=50.72\n",
      "selected:  cs/acc_i=51.43 cs/acc_c=52.94 os/recall_knw=58.11 os/recall_unk=72.25 total/acc_i=50.41 total/acc_c=40.66 total/h_score=50.72\n",
      "tensor(0)\n",
      "all:  cs/acc_i=51.43 cs/acc_c=52.94 os/recall_knw=58.11 os/recall_unk=72.25 total/acc_i=50.41 total/acc_c=40.66 total/h_score=50.72\n",
      "painting -> sketch lr= 0.001 seed= 3\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19]\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20]\n",
      "Loss: 2.5585256833878773\n",
      "Loss: 1.227436272555558\n",
      "Loss: 0.7312750947223139\n",
      "Loss: 0.555393077236004\n",
      "Loss: 0.5085687174525841\n",
      "Loss: 0.423176247291464\n",
      "Loss: 0.38356660937190684\n",
      "Loss: 0.3522429910917131\n",
      "Loss: 0.3044144516938893\n",
      "Loss: 0.2883693318439539\n",
      "tensor(True) tensor(True)\n",
      "______\n",
      "Iteration t=1\n",
      "all:  cs/acc_i=50.49 cs/acc_c=51.76 os/recall_knw=94.00 os/recall_unk=16.88 total/acc_i=37.29 total/acc_c=48.73 total/h_score=25.29\n",
      "selected:  cs/acc_i=58.51 cs/acc_c=59.31 os/recall_knw=72.40 os/recall_unk=81.90 total/acc_i=62.51 total/acc_c=54.31 total/h_score=64.30\n",
      "Loss: 2.4788570123560287\n",
      "Loss: 1.055553452787446\n",
      "Loss: 0.641741839547952\n",
      "Loss: 0.4902070106244555\n",
      "Loss: 0.4252728293923771\n",
      "Loss: 0.3708690707297886\n",
      "Loss: 0.34005626123033317\n",
      "Loss: 0.3013148444029046\n",
      "Loss: 0.2799533909807603\n",
      "Loss: 0.26505956448176327\n",
      "______\n",
      "Iteration t=2\n",
      "all:  cs/acc_i=51.32 cs/acc_c=52.66 os/recall_knw=67.96 os/recall_unk=61.19 total/acc_i=48.73 total/acc_c=43.84 total/h_score=50.49\n",
      "selected:  cs/acc_i=49.17 cs/acc_c=50.81 os/recall_knw=47.69 os/recall_unk=85.31 total/acc_i=54.21 total/acc_c=37.43 total/h_score=49.67\n",
      "Loss: 2.4256574068594414\n",
      "Loss: 0.987766088832409\n",
      "Loss: 0.5909453015261834\n",
      "Loss: 0.45688740307584813\n",
      "Loss: 0.39293282643097255\n",
      "Loss: 0.350434270713034\n",
      "Loss: 0.2998497547974827\n",
      "Loss: 0.26821760684593554\n",
      "Loss: 0.24342581506716002\n",
      "Loss: 0.21831555268086425\n",
      "______\n",
      "Iteration t=3\n",
      "all:  cs/acc_i=50.60 cs/acc_c=52.09 os/recall_knw=63.85 os/recall_unk=65.12 total/acc_i=49.19 total/acc_c=42.50 total/h_score=50.59\n",
      "selected:  cs/acc_i=48.84 cs/acc_c=50.73 os/recall_knw=52.88 os/recall_unk=78.66 total/acc_i=51.76 total/acc_c=38.86 total/h_score=50.20\n",
      "Loss: 2.362564301593995\n",
      "Loss: 0.9006630102277318\n",
      "Loss: 0.5477148173820405\n",
      "Loss: 0.4207946542666588\n",
      "Loss: 0.3633042436528516\n",
      "Loss: 0.3243138956881705\n",
      "Loss: 0.2871838169115962\n",
      "Loss: 0.26090919956951947\n",
      "Loss: 0.2237150359785918\n",
      "Loss: 0.21161498495446138\n",
      "______\n",
      "Iteration t=4\n",
      "all:  cs/acc_i=50.68 cs/acc_c=52.11 os/recall_knw=61.62 os/recall_unk=67.47 total/acc_i=49.59 total/acc_c=41.88 total/h_score=50.70\n",
      "selected:  cs/acc_i=49.07 cs/acc_c=50.98 os/recall_knw=56.22 os/recall_unk=74.49 total/acc_i=50.42 total/acc_c=39.74 total/h_score=50.33\n",
      "Loss: 2.326724071225685\n",
      "Loss: 0.87021536599551\n",
      "Loss: 0.5359046845020595\n",
      "Loss: 0.41673571866824916\n",
      "Loss: 0.359249634583214\n",
      "Loss: 0.29156172859841856\n",
      "Loss: 0.2862122243741736\n",
      "Loss: 0.23433145236115732\n",
      "Loss: 0.22262058804329501\n",
      "Loss: 0.19398311442112032\n",
      "______\n",
      "Iteration t=5\n",
      "all:  cs/acc_i=51.55 cs/acc_c=53.18 os/recall_knw=61.28 os/recall_unk=67.74 total/acc_i=49.57 total/acc_c=41.71 total/h_score=50.62\n",
      "selected:  cs/acc_i=50.44 cs/acc_c=52.47 os/recall_knw=59.19 os/recall_unk=70.26 total/acc_i=49.49 total/acc_c=40.60 total/h_score=50.25\n",
      "Loss: 2.3017447540558966\n",
      "Loss: 0.8433978667699669\n",
      "Loss: 0.5188712798447973\n",
      "Loss: 0.4099853565415225\n",
      "Loss: 0.3367842820334626\n",
      "Loss: 0.2968072409790204\n",
      "Loss: 0.26228731185437204\n",
      "Loss: 0.22524907757120438\n",
      "Loss: 0.205495105824437\n",
      "Loss: 0.19706692811415857\n",
      "______\n",
      "Iteration t=6\n",
      "all:  cs/acc_i=50.49 cs/acc_c=51.99 os/recall_knw=61.28 os/recall_unk=67.74 total/acc_i=49.57 total/acc_c=41.71 total/h_score=50.62\n",
      "selected:  cs/acc_i=49.88 cs/acc_c=51.65 os/recall_knw=60.57 os/recall_unk=68.45 total/acc_i=49.37 total/acc_c=41.23 total/h_score=50.39\n",
      "Loss: 2.288795490981091\n",
      "Loss: 0.8292443913668983\n",
      "Loss: 0.515691964522652\n",
      "Loss: 0.3813699887321872\n",
      "Loss: 0.3515144846008229\n",
      "Loss: 0.29745047571866406\n",
      "Loss: 0.26806955840512225\n",
      "Loss: 0.2382857756976318\n",
      "Loss: 0.20507470715658466\n",
      "Loss: 0.19114036896365433\n",
      "______\n",
      "Iteration t=7\n",
      "all:  cs/acc_i=51.28 cs/acc_c=52.87 os/recall_knw=61.28 os/recall_unk=67.87 total/acc_i=49.62 total/acc_c=41.71 total/h_score=50.65\n",
      "selected:  cs/acc_i=51.30 cs/acc_c=52.91 os/recall_knw=61.21 os/recall_unk=68.00 total/acc_i=49.66 total/acc_c=41.73 total/h_score=50.70\n",
      "Loss: 2.2860616230497173\n",
      "Loss: 0.8298492487739114\n",
      "Loss: 0.49268059327321895\n",
      "Loss: 0.3925580875254145\n",
      "Loss: 0.33481561824971556\n",
      "Loss: 0.282963807442609\n",
      "Loss: 0.2564866973927208\n",
      "Loss: 0.22449513830098453\n",
      "Loss: 0.2137522117910432\n",
      "Loss: 0.20039050890242352\n",
      "______\n",
      "Iteration t=8\n",
      "all:  cs/acc_i=50.79 cs/acc_c=52.41 os/recall_knw=61.28 os/recall_unk=67.87 total/acc_i=49.62 total/acc_c=41.71 total/h_score=50.65\n",
      "selected:  cs/acc_i=50.79 cs/acc_c=52.41 os/recall_knw=61.28 os/recall_unk=67.87 total/acc_i=49.62 total/acc_c=41.71 total/h_score=50.65\n",
      "Loss: 2.293734083923639\n",
      "Loss: 0.8336162549607894\n",
      "Loss: 0.4958671305693832\n",
      "Loss: 0.3911444142753003\n",
      "Loss: 0.34067154666956734\n",
      "Loss: 0.2927516569693883\n",
      "Loss: 0.2558042136477489\n",
      "Loss: 0.2258397208563253\n",
      "Loss: 0.2084201554895616\n",
      "Loss: 0.1862263663434515\n",
      "______\n",
      "Iteration t=9\n",
      "all:  cs/acc_i=50.68 cs/acc_c=52.27 os/recall_knw=61.28 os/recall_unk=67.87 total/acc_i=49.62 total/acc_c=41.71 total/h_score=50.65\n",
      "selected:  cs/acc_i=50.68 cs/acc_c=52.27 os/recall_knw=61.28 os/recall_unk=67.87 total/acc_i=49.62 total/acc_c=41.71 total/h_score=50.65\n",
      "tensor(0)\n",
      "all:  cs/acc_i=50.68 cs/acc_c=52.27 os/recall_knw=61.28 os/recall_unk=67.87 total/acc_i=49.62 total/acc_c=41.71 total/h_score=50.65\n",
      "painting -> sketch lr= 0.001 seed= 4\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19]\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20]\n",
      "Loss: 2.5839912985998486\n",
      "Loss: 1.2231501189489213\n",
      "Loss: 0.7458836942438095\n",
      "Loss: 0.5730314860268245\n",
      "Loss: 0.48669527589328704\n",
      "Loss: 0.41939431125367127\n",
      "Loss: 0.39300223506947674\n",
      "Loss: 0.3517072991167427\n",
      "Loss: 0.3066889376788543\n",
      "Loss: 0.291941982294832\n",
      "tensor(True) tensor(True)\n",
      "______\n",
      "Iteration t=1\n",
      "all:  cs/acc_i=50.19 cs/acc_c=51.70 os/recall_knw=93.66 os/recall_unk=16.30 total/acc_i=37.10 total/acc_c=49.05 total/h_score=24.66\n",
      "selected:  cs/acc_i=56.39 cs/acc_c=58.59 os/recall_knw=70.58 os/recall_unk=77.81 total/acc_i=60.83 total/acc_c=55.34 total/h_score=63.91\n",
      "Loss: 2.48928673360862\n",
      "Loss: 1.0503174796992658\n",
      "Loss: 0.6404609218531964\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.5046743188856864\n",
      "Loss: 0.43092213614898567\n",
      "Loss: 0.39716238543099047\n",
      "Loss: 0.33428581037065563\n",
      "Loss: 0.30504779415387734\n",
      "Loss: 0.28547870053672325\n",
      "Loss: 0.24978093645882374\n",
      "______\n",
      "Iteration t=2\n",
      "all:  cs/acc_i=50.87 cs/acc_c=52.45 os/recall_knw=63.32 os/recall_unk=65.90 total/acc_i=49.09 total/acc_c=42.01 total/h_score=50.41\n",
      "selected:  cs/acc_i=47.99 cs/acc_c=49.67 os/recall_knw=44.27 os/recall_unk=85.85 total/acc_i=52.79 total/acc_c=34.83 total/h_score=46.92\n",
      "Loss: 2.3962243172006867\n",
      "Loss: 0.9933954541562894\n",
      "Loss: 0.5785926861363814\n",
      "Loss: 0.4514591696612332\n",
      "Loss: 0.3730645392329321\n",
      "Loss: 0.3493897864646321\n",
      "Loss: 0.30671199592291765\n",
      "Loss: 0.27920935521705437\n",
      "Loss: 0.2466000009054711\n",
      "Loss: 0.23377023459574497\n",
      "______\n",
      "Iteration t=3\n",
      "all:  cs/acc_i=50.57 cs/acc_c=51.96 os/recall_knw=57.70 os/recall_unk=72.45 total/acc_i=49.90 total/acc_c=39.79 total/h_score=49.99\n",
      "selected:  cs/acc_i=48.81 cs/acc_c=50.54 os/recall_knw=48.63 os/recall_unk=80.74 total/acc_i=50.94 total/acc_c=36.16 total/h_score=47.78\n",
      "Loss: 2.3604880286299665\n",
      "Loss: 0.9193926587052967\n",
      "Loss: 0.551734770640083\n",
      "Loss: 0.4393149534645288\n",
      "Loss: 0.3554055194491925\n",
      "Loss: 0.32860689535737037\n",
      "Loss: 0.2849063351750374\n",
      "Loss: 0.24736410760037278\n",
      "Loss: 0.23889985675721065\n",
      "Loss: 0.20521487410625686\n",
      "______\n",
      "Iteration t=4\n",
      "all:  cs/acc_i=50.68 cs/acc_c=52.16 os/recall_knw=57.66 os/recall_unk=72.51 total/acc_i=49.93 total/acc_c=39.79 total/h_score=50.00\n",
      "selected:  cs/acc_i=49.06 cs/acc_c=51.03 os/recall_knw=52.92 os/recall_unk=76.31 total/acc_i=49.86 total/acc_c=37.60 total/h_score=48.61\n",
      "Loss: 2.3440056749966356\n",
      "Loss: 0.8779153902410962\n",
      "Loss: 0.5483594253721596\n",
      "Loss: 0.3984442055537112\n",
      "Loss: 0.3565887367687964\n",
      "Loss: 0.3236067014820406\n",
      "Loss: 0.28850341513441197\n",
      "Loss: 0.23769806953591283\n",
      "Loss: 0.22586991450901311\n",
      "Loss: 0.20547417097697698\n",
      "______\n",
      "Iteration t=5\n",
      "all:  cs/acc_i=51.66 cs/acc_c=53.11 os/recall_knw=56.83 os/recall_unk=72.84 total/acc_i=49.81 total/acc_c=39.42 total/h_score=49.73\n",
      "selected:  cs/acc_i=50.86 cs/acc_c=52.56 os/recall_knw=55.45 os/recall_unk=74.20 total/acc_i=49.61 total/acc_c=38.56 total/h_score=49.18\n",
      "Loss: 2.30973394469517\n",
      "Loss: 0.8592718384130215\n",
      "Loss: 0.5202370404712553\n",
      "Loss: 0.40249264267523116\n",
      "Loss: 0.3383038325038383\n",
      "Loss: 0.2938140147948653\n",
      "Loss: 0.26525524979442117\n",
      "Loss: 0.23254267780519114\n",
      "Loss: 0.20951692382918624\n",
      "Loss: 0.18752516772810038\n",
      "______\n",
      "Iteration t=6\n",
      "all:  cs/acc_i=50.64 cs/acc_c=52.18 os/recall_knw=56.72 os/recall_unk=72.91 total/acc_i=49.76 total/acc_c=39.31 total/h_score=49.64\n",
      "selected:  cs/acc_i=50.10 cs/acc_c=51.83 os/recall_knw=56.17 os/recall_unk=73.29 total/acc_i=49.50 total/acc_c=38.85 total/h_score=49.29\n",
      "Loss: 2.3021245959304992\n",
      "Loss: 0.8337692980083727\n",
      "Loss: 0.506766522723821\n",
      "Loss: 0.3941991724254143\n",
      "Loss: 0.3485599804309107\n",
      "Loss: 0.2915609671223548\n",
      "Loss: 0.267886909536056\n",
      "Loss: 0.2486604767430934\n",
      "Loss: 0.21299997050194971\n",
      "Loss: 0.1960065887129355\n",
      "______\n",
      "Iteration t=7\n",
      "all:  cs/acc_i=51.28 cs/acc_c=52.77 os/recall_knw=56.72 os/recall_unk=72.91 total/acc_i=49.76 total/acc_c=39.31 total/h_score=49.64\n",
      "selected:  cs/acc_i=51.27 cs/acc_c=52.76 os/recall_knw=56.67 os/recall_unk=72.91 total/acc_i=49.75 total/acc_c=39.29 total/h_score=49.62\n",
      "Loss: 2.3031469272322442\n",
      "Loss: 0.8367085246197191\n",
      "Loss: 0.5128546060926943\n",
      "Loss: 0.4048973702821866\n",
      "Loss: 0.3321057930289502\n",
      "Loss: 0.2941873417830611\n",
      "Loss: 0.2536660166360049\n",
      "Loss: 0.2322178556467874\n",
      "Loss: 0.21904106402253531\n",
      "Loss: 0.19790586624219714\n",
      "______\n",
      "Iteration t=8\n",
      "all:  cs/acc_i=51.06 cs/acc_c=52.69 os/recall_knw=56.72 os/recall_unk=72.91 total/acc_i=49.76 total/acc_c=39.31 total/h_score=49.64\n",
      "selected:  cs/acc_i=51.06 cs/acc_c=52.69 os/recall_knw=56.72 os/recall_unk=72.91 total/acc_i=49.76 total/acc_c=39.31 total/h_score=49.64\n",
      "Loss: 2.3181619055299874\n",
      "Loss: 0.8473183239798948\n",
      "Loss: 0.5079566093094378\n",
      "Loss: 0.38064664718975505\n",
      "Loss: 0.33908588594820605\n",
      "Loss: 0.29032388856133307\n",
      "Loss: 0.253969921853887\n",
      "Loss: 0.23515696283504667\n",
      "Loss: 0.21345798894164553\n",
      "Loss: 0.1904321585045043\n",
      "______\n",
      "Iteration t=9\n",
      "all:  cs/acc_i=51.47 cs/acc_c=53.03 os/recall_knw=56.72 os/recall_unk=72.91 total/acc_i=49.76 total/acc_c=39.31 total/h_score=49.64\n",
      "selected:  cs/acc_i=51.47 cs/acc_c=53.03 os/recall_knw=56.72 os/recall_unk=72.91 total/acc_i=49.76 total/acc_c=39.31 total/h_score=49.64\n",
      "tensor(0)\n",
      "all:  cs/acc_i=51.47 cs/acc_c=53.03 os/recall_knw=56.72 os/recall_unk=72.91 total/acc_i=49.76 total/acc_c=39.31 total/h_score=49.64\n",
      "painting -> sketch lr= 0.001 seed= 0\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19]\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20]\n",
      "Loss: 2.5618820335499195\n",
      "Loss: 1.2399014619292406\n",
      "Loss: 0.739087442557017\n",
      "Loss: 0.564520425424374\n",
      "Loss: 0.5003870582927472\n",
      "Loss: 0.4301820039433777\n",
      "Loss: 0.38649968191902473\n",
      "Loss: 0.3568053200210213\n",
      "Loss: 0.33001904374865626\n",
      "Loss: 0.27567896861878655\n",
      "tensor(True) tensor(True)\n",
      "______\n",
      "Iteration t=1\n",
      "all:  cs/acc_i=51.89 cs/acc_c=53.37 os/recall_knw=82.64 os/recall_unk=38.22 total/acc_i=44.18 total/acc_c=48.65 total/h_score=43.01\n",
      "selected:  cs/acc_i=48.97 cs/acc_c=50.39 os/recall_knw=47.25 os/recall_unk=90.68 total/acc_i=59.23 total/acc_c=40.26 total/h_score=53.30\n",
      "Loss: 2.4729181738460766\n",
      "Loss: 1.0769631327951656\n",
      "Loss: 0.6465641099448297\n",
      "Loss: 0.5217125363209668\n",
      "Loss: 0.4336411886501546\n",
      "Loss: 0.39835528379269675\n",
      "Loss: 0.34437934652555224\n",
      "Loss: 0.30099673854077563\n",
      "Loss: 0.2807087880358392\n",
      "Loss: 0.2601218995839065\n",
      "______\n",
      "Iteration t=2\n",
      "all:  cs/acc_i=50.75 cs/acc_c=52.27 os/recall_knw=61.96 os/recall_unk=67.15 total/acc_i=49.31 total/acc_c=41.58 total/h_score=50.37\n",
      "selected:  cs/acc_i=47.42 cs/acc_c=49.15 os/recall_knw=43.37 os/recall_unk=86.29 total/acc_i=52.51 total/acc_c=34.06 total/h_score=46.10\n",
      "Loss: 2.4340502778324513\n",
      "Loss: 0.9765893000801769\n",
      "Loss: 0.5813861997849351\n",
      "Loss: 0.44845969899805316\n",
      "Loss: 0.38979331793588234\n",
      "Loss: 0.3494916859364838\n",
      "Loss: 0.31910922327036156\n",
      "Loss: 0.26995216084456225\n",
      "Loss: 0.24788909407178744\n",
      "Loss: 0.22859635694516361\n",
      "______\n",
      "Iteration t=3\n",
      "all:  cs/acc_i=50.87 cs/acc_c=52.21 os/recall_knw=57.85 os/recall_unk=71.73 total/acc_i=49.66 total/acc_c=39.74 total/h_score=49.80\n",
      "selected:  cs/acc_i=48.72 cs/acc_c=50.35 os/recall_knw=48.86 os/recall_unk=81.13 total/acc_i=50.66 total/acc_c=35.70 total/h_score=47.35\n",
      "Loss: 2.3680500662845114\n",
      "Loss: 0.9145342059757399\n",
      "Loss: 0.5377009388545285\n",
      "Loss: 0.44957487168519394\n",
      "Loss: 0.37227353667435437\n",
      "Loss: 0.3366805106077505\n",
      "Loss: 0.29519467434805374\n",
      "Loss: 0.2596616791318292\n",
      "Loss: 0.2351856361426737\n",
      "Loss: 0.20448758929320004\n",
      "______\n",
      "Iteration t=4\n",
      "all:  cs/acc_i=50.19 cs/acc_c=51.67 os/recall_knw=57.36 os/recall_unk=72.38 total/acc_i=49.78 total/acc_c=39.58 total/h_score=49.79\n",
      "selected:  cs/acc_i=48.60 cs/acc_c=50.50 os/recall_knw=52.94 os/recall_unk=77.18 total/acc_i=50.00 total/acc_c=37.49 total/h_score=48.64\n",
      "Loss: 2.3335477457884464\n",
      "Loss: 0.8745036454380307\n",
      "Loss: 0.5194055232916915\n",
      "Loss: 0.4212046252197302\n",
      "Loss: 0.3567677162057685\n",
      "Loss: 0.31752517551308396\n",
      "Loss: 0.27763605470063796\n",
      "Loss: 0.24234901649183807\n",
      "Loss: 0.2152603330971307\n",
      "Loss: 0.20458194187152584\n",
      "______\n",
      "Iteration t=5\n",
      "all:  cs/acc_i=50.94 cs/acc_c=52.41 os/recall_knw=56.98 os/recall_unk=72.97 total/acc_i=49.81 total/acc_c=39.32 total/h_score=49.67\n",
      "selected:  cs/acc_i=50.08 cs/acc_c=51.91 os/recall_knw=55.57 os/recall_unk=74.23 total/acc_i=49.56 total/acc_c=38.49 total/h_score=49.12\n",
      "Loss: 2.308935345188389\n",
      "Loss: 0.8368209313328673\n",
      "Loss: 0.5081987566337353\n",
      "Loss: 0.4144525256280492\n",
      "Loss: 0.33627878498982605\n",
      "Loss: 0.3010110563439567\n",
      "Loss: 0.272791452402991\n",
      "Loss: 0.2369137056535337\n",
      "Loss: 0.21758684920283353\n",
      "Loss: 0.19194374392490562\n",
      "______\n",
      "Iteration t=6\n",
      "all:  cs/acc_i=51.28 cs/acc_c=52.88 os/recall_knw=56.75 os/recall_unk=73.10 total/acc_i=49.78 total/acc_c=39.21 total/h_score=49.59\n",
      "selected:  cs/acc_i=50.95 cs/acc_c=52.68 os/recall_knw=56.39 os/recall_unk=73.25 total/acc_i=49.60 total/acc_c=38.93 total/h_score=49.36\n",
      "Loss: 2.320137238790912\n",
      "Loss: 0.8402565496583139\n",
      "Loss: 0.5244720916474058\n",
      "Loss: 0.3879381329301865\n",
      "Loss: 0.3496710582065486\n",
      "Loss: 0.2931485992345598\n",
      "Loss: 0.2585796331085505\n",
      "Loss: 0.2361531999833401\n",
      "Loss: 0.21741747871161468\n",
      "Loss: 0.1926084740177518\n",
      "______\n",
      "Iteration t=7\n",
      "all:  cs/acc_i=50.94 cs/acc_c=52.61 os/recall_knw=56.75 os/recall_unk=73.10 total/acc_i=49.78 total/acc_c=39.21 total/h_score=49.59\n",
      "selected:  cs/acc_i=50.92 cs/acc_c=52.59 os/recall_knw=56.74 os/recall_unk=73.15 total/acc_i=49.78 total/acc_c=39.20 total/h_score=49.58\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 2.3030735038849244\n",
      "Loss: 0.8073698984810627\n",
      "Loss: 0.49920940273497477\n",
      "Loss: 0.40311533398178206\n",
      "Loss: 0.33031652251400623\n",
      "Loss: 0.29627627684888114\n",
      "Loss: 0.27420580010098144\n",
      "Loss: 0.23779358147796856\n",
      "Loss: 0.21918069079039565\n",
      "Loss: 0.19010969459352245\n",
      "______\n",
      "Iteration t=8\n",
      "all:  cs/acc_i=50.79 cs/acc_c=52.32 os/recall_knw=56.75 os/recall_unk=73.10 total/acc_i=49.78 total/acc_c=39.21 total/h_score=49.59\n",
      "selected:  cs/acc_i=50.79 cs/acc_c=52.32 os/recall_knw=56.75 os/recall_unk=73.10 total/acc_i=49.78 total/acc_c=39.21 total/h_score=49.59\n",
      "Loss: 2.31436820824941\n",
      "Loss: 0.8339265194762663\n",
      "Loss: 0.5026109520809717\n",
      "Loss: 0.38916830054248674\n",
      "Loss: 0.3459221311063173\n",
      "Loss: 0.2906259757029005\n",
      "Loss: 0.26520887862546855\n",
      "Loss: 0.2298070312473908\n",
      "Loss: 0.21470577286249662\n",
      "Loss: 0.20650457560896396\n",
      "______\n",
      "Iteration t=9\n",
      "all:  cs/acc_i=50.91 cs/acc_c=52.48 os/recall_knw=56.75 os/recall_unk=73.10 total/acc_i=49.78 total/acc_c=39.21 total/h_score=49.59\n",
      "selected:  cs/acc_i=50.91 cs/acc_c=52.48 os/recall_knw=56.75 os/recall_unk=73.10 total/acc_i=49.78 total/acc_c=39.21 total/h_score=49.59\n",
      "tensor(0)\n",
      "all:  cs/acc_i=50.91 cs/acc_c=52.48 os/recall_knw=56.75 os/recall_unk=73.10 total/acc_i=49.78 total/acc_c=39.21 total/h_score=49.59\n",
      "painting -> sketch lr= 0.001 seed= 1\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19]\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20]\n",
      "Loss: 2.557897247334637\n",
      "Loss: 1.1919563018455708\n",
      "Loss: 0.753025853129291\n",
      "Loss: 0.5741303649055894\n",
      "Loss: 0.4930095391929465\n",
      "Loss: 0.4296362989005588\n",
      "Loss: 0.3767354496257015\n",
      "Loss: 0.33641004609683206\n",
      "Loss: 0.3130327349223157\n",
      "Loss: 0.29392218451809\n",
      "tensor(True) tensor(True)\n",
      "______\n",
      "Iteration t=1\n",
      "all:  cs/acc_i=50.04 cs/acc_c=51.52 os/recall_knw=81.13 os/recall_unk=35.60 total/acc_i=41.53 total/acc_c=45.88 total/h_score=40.29\n",
      "selected:  cs/acc_i=46.45 cs/acc_c=47.96 os/recall_knw=44.57 os/recall_unk=88.31 total/acc_i=54.55 total/acc_c=35.98 total/h_score=48.44\n",
      "Loss: 2.4678162973301085\n",
      "Loss: 1.0673669299074249\n",
      "Loss: 0.6415245028979638\n",
      "Loss: 0.47904840513479474\n",
      "Loss: 0.4063680886710976\n",
      "Loss: 0.37509303740864874\n",
      "Loss: 0.3266602641738513\n",
      "Loss: 0.3027085731646009\n",
      "Loss: 0.27465522073793647\n",
      "Loss: 0.2519820848406822\n",
      "______\n",
      "Iteration t=2\n",
      "all:  cs/acc_i=52.38 cs/acc_c=53.93 os/recall_knw=62.83 os/recall_unk=66.36 total/acc_i=49.76 total/acc_c=42.79 total/h_score=51.15\n",
      "selected:  cs/acc_i=49.83 cs/acc_c=51.73 os/recall_knw=43.84 os/recall_unk=86.08 total/acc_i=53.38 total/acc_c=35.82 total/h_score=48.03\n",
      "Loss: 2.411933330767745\n",
      "Loss: 1.003497040736566\n",
      "Loss: 0.5820250306791122\n",
      "Loss: 0.45006197636280587\n",
      "Loss: 0.3927329345307219\n",
      "Loss: 0.34530006164531096\n",
      "Loss: 0.3066420726341392\n",
      "Loss: 0.29219698536833494\n",
      "Loss: 0.24586332037429745\n",
      "Loss: 0.2303105343064857\n",
      "______\n",
      "Iteration t=3\n",
      "all:  cs/acc_i=50.57 cs/acc_c=52.01 os/recall_knw=60.64 os/recall_unk=69.44 total/acc_i=50.17 total/acc_c=41.82 total/h_score=51.11\n",
      "selected:  cs/acc_i=48.41 cs/acc_c=50.16 os/recall_knw=50.64 os/recall_unk=80.02 total/acc_i=51.73 total/acc_c=37.94 total/h_score=49.50\n",
      "Loss: 2.3660095635946696\n",
      "Loss: 0.9312482628471408\n",
      "Loss: 0.5701732770963148\n",
      "Loss: 0.4347741048766937\n",
      "Loss: 0.3812992074466371\n",
      "Loss: 0.3074600351772783\n",
      "Loss: 0.2883532630094202\n",
      "Loss: 0.26303160477639276\n",
      "Loss: 0.2258550886274416\n",
      "Loss: 0.2174178579281935\n",
      "______\n",
      "Iteration t=4\n",
      "all:  cs/acc_i=50.91 cs/acc_c=52.44 os/recall_knw=60.45 os/recall_unk=70.29 total/acc_i=50.45 total/acc_c=41.82 total/h_score=51.31\n",
      "selected:  cs/acc_i=49.09 cs/acc_c=51.10 os/recall_knw=55.46 os/recall_unk=76.01 total/acc_i=50.82 total/acc_c=39.57 total/h_score=50.44\n",
      "Loss: 2.3324047923088074\n",
      "Loss: 0.8618294623990853\n",
      "Loss: 0.5339575401817759\n",
      "Loss: 0.4044359141029418\n",
      "Loss: 0.35433564279228447\n",
      "Loss: 0.29972640701259173\n",
      "Loss: 0.2584168239807089\n",
      "Loss: 0.25448199938982724\n",
      "Loss: 0.21351185409973064\n",
      "Loss: 0.19972985939433177\n",
      "______\n",
      "Iteration t=5\n",
      "all:  cs/acc_i=51.47 cs/acc_c=53.09 os/recall_knw=60.04 os/recall_unk=70.75 total/acc_i=50.48 total/acc_c=41.63 total/h_score=51.25\n",
      "selected:  cs/acc_i=50.55 cs/acc_c=52.51 os/recall_knw=58.11 os/recall_unk=72.70 total/acc_i=50.39 total/acc_c=40.69 total/h_score=50.84\n",
      "Loss: 2.309386822965837\n",
      "Loss: 0.849277083671862\n",
      "Loss: 0.5339431929131669\n",
      "Loss: 0.40430600550626555\n",
      "Loss: 0.32891085344336685\n",
      "Loss: 0.31115888981449025\n",
      "Loss: 0.2681193769939484\n",
      "Loss: 0.22707415363120456\n",
      "Loss: 0.2164338609323867\n",
      "Loss: 0.18795737705283588\n",
      "______\n",
      "Iteration t=6\n",
      "all:  cs/acc_i=51.96 cs/acc_c=53.73 os/recall_knw=59.85 os/recall_unk=70.88 total/acc_i=50.50 total/acc_c=41.60 total/h_score=51.25\n",
      "selected:  cs/acc_i=51.48 cs/acc_c=53.50 os/recall_knw=59.12 os/recall_unk=71.49 total/acc_i=50.34 total/acc_c=41.23 total/h_score=51.06\n",
      "Loss: 2.291280433951146\n",
      "Loss: 0.8360298319879281\n",
      "Loss: 0.49724211914843297\n",
      "Loss: 0.39919046250235035\n",
      "Loss: 0.34223958354191003\n",
      "Loss: 0.2759530469478364\n",
      "Loss: 0.26152312357824636\n",
      "Loss: 0.22996760269560187\n",
      "Loss: 0.19720308467805148\n",
      "Loss: 0.20626528023842322\n",
      "______\n",
      "Iteration t=7\n",
      "all:  cs/acc_i=52.08 cs/acc_c=53.70 os/recall_knw=59.81 os/recall_unk=71.01 total/acc_i=50.55 total/acc_c=41.61 total/h_score=51.29\n",
      "selected:  cs/acc_i=51.99 cs/acc_c=53.68 os/recall_knw=59.67 os/recall_unk=71.05 total/acc_i=50.50 total/acc_c=41.56 total/h_score=51.25\n",
      "Loss: 2.3107216533214325\n",
      "Loss: 0.8358310281284271\n",
      "Loss: 0.5021119536979805\n",
      "Loss: 0.39112317372882177\n",
      "Loss: 0.3384908718012628\n",
      "Loss: 0.2868166651340231\n",
      "Loss: 0.2600150586711982\n",
      "Loss: 0.23176218882676156\n",
      "Loss: 0.21297655523651177\n",
      "Loss: 0.20161965508605278\n",
      "______\n",
      "Iteration t=8\n",
      "all:  cs/acc_i=51.17 cs/acc_c=52.72 os/recall_knw=59.81 os/recall_unk=71.01 total/acc_i=50.55 total/acc_c=41.61 total/h_score=51.29\n",
      "selected:  cs/acc_i=51.17 cs/acc_c=52.72 os/recall_knw=59.81 os/recall_unk=71.01 total/acc_i=50.55 total/acc_c=41.61 total/h_score=51.29\n",
      "Loss: 2.284447250858186\n",
      "Loss: 0.8558642926906782\n",
      "Loss: 0.47731053373879856\n",
      "Loss: 0.39097732518400463\n",
      "Loss: 0.3273021563710201\n",
      "Loss: 0.30630859590712045\n",
      "Loss: 0.2677952589999352\n",
      "Loss: 0.2268885804990691\n",
      "Loss: 0.20809054541741573\n",
      "Loss: 0.1848428336873887\n",
      "______\n",
      "Iteration t=9\n",
      "all:  cs/acc_i=52.45 cs/acc_c=53.93 os/recall_knw=59.81 os/recall_unk=71.01 total/acc_i=50.55 total/acc_c=41.61 total/h_score=51.29\n",
      "selected:  cs/acc_i=52.45 cs/acc_c=53.93 os/recall_knw=59.81 os/recall_unk=71.01 total/acc_i=50.55 total/acc_c=41.61 total/h_score=51.29\n",
      "tensor(0)\n",
      "all:  cs/acc_i=52.45 cs/acc_c=53.93 os/recall_knw=59.81 os/recall_unk=71.01 total/acc_i=50.55 total/acc_c=41.61 total/h_score=51.29\n",
      "painting -> sketch lr= 0.001 seed= 2\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19]\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20]\n",
      "Loss: 2.570379828019117\n",
      "Loss: 1.2439879970575767\n",
      "Loss: 0.708173569548067\n",
      "Loss: 0.5784270175234981\n",
      "Loss: 0.4752930826137936\n",
      "Loss: 0.42148697309235417\n",
      "Loss: 0.37772125912406457\n",
      "Loss: 0.34210736127126784\n",
      "Loss: 0.3008639220365141\n",
      "Loss: 0.28408646930462467\n",
      "tensor(True) tensor(True)\n",
      "______\n",
      "Iteration t=1\n",
      "all:  cs/acc_i=50.15 cs/acc_c=51.78 os/recall_knw=81.81 os/recall_unk=36.78 total/acc_i=42.03 total/acc_c=46.19 total/h_score=41.13\n",
      "selected:  cs/acc_i=48.03 cs/acc_c=50.02 os/recall_knw=45.78 os/recall_unk=89.92 total/acc_i=56.41 total/acc_c=37.32 total/h_score=50.06\n",
      "Loss: 2.47355836279252\n",
      "Loss: 1.0748934964923298\n",
      "Loss: 0.6447692693156355\n",
      "Loss: 0.4906817917876384\n",
      "Loss: 0.4308665564247206\n",
      "Loss: 0.3791524708709296\n",
      "Loss: 0.34530563601383973\n",
      "Loss: 0.29278769424440815\n",
      "Loss: 0.27673047368286874\n",
      "Loss: 0.2524019639719935\n",
      "______\n",
      "Iteration t=2\n",
      "all:  cs/acc_i=50.11 cs/acc_c=51.58 os/recall_knw=63.09 os/recall_unk=67.02 total/acc_i=48.97 total/acc_c=41.29 total/h_score=50.10\n",
      "selected:  cs/acc_i=47.57 cs/acc_c=49.33 os/recall_knw=44.15 os/recall_unk=86.56 total/acc_i=52.86 total/acc_c=34.45 total/h_score=46.56\n",
      "Loss: 2.4211815781549575\n",
      "Loss: 0.962085238563905\n",
      "Loss: 0.584312766722036\n",
      "Loss: 0.4540970875035732\n",
      "Loss: 0.40238977004902077\n",
      "Loss: 0.3375009956231358\n",
      "Loss: 0.313889660488028\n",
      "Loss: 0.28073298698718396\n",
      "Loss: 0.23877951401977912\n",
      "Loss: 0.22794422573931172\n",
      "______\n",
      "Iteration t=3\n",
      "all:  cs/acc_i=50.00 cs/acc_c=51.64 os/recall_knw=59.32 os/recall_unk=71.14 total/acc_i=49.55 total/acc_c=39.98 total/h_score=49.89\n",
      "selected:  cs/acc_i=48.08 cs/acc_c=50.30 os/recall_knw=50.07 os/recall_unk=81.55 total/acc_i=51.06 total/acc_c=36.45 total/h_score=48.18\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 2.3752027667087057\n",
      "Loss: 0.9045422687478687\n",
      "Loss: 0.5392950271134791\n",
      "Loss: 0.4208266451306965\n",
      "Loss: 0.3576857667902242\n",
      "Loss: 0.3293910372516383\n",
      "Loss: 0.29095609946095424\n",
      "Loss: 0.2633653135565312\n",
      "Loss: 0.22474695567203604\n",
      "Loss: 0.20939762221406336\n",
      "______\n",
      "Iteration t=4\n",
      "all:  cs/acc_i=50.75 cs/acc_c=52.23 os/recall_knw=58.79 os/recall_unk=71.53 total/acc_i=49.45 total/acc_c=39.62 total/h_score=49.65\n",
      "selected:  cs/acc_i=49.62 cs/acc_c=51.76 os/recall_knw=54.23 os/recall_unk=76.11 total/acc_i=49.84 total/acc_c=37.96 total/h_score=48.92\n",
      "Loss: 2.311897049844265\n",
      "Loss: 0.8310560863465071\n",
      "Loss: 0.5094201701382796\n",
      "Loss: 0.41479029431939124\n",
      "Loss: 0.3541439155737559\n",
      "Loss: 0.30331881827053925\n",
      "Loss: 0.2851190727824966\n",
      "Loss: 0.24121541418135167\n",
      "Loss: 0.22012415239587427\n",
      "Loss: 0.19674411363278826\n",
      "______\n",
      "Iteration t=5\n",
      "all:  cs/acc_i=50.45 cs/acc_c=52.11 os/recall_knw=58.72 os/recall_unk=71.53 total/acc_i=49.40 total/acc_c=39.53 total/h_score=49.57\n",
      "selected:  cs/acc_i=49.51 cs/acc_c=51.65 os/recall_knw=56.74 os/recall_unk=73.45 total/acc_i=49.27 total/acc_c=38.59 total/h_score=49.07\n",
      "Loss: 2.2999722119269332\n",
      "Loss: 0.7961120547317877\n",
      "Loss: 0.5036340743545594\n",
      "Loss: 0.40330263860220833\n",
      "Loss: 0.35634432975354235\n",
      "Loss: 0.28216827288269997\n",
      "Loss: 0.27832392500183445\n",
      "Loss: 0.2390695097061192\n",
      "Loss: 0.20925903871534315\n",
      "Loss: 0.20128526899024723\n",
      "______\n",
      "Iteration t=6\n",
      "all:  cs/acc_i=50.04 cs/acc_c=51.56 os/recall_knw=58.34 os/recall_unk=71.92 total/acc_i=49.43 total/acc_c=39.38 total/h_score=49.51\n",
      "selected:  cs/acc_i=49.64 cs/acc_c=51.31 os/recall_knw=57.94 os/recall_unk=72.16 total/acc_i=49.23 total/acc_c=39.05 total/h_score=49.26\n",
      "Loss: 2.2901017847061156\n",
      "Loss: 0.8162093694210053\n",
      "Loss: 0.5141718072295189\n",
      "Loss: 0.3896516365110874\n",
      "Loss: 0.3317243157327175\n",
      "Loss: 0.2915601927638054\n",
      "Loss: 0.2557635850906372\n",
      "Loss: 0.23021867726743223\n",
      "Loss: 0.2061717310845852\n",
      "Loss: 0.1794928761869669\n",
      "______\n",
      "Iteration t=7\n",
      "all:  cs/acc_i=50.87 cs/acc_c=52.38 os/recall_knw=58.34 os/recall_unk=71.92 total/acc_i=49.43 total/acc_c=39.38 total/h_score=49.51\n",
      "selected:  cs/acc_i=50.83 cs/acc_c=52.36 os/recall_knw=58.31 os/recall_unk=71.92 total/acc_i=49.40 total/acc_c=39.35 total/h_score=49.49\n",
      "Loss: 2.29782017341173\n",
      "Loss: 0.8258933883264246\n",
      "Loss: 0.536414137399529\n",
      "Loss: 0.3897679474249304\n",
      "Loss: 0.34538182639980697\n",
      "Loss: 0.28343694262295605\n",
      "Loss: 0.2716583256346296\n",
      "Loss: 0.23026121370642783\n",
      "Loss: 0.2069905941259576\n",
      "Loss: 0.19777062214703198\n",
      "______\n",
      "Iteration t=8\n",
      "all:  cs/acc_i=51.21 cs/acc_c=52.86 os/recall_knw=58.34 os/recall_unk=71.92 total/acc_i=49.43 total/acc_c=39.38 total/h_score=49.51\n",
      "selected:  cs/acc_i=51.21 cs/acc_c=52.86 os/recall_knw=58.34 os/recall_unk=71.92 total/acc_i=49.43 total/acc_c=39.38 total/h_score=49.51\n",
      "Loss: 2.292713845393572\n",
      "Loss: 0.8431351206217154\n",
      "Loss: 0.49721861461481726\n",
      "Loss: 0.40859841623629234\n",
      "Loss: 0.3436481467340572\n",
      "Loss: 0.2955077943870746\n",
      "Loss: 0.2618186930380019\n",
      "Loss: 0.2457020605999635\n",
      "Loss: 0.21135802638245768\n",
      "Loss: 0.18526977346653484\n",
      "______\n",
      "Iteration t=9\n",
      "all:  cs/acc_i=50.53 cs/acc_c=52.10 os/recall_knw=58.34 os/recall_unk=71.92 total/acc_i=49.43 total/acc_c=39.38 total/h_score=49.51\n",
      "selected:  cs/acc_i=50.53 cs/acc_c=52.10 os/recall_knw=58.34 os/recall_unk=71.92 total/acc_i=49.43 total/acc_c=39.38 total/h_score=49.51\n",
      "tensor(0)\n",
      "all:  cs/acc_i=50.53 cs/acc_c=52.10 os/recall_knw=58.34 os/recall_unk=71.92 total/acc_i=49.43 total/acc_c=39.38 total/h_score=49.51\n",
      "painting -> sketch lr= 0.001 seed= 3\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19]\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20]\n",
      "Loss: 2.5589941531892806\n",
      "Loss: 1.228079344545092\n",
      "Loss: 0.7317760742845989\n",
      "Loss: 0.5556731902890735\n",
      "Loss: 0.5072997099665738\n",
      "Loss: 0.4229467049162224\n",
      "Loss: 0.3829396008341401\n",
      "Loss: 0.3514086204388785\n",
      "Loss: 0.30375066101945264\n",
      "Loss: 0.28867247148796366\n",
      "tensor(True) tensor(True)\n",
      "______\n",
      "Iteration t=1\n",
      "all:  cs/acc_i=50.23 cs/acc_c=51.54 os/recall_knw=81.40 os/recall_unk=36.06 total/acc_i=41.96 total/acc_c=46.13 total/h_score=40.67\n",
      "selected:  cs/acc_i=47.19 cs/acc_c=48.85 os/recall_knw=45.64 os/recall_unk=90.03 total/acc_i=55.96 total/acc_c=37.39 total/h_score=50.15\n",
      "Loss: 2.4811101830473135\n",
      "Loss: 1.0667997075646531\n",
      "Loss: 0.6302266065396515\n",
      "Loss: 0.4915992258956619\n",
      "Loss: 0.421870240320762\n",
      "Loss: 0.37782831862568855\n",
      "Loss: 0.33663027974612575\n",
      "Loss: 0.2993511299365291\n",
      "Loss: 0.2754853183001864\n",
      "Loss: 0.26529224877994434\n",
      "______\n",
      "Iteration t=2\n",
      "all:  cs/acc_i=51.02 cs/acc_c=52.45 os/recall_knw=66.72 os/recall_unk=59.88 total/acc_i=47.56 total/acc_c=42.70 total/h_score=49.26\n",
      "selected:  cs/acc_i=49.21 cs/acc_c=50.60 os/recall_knw=46.67 os/recall_unk=84.80 total/acc_i=53.02 total/acc_c=36.29 total/h_score=48.40\n",
      "Loss: 2.4350803428833636\n",
      "Loss: 0.9761653114622886\n",
      "Loss: 0.5883955284269577\n",
      "Loss: 0.4554880588836626\n",
      "Loss: 0.38935078495959624\n",
      "Loss: 0.3542375810649417\n",
      "Loss: 0.3032642328821191\n",
      "Loss: 0.27392775902029026\n",
      "Loss: 0.2559797719736165\n",
      "Loss: 0.2398759024815822\n",
      "______\n",
      "Iteration t=3\n",
      "all:  cs/acc_i=50.45 cs/acc_c=51.86 os/recall_knw=59.21 os/recall_unk=68.65 total/acc_i=48.78 total/acc_c=39.99 total/h_score=49.38\n",
      "selected:  cs/acc_i=48.51 cs/acc_c=50.35 os/recall_knw=49.72 os/recall_unk=79.89 total/acc_i=50.36 total/acc_c=36.23 total/h_score=47.75\n",
      "Loss: 2.3524360852840145\n",
      "Loss: 0.8926655633366986\n",
      "Loss: 0.5507359711122719\n",
      "Loss: 0.42044381603792114\n",
      "Loss: 0.3706247467886318\n",
      "Loss: 0.322248627226074\n",
      "Loss: 0.2977839097767681\n",
      "Loss: 0.2481608915735375\n",
      "Loss: 0.23055006057282032\n",
      "Loss: 0.20874754582971206\n",
      "______\n",
      "Iteration t=4\n",
      "all:  cs/acc_i=50.75 cs/acc_c=52.17 os/recall_knw=58.42 os/recall_unk=69.24 total/acc_i=48.68 total/acc_c=39.52 total/h_score=49.10\n",
      "selected:  cs/acc_i=49.54 cs/acc_c=51.30 os/recall_knw=53.97 os/recall_unk=75.09 total/acc_i=49.30 total/acc_c=37.70 total/h_score=48.51\n",
      "Loss: 2.3368151942888895\n",
      "Loss: 0.87581610220174\n",
      "Loss: 0.5306249133000771\n",
      "Loss: 0.39733152265350025\n",
      "Loss: 0.34840213938926656\n",
      "Loss: 0.29458499774336816\n",
      "Loss: 0.277224731259048\n",
      "Loss: 0.25701564581443864\n",
      "Loss: 0.2207517688628286\n",
      "Loss: 0.18927411222830415\n",
      "______\n",
      "Iteration t=5\n",
      "all:  cs/acc_i=50.45 cs/acc_c=52.00 os/recall_knw=58.15 os/recall_unk=69.44 total/acc_i=48.73 total/acc_c=39.50 total/h_score=49.12\n",
      "selected:  cs/acc_i=49.49 cs/acc_c=51.43 os/recall_knw=56.24 os/recall_unk=72.28 total/acc_i=48.80 total/acc_c=38.54 total/h_score=48.82\n",
      "Loss: 2.316489332575139\n",
      "Loss: 0.8710932669843116\n",
      "Loss: 0.5238782786499194\n",
      "Loss: 0.40643251905354055\n",
      "Loss: 0.34917957117644755\n",
      "Loss: 0.30209731510499627\n",
      "Loss: 0.2681185286340675\n",
      "Loss: 0.2452349405342001\n",
      "Loss: 0.21651789714105246\n",
      "Loss: 0.20338275257831182\n",
      "______\n",
      "Iteration t=6\n",
      "all:  cs/acc_i=50.94 cs/acc_c=52.51 os/recall_knw=58.15 os/recall_unk=69.44 total/acc_i=48.73 total/acc_c=39.50 total/h_score=49.12\n",
      "selected:  cs/acc_i=50.52 cs/acc_c=52.28 os/recall_knw=57.69 os/recall_unk=70.13 total/acc_i=48.62 total/acc_c=39.17 total/h_score=48.97\n",
      "Loss: 2.2835023560523986\n",
      "Loss: 0.8188216879367828\n",
      "Loss: 0.5109894835352897\n",
      "Loss: 0.4006491647362709\n",
      "Loss: 0.3306311945319176\n",
      "Loss: 0.28993079042434694\n",
      "Loss: 0.26406878685951235\n",
      "Loss: 0.23044734632968902\n",
      "Loss: 0.2064390997439623\n",
      "Loss: 0.18044281663745643\n",
      "______\n",
      "Iteration t=7\n",
      "all:  cs/acc_i=50.79 cs/acc_c=52.39 os/recall_knw=58.15 os/recall_unk=69.44 total/acc_i=48.73 total/acc_c=39.50 total/h_score=49.12\n",
      "selected:  cs/acc_i=50.76 cs/acc_c=52.38 os/recall_knw=58.09 os/recall_unk=69.48 total/acc_i=48.72 total/acc_c=39.47 total/h_score=49.11\n",
      "Loss: 2.285747757506749\n",
      "Loss: 0.8437888868271358\n",
      "Loss: 0.5082696000380176\n",
      "Loss: 0.4155117457821256\n",
      "Loss: 0.33565888840646024\n",
      "Loss: 0.29468736481217167\n",
      "Loss: 0.2557273256104617\n",
      "Loss: 0.23602371316935336\n",
      "Loss: 0.19819394431062162\n",
      "Loss: 0.18739808220711965\n",
      "______\n",
      "Iteration t=8\n",
      "all:  cs/acc_i=51.40 cs/acc_c=52.87 os/recall_knw=58.15 os/recall_unk=69.44 total/acc_i=48.73 total/acc_c=39.50 total/h_score=49.12\n",
      "selected:  cs/acc_i=51.40 cs/acc_c=52.87 os/recall_knw=58.15 os/recall_unk=69.44 total/acc_i=48.73 total/acc_c=39.50 total/h_score=49.12\n",
      "Loss: 2.291231078287912\n",
      "Loss: 0.827327279580964\n",
      "Loss: 0.4967100364821298\n",
      "Loss: 0.38870105972247465\n",
      "Loss: 0.33787786395895103\n",
      "Loss: 0.28095288833396304\n",
      "Loss: 0.26111774650653674\n",
      "Loss: 0.23262603983046518\n",
      "Loss: 0.21135582897575603\n",
      "Loss: 0.20285581507616574\n",
      "______\n",
      "Iteration t=9\n",
      "all:  cs/acc_i=51.25 cs/acc_c=52.84 os/recall_knw=58.15 os/recall_unk=69.44 total/acc_i=48.73 total/acc_c=39.50 total/h_score=49.12\n",
      "selected:  cs/acc_i=51.25 cs/acc_c=52.84 os/recall_knw=58.15 os/recall_unk=69.44 total/acc_i=48.73 total/acc_c=39.50 total/h_score=49.12\n",
      "tensor(0)\n",
      "all:  cs/acc_i=51.25 cs/acc_c=52.84 os/recall_knw=58.15 os/recall_unk=69.44 total/acc_i=48.73 total/acc_c=39.50 total/h_score=49.12\n",
      "painting -> sketch lr= 0.001 seed= 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19]\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20]\n",
      "Loss: 2.5834520525402493\n",
      "Loss: 1.2236166807709548\n",
      "Loss: 0.7483087973619895\n",
      "Loss: 0.5752163395364448\n",
      "Loss: 0.48868962941030974\n",
      "Loss: 0.42066927790326414\n",
      "Loss: 0.3934758292146461\n",
      "Loss: 0.3521909189839212\n",
      "Loss: 0.30739166197322665\n",
      "Loss: 0.2930068579063844\n",
      "tensor(True) tensor(True)\n",
      "______\n",
      "Iteration t=1\n",
      "all:  cs/acc_i=50.45 cs/acc_c=51.97 os/recall_knw=81.74 os/recall_unk=36.65 total/acc_i=42.22 total/acc_c=46.36 total/h_score=41.13\n",
      "selected:  cs/acc_i=48.09 cs/acc_c=49.27 os/recall_knw=45.50 os/recall_unk=88.89 total/acc_i=56.26 total/acc_c=37.21 total/h_score=49.84\n",
      "Loss: 2.484727006332547\n",
      "Loss: 1.0462610308153957\n",
      "Loss: 0.6274228063868541\n",
      "Loss: 0.5014522179376846\n",
      "Loss: 0.44689520959760626\n",
      "Loss: 0.3826810209920593\n",
      "Loss: 0.34200063866435315\n",
      "Loss: 0.29744171822334037\n",
      "Loss: 0.2807306557090259\n",
      "Loss: 0.2452830726317331\n",
      "______\n",
      "Iteration t=2\n",
      "all:  cs/acc_i=51.32 cs/acc_c=53.01 os/recall_knw=62.08 os/recall_unk=67.21 total/acc_i=49.40 total/acc_c=41.86 total/h_score=50.61\n",
      "selected:  cs/acc_i=49.33 cs/acc_c=51.19 os/recall_knw=43.85 os/recall_unk=87.03 total/acc_i=53.43 total/acc_c=35.63 total/h_score=47.92\n",
      "Loss: 2.405992705340779\n",
      "Loss: 0.9972579584482613\n",
      "Loss: 0.5944793778001716\n",
      "Loss: 0.45175054259256486\n",
      "Loss: 0.3979622023778224\n",
      "Loss: 0.34589669580033067\n",
      "Loss: 0.31308895763043965\n",
      "Loss: 0.2708247791668144\n",
      "Loss: 0.25015863800130855\n",
      "Loss: 0.23294679193390072\n",
      "______\n",
      "Iteration t=3\n",
      "all:  cs/acc_i=50.83 cs/acc_c=52.31 os/recall_knw=56.45 os/recall_unk=73.69 total/acc_i=50.10 total/acc_c=39.48 total/h_score=49.94\n",
      "selected:  cs/acc_i=48.66 cs/acc_c=50.37 os/recall_knw=47.62 os/recall_unk=81.24 total/acc_i=50.65 total/acc_c=35.34 total/h_score=46.98\n",
      "Loss: 2.3763289150984392\n",
      "Loss: 0.9231749284526576\n",
      "Loss: 0.538895401812118\n",
      "Loss: 0.4477837995342586\n",
      "Loss: 0.3624281883887623\n",
      "Loss: 0.318424287567968\n",
      "Loss: 0.2921598571150199\n",
      "Loss: 0.25258067617921726\n",
      "Loss: 0.23374909800679788\n",
      "Loss: 0.2110452463121518\n",
      "______\n",
      "Iteration t=4\n",
      "all:  cs/acc_i=50.68 cs/acc_c=52.28 os/recall_knw=55.92 os/recall_unk=74.08 total/acc_i=50.00 total/acc_c=39.15 total/h_score=49.71\n",
      "selected:  cs/acc_i=49.18 cs/acc_c=51.22 os/recall_knw=52.01 os/recall_unk=77.06 total/acc_i=49.78 total/acc_c=37.12 total/h_score=48.25\n",
      "Loss: 2.328784523648697\n",
      "Loss: 0.8641836155657988\n",
      "Loss: 0.5154565157501269\n",
      "Loss: 0.4085358791209165\n",
      "Loss: 0.35552813243666453\n",
      "Loss: 0.32053126111065494\n",
      "Loss: 0.283371348822466\n",
      "Loss: 0.2511099853151513\n",
      "Loss: 0.2215812140802958\n",
      "Loss: 0.21490537939460708\n",
      "______\n",
      "Iteration t=5\n",
      "all:  cs/acc_i=51.36 cs/acc_c=53.05 os/recall_knw=55.40 os/recall_unk=74.35 total/acc_i=49.93 total/acc_c=38.88 total/h_score=49.51\n",
      "selected:  cs/acc_i=50.48 cs/acc_c=52.48 os/recall_knw=54.35 os/recall_unk=74.88 total/acc_i=49.49 total/acc_c=38.04 total/h_score=48.80\n",
      "Loss: 2.3046560837298022\n",
      "Loss: 0.8503546220915658\n",
      "Loss: 0.5309218892029354\n",
      "Loss: 0.4216072030213414\n",
      "Loss: 0.33695385559481017\n",
      "Loss: 0.2932915329324956\n",
      "Loss: 0.2764684586500635\n",
      "Loss: 0.23719225014959064\n",
      "Loss: 0.2066852546468073\n",
      "Loss: 0.1971592204151105\n",
      "______\n",
      "Iteration t=6\n",
      "all:  cs/acc_i=51.28 cs/acc_c=52.91 os/recall_knw=55.40 os/recall_unk=74.48 total/acc_i=49.98 total/acc_c=38.89 total/h_score=49.54\n",
      "selected:  cs/acc_i=50.93 cs/acc_c=52.69 os/recall_knw=55.04 os/recall_unk=74.57 total/acc_i=49.77 total/acc_c=38.59 total/h_score=49.27\n",
      "Loss: 2.309068200549459\n",
      "Loss: 0.8434230513204404\n",
      "Loss: 0.5065249687409014\n",
      "Loss: 0.39802824987507446\n",
      "Loss: 0.32765146402445267\n",
      "Loss: 0.30216952240685135\n",
      "Loss: 0.2586223735829921\n",
      "Loss: 0.24460909168834125\n",
      "Loss: 0.21245336682512994\n",
      "Loss: 0.2009167897598288\n",
      "______\n",
      "Iteration t=7\n",
      "all:  cs/acc_i=51.55 cs/acc_c=53.25 os/recall_knw=55.36 os/recall_unk=74.48 total/acc_i=49.95 total/acc_c=38.86 total/h_score=49.51\n",
      "selected:  cs/acc_i=51.55 cs/acc_c=53.25 os/recall_knw=55.36 os/recall_unk=74.48 total/acc_i=49.95 total/acc_c=38.86 total/h_score=49.51\n",
      "Loss: 2.312216597530041\n",
      "Loss: 0.8485512090356726\n",
      "Loss: 0.526032832228703\n",
      "Loss: 0.4045078172254176\n",
      "Loss: 0.3382623074689375\n",
      "Loss: 0.2884970027123868\n",
      "Loss: 0.26656283664437924\n",
      "Loss: 0.2332536006866679\n",
      "Loss: 0.2210776973741981\n",
      "Loss: 0.19169536261604384\n",
      "______\n",
      "Iteration t=8\n",
      "all:  cs/acc_i=51.74 cs/acc_c=53.37 os/recall_knw=55.36 os/recall_unk=74.48 total/acc_i=49.95 total/acc_c=38.86 total/h_score=49.51\n",
      "selected:  cs/acc_i=51.74 cs/acc_c=53.37 os/recall_knw=55.36 os/recall_unk=74.48 total/acc_i=49.95 total/acc_c=38.86 total/h_score=49.51\n",
      "Loss: 2.3129852098009365\n",
      "Loss: 0.8403321955850732\n",
      "Loss: 0.5183251444024113\n",
      "Loss: 0.40770969090432774\n",
      "Loss: 0.3423322566487046\n",
      "Loss: 0.3013211915548514\n",
      "Loss: 0.26554985477132836\n",
      "Loss: 0.23583086058195785\n",
      "Loss: 0.2055676751713521\n",
      "Loss: 0.18572582070704413\n",
      "______\n",
      "Iteration t=9\n",
      "all:  cs/acc_i=51.70 cs/acc_c=53.29 os/recall_knw=55.36 os/recall_unk=74.48 total/acc_i=49.95 total/acc_c=38.86 total/h_score=49.51\n",
      "selected:  cs/acc_i=51.70 cs/acc_c=53.29 os/recall_knw=55.36 os/recall_unk=74.48 total/acc_i=49.95 total/acc_c=38.86 total/h_score=49.51\n",
      "tensor(0)\n",
      "all:  cs/acc_i=51.70 cs/acc_c=53.29 os/recall_knw=55.36 os/recall_unk=74.48 total/acc_i=49.95 total/acc_c=38.86 total/h_score=49.51\n",
      "painting -> sketch lr= 0.001 seed= 0\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19]\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20]\n",
      "Loss: 2.5623198621487493\n",
      "Loss: 1.2404462275681671\n",
      "Loss: 0.7387243704821067\n",
      "Loss: 0.5639391965651638\n",
      "Loss: 0.4997973729851385\n",
      "Loss: 0.4289968772224648\n",
      "Loss: 0.38632712864055835\n",
      "Loss: 0.3551850943732514\n",
      "Loss: 0.3288625209892868\n",
      "Loss: 0.27412628611086537\n",
      "tensor(True) tensor(True)\n",
      "______\n",
      "Iteration t=1\n",
      "all:  cs/acc_i=51.70 cs/acc_c=53.22 os/recall_knw=82.57 os/recall_unk=38.09 total/acc_i=43.73 total/acc_c=47.99 total/h_score=42.66\n",
      "selected:  cs/acc_i=50.23 cs/acc_c=51.53 os/recall_knw=47.02 os/recall_unk=90.23 total/acc_i=59.00 total/acc_c=39.91 total/h_score=52.88\n",
      "Loss: 2.476105615788815\n",
      "Loss: 1.0771830385806513\n",
      "Loss: 0.6378812182183359\n",
      "Loss: 0.5103190677130923\n",
      "Loss: 0.43712706542482566\n",
      "Loss: 0.3875920964660598\n",
      "Loss: 0.3381852453172791\n",
      "Loss: 0.29303341055763704\n",
      "Loss: 0.2779064006263427\n",
      "Loss: 0.24251768778206087\n",
      "______\n",
      "Iteration t=2\n",
      "all:  cs/acc_i=50.15 cs/acc_c=51.74 os/recall_knw=63.21 os/recall_unk=65.58 total/acc_i=48.99 total/acc_c=42.02 total/h_score=50.33\n",
      "selected:  cs/acc_i=46.60 cs/acc_c=48.28 os/recall_knw=44.32 os/recall_unk=86.01 total/acc_i=52.61 total/acc_c=34.49 total/h_score=46.55\n",
      "Loss: 2.4233226765186413\n",
      "Loss: 0.9659857357587289\n",
      "Loss: 0.5738741129363348\n",
      "Loss: 0.45441929838799555\n",
      "Loss: 0.39800724927165093\n",
      "Loss: 0.34754050734939923\n",
      "Loss: 0.31615900791703017\n",
      "Loss: 0.2780856423490091\n",
      "Loss: 0.25515854556899553\n",
      "Loss: 0.23674642783376054\n",
      "______\n",
      "Iteration t=3\n",
      "all:  cs/acc_i=50.15 cs/acc_c=51.66 os/recall_knw=59.40 os/recall_unk=70.29 total/acc_i=49.74 total/acc_c=40.69 total/h_score=50.34\n",
      "selected:  cs/acc_i=48.21 cs/acc_c=49.90 os/recall_knw=49.98 os/recall_unk=81.24 total/acc_i=51.43 total/acc_c=37.05 total/h_score=48.77\n",
      "Loss: 2.3645444849263066\n",
      "Loss: 0.8944966182760571\n",
      "Loss: 0.5406051981708277\n",
      "Loss: 0.4362401247996351\n",
      "Loss: 0.36322197486525\n",
      "Loss: 0.3188303765071475\n",
      "Loss: 0.27137929288589435\n",
      "Loss: 0.26241051804112353\n",
      "Loss: 0.23406561294003672\n",
      "Loss: 0.20280182241745617\n",
      "______\n",
      "Iteration t=4\n",
      "all:  cs/acc_i=50.68 cs/acc_c=52.31 os/recall_knw=57.13 os/recall_unk=71.92 total/acc_i=49.66 total/acc_c=39.74 total/h_score=49.84\n",
      "selected:  cs/acc_i=49.29 cs/acc_c=51.33 os/recall_knw=52.63 os/recall_unk=76.00 total/acc_i=49.79 total/acc_c=37.70 total/h_score=48.66\n",
      "Loss: 2.3314403674592534\n",
      "Loss: 0.8773055066623449\n",
      "Loss: 0.5154022885541037\n",
      "Loss: 0.4098324781930596\n",
      "Loss: 0.3532790364580673\n",
      "Loss: 0.3199016649790389\n",
      "Loss: 0.2811666150347458\n",
      "Loss: 0.2364836075970568\n",
      "Loss: 0.21537856364848723\n",
      "Loss: 0.2038678514408766\n",
      "______\n",
      "Iteration t=5\n",
      "all:  cs/acc_i=51.06 cs/acc_c=52.49 os/recall_knw=56.87 os/recall_unk=72.12 total/acc_i=49.64 total/acc_c=39.59 total/h_score=49.74\n",
      "selected:  cs/acc_i=50.27 cs/acc_c=51.98 os/recall_knw=55.35 os/recall_unk=73.86 total/acc_i=49.56 total/acc_c=38.75 total/h_score=49.29\n",
      "Loss: 2.3182758384821365\n",
      "Loss: 0.8376562099067533\n",
      "Loss: 0.510449623635837\n",
      "Loss: 0.4015773176538701\n",
      "Loss: 0.3213851561655804\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.3062718505457956\n",
      "Loss: 0.2708525151926644\n",
      "Loss: 0.24149658051984652\n",
      "Loss: 0.20034344048828495\n",
      "Loss: 0.1990043965681475\n",
      "______\n",
      "Iteration t=6\n",
      "all:  cs/acc_i=51.58 cs/acc_c=53.35 os/recall_knw=56.75 os/recall_unk=72.45 total/acc_i=49.74 total/acc_c=39.57 total/h_score=49.79\n",
      "selected:  cs/acc_i=51.33 cs/acc_c=53.22 os/recall_knw=56.39 os/recall_unk=72.54 total/acc_i=49.59 total/acc_c=39.33 total/h_score=49.59\n",
      "Loss: 2.295736845462553\n",
      "Loss: 0.8420177801482139\n",
      "Loss: 0.511451895679197\n",
      "Loss: 0.39031860394583595\n",
      "Loss: 0.33652029372751713\n",
      "Loss: 0.2947733903664254\n",
      "Loss: 0.2609052549927465\n",
      "Loss: 0.22763291624705156\n",
      "Loss: 0.21667509378805275\n",
      "Loss: 0.18606323742818448\n",
      "______\n",
      "Iteration t=7\n",
      "all:  cs/acc_i=51.06 cs/acc_c=52.73 os/recall_knw=56.75 os/recall_unk=72.45 total/acc_i=49.74 total/acc_c=39.57 total/h_score=49.79\n",
      "selected:  cs/acc_i=51.04 cs/acc_c=52.72 os/recall_knw=56.74 os/recall_unk=72.45 total/acc_i=49.72 total/acc_c=39.56 total/h_score=49.78\n",
      "Loss: 2.298921634394481\n",
      "Loss: 0.8223856080727405\n",
      "Loss: 0.5093078434946068\n",
      "Loss: 0.3960860575956992\n",
      "Loss: 0.33433742542941886\n",
      "Loss: 0.2791368359303379\n",
      "Loss: 0.2678464670856315\n",
      "Loss: 0.2342727117569571\n",
      "Loss: 0.2116998745106071\n",
      "Loss: 0.18360162692436252\n",
      "______\n",
      "Iteration t=8\n",
      "all:  cs/acc_i=51.13 cs/acc_c=52.81 os/recall_knw=56.75 os/recall_unk=72.45 total/acc_i=49.74 total/acc_c=39.57 total/h_score=49.79\n",
      "selected:  cs/acc_i=51.13 cs/acc_c=52.81 os/recall_knw=56.75 os/recall_unk=72.45 total/acc_i=49.74 total/acc_c=39.57 total/h_score=49.79\n",
      "Loss: 2.3105572682307907\n",
      "Loss: 0.8369707758407516\n",
      "Loss: 0.5117409443520159\n",
      "Loss: 0.3936262274362955\n",
      "Loss: 0.33485026527420586\n",
      "Loss: 0.30363291660585556\n",
      "Loss: 0.2672675576913788\n",
      "Loss: 0.22520039727290472\n",
      "Loss: 0.20347452281888231\n",
      "Loss: 0.1960385001477707\n",
      "______\n",
      "Iteration t=9\n",
      "all:  cs/acc_i=50.34 cs/acc_c=51.86 os/recall_knw=56.75 os/recall_unk=72.45 total/acc_i=49.74 total/acc_c=39.57 total/h_score=49.79\n",
      "selected:  cs/acc_i=50.34 cs/acc_c=51.86 os/recall_knw=56.75 os/recall_unk=72.45 total/acc_i=49.74 total/acc_c=39.57 total/h_score=49.79\n",
      "tensor(0)\n",
      "all:  cs/acc_i=50.34 cs/acc_c=51.86 os/recall_knw=56.75 os/recall_unk=72.45 total/acc_i=49.74 total/acc_c=39.57 total/h_score=49.79\n",
      "painting -> sketch lr= 0.001 seed= 1\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19]\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20]\n",
      "Loss: 2.557188004412979\n",
      "Loss: 1.190651016260581\n",
      "Loss: 0.7527976155911804\n",
      "Loss: 0.5739873523119265\n",
      "Loss: 0.49316215601863056\n",
      "Loss: 0.43031122791704046\n",
      "Loss: 0.3774166741068401\n",
      "Loss: 0.3368862431358408\n",
      "Loss: 0.31358335723006536\n",
      "Loss: 0.2940514641148703\n",
      "tensor(True) tensor(True)\n",
      "______\n",
      "Iteration t=1\n",
      "all:  cs/acc_i=49.81 cs/acc_c=51.22 os/recall_knw=81.06 os/recall_unk=35.47 total/acc_i=41.41 total/acc_c=45.76 total/h_score=40.16\n",
      "selected:  cs/acc_i=46.31 cs/acc_c=47.76 os/recall_knw=44.77 os/recall_unk=89.00 total/acc_i=54.74 total/acc_c=36.24 total/h_score=48.78\n",
      "Loss: 2.47094586316277\n",
      "Loss: 1.0579066592104294\n",
      "Loss: 0.6215213635096363\n",
      "Loss: 0.4810049534574443\n",
      "Loss: 0.41845953727469726\n",
      "Loss: 0.37970218730761723\n",
      "Loss: 0.3263667289752002\n",
      "Loss: 0.3086260363605677\n",
      "Loss: 0.27392904679564867\n",
      "Loss: 0.24130188699300384\n",
      "______\n",
      "Iteration t=2\n",
      "all:  cs/acc_i=50.08 cs/acc_c=51.62 os/recall_knw=60.34 os/recall_unk=67.80 total/acc_i=48.73 total/acc_c=40.47 total/h_score=49.60\n",
      "selected:  cs/acc_i=47.01 cs/acc_c=48.80 os/recall_knw=42.35 os/recall_unk=86.26 total/acc_i=51.79 total/acc_c=33.39 total/h_score=45.34\n",
      "Loss: 2.411859488268511\n",
      "Loss: 1.0156360809956122\n",
      "Loss: 0.5766992557349555\n",
      "Loss: 0.45395781339035124\n",
      "Loss: 0.3819258019601533\n",
      "Loss: 0.3610421043880489\n",
      "Loss: 0.3185227122328697\n",
      "Loss: 0.2742257451792376\n",
      "Loss: 0.2494913006218475\n",
      "Loss: 0.23682700408571358\n",
      "______\n",
      "Iteration t=3\n",
      "all:  cs/acc_i=50.79 cs/acc_c=52.46 os/recall_knw=56.98 os/recall_unk=71.73 total/acc_i=49.07 total/acc_c=38.93 total/h_score=49.07\n",
      "selected:  cs/acc_i=49.30 cs/acc_c=51.52 os/recall_knw=48.53 os/recall_unk=80.77 total/acc_i=50.28 total/acc_c=35.70 total/h_score=47.30\n",
      "Loss: 2.3640938832130267\n",
      "Loss: 0.9068087122657082\n",
      "Loss: 0.547610795665613\n",
      "Loss: 0.43873858942097915\n",
      "Loss: 0.3791601621098333\n",
      "Loss: 0.3064341928277697\n",
      "Loss: 0.27739161385215205\n",
      "Loss: 0.2516870932468088\n",
      "Loss: 0.23708411020698486\n",
      "Loss: 0.21658084733468114\n",
      "______\n",
      "Iteration t=4\n",
      "all:  cs/acc_i=50.60 cs/acc_c=52.08 os/recall_knw=56.45 os/recall_unk=72.77 total/acc_i=49.31 total/acc_c=38.77 total/h_score=49.12\n",
      "selected:  cs/acc_i=49.36 cs/acc_c=51.18 os/recall_knw=52.45 os/recall_unk=76.37 total/acc_i=49.37 total/acc_c=36.88 total/h_score=47.91\n",
      "Loss: 2.3422132303317387\n",
      "Loss: 0.8678854593386253\n",
      "Loss: 0.5344685131063064\n",
      "Loss: 0.4108106420375407\n",
      "Loss: 0.35916729845727485\n",
      "Loss: 0.29253483545035125\n",
      "Loss: 0.2758787260235598\n",
      "Loss: 0.23974889960760873\n",
      "Loss: 0.2254217010612289\n",
      "Loss: 0.20147176111737888\n",
      "______\n",
      "Iteration t=5\n",
      "all:  cs/acc_i=49.92 cs/acc_c=51.47 os/recall_knw=56.11 os/recall_unk=72.97 total/acc_i=49.23 total/acc_c=38.55 total/h_score=48.95\n",
      "selected:  cs/acc_i=49.09 cs/acc_c=50.89 os/recall_knw=54.80 os/recall_unk=73.94 total/acc_i=48.93 total/acc_c=37.68 total/h_score=48.30\n",
      "Loss: 2.321192483026154\n",
      "Loss: 0.8602108286351574\n",
      "Loss: 0.522935852225946\n",
      "Loss: 0.4090111876020626\n",
      "Loss: 0.33575425461238745\n",
      "Loss: 0.3020704596626515\n",
      "Loss: 0.26445172407797407\n",
      "Loss: 0.23627673375363253\n",
      "Loss: 0.21530795220513732\n",
      "Loss: 0.19893001366634758\n",
      "______\n",
      "Iteration t=6\n",
      "all:  cs/acc_i=50.60 cs/acc_c=52.24 os/recall_knw=55.81 os/recall_unk=72.97 total/acc_i=49.16 total/acc_c=38.42 total/h_score=48.84\n",
      "selected:  cs/acc_i=50.36 cs/acc_c=52.11 os/recall_knw=55.53 os/recall_unk=73.07 total/acc_i=49.03 total/acc_c=38.20 total/h_score=48.65\n",
      "Loss: 2.302055084897626\n",
      "Loss: 0.8236488024553945\n",
      "Loss: 0.5052956360121889\n",
      "Loss: 0.4027634637370225\n",
      "Loss: 0.34151875356873196\n",
      "Loss: 0.3004747210971771\n",
      "Loss: 0.2685639150140266\n",
      "Loss: 0.25202191385230227\n",
      "Loss: 0.2028083580906593\n",
      "Loss: 0.20031208104844536\n",
      "______\n",
      "Iteration t=7\n",
      "all:  cs/acc_i=50.75 cs/acc_c=52.27 os/recall_knw=55.77 os/recall_unk=72.97 total/acc_i=49.16 total/acc_c=38.42 total/h_score=48.84\n",
      "selected:  cs/acc_i=50.75 cs/acc_c=52.27 os/recall_knw=55.77 os/recall_unk=72.97 total/acc_i=49.16 total/acc_c=38.42 total/h_score=48.84\n",
      "Loss: 2.300766572356224\n",
      "Loss: 0.8387084487945803\n",
      "Loss: 0.5148235310109393\n",
      "Loss: 0.40401571983050916\n",
      "Loss: 0.34197370059067206\n",
      "Loss: 0.2976845590277545\n",
      "Loss: 0.27285194399976925\n",
      "Loss: 0.24190555094561028\n",
      "Loss: 0.21808831235994736\n",
      "Loss: 0.20126268286408194\n",
      "______\n",
      "Iteration t=8\n",
      "all:  cs/acc_i=51.09 cs/acc_c=52.77 os/recall_knw=55.77 os/recall_unk=72.97 total/acc_i=49.16 total/acc_c=38.42 total/h_score=48.84\n",
      "selected:  cs/acc_i=51.09 cs/acc_c=52.77 os/recall_knw=55.77 os/recall_unk=72.97 total/acc_i=49.16 total/acc_c=38.42 total/h_score=48.84\n",
      "Loss: 2.2947820602886138\n",
      "Loss: 0.8390769263909709\n",
      "Loss: 0.5218959951833371\n",
      "Loss: 0.39479222803586916\n",
      "Loss: 0.3377530468747981\n",
      "Loss: 0.29522508439878303\n",
      "Loss: 0.2643988751806319\n",
      "Loss: 0.23669760593123013\n",
      "Loss: 0.21978714214938302\n",
      "Loss: 0.19240984772782652\n",
      "______\n",
      "Iteration t=9\n",
      "all:  cs/acc_i=50.68 cs/acc_c=52.29 os/recall_knw=55.77 os/recall_unk=72.97 total/acc_i=49.16 total/acc_c=38.42 total/h_score=48.84\n",
      "selected:  cs/acc_i=50.68 cs/acc_c=52.29 os/recall_knw=55.77 os/recall_unk=72.97 total/acc_i=49.16 total/acc_c=38.42 total/h_score=48.84\n",
      "tensor(0)\n",
      "all:  cs/acc_i=50.68 cs/acc_c=52.29 os/recall_knw=55.77 os/recall_unk=72.97 total/acc_i=49.16 total/acc_c=38.42 total/h_score=48.84\n",
      "painting -> sketch lr= 0.001 seed= 2\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19]\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20]\n",
      "Loss: 2.566648314869593\n",
      "Loss: 1.2390778026883564\n",
      "Loss: 0.7080732273361671\n",
      "Loss: 0.5792105980020351\n",
      "Loss: 0.47620570147163654\n",
      "Loss: 0.42258790809483754\n",
      "Loss: 0.37894157379392596\n",
      "Loss: 0.3434411164314028\n",
      "Loss: 0.3025425609063219\n",
      "Loss: 0.28454315689978776\n",
      "tensor(True) tensor(True)\n",
      "______\n",
      "Iteration t=1\n",
      "all:  cs/acc_i=50.15 cs/acc_c=51.77 os/recall_knw=81.32 os/recall_unk=35.93 total/acc_i=41.62 total/acc_c=45.95 total/h_score=40.52\n",
      "selected:  cs/acc_i=47.67 cs/acc_c=49.35 os/recall_knw=45.12 os/recall_unk=89.41 total/acc_i=55.41 total/acc_c=36.66 total/h_score=49.29\n",
      "Loss: 2.4725426780242548\n",
      "Loss: 1.0847449511581777\n",
      "Loss: 0.6296517911787126\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.5100984313324386\n",
      "Loss: 0.4416350924647322\n",
      "Loss: 0.38049251177147325\n",
      "Loss: 0.3273440875003443\n",
      "Loss: 0.30232551441911387\n",
      "Loss: 0.27729800449428604\n",
      "Loss: 0.24488340135590703\n",
      "______\n",
      "Iteration t=2\n",
      "all:  cs/acc_i=49.70 cs/acc_c=51.24 os/recall_knw=63.21 os/recall_unk=65.25 total/acc_i=48.18 total/acc_c=40.95 total/h_score=49.39\n",
      "selected:  cs/acc_i=46.82 cs/acc_c=48.54 os/recall_knw=44.13 os/recall_unk=85.87 total/acc_i=52.06 total/acc_c=33.70 total/h_score=45.65\n",
      "Loss: 2.415758552901242\n",
      "Loss: 0.98297720641718\n",
      "Loss: 0.5769977462264376\n",
      "Loss: 0.45908222641419927\n",
      "Loss: 0.3837991223901237\n",
      "Loss: 0.35160650213787314\n",
      "Loss: 0.31010107528589187\n",
      "Loss: 0.2751628285393529\n",
      "Loss: 0.2529005725962033\n",
      "Loss: 0.21927072030893707\n",
      "______\n",
      "Iteration t=3\n",
      "all:  cs/acc_i=49.81 cs/acc_c=51.25 os/recall_knw=59.62 os/recall_unk=69.37 total/acc_i=48.88 total/acc_c=39.80 total/h_score=49.37\n",
      "selected:  cs/acc_i=48.09 cs/acc_c=49.77 os/recall_knw=50.23 os/recall_unk=80.12 total/acc_i=50.56 total/acc_c=36.14 total/h_score=47.68\n",
      "Loss: 2.355045280931316\n",
      "Loss: 0.8907639481030502\n",
      "Loss: 0.5382559265280182\n",
      "Loss: 0.4302948186923931\n",
      "Loss: 0.36174401815061447\n",
      "Loss: 0.3335618136120049\n",
      "Loss: 0.280670498808225\n",
      "Loss: 0.26455388963222504\n",
      "Loss: 0.22979747568503087\n",
      "Loss: 0.20797706351038955\n",
      "______\n",
      "Iteration t=4\n",
      "all:  cs/acc_i=50.30 cs/acc_c=51.85 os/recall_knw=58.87 os/recall_unk=69.96 total/acc_i=48.90 total/acc_c=39.53 total/h_score=49.26\n",
      "selected:  cs/acc_i=48.86 cs/acc_c=50.89 os/recall_knw=54.05 os/recall_unk=76.09 total/acc_i=49.48 total/acc_c=37.45 total/h_score=48.43\n",
      "Loss: 2.3305818503101667\n",
      "Loss: 0.8952512264251709\n",
      "Loss: 0.5192786758144696\n",
      "Loss: 0.4410836217924953\n",
      "Loss: 0.3468355240610739\n",
      "Loss: 0.290970444586128\n",
      "Loss: 0.28441294527923067\n",
      "Loss: 0.24458359604080518\n",
      "Loss: 0.22258775702988107\n",
      "Loss: 0.2098739649945249\n",
      "______\n",
      "Iteration t=5\n",
      "all:  cs/acc_i=50.00 cs/acc_c=51.51 os/recall_knw=58.57 os/recall_unk=70.03 total/acc_i=48.80 total/acc_c=39.37 total/h_score=49.13\n",
      "selected:  cs/acc_i=48.70 cs/acc_c=50.74 os/recall_knw=56.84 os/recall_unk=72.35 total/acc_i=48.55 total/acc_c=38.22 total/h_score=48.53\n",
      "Loss: 2.315726003183527\n",
      "Loss: 0.8209046418608924\n",
      "Loss: 0.4994813627318332\n",
      "Loss: 0.42093113734413257\n",
      "Loss: 0.339128768456127\n",
      "Loss: 0.31071709585093293\n",
      "Loss: 0.2762578249068154\n",
      "Loss: 0.23416862247685188\n",
      "Loss: 0.21174478916986753\n",
      "Loss: 0.1898268118561038\n",
      "______\n",
      "Iteration t=6\n",
      "all:  cs/acc_i=50.72 cs/acc_c=52.37 os/recall_knw=58.30 os/recall_unk=70.42 total/acc_i=48.83 total/acc_c=39.20 total/h_score=49.06\n",
      "selected:  cs/acc_i=50.30 cs/acc_c=52.13 os/recall_knw=57.95 os/recall_unk=70.79 total/acc_i=48.65 total/acc_c=38.88 total/h_score=48.84\n",
      "Loss: 2.2937184395790102\n",
      "Loss: 0.8264125620126724\n",
      "Loss: 0.5094528012275695\n",
      "Loss: 0.39693209785223005\n",
      "Loss: 0.33553043499588964\n",
      "Loss: 0.2843524557352066\n",
      "Loss: 0.2639102310091257\n",
      "Loss: 0.22555795803666115\n",
      "Loss: 0.20886839798092843\n",
      "Loss: 0.18783917862176897\n",
      "______\n",
      "Iteration t=7\n",
      "all:  cs/acc_i=50.23 cs/acc_c=51.73 os/recall_knw=58.26 os/recall_unk=70.48 total/acc_i=48.83 total/acc_c=39.16 total/h_score=49.04\n",
      "selected:  cs/acc_i=50.21 cs/acc_c=51.71 os/recall_knw=58.25 os/recall_unk=70.48 total/acc_i=48.81 total/acc_c=39.14 total/h_score=49.02\n",
      "Loss: 2.3045121754308147\n",
      "Loss: 0.8494370369559741\n",
      "Loss: 0.4961162921916916\n",
      "Loss: 0.39390081357196033\n",
      "Loss: 0.3418289848651544\n",
      "Loss: 0.2953622342937021\n",
      "Loss: 0.26120301453300204\n",
      "Loss: 0.22028670011763554\n",
      "Loss: 0.2188448921231872\n",
      "Loss: 0.19140662873289974\n",
      "______\n",
      "Iteration t=8\n",
      "all:  cs/acc_i=50.75 cs/acc_c=52.30 os/recall_knw=58.26 os/recall_unk=70.48 total/acc_i=48.83 total/acc_c=39.16 total/h_score=49.04\n",
      "selected:  cs/acc_i=50.75 cs/acc_c=52.30 os/recall_knw=58.26 os/recall_unk=70.48 total/acc_i=48.83 total/acc_c=39.16 total/h_score=49.04\n",
      "Loss: 2.2890691600472803\n",
      "Loss: 0.8208871703461347\n",
      "Loss: 0.5073979859689317\n",
      "Loss: 0.39407055869520424\n",
      "Loss: 0.33156403789363537\n",
      "Loss: 0.2960577659694797\n",
      "Loss: 0.26656285658538104\n",
      "Loss: 0.2418501297850533\n",
      "Loss: 0.21737337194056625\n",
      "Loss: 0.18061172932505132\n",
      "______\n",
      "Iteration t=9\n",
      "all:  cs/acc_i=50.57 cs/acc_c=52.02 os/recall_knw=58.26 os/recall_unk=70.48 total/acc_i=48.83 total/acc_c=39.16 total/h_score=49.04\n",
      "selected:  cs/acc_i=50.57 cs/acc_c=52.02 os/recall_knw=58.26 os/recall_unk=70.48 total/acc_i=48.83 total/acc_c=39.16 total/h_score=49.04\n",
      "tensor(0)\n",
      "all:  cs/acc_i=50.57 cs/acc_c=52.02 os/recall_knw=58.26 os/recall_unk=70.48 total/acc_i=48.83 total/acc_c=39.16 total/h_score=49.04\n",
      "painting -> sketch lr= 0.001 seed= 3\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19]\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20]\n",
      "Loss: 2.5611779721325667\n",
      "Loss: 1.2300274901919894\n",
      "Loss: 0.7316313297660263\n",
      "Loss: 0.5559258806327033\n",
      "Loss: 0.5079214670670726\n",
      "Loss: 0.4222338076621767\n",
      "Loss: 0.38299407837567506\n",
      "Loss: 0.3506879982336488\n",
      "Loss: 0.3036658637935207\n",
      "Loss: 0.2874771068414683\n",
      "tensor(True) tensor(True)\n",
      "______\n",
      "Iteration t=1\n",
      "all:  cs/acc_i=50.64 cs/acc_c=51.88 os/recall_knw=81.70 os/recall_unk=36.58 total/acc_i=42.13 total/acc_c=46.07 total/h_score=40.97\n",
      "selected:  cs/acc_i=48.66 cs/acc_c=49.25 os/recall_knw=45.99 os/recall_unk=90.45 total/acc_i=56.40 total/acc_c=37.02 total/h_score=49.79\n",
      "Loss: 2.4828249245297673\n",
      "Loss: 1.0516143157786013\n",
      "Loss: 0.6311986927016109\n",
      "Loss: 0.49282793109031287\n",
      "Loss: 0.42667528030042556\n",
      "Loss: 0.38379134624904276\n",
      "Loss: 0.33318186025409136\n",
      "Loss: 0.30458098025444674\n",
      "Loss: 0.2818647383474836\n",
      "Loss: 0.24432493749932915\n",
      "______\n",
      "Iteration t=2\n",
      "all:  cs/acc_i=50.57 cs/acc_c=51.95 os/recall_knw=60.34 os/recall_unk=67.21 total/acc_i=48.49 total/acc_c=40.21 total/h_score=49.25\n",
      "selected:  cs/acc_i=47.95 cs/acc_c=49.44 os/recall_knw=42.54 os/recall_unk=86.59 total/acc_i=51.84 total/acc_c=33.18 total/h_score=45.12\n",
      "Loss: 2.416534080417878\n",
      "Loss: 0.9629022198806115\n",
      "Loss: 0.5895220507448966\n",
      "Loss: 0.45648440841687926\n",
      "Loss: 0.3854928439090011\n",
      "Loss: 0.35808629272591086\n",
      "Loss: 0.2896071461909408\n",
      "Loss: 0.2821781486101927\n",
      "Loss: 0.24928566806633537\n",
      "Loss: 0.22172864637585407\n",
      "______\n",
      "Iteration t=3\n",
      "all:  cs/acc_i=50.45 cs/acc_c=51.84 os/recall_knw=58.30 os/recall_unk=70.09 total/acc_i=49.11 total/acc_c=39.70 total/h_score=49.43\n",
      "selected:  cs/acc_i=48.59 cs/acc_c=50.19 os/recall_knw=49.05 os/recall_unk=81.20 total/acc_i=50.72 total/acc_c=35.91 total/h_score=47.57\n",
      "Loss: 2.3587765875069993\n",
      "Loss: 0.9136383796515672\n",
      "Loss: 0.5280053635654243\n",
      "Loss: 0.4350340964353603\n",
      "Loss: 0.3502667915885863\n",
      "Loss: 0.32221538281959033\n",
      "Loss: 0.2901873834107233\n",
      "Loss: 0.2483498919107344\n",
      "Loss: 0.23672292648774126\n",
      "Loss: 0.2023871317991744\n",
      "______\n",
      "Iteration t=4\n",
      "all:  cs/acc_i=51.09 cs/acc_c=52.54 os/recall_knw=57.06 os/recall_unk=71.47 total/acc_i=49.40 total/acc_c=39.43 total/h_score=49.47\n",
      "selected:  cs/acc_i=49.75 cs/acc_c=51.61 os/recall_knw=52.86 os/recall_unk=76.42 total/acc_i=49.73 total/acc_c=37.51 total/h_score=48.54\n",
      "Loss: 2.335327002293894\n",
      "Loss: 0.8639689350976106\n",
      "Loss: 0.50450940623443\n",
      "Loss: 0.4077253719503411\n",
      "Loss: 0.36214033744948676\n",
      "Loss: 0.304256177737249\n",
      "Loss: 0.2868494613711804\n",
      "Loss: 0.25149201015672923\n",
      "Loss: 0.218257968021736\n",
      "Loss: 0.19047453999519348\n",
      "______\n",
      "Iteration t=5\n",
      "all:  cs/acc_i=50.75 cs/acc_c=52.40 os/recall_knw=57.02 os/recall_unk=71.47 total/acc_i=49.40 total/acc_c=39.43 total/h_score=49.47\n",
      "selected:  cs/acc_i=49.67 cs/acc_c=51.71 os/recall_knw=55.56 os/recall_unk=72.95 total/acc_i=49.06 total/acc_c=38.41 total/h_score=48.81\n",
      "Loss: 2.302105993274751\n",
      "Loss: 0.8598599614408927\n",
      "Loss: 0.5103294327249371\n",
      "Loss: 0.39829216885372876\n",
      "Loss: 0.34181193643953744\n",
      "Loss: 0.2911209397593407\n",
      "Loss: 0.26077252923230815\n",
      "Loss: 0.23150389270508678\n",
      "Loss: 0.21628138812152836\n",
      "Loss: 0.19239530719937833\n",
      "______\n",
      "Iteration t=6\n",
      "all:  cs/acc_i=50.98 cs/acc_c=52.55 os/recall_knw=56.79 os/recall_unk=71.73 total/acc_i=49.47 total/acc_c=39.41 total/h_score=49.50\n",
      "selected:  cs/acc_i=50.78 cs/acc_c=52.43 os/recall_knw=56.61 os/recall_unk=71.96 total/acc_i=49.40 total/acc_c=39.24 total/h_score=49.40\n",
      "Loss: 2.2951719100216783\n",
      "Loss: 0.8363369769121269\n",
      "Loss: 0.5176638438400015\n",
      "Loss: 0.3946133162901105\n",
      "Loss: 0.340618962923207\n",
      "Loss: 0.2939445764933485\n",
      "Loss: 0.2628897318399575\n",
      "Loss: 0.24379933188598318\n",
      "Loss: 0.21977855631685161\n",
      "Loss: 0.18712998967034272\n",
      "______\n",
      "Iteration t=7\n",
      "all:  cs/acc_i=51.21 cs/acc_c=52.85 os/recall_knw=56.79 os/recall_unk=71.79 total/acc_i=49.50 total/acc_c=39.41 total/h_score=49.52\n",
      "selected:  cs/acc_i=51.21 cs/acc_c=52.85 os/recall_knw=56.79 os/recall_unk=71.79 total/acc_i=49.50 total/acc_c=39.41 total/h_score=49.52\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 2.2948893361091613\n",
      "Loss: 0.8482475395202637\n",
      "Loss: 0.5062946605682374\n",
      "Loss: 0.4030727084577084\n",
      "Loss: 0.3464819370508194\n",
      "Loss: 0.29574781328439714\n",
      "Loss: 0.2511770345568657\n",
      "Loss: 0.23723549042642117\n",
      "Loss: 0.20838778661191462\n",
      "Loss: 0.1850410497933626\n",
      "______\n",
      "Iteration t=8\n",
      "all:  cs/acc_i=51.92 cs/acc_c=53.61 os/recall_knw=56.79 os/recall_unk=71.79 total/acc_i=49.50 total/acc_c=39.41 total/h_score=49.52\n",
      "selected:  cs/acc_i=51.92 cs/acc_c=53.61 os/recall_knw=56.79 os/recall_unk=71.79 total/acc_i=49.50 total/acc_c=39.41 total/h_score=49.52\n",
      "Loss: 2.3303096265792846\n",
      "Loss: 0.8555096254348755\n",
      "Loss: 0.5134921852946281\n",
      "Loss: 0.40603559142351153\n",
      "Loss: 0.3389749972224236\n",
      "Loss: 0.2915502821356058\n",
      "Loss: 0.27273183093965053\n",
      "Loss: 0.23619002145528795\n",
      "Loss: 0.22360504634678363\n",
      "Loss: 0.20209195217490197\n",
      "______\n",
      "Iteration t=9\n",
      "all:  cs/acc_i=51.02 cs/acc_c=52.51 os/recall_knw=56.79 os/recall_unk=71.79 total/acc_i=49.50 total/acc_c=39.41 total/h_score=49.52\n",
      "selected:  cs/acc_i=51.02 cs/acc_c=52.51 os/recall_knw=56.79 os/recall_unk=71.79 total/acc_i=49.50 total/acc_c=39.41 total/h_score=49.52\n",
      "tensor(0)\n",
      "all:  cs/acc_i=51.02 cs/acc_c=52.51 os/recall_knw=56.79 os/recall_unk=71.79 total/acc_i=49.50 total/acc_c=39.41 total/h_score=49.52\n",
      "painting -> sketch lr= 0.001 seed= 4\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19]\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20]\n",
      "Loss: 2.5832528601247797\n",
      "Loss: 1.2234810770504059\n",
      "Loss: 0.7473830317378675\n",
      "Loss: 0.5751389131817237\n",
      "Loss: 0.488363726034997\n",
      "Loss: 0.4208928057283321\n",
      "Loss: 0.3941426503437537\n",
      "Loss: 0.3543337977358273\n",
      "Loss: 0.3090186940220298\n",
      "Loss: 0.2952229007290154\n",
      "tensor(True) tensor(True)\n",
      "______\n",
      "Iteration t=1\n",
      "all:  cs/acc_i=50.42 cs/acc_c=51.92 os/recall_knw=81.62 os/recall_unk=36.45 total/acc_i=42.25 total/acc_c=46.44 total/h_score=41.04\n",
      "selected:  cs/acc_i=47.59 cs/acc_c=48.88 os/recall_knw=45.34 os/recall_unk=88.69 total/acc_i=56.16 total/acc_c=37.34 total/h_score=49.96\n",
      "Loss: 2.478413748390534\n",
      "Loss: 1.0719966835835402\n",
      "Loss: 0.6518102678305963\n",
      "Loss: 0.4891638601673584\n",
      "Loss: 0.4254191966325629\n",
      "Loss: 0.3853387362232395\n",
      "Loss: 0.33679824231155947\n",
      "Loss: 0.3082907812706396\n",
      "Loss: 0.2815260679698458\n",
      "Loss: 0.2538570216400366\n",
      "______\n",
      "Iteration t=2\n",
      "all:  cs/acc_i=50.23 cs/acc_c=51.67 os/recall_knw=62.42 os/recall_unk=66.16 total/acc_i=48.54 total/acc_c=40.95 total/h_score=49.61\n",
      "selected:  cs/acc_i=47.25 cs/acc_c=48.54 os/recall_knw=43.51 os/recall_unk=85.82 total/acc_i=52.02 total/acc_c=33.56 total/h_score=45.49\n",
      "Loss: 2.4275132844207485\n",
      "Loss: 0.9974939790340739\n",
      "Loss: 0.595853124599938\n",
      "Loss: 0.46026986502452727\n",
      "Loss: 0.37609541566546906\n",
      "Loss: 0.3328807569630102\n",
      "Loss: 0.30753303971996\n",
      "Loss: 0.27833266340948026\n",
      "Loss: 0.2365661295592238\n",
      "Loss: 0.24044171240556678\n",
      "______\n",
      "Iteration t=3\n",
      "all:  cs/acc_i=50.30 cs/acc_c=51.71 os/recall_knw=58.42 os/recall_unk=70.35 total/acc_i=48.99 total/acc_c=39.40 total/h_score=49.23\n",
      "selected:  cs/acc_i=48.42 cs/acc_c=49.89 os/recall_knw=48.79 os/recall_unk=80.46 total/acc_i=50.34 total/acc_c=35.41 total/h_score=46.96\n",
      "Loss: 2.3776557730591814\n",
      "Loss: 0.9094933867454529\n",
      "Loss: 0.5543377264038376\n",
      "Loss: 0.41577078907386117\n",
      "Loss: 0.3628086792062158\n",
      "Loss: 0.3268400489960028\n",
      "Loss: 0.28662034329836783\n",
      "Loss: 0.2608332389884669\n",
      "Loss: 0.23244786068149234\n",
      "Loss: 0.2074696844038756\n",
      "______\n",
      "Iteration t=4\n",
      "all:  cs/acc_i=50.42 cs/acc_c=51.79 os/recall_knw=57.36 os/recall_unk=71.20 total/acc_i=49.02 total/acc_c=39.02 total/h_score=49.05\n",
      "selected:  cs/acc_i=49.40 cs/acc_c=51.14 os/recall_knw=53.05 os/recall_unk=75.50 total/acc_i=49.40 total/acc_c=37.34 total/h_score=48.23\n",
      "Loss: 2.3389749070008596\n",
      "Loss: 0.8619270163277785\n",
      "Loss: 0.5137002378081282\n",
      "Loss: 0.4107626410511633\n",
      "Loss: 0.3485592997012039\n",
      "Loss: 0.31483732579896845\n",
      "Loss: 0.2766996980023881\n",
      "Loss: 0.2367411520332098\n",
      "Loss: 0.22603184782589475\n",
      "Loss: 0.20604549216416976\n",
      "______\n",
      "Iteration t=5\n",
      "all:  cs/acc_i=50.98 cs/acc_c=52.60 os/recall_knw=57.21 os/recall_unk=71.40 total/acc_i=49.07 total/acc_c=38.99 total/h_score=49.06\n",
      "selected:  cs/acc_i=50.22 cs/acc_c=52.18 os/recall_knw=55.41 os/recall_unk=73.37 total/acc_i=49.03 total/acc_c=38.12 total/h_score=48.62\n",
      "Loss: 2.300381809837964\n",
      "Loss: 0.8420154003464446\n",
      "Loss: 0.5042539089918137\n",
      "Loss: 0.39351627540831663\n",
      "Loss: 0.3294797995564889\n",
      "Loss: 0.30304652723122616\n",
      "Loss: 0.27334482736733495\n",
      "Loss: 0.24080354591109315\n",
      "Loss: 0.2141437221242457\n",
      "Loss: 0.20856396026757298\n",
      "______\n",
      "Iteration t=6\n",
      "all:  cs/acc_i=50.57 cs/acc_c=52.14 os/recall_knw=57.06 os/recall_unk=71.47 total/acc_i=49.02 total/acc_c=38.89 total/h_score=48.98\n",
      "selected:  cs/acc_i=50.11 cs/acc_c=51.91 os/recall_knw=56.50 os/recall_unk=71.94 total/acc_i=48.84 total/acc_c=38.52 total/h_score=48.74\n",
      "Loss: 2.3085637781993453\n",
      "Loss: 0.843462411299288\n",
      "Loss: 0.5094492369028459\n",
      "Loss: 0.3910915896176813\n",
      "Loss: 0.34039368414615534\n",
      "Loss: 0.2967415939732249\n",
      "Loss: 0.2505508214684136\n",
      "Loss: 0.23989966044943017\n",
      "Loss: 0.21146671093970418\n",
      "Loss: 0.19417546424700552\n",
      "______\n",
      "Iteration t=7\n",
      "all:  cs/acc_i=51.36 cs/acc_c=52.84 os/recall_knw=57.06 os/recall_unk=71.47 total/acc_i=49.02 total/acc_c=38.89 total/h_score=48.98\n",
      "selected:  cs/acc_i=51.32 cs/acc_c=52.83 os/recall_knw=56.99 os/recall_unk=71.47 total/acc_i=48.99 total/acc_c=38.85 total/h_score=48.95\n",
      "Loss: 2.2967179098129273\n",
      "Loss: 0.815189448595047\n",
      "Loss: 0.5138350948095322\n",
      "Loss: 0.4097237161099911\n",
      "Loss: 0.35146007683873176\n",
      "Loss: 0.2822356647849083\n",
      "Loss: 0.25849757397174833\n",
      "Loss: 0.23343979351222516\n",
      "Loss: 0.21576318913698198\n",
      "Loss: 0.20293414823710917\n",
      "______\n",
      "Iteration t=8\n",
      "all:  cs/acc_i=49.92 cs/acc_c=51.53 os/recall_knw=57.06 os/recall_unk=71.47 total/acc_i=49.02 total/acc_c=38.89 total/h_score=48.98\n",
      "selected:  cs/acc_i=49.92 cs/acc_c=51.53 os/recall_knw=57.06 os/recall_unk=71.47 total/acc_i=49.02 total/acc_c=38.89 total/h_score=48.98\n",
      "Loss: 2.305836675643921\n",
      "Loss: 0.8219303551912308\n",
      "Loss: 0.49687249529361727\n",
      "Loss: 0.38041521030664444\n",
      "Loss: 0.33054252433776854\n",
      "Loss: 0.2933480842113495\n",
      "Loss: 0.25986043441295625\n",
      "Loss: 0.2347109621167183\n",
      "Loss: 0.21645512901991606\n",
      "Loss: 0.19305145736038684\n",
      "______\n",
      "Iteration t=9\n",
      "all:  cs/acc_i=50.60 cs/acc_c=52.26 os/recall_knw=57.06 os/recall_unk=71.47 total/acc_i=49.02 total/acc_c=38.89 total/h_score=48.98\n",
      "selected:  cs/acc_i=50.60 cs/acc_c=52.26 os/recall_knw=57.06 os/recall_unk=71.47 total/acc_i=49.02 total/acc_c=38.89 total/h_score=48.98\n",
      "tensor(0)\n",
      "all:  cs/acc_i=50.60 cs/acc_c=52.26 os/recall_knw=57.06 os/recall_unk=71.47 total/acc_i=49.02 total/acc_c=38.89 total/h_score=48.98\n",
      "painting -> sketch lr= 0.001 seed= 0\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19]\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20]\n",
      "Loss: 2.5621708309839644\n",
      "Loss: 1.239593985219481\n",
      "Loss: 0.7388352065805405\n",
      "Loss: 0.5644448315971112\n",
      "Loss: 0.4997597604832321\n",
      "Loss: 0.43026033643061523\n",
      "Loss: 0.3869136982257404\n",
      "Loss: 0.3565823295838618\n",
      "Loss: 0.33008900280825043\n",
      "Loss: 0.2757910179792258\n",
      "tensor(True) tensor(True)\n",
      "______\n",
      "Iteration t=1\n",
      "all:  cs/acc_i=51.62 cs/acc_c=53.15 os/recall_knw=82.75 os/recall_unk=38.42 total/acc_i=44.14 total/acc_c=48.43 total/h_score=43.04\n",
      "selected:  cs/acc_i=48.80 cs/acc_c=50.45 os/recall_knw=47.65 os/recall_unk=91.01 total/acc_i=59.42 total/acc_c=40.27 total/h_score=53.35\n",
      "Loss: 2.4723300653345444\n",
      "Loss: 1.069566190534947\n",
      "Loss: 0.6235789164316421\n",
      "Loss: 0.5048073095579942\n",
      "Loss: 0.42508285324655326\n",
      "Loss: 0.38295641004600944\n",
      "Loss: 0.3530247334171744\n",
      "Loss: 0.30954418123206673\n",
      "Loss: 0.2790337374762577\n",
      "Loss: 0.25046088798519445\n",
      "______\n",
      "Iteration t=2\n",
      "all:  cs/acc_i=50.23 cs/acc_c=51.92 os/recall_knw=60.83 os/recall_unk=68.00 total/acc_i=49.33 total/acc_c=41.35 total/h_score=50.38\n",
      "selected:  cs/acc_i=46.67 cs/acc_c=48.45 os/recall_knw=42.46 os/recall_unk=85.94 total/acc_i=52.17 total/acc_c=33.67 total/h_score=45.63\n",
      "Loss: 2.433101566012846\n",
      "Loss: 0.9611821769300951\n",
      "Loss: 0.5741815204057125\n",
      "Loss: 0.4496620959781725\n",
      "Loss: 0.4060621930440085\n",
      "Loss: 0.3289051329324005\n",
      "Loss: 0.304948145335694\n",
      "Loss: 0.27081257125379843\n",
      "Loss: 0.24456837974967213\n",
      "Loss: 0.2519048153670556\n",
      "______\n",
      "Iteration t=3\n",
      "all:  cs/acc_i=49.74 cs/acc_c=51.24 os/recall_knw=57.02 os/recall_unk=71.86 total/acc_i=49.52 total/acc_c=39.63 total/h_score=49.73\n",
      "selected:  cs/acc_i=47.19 cs/acc_c=49.04 os/recall_knw=48.46 os/recall_unk=80.97 total/acc_i=50.31 total/acc_c=35.51 total/h_score=47.13\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 2.3812445175080073\n",
      "Loss: 0.9269406596819559\n",
      "Loss: 0.559791510561844\n",
      "Loss: 0.43853354228265357\n",
      "Loss: 0.36757172418363165\n",
      "Loss: 0.31942262471496286\n",
      "Loss: 0.29353363928082704\n",
      "Loss: 0.24968861340186296\n",
      "Loss: 0.24111103056829214\n",
      "Loss: 0.21005539483193195\n",
      "______\n",
      "Iteration t=4\n",
      "all:  cs/acc_i=50.19 cs/acc_c=51.83 os/recall_knw=56.04 os/recall_unk=72.84 total/acc_i=49.55 total/acc_c=39.15 total/h_score=49.48\n",
      "selected:  cs/acc_i=48.68 cs/acc_c=50.70 os/recall_knw=52.10 os/recall_unk=76.60 total/acc_i=49.52 total/acc_c=37.09 total/h_score=48.15\n",
      "Loss: 2.3393244488967513\n",
      "Loss: 0.8644759495388015\n",
      "Loss: 0.5155451279055623\n",
      "Loss: 0.41351284242574143\n",
      "Loss: 0.37593971407937204\n",
      "Loss: 0.31128137521289884\n",
      "Loss: 0.27262454825963933\n",
      "Loss: 0.24331778984625968\n",
      "Loss: 0.22015691271137494\n",
      "Loss: 0.20195248885134773\n",
      "______\n",
      "Iteration t=5\n",
      "all:  cs/acc_i=50.49 cs/acc_c=52.04 os/recall_knw=55.70 os/recall_unk=73.23 total/acc_i=49.62 total/acc_c=39.07 total/h_score=49.48\n",
      "selected:  cs/acc_i=49.51 cs/acc_c=51.33 os/recall_knw=54.19 os/recall_unk=74.11 total/acc_i=49.20 total/acc_c=38.02 total/h_score=48.65\n",
      "Loss: 2.317130208015442\n",
      "Loss: 0.8561566774942437\n",
      "Loss: 0.5162395985150824\n",
      "Loss: 0.41261438064429223\n",
      "Loss: 0.3292909655643969\n",
      "Loss: 0.2910805329072232\n",
      "Loss: 0.27276041820949437\n",
      "Loss: 0.24072010997606783\n",
      "Loss: 0.21909792915898926\n",
      "Loss: 0.2049378753164593\n",
      "______\n",
      "Iteration t=6\n",
      "all:  cs/acc_i=50.57 cs/acc_c=52.23 os/recall_knw=55.70 os/recall_unk=73.30 total/acc_i=49.64 total/acc_c=39.07 total/h_score=49.49\n",
      "selected:  cs/acc_i=50.38 cs/acc_c=52.12 os/recall_knw=55.43 os/recall_unk=73.59 total/acc_i=49.59 total/acc_c=38.90 total/h_score=49.39\n",
      "Loss: 2.3257950698798484\n",
      "Loss: 0.8545990997721792\n",
      "Loss: 0.5145463737157675\n",
      "Loss: 0.39779339935856795\n",
      "Loss: 0.33589754878026756\n",
      "Loss: 0.2957607515246762\n",
      "Loss: 0.26550186500858197\n",
      "Loss: 0.2354728600032899\n",
      "Loss: 0.21834688535646388\n",
      "Loss: 0.19072767793528947\n",
      "______\n",
      "Iteration t=7\n",
      "all:  cs/acc_i=51.58 cs/acc_c=53.32 os/recall_knw=55.70 os/recall_unk=73.30 total/acc_i=49.64 total/acc_c=39.07 total/h_score=49.49\n",
      "selected:  cs/acc_i=51.58 cs/acc_c=53.32 os/recall_knw=55.70 os/recall_unk=73.30 total/acc_i=49.64 total/acc_c=39.07 total/h_score=49.49\n",
      "Loss: 2.2894386591449862\n",
      "Loss: 0.8484906782546351\n",
      "Loss: 0.5017878007023565\n",
      "Loss: 0.3912852595770551\n",
      "Loss: 0.35046183966821237\n",
      "Loss: 0.2902866739238943\n",
      "Loss: 0.27153137338257605\n",
      "Loss: 0.23862257744035414\n",
      "Loss: 0.20845696239942504\n",
      "Loss: 0.18465606947880117\n",
      "______\n",
      "Iteration t=8\n",
      "all:  cs/acc_i=51.02 cs/acc_c=52.71 os/recall_knw=55.70 os/recall_unk=73.30 total/acc_i=49.64 total/acc_c=39.07 total/h_score=49.49\n",
      "selected:  cs/acc_i=51.02 cs/acc_c=52.71 os/recall_knw=55.70 os/recall_unk=73.30 total/acc_i=49.64 total/acc_c=39.07 total/h_score=49.49\n",
      "Loss: 2.2892535045262306\n",
      "Loss: 0.8409200512593792\n",
      "Loss: 0.5088609249120758\n",
      "Loss: 0.4061097702191722\n",
      "Loss: 0.34434205693222825\n",
      "Loss: 0.2979991449223411\n",
      "Loss: 0.26532108225529233\n",
      "Loss: 0.23434504121541977\n",
      "Loss: 0.19959496917022812\n",
      "Loss: 0.19082912362571205\n",
      "______\n",
      "Iteration t=9\n",
      "all:  cs/acc_i=50.94 cs/acc_c=52.55 os/recall_knw=55.70 os/recall_unk=73.30 total/acc_i=49.64 total/acc_c=39.07 total/h_score=49.49\n",
      "selected:  cs/acc_i=50.94 cs/acc_c=52.55 os/recall_knw=55.70 os/recall_unk=73.30 total/acc_i=49.64 total/acc_c=39.07 total/h_score=49.49\n",
      "tensor(0)\n",
      "all:  cs/acc_i=50.94 cs/acc_c=52.55 os/recall_knw=55.70 os/recall_unk=73.30 total/acc_i=49.64 total/acc_c=39.07 total/h_score=49.49\n",
      "painting -> sketch lr= 0.001 seed= 1\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19]\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20]\n",
      "Loss: 2.556820195187967\n",
      "Loss: 1.1924647297808733\n",
      "Loss: 0.7536967081367654\n",
      "Loss: 0.5750743449522705\n",
      "Loss: 0.4938510113923007\n",
      "Loss: 0.4308966524386532\n",
      "Loss: 0.37807317834997933\n",
      "Loss: 0.33724698589907753\n",
      "Loss: 0.31460888080653693\n",
      "Loss: 0.2952398144536548\n",
      "tensor(True) tensor(True)\n",
      "______\n",
      "Iteration t=1\n",
      "all:  cs/acc_i=50.11 cs/acc_c=51.52 os/recall_knw=81.09 os/recall_unk=35.54 total/acc_i=41.65 total/acc_c=46.10 total/h_score=40.34\n",
      "selected:  cs/acc_i=46.07 cs/acc_c=47.53 os/recall_knw=44.52 os/recall_unk=88.44 total/acc_i=54.58 total/acc_c=36.06 total/h_score=48.53\n",
      "Loss: 2.468488382358177\n",
      "Loss: 1.0537945423640458\n",
      "Loss: 0.6239905912502139\n",
      "Loss: 0.4768741154203228\n",
      "Loss: 0.4132847329419033\n",
      "Loss: 0.37517890293954637\n",
      "Loss: 0.3302322310194665\n",
      "Loss: 0.30830123863529924\n",
      "Loss: 0.27276315561988773\n",
      "Loss: 0.25592594170102884\n",
      "______\n",
      "Iteration t=2\n",
      "all:  cs/acc_i=50.64 cs/acc_c=52.16 os/recall_knw=60.15 os/recall_unk=68.13 total/acc_i=48.85 total/acc_c=40.37 total/h_score=49.59\n",
      "selected:  cs/acc_i=48.00 cs/acc_c=49.52 os/recall_knw=42.14 os/recall_unk=86.25 total/acc_i=51.95 total/acc_c=33.34 total/h_score=45.28\n",
      "Loss: 2.422740449052338\n",
      "Loss: 1.0053041917741845\n",
      "Loss: 0.5739594997342573\n",
      "Loss: 0.4465560240483065\n",
      "Loss: 0.38067272469538066\n",
      "Loss: 0.33303474761340596\n",
      "Loss: 0.30870043445344364\n",
      "Loss: 0.27731294495933645\n",
      "Loss: 0.2442233102447396\n",
      "Loss: 0.22096001960063746\n",
      "______\n",
      "Iteration t=3\n",
      "all:  cs/acc_i=51.32 cs/acc_c=52.75 os/recall_knw=56.00 os/recall_unk=73.76 total/acc_i=49.86 total/acc_c=38.92 total/h_score=49.43\n",
      "selected:  cs/acc_i=49.30 cs/acc_c=51.17 os/recall_knw=47.45 os/recall_unk=81.37 total/acc_i=50.42 total/acc_c=34.99 total/h_score=46.62\n",
      "Loss: 2.370334301824155\n",
      "Loss: 0.9350906539222469\n",
      "Loss: 0.5585289578074994\n",
      "Loss: 0.43182574795640033\n",
      "Loss: 0.3709059193082478\n",
      "Loss: 0.32114694886233497\n",
      "Loss: 0.29378084624591083\n",
      "Loss: 0.2593268472539342\n",
      "Loss: 0.23986211945505245\n",
      "Loss: 0.2111884350038093\n",
      "______\n",
      "Iteration t=4\n",
      "all:  cs/acc_i=50.23 cs/acc_c=51.74 os/recall_knw=55.28 os/recall_unk=73.95 total/acc_i=49.71 total/acc_c=38.58 total/h_score=49.16\n",
      "selected:  cs/acc_i=48.44 cs/acc_c=50.47 os/recall_knw=51.35 os/recall_unk=78.53 total/acc_i=49.70 total/acc_c=36.45 total/h_score=47.79\n",
      "Loss: 2.333873961152149\n",
      "Loss: 0.8637497291094115\n",
      "Loss: 0.5311233172772312\n",
      "Loss: 0.4150678445937253\n",
      "Loss: 0.3591362480856791\n",
      "Loss: 0.3199879561840486\n",
      "Loss: 0.285894750828753\n",
      "Loss: 0.24765133361543426\n",
      "Loss: 0.2352755293876183\n",
      "Loss: 0.19961443238210777\n",
      "______\n",
      "Iteration t=5\n",
      "all:  cs/acc_i=49.55 cs/acc_c=51.09 os/recall_knw=55.13 os/recall_unk=73.95 total/acc_i=49.66 total/acc_c=38.51 total/h_score=49.09\n",
      "selected:  cs/acc_i=48.41 cs/acc_c=50.30 os/recall_knw=53.77 os/recall_unk=74.93 total/acc_i=49.19 total/acc_c=37.43 total/h_score=48.22\n",
      "Loss: 2.306045095451543\n",
      "Loss: 0.8305508140169207\n",
      "Loss: 0.5088758918716282\n",
      "Loss: 0.4054477621847\n",
      "Loss: 0.3444276562907168\n",
      "Loss: 0.3050363410081043\n",
      "Loss: 0.2675506384951658\n",
      "Loss: 0.23968883402279165\n",
      "Loss: 0.21562035456605133\n",
      "Loss: 0.2040889169944481\n",
      "______\n",
      "Iteration t=6\n",
      "all:  cs/acc_i=51.17 cs/acc_c=52.77 os/recall_knw=55.13 os/recall_unk=73.95 total/acc_i=49.66 total/acc_c=38.51 total/h_score=49.09\n",
      "selected:  cs/acc_i=50.69 cs/acc_c=52.47 os/recall_knw=54.69 os/recall_unk=74.34 total/acc_i=49.44 total/acc_c=38.11 total/h_score=48.78\n",
      "Loss: 2.3193079790448756\n",
      "Loss: 0.8485469935628457\n",
      "Loss: 0.5239276145774174\n",
      "Loss: 0.40703812174923054\n",
      "Loss: 0.3346571853248084\n",
      "Loss: 0.2974371180483481\n",
      "Loss: 0.2655193024595094\n",
      "Loss: 0.2358760743333799\n",
      "Loss: 0.22327427772002492\n",
      "Loss: 0.20044651810776412\n",
      "______\n",
      "Iteration t=7\n",
      "all:  cs/acc_i=51.25 cs/acc_c=52.85 os/recall_knw=55.13 os/recall_unk=73.95 total/acc_i=49.66 total/acc_c=38.51 total/h_score=49.09\n",
      "selected:  cs/acc_i=51.25 cs/acc_c=52.85 os/recall_knw=55.13 os/recall_unk=73.95 total/acc_i=49.66 total/acc_c=38.51 total/h_score=49.09\n",
      "Loss: 2.3244892474610794\n",
      "Loss: 0.8557266188777892\n",
      "Loss: 0.5076823582654058\n",
      "Loss: 0.41471159931739815\n",
      "Loss: 0.3423123379286967\n",
      "Loss: 0.2957671201120504\n",
      "Loss: 0.2636805735076005\n",
      "Loss: 0.25091656464857126\n",
      "Loss: 0.22257642119157653\n",
      "Loss: 0.21014312582339353\n",
      "______\n",
      "Iteration t=8\n",
      "all:  cs/acc_i=51.28 cs/acc_c=52.85 os/recall_knw=55.13 os/recall_unk=73.95 total/acc_i=49.66 total/acc_c=38.51 total/h_score=49.09\n",
      "selected:  cs/acc_i=51.28 cs/acc_c=52.85 os/recall_knw=55.13 os/recall_unk=73.95 total/acc_i=49.66 total/acc_c=38.51 total/h_score=49.09\n",
      "Loss: 2.3004631310822026\n",
      "Loss: 0.8407848671621639\n",
      "Loss: 0.524096354118243\n",
      "Loss: 0.3901093899600419\n",
      "Loss: 0.3158986903877876\n",
      "Loss: 0.305800183702577\n",
      "Loss: 0.2621243151756916\n",
      "Loss: 0.23359890873374245\n",
      "Loss: 0.21010068778386\n",
      "Loss: 0.19452777809580327\n",
      "______\n",
      "Iteration t=9\n",
      "all:  cs/acc_i=51.96 cs/acc_c=53.64 os/recall_knw=55.13 os/recall_unk=73.95 total/acc_i=49.66 total/acc_c=38.51 total/h_score=49.09\n",
      "selected:  cs/acc_i=51.96 cs/acc_c=53.64 os/recall_knw=55.13 os/recall_unk=73.95 total/acc_i=49.66 total/acc_c=38.51 total/h_score=49.09\n",
      "tensor(0)\n",
      "all:  cs/acc_i=51.96 cs/acc_c=53.64 os/recall_knw=55.13 os/recall_unk=73.95 total/acc_i=49.66 total/acc_c=38.51 total/h_score=49.09\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "painting -> sketch lr= 0.001 seed= 2\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19]\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20]\n",
      "Loss: 2.5668929209784856\n",
      "Loss: 1.2376507016086074\n",
      "Loss: 0.7070717049969567\n",
      "Loss: 0.5790027256995912\n",
      "Loss: 0.47644240554993744\n",
      "Loss: 0.42254357544518023\n",
      "Loss: 0.37938168219157625\n",
      "Loss: 0.3434610495333949\n",
      "Loss: 0.30248160549887904\n",
      "Loss: 0.28449626109272086\n",
      "tensor(True) tensor(True)\n",
      "______\n",
      "Iteration t=1\n",
      "all:  cs/acc_i=50.34 cs/acc_c=51.93 os/recall_knw=81.77 os/recall_unk=36.71 total/acc_i=42.13 total/acc_c=46.32 total/h_score=41.15\n",
      "selected:  cs/acc_i=47.58 cs/acc_c=49.41 os/recall_knw=45.67 os/recall_unk=89.33 total/acc_i=55.97 total/acc_c=36.82 total/h_score=49.46\n",
      "Loss: 2.4671410906548594\n",
      "Loss: 1.0856610539497114\n",
      "Loss: 0.6524357167529125\n",
      "Loss: 0.5201676688065716\n",
      "Loss: 0.4330560831608726\n",
      "Loss: 0.37017248906925615\n",
      "Loss: 0.3344957271189082\n",
      "Loss: 0.3011379446469101\n",
      "Loss: 0.2892527617879358\n",
      "Loss: 0.25395176285768256\n",
      "______\n",
      "Iteration t=2\n",
      "all:  cs/acc_i=50.04 cs/acc_c=51.57 os/recall_knw=62.49 os/recall_unk=64.79 total/acc_i=47.99 total/acc_c=40.81 total/h_score=49.17\n",
      "selected:  cs/acc_i=47.30 cs/acc_c=48.98 os/recall_knw=43.43 os/recall_unk=85.20 total/acc_i=51.73 total/acc_c=33.68 total/h_score=45.57\n",
      "Loss: 2.4084743737080774\n",
      "Loss: 0.9574670078010734\n",
      "Loss: 0.5799926181725406\n",
      "Loss: 0.4413196328309698\n",
      "Loss: 0.38546133106318087\n",
      "Loss: 0.33988819411451665\n",
      "Loss: 0.29293687614279057\n",
      "Loss: 0.2720360427223351\n",
      "Loss: 0.24248950443136583\n",
      "Loss: 0.22895875795308604\n",
      "______\n",
      "Iteration t=3\n",
      "all:  cs/acc_i=49.96 cs/acc_c=51.33 os/recall_knw=56.72 os/recall_unk=71.47 total/acc_i=49.09 total/acc_c=38.96 total/h_score=49.05\n",
      "selected:  cs/acc_i=47.71 cs/acc_c=49.37 os/recall_knw=47.93 os/recall_unk=80.47 total/acc_i=49.94 total/acc_c=34.90 total/h_score=46.43\n",
      "Loss: 2.3702589086864307\n",
      "Loss: 0.8885778232761051\n",
      "Loss: 0.5420255577434664\n",
      "Loss: 0.43442912001324735\n",
      "Loss: 0.35751408749948377\n",
      "Loss: 0.3273407537976037\n",
      "Loss: 0.2869344841364933\n",
      "Loss: 0.2549079387894143\n",
      "Loss: 0.2290043236768764\n",
      "Loss: 0.19847040289770002\n",
      "______\n",
      "Iteration t=4\n",
      "all:  cs/acc_i=50.87 cs/acc_c=52.56 os/recall_knw=55.58 os/recall_unk=72.58 total/acc_i=49.16 total/acc_c=38.49 total/h_score=48.83\n",
      "selected:  cs/acc_i=49.49 cs/acc_c=51.47 os/recall_knw=51.78 os/recall_unk=76.22 total/acc_i=49.13 total/acc_c=36.47 total/h_score=47.48\n",
      "Loss: 2.32171659240164\n",
      "Loss: 0.838613130806879\n",
      "Loss: 0.5150950710020304\n",
      "Loss: 0.4090129976242656\n",
      "Loss: 0.3463142676021764\n",
      "Loss: 0.30709063866522524\n",
      "Loss: 0.26407072219265054\n",
      "Loss: 0.23568335222275189\n",
      "Loss: 0.22303264404191134\n",
      "Loss: 0.20176121675132708\n",
      "______\n",
      "Iteration t=5\n",
      "all:  cs/acc_i=49.89 cs/acc_c=51.54 os/recall_knw=55.51 os/recall_unk=72.58 total/acc_i=49.14 total/acc_c=38.46 total/h_score=48.80\n",
      "selected:  cs/acc_i=48.88 cs/acc_c=50.84 os/recall_knw=54.27 os/recall_unk=73.54 total/acc_i=48.73 total/acc_c=37.48 total/h_score=48.04\n",
      "Loss: 2.3050594748282918\n",
      "Loss: 0.8330119667004566\n",
      "Loss: 0.5034787265013675\n",
      "Loss: 0.41578753505434307\n",
      "Loss: 0.33931389058731043\n",
      "Loss: 0.2902745399243978\n",
      "Loss: 0.27866949397994545\n",
      "Loss: 0.22654157034596617\n",
      "Loss: 0.21107461996832672\n",
      "Loss: 0.1871987790021361\n",
      "______\n",
      "Iteration t=6\n",
      "all:  cs/acc_i=51.09 cs/acc_c=52.57 os/recall_knw=55.43 os/recall_unk=72.71 total/acc_i=49.16 total/acc_c=38.43 total/h_score=48.79\n",
      "selected:  cs/acc_i=50.97 cs/acc_c=52.53 os/recall_knw=55.25 os/recall_unk=72.90 total/acc_i=49.12 total/acc_c=38.33 total/h_score=48.73\n",
      "Loss: 2.2923545707092594\n",
      "Loss: 0.8185748471180919\n",
      "Loss: 0.5147716979145521\n",
      "Loss: 0.41354903005636656\n",
      "Loss: 0.3491304746342574\n",
      "Loss: 0.2855586754497488\n",
      "Loss: 0.27421745250702867\n",
      "Loss: 0.2336815363060125\n",
      "Loss: 0.2207512382402835\n",
      "Loss: 0.1950606129279262\n",
      "______\n",
      "Iteration t=7\n",
      "all:  cs/acc_i=50.98 cs/acc_c=52.63 os/recall_knw=55.43 os/recall_unk=72.77 total/acc_i=49.19 total/acc_c=38.43 total/h_score=48.81\n",
      "selected:  cs/acc_i=50.98 cs/acc_c=52.63 os/recall_knw=55.43 os/recall_unk=72.77 total/acc_i=49.19 total/acc_c=38.43 total/h_score=48.81\n",
      "Loss: 2.298589661717415\n",
      "Loss: 0.8463361119070361\n",
      "Loss: 0.5054147376288329\n",
      "Loss: 0.40015424385426507\n",
      "Loss: 0.3297419292071173\n",
      "Loss: 0.30625991610389564\n",
      "Loss: 0.2508538622529276\n",
      "Loss: 0.2376552245940172\n",
      "Loss: 0.21812686288068373\n",
      "Loss: 0.1930224422004915\n",
      "______\n",
      "Iteration t=8\n",
      "all:  cs/acc_i=50.87 cs/acc_c=52.45 os/recall_knw=55.43 os/recall_unk=72.77 total/acc_i=49.19 total/acc_c=38.43 total/h_score=48.81\n",
      "selected:  cs/acc_i=50.87 cs/acc_c=52.45 os/recall_knw=55.43 os/recall_unk=72.77 total/acc_i=49.19 total/acc_c=38.43 total/h_score=48.81\n",
      "Loss: 2.3117170670340137\n",
      "Loss: 0.8231469044281591\n",
      "Loss: 0.49789807645063244\n",
      "Loss: 0.40404210059392837\n",
      "Loss: 0.31996200365885613\n",
      "Loss: 0.2904974690698568\n",
      "Loss: 0.2578055150506477\n",
      "Loss: 0.2365566571994174\n",
      "Loss: 0.2157484496372842\n",
      "Loss: 0.2041193280601874\n",
      "______\n",
      "Iteration t=9\n",
      "all:  cs/acc_i=50.53 cs/acc_c=52.08 os/recall_knw=55.43 os/recall_unk=72.77 total/acc_i=49.19 total/acc_c=38.43 total/h_score=48.81\n",
      "selected:  cs/acc_i=50.53 cs/acc_c=52.08 os/recall_knw=55.43 os/recall_unk=72.77 total/acc_i=49.19 total/acc_c=38.43 total/h_score=48.81\n",
      "tensor(0)\n",
      "all:  cs/acc_i=50.53 cs/acc_c=52.08 os/recall_knw=55.43 os/recall_unk=72.77 total/acc_i=49.19 total/acc_c=38.43 total/h_score=48.81\n",
      "painting -> sketch lr= 0.001 seed= 3\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19]\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20]\n",
      "Loss: 2.558187306873382\n",
      "Loss: 1.228447293478345\n",
      "Loss: 0.7319680307277296\n",
      "Loss: 0.5562294646703377\n",
      "Loss: 0.5083126582638927\n",
      "Loss: 0.4225647979312473\n",
      "Loss: 0.38301404419714813\n",
      "Loss: 0.35122696085581706\n",
      "Loss: 0.3036785121790316\n",
      "Loss: 0.2875549310729617\n",
      "tensor(True) tensor(True)\n",
      "______\n",
      "Iteration t=1\n",
      "all:  cs/acc_i=50.26 cs/acc_c=51.52 os/recall_knw=81.74 os/recall_unk=36.65 total/acc_i=42.32 total/acc_c=46.38 total/h_score=41.13\n",
      "selected:  cs/acc_i=46.84 cs/acc_c=48.06 os/recall_knw=46.40 os/recall_unk=90.91 total/acc_i=56.55 total/acc_c=37.39 total/h_score=50.24\n",
      "Loss: 2.4718103496467365\n",
      "Loss: 1.0793344799210043\n",
      "Loss: 0.6421201031874207\n",
      "Loss: 0.5014713777630937\n",
      "Loss: 0.42597368739399255\n",
      "Loss: 0.3671811784745431\n",
      "Loss: 0.3518094928095154\n",
      "Loss: 0.296963758273598\n",
      "Loss: 0.26672482194707675\n",
      "Loss: 0.2495449055351463\n",
      "______\n",
      "Iteration t=2\n",
      "all:  cs/acc_i=50.42 cs/acc_c=51.85 os/recall_knw=65.92 os/recall_unk=60.93 total/acc_i=47.37 total/acc_c=41.83 total/h_score=48.93\n",
      "selected:  cs/acc_i=48.49 cs/acc_c=50.34 os/recall_knw=46.41 os/recall_unk=85.81 total/acc_i=52.71 total/acc_c=35.69 total/h_score=47.86\n",
      "Loss: 2.4299480537755773\n",
      "Loss: 0.9747693077960146\n",
      "Loss: 0.564598320410886\n",
      "Loss: 0.4608989101620989\n",
      "Loss: 0.38231680227802434\n",
      "Loss: 0.3434458215712407\n",
      "Loss: 0.31759142807317436\n",
      "Loss: 0.27477062989128836\n",
      "Loss: 0.264151684649357\n",
      "Loss: 0.23462260904115276\n",
      "______\n",
      "Iteration t=3\n",
      "all:  cs/acc_i=50.08 cs/acc_c=51.56 os/recall_knw=59.51 os/recall_unk=69.31 total/acc_i=48.85 total/acc_c=39.80 total/h_score=49.36\n",
      "selected:  cs/acc_i=48.43 cs/acc_c=50.19 os/recall_knw=49.70 os/recall_unk=80.53 total/acc_i=50.67 total/acc_c=36.20 total/h_score=47.80\n",
      "Loss: 2.3546999547792518\n",
      "Loss: 0.9125923599885858\n",
      "Loss: 0.5392262387534846\n",
      "Loss: 0.4276709368047507\n",
      "Loss: 0.361989080776339\n",
      "Loss: 0.3167910557402217\n",
      "Loss: 0.2856778642081696\n",
      "Loss: 0.2512874853999718\n",
      "Loss: 0.23365426405292491\n",
      "Loss: 0.2175508305106474\n",
      "______\n",
      "Iteration t=4\n",
      "all:  cs/acc_i=50.75 cs/acc_c=52.30 os/recall_knw=59.02 os/recall_unk=69.96 total/acc_i=49.02 total/acc_c=39.71 total/h_score=49.42\n",
      "selected:  cs/acc_i=49.75 cs/acc_c=51.76 os/recall_knw=54.14 os/recall_unk=75.55 total/acc_i=49.72 total/acc_c=37.97 total/h_score=48.84\n",
      "Loss: 2.325136596461137\n",
      "Loss: 0.8704114127904177\n",
      "Loss: 0.5362831421196461\n",
      "Loss: 0.42303293955822785\n",
      "Loss: 0.3607950334747632\n",
      "Loss: 0.3068179548407594\n",
      "Loss: 0.2816127397119999\n",
      "Loss: 0.24566103219985963\n",
      "Loss: 0.21177376609606047\n",
      "Loss: 0.20381666324101388\n",
      "______\n",
      "Iteration t=5\n",
      "all:  cs/acc_i=51.28 cs/acc_c=52.99 os/recall_knw=58.94 os/recall_unk=69.96 total/acc_i=48.99 total/acc_c=39.67 total/h_score=49.38\n",
      "selected:  cs/acc_i=50.71 cs/acc_c=52.83 os/recall_knw=57.13 os/recall_unk=71.94 total/acc_i=49.08 total/acc_c=39.02 total/h_score=49.19\n",
      "Loss: 2.301754645973082\n",
      "Loss: 0.84686824751769\n",
      "Loss: 0.5066091657167504\n",
      "Loss: 0.40175541429987804\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.337010135444311\n",
      "Loss: 0.3035033654557307\n",
      "Loss: 0.27388115549980385\n",
      "Loss: 0.24023318269595442\n",
      "Loss: 0.2265217051302132\n",
      "Loss: 0.19182978098390074\n",
      "______\n",
      "Iteration t=6\n",
      "all:  cs/acc_i=50.68 cs/acc_c=52.28 os/recall_knw=58.75 os/recall_unk=70.16 total/acc_i=49.04 total/acc_c=39.65 total/h_score=49.40\n",
      "selected:  cs/acc_i=50.48 cs/acc_c=52.18 os/recall_knw=58.36 os/recall_unk=70.62 total/acc_i=49.02 total/acc_c=39.44 total/h_score=49.31\n",
      "Loss: 2.277674662164483\n",
      "Loss: 0.8380235630677516\n",
      "Loss: 0.5062017357681852\n",
      "Loss: 0.39794045188037525\n",
      "Loss: 0.34977038854740533\n",
      "Loss: 0.28926217161208034\n",
      "Loss: 0.26555763924145603\n",
      "Loss: 0.23936885648752113\n",
      "Loss: 0.2129479215677041\n",
      "Loss: 0.19231349620151805\n",
      "______\n",
      "Iteration t=7\n",
      "all:  cs/acc_i=51.81 cs/acc_c=53.39 os/recall_knw=58.75 os/recall_unk=70.16 total/acc_i=49.04 total/acc_c=39.65 total/h_score=49.40\n",
      "selected:  cs/acc_i=51.81 cs/acc_c=53.39 os/recall_knw=58.75 os/recall_unk=70.16 total/acc_i=49.04 total/acc_c=39.65 total/h_score=49.40\n",
      "Loss: 2.285227942561346\n",
      "Loss: 0.8081448340699786\n",
      "Loss: 0.4808333325125868\n",
      "Loss: 0.4118995295748824\n",
      "Loss: 0.3382360709919816\n",
      "Loss: 0.2950739282523356\n",
      "Loss: 0.2644791487190459\n",
      "Loss: 0.22808355141785883\n",
      "Loss: 0.21270862187717168\n",
      "Loss: 0.18511167567755496\n",
      "______\n",
      "Iteration t=8\n",
      "all:  cs/acc_i=51.06 cs/acc_c=52.68 os/recall_knw=58.75 os/recall_unk=70.16 total/acc_i=49.04 total/acc_c=39.65 total/h_score=49.40\n",
      "selected:  cs/acc_i=51.06 cs/acc_c=52.68 os/recall_knw=58.75 os/recall_unk=70.16 total/acc_i=49.04 total/acc_c=39.65 total/h_score=49.40\n",
      "Loss: 2.304252512871273\n",
      "Loss: 0.8439704229434332\n",
      "Loss: 0.5038403012449779\n",
      "Loss: 0.39010714437989963\n",
      "Loss: 0.33955752033562886\n",
      "Loss: 0.307021140194838\n",
      "Loss: 0.26517403962474967\n",
      "Loss: 0.23341311169936071\n",
      "Loss: 0.22633571594598748\n",
      "Loss: 0.19347103728011014\n",
      "______\n",
      "Iteration t=9\n",
      "all:  cs/acc_i=51.13 cs/acc_c=52.65 os/recall_knw=58.75 os/recall_unk=70.16 total/acc_i=49.04 total/acc_c=39.65 total/h_score=49.40\n",
      "selected:  cs/acc_i=51.13 cs/acc_c=52.65 os/recall_knw=58.75 os/recall_unk=70.16 total/acc_i=49.04 total/acc_c=39.65 total/h_score=49.40\n",
      "tensor(0)\n",
      "all:  cs/acc_i=51.13 cs/acc_c=52.65 os/recall_knw=58.75 os/recall_unk=70.16 total/acc_i=49.04 total/acc_c=39.65 total/h_score=49.40\n",
      "painting -> sketch lr= 0.001 seed= 4\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19]\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20]\n",
      "Loss: 2.5832644543319785\n",
      "Loss: 1.2227652325201286\n",
      "Loss: 0.747208836217406\n",
      "Loss: 0.5752452261864193\n",
      "Loss: 0.48900928454739706\n",
      "Loss: 0.4218439786995529\n",
      "Loss: 0.39474371911356687\n",
      "Loss: 0.35434866160469713\n",
      "Loss: 0.30950733711795203\n",
      "Loss: 0.29467876302817514\n",
      "tensor(True) tensor(True)\n",
      "______\n",
      "Iteration t=1\n",
      "all:  cs/acc_i=50.26 cs/acc_c=51.76 os/recall_knw=81.81 os/recall_unk=36.78 total/acc_i=42.39 total/acc_c=46.54 total/h_score=41.28\n",
      "selected:  cs/acc_i=47.17 cs/acc_c=48.21 os/recall_knw=45.48 os/recall_unk=88.78 total/acc_i=56.43 total/acc_c=37.34 total/h_score=49.97\n",
      "Loss: 2.4814893498140225\n",
      "Loss: 1.0404180180208356\n",
      "Loss: 0.6266301248003455\n",
      "Loss: 0.5065129038457777\n",
      "Loss: 0.434983013307347\n",
      "Loss: 0.3972724795925851\n",
      "Loss: 0.3429182531202541\n",
      "Loss: 0.29393777642033847\n",
      "Loss: 0.2853292096954058\n",
      "Loss: 0.25030360661227913\n",
      "______\n",
      "Iteration t=2\n",
      "all:  cs/acc_i=51.25 cs/acc_c=52.90 os/recall_knw=61.02 os/recall_unk=68.46 total/acc_i=49.64 total/acc_c=41.53 total/h_score=50.64\n",
      "selected:  cs/acc_i=48.51 cs/acc_c=50.09 os/recall_knw=42.87 os/recall_unk=86.59 total/acc_i=52.82 total/acc_c=34.48 total/h_score=46.59\n",
      "Loss: 2.409044001080574\n",
      "Loss: 0.9660852581536005\n",
      "Loss: 0.5655824743006208\n",
      "Loss: 0.458706623780618\n",
      "Loss: 0.36762795802376685\n",
      "Loss: 0.34119313282020597\n",
      "Loss: 0.3112418296823808\n",
      "Loss: 0.2865206515501945\n",
      "Loss: 0.24789789742832885\n",
      "Loss: 0.23217622354763365\n",
      "______\n",
      "Iteration t=3\n",
      "all:  cs/acc_i=50.68 cs/acc_c=52.21 os/recall_knw=56.64 os/recall_unk=72.84 total/acc_i=49.71 total/acc_c=39.32 total/h_score=49.64\n",
      "selected:  cs/acc_i=48.55 cs/acc_c=50.38 os/recall_knw=48.01 os/recall_unk=80.95 total/acc_i=50.40 total/acc_c=35.39 total/h_score=47.00\n",
      "Loss: 2.369963311630747\n",
      "Loss: 0.9144812057847562\n",
      "Loss: 0.546714802151141\n",
      "Loss: 0.4251932228388994\n",
      "Loss: 0.355172315110331\n",
      "Loss: 0.31589843770084175\n",
      "Loss: 0.2876800867850366\n",
      "Loss: 0.2469847158083449\n",
      "Loss: 0.23750680607298147\n",
      "Loss: 0.21244354929936968\n",
      "______\n",
      "Iteration t=4\n",
      "all:  cs/acc_i=50.34 cs/acc_c=51.84 os/recall_knw=55.96 os/recall_unk=73.63 total/acc_i=49.74 total/acc_c=38.92 total/h_score=49.42\n",
      "selected:  cs/acc_i=48.55 cs/acc_c=50.48 os/recall_knw=52.27 os/recall_unk=76.95 total/acc_i=49.42 total/acc_c=36.70 total/h_score=47.82\n",
      "Loss: 2.3336425555799796\n",
      "Loss: 0.8668291556286513\n",
      "Loss: 0.5360170662029019\n",
      "Loss: 0.41665441199950093\n",
      "Loss: 0.3447660720560341\n",
      "Loss: 0.32526000866580707\n",
      "Loss: 0.2864450626854617\n",
      "Loss: 0.2402936744827107\n",
      "Loss: 0.22463056939229306\n",
      "Loss: 0.1989880250494101\n",
      "______\n",
      "Iteration t=5\n",
      "all:  cs/acc_i=49.92 cs/acc_c=51.47 os/recall_knw=55.89 os/recall_unk=73.63 total/acc_i=49.71 total/acc_c=38.89 total/h_score=49.39\n",
      "selected:  cs/acc_i=48.81 cs/acc_c=50.70 os/recall_knw=54.46 os/recall_unk=74.70 total/acc_i=49.28 total/acc_c=37.81 total/h_score=48.56\n",
      "Loss: 2.3043663326574833\n",
      "Loss: 0.8367128272445834\n",
      "Loss: 0.5131033927202224\n",
      "Loss: 0.3967890799653773\n",
      "Loss: 0.33404655146355533\n",
      "Loss: 0.29620849117636683\n",
      "Loss: 0.2642336880065957\n",
      "Loss: 0.22137335884023684\n",
      "Loss: 0.21930144474822647\n",
      "Loss: 0.19354053361683476\n",
      "______\n",
      "Iteration t=6\n",
      "all:  cs/acc_i=50.68 cs/acc_c=52.26 os/recall_knw=55.81 os/recall_unk=73.63 total/acc_i=49.69 total/acc_c=38.86 total/h_score=49.36\n",
      "selected:  cs/acc_i=50.30 cs/acc_c=52.01 os/recall_knw=55.41 os/recall_unk=73.96 total/acc_i=49.53 total/acc_c=38.52 total/h_score=49.10\n",
      "Loss: 2.312892545572659\n",
      "Loss: 0.8627254582851039\n",
      "Loss: 0.509803221956921\n",
      "Loss: 0.4144582530023598\n",
      "Loss: 0.33348801879868334\n",
      "Loss: 0.288428245738209\n",
      "Loss: 0.2693052911746357\n",
      "Loss: 0.24616191768453188\n",
      "Loss: 0.22201629691881689\n",
      "Loss: 0.1965009431139781\n",
      "______\n",
      "Iteration t=7\n",
      "all:  cs/acc_i=51.47 cs/acc_c=53.12 os/recall_knw=55.81 os/recall_unk=73.63 total/acc_i=49.69 total/acc_c=38.86 total/h_score=49.36\n",
      "selected:  cs/acc_i=51.47 cs/acc_c=53.12 os/recall_knw=55.81 os/recall_unk=73.63 total/acc_i=49.69 total/acc_c=38.86 total/h_score=49.36\n",
      "Loss: 2.309311884064828\n",
      "Loss: 0.8457778706665962\n",
      "Loss: 0.5108916033059359\n",
      "Loss: 0.39845394108804966\n",
      "Loss: 0.33865830425413385\n",
      "Loss: 0.3023822656081569\n",
      "Loss: 0.25456442140162955\n",
      "Loss: 0.234785785162521\n",
      "Loss: 0.21759938819694422\n",
      "Loss: 0.19577242093040578\n",
      "______\n",
      "Iteration t=8\n",
      "all:  cs/acc_i=50.75 cs/acc_c=52.32 os/recall_knw=55.81 os/recall_unk=73.63 total/acc_i=49.69 total/acc_c=38.86 total/h_score=49.36\n",
      "selected:  cs/acc_i=50.75 cs/acc_c=52.32 os/recall_knw=55.81 os/recall_unk=73.63 total/acc_i=49.69 total/acc_c=38.86 total/h_score=49.36\n",
      "Loss: 2.3151208455524137\n",
      "Loss: 0.8146149278167756\n",
      "Loss: 0.5176682600210751\n",
      "Loss: 0.39843916700732324\n",
      "Loss: 0.33860790026524373\n",
      "Loss: 0.29756919787295405\n",
      "Loss: 0.2587460710051199\n",
      "Loss: 0.2373796090964348\n",
      "Loss: 0.21171600733613294\n",
      "Loss: 0.20674765380399843\n",
      "______\n",
      "Iteration t=9\n",
      "all:  cs/acc_i=50.64 cs/acc_c=52.32 os/recall_knw=55.81 os/recall_unk=73.63 total/acc_i=49.69 total/acc_c=38.86 total/h_score=49.36\n",
      "selected:  cs/acc_i=50.64 cs/acc_c=52.32 os/recall_knw=55.81 os/recall_unk=73.63 total/acc_i=49.69 total/acc_c=38.86 total/h_score=49.36\n",
      "tensor(0)\n",
      "all:  cs/acc_i=50.64 cs/acc_c=52.32 os/recall_knw=55.81 os/recall_unk=73.63 total/acc_i=49.69 total/acc_c=38.86 total/h_score=49.36\n",
      "painting -> sketch lr= 0.001 seed= 0\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19]\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20]\n",
      "Loss: 2.5621064403069713\n",
      "Loss: 1.2388779937274872\n",
      "Loss: 0.7381870152142943\n",
      "Loss: 0.5639396533764228\n",
      "Loss: 0.49991764348966106\n",
      "Loss: 0.429726974122108\n",
      "Loss: 0.38649372697349577\n",
      "Loss: 0.3563021680823079\n",
      "Loss: 0.3297040345413344\n",
      "Loss: 0.27552953598991275\n",
      "tensor(True) tensor(True)\n",
      "______\n",
      "Iteration t=1\n",
      "all:  cs/acc_i=51.92 cs/acc_c=53.44 os/recall_knw=83.09 os/recall_unk=39.01 total/acc_i=44.42 total/acc_c=48.54 total/h_score=43.44\n",
      "selected:  cs/acc_i=50.00 cs/acc_c=51.75 os/recall_knw=47.91 os/recall_unk=90.58 total/acc_i=59.95 total/acc_c=40.86 total/h_score=53.91\n",
      "Loss: 2.467878152926763\n",
      "Loss: 1.0842910495166684\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.637022013027294\n",
      "Loss: 0.5246479018938308\n",
      "Loss: 0.42793455749165776\n",
      "Loss: 0.36979027998213676\n",
      "Loss: 0.35223479408259484\n",
      "Loss: 0.29925658674362826\n",
      "Loss: 0.2791132073593782\n",
      "Loss: 0.260794529727861\n",
      "______\n",
      "Iteration t=2\n",
      "all:  cs/acc_i=50.26 cs/acc_c=51.76 os/recall_knw=63.28 os/recall_unk=64.14 total/acc_i=48.32 total/acc_c=41.66 total/h_score=49.68\n",
      "selected:  cs/acc_i=47.22 cs/acc_c=49.02 os/recall_knw=44.18 os/recall_unk=85.37 total/acc_i=52.23 total/acc_c=34.53 total/h_score=46.54\n",
      "Loss: 2.4174397407321755\n",
      "Loss: 0.9462352169489642\n",
      "Loss: 0.5930584960300987\n",
      "Loss: 0.4599571005877005\n",
      "Loss: 0.3840225613035193\n",
      "Loss: 0.3426247458529035\n",
      "Loss: 0.32646687501409183\n",
      "Loss: 0.2737807951047333\n",
      "Loss: 0.253561001185567\n",
      "Loss: 0.2351929070855226\n",
      "______\n",
      "Iteration t=3\n",
      "all:  cs/acc_i=50.08 cs/acc_c=51.70 os/recall_knw=59.85 os/recall_unk=69.24 total/acc_i=49.23 total/acc_c=40.44 total/h_score=49.89\n",
      "selected:  cs/acc_i=48.26 cs/acc_c=50.51 os/recall_knw=49.91 os/recall_unk=79.91 total/acc_i=50.90 total/acc_c=36.92 total/h_score=48.45\n",
      "Loss: 2.365943413195403\n",
      "Loss: 0.8970827078041823\n",
      "Loss: 0.5493150518640227\n",
      "Loss: 0.4216988675620245\n",
      "Loss: 0.3703059854714767\n",
      "Loss: 0.33394891878832944\n",
      "Loss: 0.27813954087703124\n",
      "Loss: 0.2651511090281217\n",
      "Loss: 0.22172061632508816\n",
      "Loss: 0.21463436268917893\n",
      "______\n",
      "Iteration t=4\n",
      "all:  cs/acc_i=50.26 cs/acc_c=51.81 os/recall_knw=57.96 os/recall_unk=70.81 total/acc_i=49.35 total/acc_c=39.78 total/h_score=49.65\n",
      "selected:  cs/acc_i=48.52 cs/acc_c=50.51 os/recall_knw=53.60 os/recall_unk=75.51 total/acc_i=49.43 total/acc_c=37.46 total/h_score=48.35\n",
      "Loss: 2.3262705246607465\n",
      "Loss: 0.8474294513463974\n",
      "Loss: 0.5041577157874902\n",
      "Loss: 0.41745863122244675\n",
      "Loss: 0.34392983860646686\n",
      "Loss: 0.3027468155914297\n",
      "Loss: 0.26808604237933953\n",
      "Loss: 0.2341936505554865\n",
      "Loss: 0.2161196350120008\n",
      "Loss: 0.200935281207785\n",
      "______\n",
      "Iteration t=5\n",
      "all:  cs/acc_i=50.04 cs/acc_c=51.41 os/recall_knw=57.43 os/recall_unk=71.01 total/acc_i=49.23 total/acc_c=39.50 total/h_score=49.44\n",
      "selected:  cs/acc_i=48.79 cs/acc_c=50.48 os/recall_knw=55.97 os/recall_unk=72.19 total/acc_i=48.73 total/acc_c=38.26 total/h_score=48.54\n",
      "Loss: 2.3193908061093165\n",
      "Loss: 0.8432348257134318\n",
      "Loss: 0.5228238863500989\n",
      "Loss: 0.3905855318915989\n",
      "Loss: 0.3284492032670299\n",
      "Loss: 0.2916842675522754\n",
      "Loss: 0.25968491822963785\n",
      "Loss: 0.24248160928608434\n",
      "Loss: 0.20649442981611862\n",
      "Loss: 0.1952673534481873\n",
      "______\n",
      "Iteration t=6\n",
      "all:  cs/acc_i=50.87 cs/acc_c=52.42 os/recall_knw=57.40 os/recall_unk=71.07 total/acc_i=49.23 total/acc_c=39.47 total/h_score=49.43\n",
      "selected:  cs/acc_i=50.57 cs/acc_c=52.26 os/recall_knw=56.94 os/recall_unk=71.40 total/acc_i=49.12 total/acc_c=39.20 total/h_score=49.25\n",
      "Loss: 2.3027613450245683\n",
      "Loss: 0.8421668227178505\n",
      "Loss: 0.5082992481658737\n",
      "Loss: 0.38280569884671745\n",
      "Loss: 0.35199068265267647\n",
      "Loss: 0.28421620114979496\n",
      "Loss: 0.28453670534862574\n",
      "Loss: 0.22344743289861335\n",
      "Loss: 0.20535932333174958\n",
      "Loss: 0.20403055775626358\n",
      "______\n",
      "Iteration t=7\n",
      "all:  cs/acc_i=51.09 cs/acc_c=52.59 os/recall_knw=57.40 os/recall_unk=71.07 total/acc_i=49.23 total/acc_c=39.47 total/h_score=49.43\n",
      "selected:  cs/acc_i=51.08 cs/acc_c=52.59 os/recall_knw=57.35 os/recall_unk=71.07 total/acc_i=49.22 total/acc_c=39.45 total/h_score=49.41\n",
      "Loss: 2.2985410342216492\n",
      "Loss: 0.8270124143362045\n",
      "Loss: 0.5083544160723686\n",
      "Loss: 0.3906937099695206\n",
      "Loss: 0.34289628255367277\n",
      "Loss: 0.2836092776358128\n",
      "Loss: 0.2717392954230309\n",
      "Loss: 0.24560370668768883\n",
      "Loss: 0.2136023707613349\n",
      "Loss: 0.19365546187758445\n",
      "______\n",
      "Iteration t=8\n",
      "all:  cs/acc_i=51.17 cs/acc_c=52.80 os/recall_knw=57.40 os/recall_unk=71.07 total/acc_i=49.23 total/acc_c=39.47 total/h_score=49.43\n",
      "selected:  cs/acc_i=51.17 cs/acc_c=52.80 os/recall_knw=57.40 os/recall_unk=71.07 total/acc_i=49.23 total/acc_c=39.47 total/h_score=49.43\n",
      "Loss: 2.297353591918945\n",
      "Loss: 0.8245455293655396\n",
      "Loss: 0.4978379863500595\n",
      "Loss: 0.4119659132659435\n",
      "Loss: 0.34351273703575136\n",
      "Loss: 0.30097661837935447\n",
      "Loss: 0.25678308284282686\n",
      "Loss: 0.2458510409742594\n",
      "Loss: 0.20826110224425792\n",
      "Loss: 0.1862892809510231\n",
      "______\n",
      "Iteration t=9\n",
      "all:  cs/acc_i=51.81 cs/acc_c=53.40 os/recall_knw=57.40 os/recall_unk=71.07 total/acc_i=49.23 total/acc_c=39.47 total/h_score=49.43\n",
      "selected:  cs/acc_i=51.81 cs/acc_c=53.40 os/recall_knw=57.40 os/recall_unk=71.07 total/acc_i=49.23 total/acc_c=39.47 total/h_score=49.43\n",
      "tensor(0)\n",
      "all:  cs/acc_i=51.81 cs/acc_c=53.40 os/recall_knw=57.40 os/recall_unk=71.07 total/acc_i=49.23 total/acc_c=39.47 total/h_score=49.43\n",
      "painting -> sketch lr= 0.001 seed= 1\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19]\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20]\n",
      "Loss: 2.556227938838737\n",
      "Loss: 1.1915881394078491\n",
      "Loss: 0.7534991363999705\n",
      "Loss: 0.5751551279315242\n",
      "Loss: 0.49390191383778104\n",
      "Loss: 0.43080058906759533\n",
      "Loss: 0.37762883739181297\n",
      "Loss: 0.337769036531133\n",
      "Loss: 0.31473566765192323\n",
      "Loss: 0.2953568619316217\n",
      "tensor(True) tensor(True)\n",
      "______\n",
      "Iteration t=1\n",
      "all:  cs/acc_i=49.81 cs/acc_c=51.27 os/recall_knw=81.21 os/recall_unk=35.73 total/acc_i=41.93 total/acc_c=46.45 total/h_score=40.59\n",
      "selected:  cs/acc_i=44.24 cs/acc_c=46.22 os/recall_knw=44.79 os/recall_unk=88.64 total/acc_i=54.74 total/acc_c=36.53 total/h_score=49.06\n",
      "Loss: 2.470398032197765\n",
      "Loss: 1.0655898767359115\n",
      "Loss: 0.6283143691572488\n",
      "Loss: 0.4800444183250268\n",
      "Loss: 0.420875153339961\n",
      "Loss: 0.37457419738319575\n",
      "Loss: 0.3361870992344384\n",
      "Loss: 0.30634380394921584\n",
      "Loss: 0.270464034057131\n",
      "Loss: 0.25416921217944105\n",
      "______\n",
      "Iteration t=2\n",
      "all:  cs/acc_i=50.94 cs/acc_c=52.58 os/recall_knw=59.55 os/recall_unk=69.96 total/acc_i=49.45 total/acc_c=40.46 total/h_score=50.07\n",
      "selected:  cs/acc_i=48.13 cs/acc_c=50.18 os/recall_knw=41.90 os/recall_unk=86.91 total/acc_i=52.16 total/acc_c=33.47 total/h_score=45.47\n",
      "Loss: 2.405929938368841\n",
      "Loss: 0.9871570407797438\n",
      "Loss: 0.5940498981727372\n",
      "Loss: 0.47340561018897853\n",
      "Loss: 0.38019678635744875\n",
      "Loss: 0.36646485854999733\n",
      "Loss: 0.29879720064751597\n",
      "Loss: 0.26845449332250365\n",
      "Loss: 0.2475646983900475\n",
      "Loss: 0.23346990463110284\n",
      "______\n",
      "Iteration t=3\n",
      "all:  cs/acc_i=51.06 cs/acc_c=52.56 os/recall_knw=56.64 os/recall_unk=73.56 total/acc_i=49.93 total/acc_c=39.32 total/h_score=49.77\n",
      "selected:  cs/acc_i=49.10 cs/acc_c=51.02 os/recall_knw=48.15 os/recall_unk=81.16 total/acc_i=50.57 total/acc_c=35.63 total/h_score=47.28\n",
      "Loss: 2.3634244260333834\n",
      "Loss: 0.92482359236453\n",
      "Loss: 0.5512975145340998\n",
      "Loss: 0.4386270442953357\n",
      "Loss: 0.35499746620139\n",
      "Loss: 0.3172382591413213\n",
      "Loss: 0.280204937571571\n",
      "Loss: 0.26420797420528547\n",
      "Loss: 0.2510905818312199\n",
      "Loss: 0.2233005202822871\n",
      "______\n",
      "Iteration t=4\n",
      "all:  cs/acc_i=50.64 cs/acc_c=52.20 os/recall_knw=55.96 os/recall_unk=74.02 total/acc_i=49.90 total/acc_c=39.03 total/h_score=49.59\n",
      "selected:  cs/acc_i=49.05 cs/acc_c=51.10 os/recall_knw=51.90 os/recall_unk=77.89 total/acc_i=49.85 total/acc_c=36.97 total/h_score=48.23\n",
      "Loss: 2.3309483427961335\n",
      "Loss: 0.8574401353086744\n",
      "Loss: 0.5277858814146338\n",
      "Loss: 0.42758632163290217\n",
      "Loss: 0.3468496592856255\n",
      "Loss: 0.3148769109564669\n",
      "Loss: 0.28718249956850245\n",
      "Loss: 0.25070190471949194\n",
      "Loss: 0.22461322479012633\n",
      "Loss: 0.2076132049580582\n",
      "______\n",
      "Iteration t=5\n",
      "all:  cs/acc_i=50.68 cs/acc_c=52.24 os/recall_knw=55.55 os/recall_unk=74.15 total/acc_i=49.78 total/acc_c=38.78 total/h_score=49.37\n",
      "selected:  cs/acc_i=49.34 cs/acc_c=51.25 os/recall_knw=54.02 os/recall_unk=75.18 total/acc_i=49.18 total/acc_c=37.45 total/h_score=48.29\n",
      "Loss: 2.321533081472897\n",
      "Loss: 0.865627054918985\n",
      "Loss: 0.5339489405150296\n",
      "Loss: 0.4048401224808615\n",
      "Loss: 0.3447095892529507\n",
      "Loss: 0.3072272454861735\n",
      "Loss: 0.2691065962655378\n",
      "Loss: 0.24517601844472964\n",
      "Loss: 0.21206976206148745\n",
      "Loss: 0.1957414856058408\n",
      "______\n",
      "Iteration t=6\n",
      "all:  cs/acc_i=50.98 cs/acc_c=52.62 os/recall_knw=55.47 os/recall_unk=74.15 total/acc_i=49.74 total/acc_c=38.70 total/h_score=49.30\n",
      "selected:  cs/acc_i=50.80 cs/acc_c=52.54 os/recall_knw=55.20 os/recall_unk=74.44 total/acc_i=49.69 total/acc_c=38.56 total/h_score=49.22\n",
      "Loss: 2.304356630514508\n",
      "Loss: 0.8282943699765302\n",
      "Loss: 0.5026722443007264\n",
      "Loss: 0.40610916073988323\n",
      "Loss: 0.34037503241165445\n",
      "Loss: 0.28567622846316715\n",
      "Loss: 0.27109126963837427\n",
      "Loss: 0.2536219950418482\n",
      "Loss: 0.21822960638565572\n",
      "Loss: 0.19922135399300078\n",
      "______\n",
      "Iteration t=7\n",
      "all:  cs/acc_i=50.23 cs/acc_c=51.76 os/recall_knw=55.47 os/recall_unk=74.15 total/acc_i=49.74 total/acc_c=38.70 total/h_score=49.30\n",
      "selected:  cs/acc_i=50.19 cs/acc_c=51.75 os/recall_knw=55.37 os/recall_unk=74.20 total/acc_i=49.72 total/acc_c=38.68 total/h_score=49.29\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 2.2970363297443157\n",
      "Loss: 0.8323256530259785\n",
      "Loss: 0.5018992863806636\n",
      "Loss: 0.4089645486370272\n",
      "Loss: 0.34448934744606136\n",
      "Loss: 0.29583841474794664\n",
      "Loss: 0.26685621900114453\n",
      "Loss: 0.2434372321253846\n",
      "Loss: 0.2323527325110638\n",
      "Loss: 0.21405516398942423\n",
      "______\n",
      "Iteration t=8\n",
      "all:  cs/acc_i=51.32 cs/acc_c=52.92 os/recall_knw=55.47 os/recall_unk=74.15 total/acc_i=49.74 total/acc_c=38.70 total/h_score=49.30\n",
      "selected:  cs/acc_i=51.32 cs/acc_c=52.92 os/recall_knw=55.47 os/recall_unk=74.15 total/acc_i=49.74 total/acc_c=38.70 total/h_score=49.30\n",
      "Loss: 2.3084147275700744\n",
      "Loss: 0.8489631153793953\n",
      "Loss: 0.5244821634611138\n",
      "Loss: 0.39605632463568136\n",
      "Loss: 0.3314239479571219\n",
      "Loss: 0.31224738364579224\n",
      "Loss: 0.2687757094862007\n",
      "Loss: 0.24432182369323877\n",
      "Loss: 0.2157778182643869\n",
      "Loss: 0.20095165446400642\n",
      "______\n",
      "Iteration t=9\n",
      "all:  cs/acc_i=50.60 cs/acc_c=52.29 os/recall_knw=55.47 os/recall_unk=74.15 total/acc_i=49.74 total/acc_c=38.70 total/h_score=49.30\n",
      "selected:  cs/acc_i=50.60 cs/acc_c=52.29 os/recall_knw=55.47 os/recall_unk=74.15 total/acc_i=49.74 total/acc_c=38.70 total/h_score=49.30\n",
      "tensor(0)\n",
      "all:  cs/acc_i=50.60 cs/acc_c=52.29 os/recall_knw=55.47 os/recall_unk=74.15 total/acc_i=49.74 total/acc_c=38.70 total/h_score=49.30\n",
      "painting -> sketch lr= 0.001 seed= 2\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19]\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20]\n",
      "Loss: 2.5674895584267916\n",
      "Loss: 1.2396543754471674\n",
      "Loss: 0.7066385757040095\n",
      "Loss: 0.5784547980184909\n",
      "Loss: 0.47594691560697305\n",
      "Loss: 0.422809289797904\n",
      "Loss: 0.37850802375999076\n",
      "Loss: 0.3433200180451706\n",
      "Loss: 0.3017580768576375\n",
      "Loss: 0.28481265733008665\n",
      "tensor(True) tensor(True)\n",
      "______\n",
      "Iteration t=1\n",
      "all:  cs/acc_i=50.11 cs/acc_c=51.74 os/recall_knw=82.53 os/recall_unk=38.02 total/acc_i=42.77 total/acc_c=46.67 total/h_score=42.08\n",
      "selected:  cs/acc_i=47.07 cs/acc_c=49.09 os/recall_knw=46.84 os/recall_unk=90.22 total/acc_i=57.36 total/acc_c=37.95 total/h_score=50.78\n",
      "Loss: 2.468945841578876\n",
      "Loss: 1.076106907252003\n",
      "Loss: 0.6586012505725318\n",
      "Loss: 0.5195032058685434\n",
      "Loss: 0.43375763779177384\n",
      "Loss: 0.37821563786151363\n",
      "Loss: 0.34425960806216677\n",
      "Loss: 0.30554941771369354\n",
      "Loss: 0.28680919475999533\n",
      "Loss: 0.24796680236856142\n",
      "______\n",
      "Iteration t=2\n",
      "all:  cs/acc_i=50.57 cs/acc_c=52.07 os/recall_knw=62.15 os/recall_unk=67.54 total/acc_i=49.55 total/acc_c=41.94 total/h_score=50.76\n",
      "selected:  cs/acc_i=47.13 cs/acc_c=48.80 os/recall_knw=43.65 os/recall_unk=86.50 total/acc_i=52.77 total/acc_c=34.46 total/h_score=46.57\n",
      "Loss: 2.4202131557902065\n",
      "Loss: 0.9971586416620727\n",
      "Loss: 0.5971582861395057\n",
      "Loss: 0.46348508009943395\n",
      "Loss: 0.38832441676373874\n",
      "Loss: 0.34125690671418785\n",
      "Loss: 0.30214450713417945\n",
      "Loss: 0.2724748250404629\n",
      "Loss: 0.2567705810582692\n",
      "Loss: 0.2443106145760335\n",
      "______\n",
      "Iteration t=3\n",
      "all:  cs/acc_i=51.09 cs/acc_c=52.51 os/recall_knw=60.94 os/recall_unk=69.37 total/acc_i=49.90 total/acc_c=41.49 total/h_score=50.82\n",
      "selected:  cs/acc_i=49.41 cs/acc_c=51.13 os/recall_knw=51.02 os/recall_unk=80.55 total/acc_i=51.76 total/acc_c=37.73 total/h_score=49.37\n",
      "Loss: 2.354666816723811\n",
      "Loss: 0.8822012941042582\n",
      "Loss: 0.5437879508836961\n",
      "Loss: 0.42526414803354257\n",
      "Loss: 0.3676774475352589\n",
      "Loss: 0.3215744996935258\n",
      "Loss: 0.28595286140065174\n",
      "Loss: 0.2536014084627618\n",
      "Loss: 0.23208690599187629\n",
      "Loss: 0.22465444815816818\n",
      "______\n",
      "Iteration t=4\n",
      "all:  cs/acc_i=51.43 cs/acc_c=52.99 os/recall_knw=59.74 os/recall_unk=70.88 total/acc_i=50.10 total/acc_c=41.03 total/h_score=50.76\n",
      "selected:  cs/acc_i=50.23 cs/acc_c=52.18 os/recall_knw=54.85 os/recall_unk=75.73 total/acc_i=50.54 total/acc_c=39.07 total/h_score=49.93\n",
      "Loss: 2.347743226091067\n",
      "Loss: 0.8540160118291775\n",
      "Loss: 0.5360900331909458\n",
      "Loss: 0.4109282856186231\n",
      "Loss: 0.3478341740556061\n",
      "Loss: 0.3052538530280193\n",
      "Loss: 0.28116270986696085\n",
      "Loss: 0.25173291759565475\n",
      "Loss: 0.215493910961474\n",
      "Loss: 0.19619123473142583\n",
      "______\n",
      "Iteration t=5\n",
      "all:  cs/acc_i=51.21 cs/acc_c=52.85 os/recall_knw=59.06 os/recall_unk=71.53 total/acc_i=50.12 total/acc_c=40.72 total/h_score=50.62\n",
      "selected:  cs/acc_i=50.22 cs/acc_c=52.26 os/recall_knw=57.47 os/recall_unk=72.77 total/acc_i=49.79 total/acc_c=39.76 total/h_score=50.02\n",
      "Loss: 2.3041454303649163\n",
      "Loss: 0.8365120241238225\n",
      "Loss: 0.5038589087104605\n",
      "Loss: 0.40144013880842155\n",
      "Loss: 0.3291616064586466\n",
      "Loss: 0.3035101720822915\n",
      "Loss: 0.27214457677497017\n",
      "Loss: 0.23383372326591803\n",
      "Loss: 0.214350079561794\n",
      "Loss: 0.18453470288565563\n",
      "______\n",
      "Iteration t=6\n",
      "all:  cs/acc_i=51.51 cs/acc_c=53.18 os/recall_knw=58.94 os/recall_unk=71.53 total/acc_i=50.07 total/acc_c=40.64 total/h_score=50.56\n",
      "selected:  cs/acc_i=51.26 cs/acc_c=53.05 os/recall_knw=58.57 os/recall_unk=71.91 total/acc_i=50.00 total/acc_c=40.42 total/h_score=50.44\n",
      "Loss: 2.280763598918915\n",
      "Loss: 0.8336585009098053\n",
      "Loss: 0.5014950281381607\n",
      "Loss: 0.3797526735365391\n",
      "Loss: 0.326254673153162\n",
      "Loss: 0.28569374239444734\n",
      "Loss: 0.27159842985868454\n",
      "Loss: 0.23100137339532376\n",
      "Loss: 0.21083577306568624\n",
      "Loss: 0.19074590523540974\n",
      "______\n",
      "Iteration t=7\n",
      "all:  cs/acc_i=51.43 cs/acc_c=53.12 os/recall_knw=58.94 os/recall_unk=71.53 total/acc_i=50.07 total/acc_c=40.64 total/h_score=50.56\n",
      "selected:  cs/acc_i=51.40 cs/acc_c=53.10 os/recall_knw=58.91 os/recall_unk=71.58 total/acc_i=50.06 total/acc_c=40.61 total/h_score=50.54\n",
      "Loss: 2.2995716404629896\n",
      "Loss: 0.8392740809822462\n",
      "Loss: 0.5091823670731123\n",
      "Loss: 0.41166664986496426\n",
      "Loss: 0.3418393273693157\n",
      "Loss: 0.296169873460593\n",
      "Loss: 0.27080819022607994\n",
      "Loss: 0.2457998589690463\n",
      "Loss: 0.21734223611266965\n",
      "Loss: 0.1945822658796472\n",
      "______\n",
      "Iteration t=8\n",
      "all:  cs/acc_i=50.64 cs/acc_c=52.41 os/recall_knw=58.94 os/recall_unk=71.53 total/acc_i=50.07 total/acc_c=40.64 total/h_score=50.56\n",
      "selected:  cs/acc_i=50.64 cs/acc_c=52.41 os/recall_knw=58.94 os/recall_unk=71.53 total/acc_i=50.07 total/acc_c=40.64 total/h_score=50.56\n",
      "Loss: 2.2900291776277153\n",
      "Loss: 0.8285981145987947\n",
      "Loss: 0.512661023622015\n",
      "Loss: 0.3977117318496761\n",
      "Loss: 0.3421293764237864\n",
      "Loss: 0.3114745430203073\n",
      "Loss: 0.25529197437236034\n",
      "Loss: 0.22639239178710724\n",
      "Loss: 0.20698810934248674\n",
      "Loss: 0.1919129843048128\n",
      "______\n",
      "Iteration t=9\n",
      "all:  cs/acc_i=52.04 cs/acc_c=53.82 os/recall_knw=58.94 os/recall_unk=71.53 total/acc_i=50.07 total/acc_c=40.64 total/h_score=50.56\n",
      "selected:  cs/acc_i=52.04 cs/acc_c=53.82 os/recall_knw=58.94 os/recall_unk=71.53 total/acc_i=50.07 total/acc_c=40.64 total/h_score=50.56\n",
      "tensor(0)\n",
      "all:  cs/acc_i=52.04 cs/acc_c=53.82 os/recall_knw=58.94 os/recall_unk=71.53 total/acc_i=50.07 total/acc_c=40.64 total/h_score=50.56\n",
      "painting -> sketch lr= 0.001 seed= 3\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19]\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20]\n",
      "Loss: 2.5562935537762113\n",
      "Loss: 1.2268213178745653\n",
      "Loss: 0.7319071313376149\n",
      "Loss: 0.5560495924381983\n",
      "Loss: 0.5081599916888293\n",
      "Loss: 0.42291164555877603\n",
      "Loss: 0.3832268714116364\n",
      "Loss: 0.3505529257513228\n",
      "Loss: 0.3037452879484999\n",
      "Loss: 0.28798198065272085\n",
      "tensor(True) tensor(True)\n",
      "______\n",
      "Iteration t=1\n",
      "all:  cs/acc_i=50.38 cs/acc_c=51.69 os/recall_knw=82.11 os/recall_unk=37.30 total/acc_i=42.56 total/acc_c=46.41 total/h_score=41.54\n",
      "selected:  cs/acc_i=47.81 cs/acc_c=49.57 os/recall_knw=46.80 os/recall_unk=90.76 total/acc_i=57.21 total/acc_c=38.03 total/h_score=50.92\n",
      "Loss: 2.480461822420943\n",
      "Loss: 1.0609365742580563\n",
      "Loss: 0.630065455302304\n",
      "Loss: 0.5000803477185614\n",
      "Loss: 0.41829418098809673\n",
      "Loss: 0.36597227962578044\n",
      "Loss: 0.3380905372620213\n",
      "Loss: 0.29625334150577876\n",
      "Loss: 0.27672815369442105\n",
      "Loss: 0.2597231246056218\n",
      "______\n",
      "Iteration t=2\n",
      "all:  cs/acc_i=50.34 cs/acc_c=51.65 os/recall_knw=64.72 os/recall_unk=64.40 total/acc_i=48.25 total/acc_c=41.31 total/h_score=49.47\n",
      "selected:  cs/acc_i=48.60 cs/acc_c=50.13 os/recall_knw=45.32 os/recall_unk=85.86 total/acc_i=52.98 total/acc_c=34.88 total/h_score=46.97\n",
      "Loss: 2.4245560016107124\n",
      "Loss: 0.9858745642758291\n",
      "Loss: 0.5921251401988739\n",
      "Loss: 0.4473809655926643\n",
      "Loss: 0.38988019423473863\n",
      "Loss: 0.35194784853983363\n",
      "Loss: 0.30696206779108137\n",
      "Loss: 0.27374253996195047\n",
      "Loss: 0.2436423757104972\n",
      "Loss: 0.23602644188346666\n",
      "______\n",
      "Iteration t=3\n",
      "all:  cs/acc_i=50.64 cs/acc_c=51.98 os/recall_knw=57.66 os/recall_unk=71.20 total/acc_i=48.97 total/acc_c=38.96 total/h_score=49.00\n",
      "selected:  cs/acc_i=49.38 cs/acc_c=50.95 os/recall_knw=48.22 os/recall_unk=81.13 total/acc_i=50.57 total/acc_c=35.57 total/h_score=47.21\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 2.351287395539491\n",
      "Loss: 0.9108738454787627\n",
      "Loss: 0.5264431175978287\n",
      "Loss: 0.4376637622066166\n",
      "Loss: 0.37234365195035934\n",
      "Loss: 0.31262777483333715\n",
      "Loss: 0.2876870989151623\n",
      "Loss: 0.25439322302522865\n",
      "Loss: 0.23111111034193765\n",
      "Loss: 0.212281615756776\n",
      "______\n",
      "Iteration t=4\n",
      "all:  cs/acc_i=50.68 cs/acc_c=52.24 os/recall_knw=57.09 os/recall_unk=71.60 total/acc_i=49.02 total/acc_c=38.82 total/h_score=48.94\n",
      "selected:  cs/acc_i=49.92 cs/acc_c=52.00 os/recall_knw=52.94 os/recall_unk=76.45 total/acc_i=49.68 total/acc_c=37.47 total/h_score=48.51\n",
      "Loss: 2.3349765946467715\n",
      "Loss: 0.8561237984647353\n",
      "Loss: 0.5325938082610567\n",
      "Loss: 0.39142946039016047\n",
      "Loss: 0.34258633010710277\n",
      "Loss: 0.3193958092170457\n",
      "Loss: 0.2818552721757442\n",
      "Loss: 0.24395981940130393\n",
      "Loss: 0.22776553224151333\n",
      "Loss: 0.20067771129931014\n",
      "______\n",
      "Iteration t=5\n",
      "all:  cs/acc_i=50.34 cs/acc_c=51.78 os/recall_knw=56.91 os/recall_unk=71.73 total/acc_i=48.99 total/acc_c=38.71 total/h_score=48.87\n",
      "selected:  cs/acc_i=49.48 cs/acc_c=51.28 os/recall_knw=55.62 os/recall_unk=73.21 total/acc_i=48.80 total/acc_c=37.88 total/h_score=48.37\n",
      "Loss: 2.295193155606588\n",
      "Loss: 0.8425609227118454\n",
      "Loss: 0.5014453323754838\n",
      "Loss: 0.4054735062447021\n",
      "Loss: 0.3460252568792037\n",
      "Loss: 0.2957055581415572\n",
      "Loss: 0.28064729785168074\n",
      "Loss: 0.23389373431966556\n",
      "Loss: 0.21743720950846507\n",
      "Loss: 0.1928600144262115\n",
      "______\n",
      "Iteration t=6\n",
      "all:  cs/acc_i=51.25 cs/acc_c=52.87 os/recall_knw=56.83 os/recall_unk=71.73 total/acc_i=48.97 total/acc_c=38.67 total/h_score=48.84\n",
      "selected:  cs/acc_i=51.04 cs/acc_c=52.76 os/recall_knw=56.62 os/recall_unk=72.20 total/acc_i=48.95 total/acc_c=38.52 total/h_score=48.79\n",
      "Loss: 2.292325851907692\n",
      "Loss: 0.8341122798651577\n",
      "Loss: 0.5021294955627985\n",
      "Loss: 0.39133888596751126\n",
      "Loss: 0.3421102615305219\n",
      "Loss: 0.29009069298884\n",
      "Loss: 0.2678629677877369\n",
      "Loss: 0.24411989832259565\n",
      "Loss: 0.22066927922657695\n",
      "Loss: 0.19233796560022248\n",
      "______\n",
      "Iteration t=7\n",
      "all:  cs/acc_i=50.23 cs/acc_c=51.91 os/recall_knw=56.83 os/recall_unk=71.73 total/acc_i=48.97 total/acc_c=38.67 total/h_score=48.84\n",
      "selected:  cs/acc_i=50.21 cs/acc_c=51.90 os/recall_knw=56.81 os/recall_unk=71.73 total/acc_i=48.96 total/acc_c=38.66 total/h_score=48.82\n",
      "Loss: 2.286900438785553\n",
      "Loss: 0.8296950018405914\n",
      "Loss: 0.5057373229265213\n",
      "Loss: 0.412514151096344\n",
      "Loss: 0.33530582100152967\n",
      "Loss: 0.3084916153848171\n",
      "Loss: 0.2664210956990719\n",
      "Loss: 0.23321838822960853\n",
      "Loss: 0.2133167546391487\n",
      "Loss: 0.1819199013337493\n",
      "______\n",
      "Iteration t=8\n",
      "all:  cs/acc_i=50.83 cs/acc_c=52.34 os/recall_knw=56.83 os/recall_unk=71.73 total/acc_i=48.97 total/acc_c=38.67 total/h_score=48.84\n",
      "selected:  cs/acc_i=50.83 cs/acc_c=52.34 os/recall_knw=56.83 os/recall_unk=71.73 total/acc_i=48.97 total/acc_c=38.67 total/h_score=48.84\n",
      "Loss: 2.29154101896286\n",
      "Loss: 0.8305957462787629\n",
      "Loss: 0.5123084721565246\n",
      "Loss: 0.40096491450071337\n",
      "Loss: 0.3457783647477627\n",
      "Loss: 0.28890303552150726\n",
      "Loss: 0.26934253749251363\n",
      "Loss: 0.23923222337663175\n",
      "Loss: 0.21391374062001706\n",
      "Loss: 0.2019578582942486\n",
      "______\n",
      "Iteration t=9\n",
      "all:  cs/acc_i=51.17 cs/acc_c=52.71 os/recall_knw=56.83 os/recall_unk=71.73 total/acc_i=48.97 total/acc_c=38.67 total/h_score=48.84\n",
      "selected:  cs/acc_i=51.17 cs/acc_c=52.71 os/recall_knw=56.83 os/recall_unk=71.73 total/acc_i=48.97 total/acc_c=38.67 total/h_score=48.84\n",
      "tensor(0)\n",
      "all:  cs/acc_i=51.17 cs/acc_c=52.71 os/recall_knw=56.83 os/recall_unk=71.73 total/acc_i=48.97 total/acc_c=38.67 total/h_score=48.84\n",
      "painting -> sketch lr= 0.001 seed= 4\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19]\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20]\n",
      "Loss: 2.5831134546370733\n",
      "Loss: 1.218146955210065\n",
      "Loss: 0.7452476961272103\n",
      "Loss: 0.5739299301747922\n",
      "Loss: 0.48794234406065057\n",
      "Loss: 0.4205038217955796\n",
      "Loss: 0.3938408387558801\n",
      "Loss: 0.3535104314722712\n",
      "Loss: 0.3087056735284114\n",
      "Loss: 0.29427439333112154\n",
      "tensor(True) tensor(True)\n",
      "______\n",
      "Iteration t=1\n",
      "all:  cs/acc_i=50.42 cs/acc_c=51.95 os/recall_knw=82.11 os/recall_unk=37.30 total/acc_i=42.75 total/acc_c=46.86 total/h_score=41.73\n",
      "selected:  cs/acc_i=47.44 cs/acc_c=48.96 os/recall_knw=46.08 os/recall_unk=89.34 total/acc_i=57.15 total/acc_c=38.20 total/h_score=50.96\n",
      "Loss: 2.482869859419617\n",
      "Loss: 1.0505828046623398\n",
      "Loss: 0.6467589090267817\n",
      "Loss: 0.5060464102117455\n",
      "Loss: 0.44087793780308143\n",
      "Loss: 0.3839234788628185\n",
      "Loss: 0.3425398752750719\n",
      "Loss: 0.3058421290753519\n",
      "Loss: 0.28039178478659366\n",
      "Loss: 0.2504414237816544\n",
      "______\n",
      "Iteration t=2\n",
      "all:  cs/acc_i=50.87 cs/acc_c=52.44 os/recall_knw=65.25 os/recall_unk=64.01 total/acc_i=49.14 total/acc_c=43.02 total/h_score=50.69\n",
      "selected:  cs/acc_i=48.14 cs/acc_c=49.71 os/recall_knw=45.66 os/recall_unk=86.02 total/acc_i=53.71 total/acc_c=36.23 total/h_score=48.47\n",
      "Loss: 2.4076422507609796\n",
      "Loss: 0.9673436962136435\n",
      "Loss: 0.5801327007079343\n",
      "Loss: 0.44908549910018203\n",
      "Loss: 0.397161942214594\n",
      "Loss: 0.33779792784960994\n",
      "Loss: 0.2950373996356758\n",
      "Loss: 0.2668152248162195\n",
      "Loss: 0.25694018735661417\n",
      "Loss: 0.23625280815732042\n",
      "______\n",
      "Iteration t=3\n",
      "all:  cs/acc_i=50.79 cs/acc_c=52.34 os/recall_knw=59.89 os/recall_unk=69.76 total/acc_i=49.71 total/acc_c=40.85 total/h_score=50.37\n",
      "selected:  cs/acc_i=48.56 cs/acc_c=50.45 os/recall_knw=49.88 os/recall_unk=80.64 total/acc_i=51.15 total/acc_c=36.67 total/h_score=48.30\n",
      "Loss: 2.3704483654188073\n",
      "Loss: 0.9167148963264797\n",
      "Loss: 0.5622890471116356\n",
      "Loss: 0.4266948557094387\n",
      "Loss: 0.36486293566615685\n",
      "Loss: 0.3286671863625879\n",
      "Loss: 0.28381318647576415\n",
      "Loss: 0.2508380622157584\n",
      "Loss: 0.23988167303411856\n",
      "Loss: 0.20774413420130378\n",
      "______\n",
      "Iteration t=4\n",
      "all:  cs/acc_i=50.53 cs/acc_c=51.94 os/recall_knw=59.55 os/recall_unk=69.90 total/acc_i=49.66 total/acc_c=40.69 total/h_score=50.26\n",
      "selected:  cs/acc_i=48.67 cs/acc_c=50.54 os/recall_knw=54.71 os/recall_unk=76.07 total/acc_i=50.07 total/acc_c=38.33 total/h_score=49.28\n",
      "Loss: 2.3330356985330583\n",
      "Loss: 0.856354579826196\n",
      "Loss: 0.5141014563540618\n",
      "Loss: 0.4059789600161215\n",
      "Loss: 0.35278818644583226\n",
      "Loss: 0.31937571164841455\n",
      "Loss: 0.27345482343807814\n",
      "Loss: 0.24029310986710092\n",
      "Loss: 0.22274321449610093\n",
      "Loss: 0.20210448978468776\n",
      "______\n",
      "Iteration t=5\n",
      "all:  cs/acc_i=51.51 cs/acc_c=53.02 os/recall_knw=59.21 os/recall_unk=70.09 total/acc_i=49.59 total/acc_c=40.47 total/h_score=50.11\n",
      "selected:  cs/acc_i=50.37 cs/acc_c=52.28 os/recall_knw=57.56 os/recall_unk=72.07 total/acc_i=49.34 total/acc_c=39.39 total/h_score=49.55\n",
      "Loss: 2.2952406863051076\n",
      "Loss: 0.8156569920960934\n",
      "Loss: 0.5046366333600975\n",
      "Loss: 0.4044506559448858\n",
      "Loss: 0.34774502811412655\n",
      "Loss: 0.27458861097693443\n",
      "Loss: 0.26626928120611176\n",
      "Loss: 0.2416378133028986\n",
      "Loss: 0.21020075394922205\n",
      "Loss: 0.19819815618346534\n",
      "______\n",
      "Iteration t=6\n",
      "all:  cs/acc_i=50.75 cs/acc_c=52.40 os/recall_knw=59.13 os/recall_unk=70.16 total/acc_i=49.59 total/acc_c=40.43 total/h_score=50.09\n",
      "selected:  cs/acc_i=50.27 cs/acc_c=52.13 os/recall_knw=58.66 os/recall_unk=70.90 total/acc_i=49.47 total/acc_c=40.09 total/h_score=49.95\n",
      "Loss: 2.3010315477135648\n",
      "Loss: 0.8323277860761163\n",
      "Loss: 0.5165067750856696\n",
      "Loss: 0.3785917078000141\n",
      "Loss: 0.3359871064999189\n",
      "Loss: 0.27673856637986055\n",
      "Loss: 0.27450679949080325\n",
      "Loss: 0.23779707738899614\n",
      "Loss: 0.21204572117542367\n",
      "Loss: 0.18743505912176167\n",
      "______\n",
      "Iteration t=7\n",
      "all:  cs/acc_i=50.57 cs/acc_c=52.17 os/recall_knw=59.13 os/recall_unk=70.16 total/acc_i=49.59 total/acc_c=40.43 total/h_score=50.09\n",
      "selected:  cs/acc_i=50.51 cs/acc_c=52.14 os/recall_knw=59.09 os/recall_unk=70.30 total/acc_i=49.59 total/acc_c=40.40 total/h_score=50.08\n",
      "Loss: 2.3009752763642206\n",
      "Loss: 0.8362769269280963\n",
      "Loss: 0.5035582057658642\n",
      "Loss: 0.3892267494802437\n",
      "Loss: 0.3397089625516581\n",
      "Loss: 0.30226684435610734\n",
      "Loss: 0.25409412156376576\n",
      "Loss: 0.2301408356380841\n",
      "Loss: 0.21243107327747912\n",
      "Loss: 0.19089915260436044\n",
      "______\n",
      "Iteration t=8\n",
      "all:  cs/acc_i=50.79 cs/acc_c=52.34 os/recall_knw=59.13 os/recall_unk=70.16 total/acc_i=49.59 total/acc_c=40.43 total/h_score=50.09\n",
      "selected:  cs/acc_i=50.79 cs/acc_c=52.34 os/recall_knw=59.13 os/recall_unk=70.16 total/acc_i=49.59 total/acc_c=40.43 total/h_score=50.09\n",
      "Loss: 2.3061581925740318\n",
      "Loss: 0.829977077978944\n",
      "Loss: 0.5031451555708099\n",
      "Loss: 0.41252077211226734\n",
      "Loss: 0.3312596326013879\n",
      "Loss: 0.2959789817945825\n",
      "Loss: 0.2518524043557663\n",
      "Loss: 0.2220453011936375\n",
      "Loss: 0.20815066840972693\n",
      "Loss: 0.19384937400796584\n",
      "______\n",
      "Iteration t=9\n",
      "all:  cs/acc_i=51.81 cs/acc_c=53.56 os/recall_knw=59.13 os/recall_unk=70.16 total/acc_i=49.59 total/acc_c=40.43 total/h_score=50.09\n",
      "selected:  cs/acc_i=51.81 cs/acc_c=53.56 os/recall_knw=59.13 os/recall_unk=70.16 total/acc_i=49.59 total/acc_c=40.43 total/h_score=50.09\n",
      "tensor(0)\n",
      "all:  cs/acc_i=51.81 cs/acc_c=53.56 os/recall_knw=59.13 os/recall_unk=70.16 total/acc_i=49.59 total/acc_c=40.43 total/h_score=50.09\n",
      "painting -> real lr= 0.001 seed= 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19]\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20]\n",
      "Loss: 2.3612909257411956\n",
      "Loss: 0.9965862630556027\n",
      "Loss: 0.6552086688578129\n",
      "Loss: 0.5392845406507453\n",
      "Loss: 0.4792923384346068\n",
      "Loss: 0.4125278808797399\n",
      "Loss: 0.38990380040680367\n",
      "Loss: 0.34852900619929034\n",
      "Loss: 0.33218856702248256\n",
      "Loss: 0.3190780110967656\n",
      "tensor(True) tensor(True)\n",
      "______\n",
      "Iteration t=1\n",
      "all:  cs/acc_i=79.97 cs/acc_c=80.72 os/recall_knw=97.50 os/recall_unk=26.70 total/acc_i=63.09 total/acc_c=77.58 total/h_score=40.05\n",
      "selected:  cs/acc_i=88.97 cs/acc_c=87.74 os/recall_knw=86.68 os/recall_unk=99.28 total/acc_i=91.14 total/acc_c=85.15 total/h_score=91.26\n",
      "Loss: 2.2606778731641843\n",
      "Loss: 0.8710469086040822\n",
      "Loss: 0.5999070829892343\n",
      "Loss: 0.4850954778434694\n",
      "Loss: 0.4318887235582337\n",
      "Loss: 0.3649052417324495\n",
      "Loss: 0.3601532369390015\n",
      "Loss: 0.3113858227350915\n",
      "Loss: 0.28209142906721246\n",
      "Loss: 0.2797661318566448\n",
      "______\n",
      "Iteration t=2\n",
      "all:  cs/acc_i=81.17 cs/acc_c=81.81 os/recall_knw=78.15 os/recall_unk=85.30 total/acc_i=75.80 total/acc_c=72.91 total/h_score=78.26\n",
      "selected:  cs/acc_i=76.23 cs/acc_c=79.11 os/recall_knw=59.31 os/recall_unk=98.74 total/acc_i=75.23 total/acc_c=63.68 total/h_score=76.12\n",
      "Loss: 2.1844583216580475\n",
      "Loss: 0.7994114118272608\n",
      "Loss: 0.5022628927230834\n",
      "Loss: 0.4455415783687071\n",
      "Loss: 0.3755118470842188\n",
      "Loss: 0.3573211067102172\n",
      "Loss: 0.3226159080862999\n",
      "Loss: 0.29181125990369106\n",
      "Loss: 0.27745574590834704\n",
      "Loss: 0.2449512609026649\n",
      "______\n",
      "Iteration t=3\n",
      "all:  cs/acc_i=81.40 cs/acc_c=82.25 os/recall_knw=75.45 os/recall_unk=88.06 total/acc_i=75.54 total/acc_c=71.61 total/h_score=78.49\n",
      "selected:  cs/acc_i=79.19 cs/acc_c=81.29 os/recall_knw=65.49 os/recall_unk=96.69 total/acc_i=75.32 total/acc_c=66.67 total/h_score=77.86\n",
      "Loss: 2.097817064556357\n",
      "Loss: 0.6939415720431772\n",
      "Loss: 0.49584479145195387\n",
      "Loss: 0.4033598602838712\n",
      "Loss: 0.3548355256398655\n",
      "Loss: 0.34554450714016616\n",
      "Loss: 0.2985183896420345\n",
      "Loss: 0.2681968703687395\n",
      "Loss: 0.2438650319021042\n",
      "Loss: 0.23699670265849732\n",
      "______\n",
      "Iteration t=4\n",
      "all:  cs/acc_i=81.81 cs/acc_c=82.35 os/recall_knw=74.56 os/recall_unk=88.83 total/acc_i=75.48 total/acc_c=71.26 total/h_score=78.54\n",
      "selected:  cs/acc_i=80.54 cs/acc_c=81.72 os/recall_knw=69.09 os/recall_unk=92.82 total/acc_i=74.92 total/acc_c=68.50 total/h_score=78.02\n",
      "Loss: 2.0483133425478077\n",
      "Loss: 0.6548905368222565\n",
      "Loss: 0.46324352025985716\n",
      "Loss: 0.3992174684268529\n",
      "Loss: 0.3540762776966955\n",
      "Loss: 0.31178633397231337\n",
      "Loss: 0.28015346163120425\n",
      "Loss: 0.2560628722681374\n",
      "Loss: 0.23018398922486383\n",
      "Loss: 0.22097218721860745\n",
      "______\n",
      "Iteration t=5\n",
      "all:  cs/acc_i=81.81 cs/acc_c=82.78 os/recall_knw=74.27 os/recall_unk=88.96 total/acc_i=75.42 total/acc_c=71.14 total/h_score=78.51\n",
      "selected:  cs/acc_i=81.38 cs/acc_c=82.80 os/recall_knw=71.80 os/recall_unk=90.53 total/acc_i=75.15 total/acc_c=70.20 total/h_score=78.43\n",
      "Loss: 2.0123372732461253\n",
      "Loss: 0.6463869681369655\n",
      "Loss: 0.4458088427310503\n",
      "Loss: 0.36729606462618974\n",
      "Loss: 0.34521394390377064\n",
      "Loss: 0.2961575643312705\n",
      "Loss: 0.2684375338397826\n",
      "Loss: 0.24532159979018983\n",
      "Loss: 0.23018921761997516\n",
      "Loss: 0.215772519760494\n",
      "______\n",
      "Iteration t=6\n",
      "all:  cs/acc_i=82.27 cs/acc_c=83.02 os/recall_knw=74.13 os/recall_unk=89.09 total/acc_i=75.42 total/acc_c=71.10 total/h_score=78.53\n",
      "selected:  cs/acc_i=82.27 cs/acc_c=83.19 os/recall_knw=73.36 os/recall_unk=89.95 total/acc_i=75.51 total/acc_c=71.00 total/h_score=78.77\n",
      "Loss: 2.0021434787267482\n",
      "Loss: 0.6321221178177721\n",
      "Loss: 0.4381295161217636\n",
      "Loss: 0.37360230111372394\n",
      "Loss: 0.3188081655581916\n",
      "Loss: 0.28806016260977857\n",
      "Loss: 0.27469852034534725\n",
      "Loss: 0.24201696593985425\n",
      "Loss: 0.22627909721008369\n",
      "Loss: 0.20058745662652835\n",
      "______\n",
      "Iteration t=7\n",
      "all:  cs/acc_i=81.83 cs/acc_c=82.60 os/recall_knw=74.04 os/recall_unk=89.15 total/acc_i=75.42 total/acc_c=71.08 total/h_score=78.53\n",
      "selected:  cs/acc_i=81.86 cs/acc_c=82.65 os/recall_knw=73.96 os/recall_unk=89.27 total/acc_i=75.46 total/acc_c=71.10 total/h_score=78.59\n",
      "Loss: 2.0021479137127214\n",
      "Loss: 0.6371216903741543\n",
      "Loss: 0.4309843863890721\n",
      "Loss: 0.36052051711540956\n",
      "Loss: 0.30721273406193805\n",
      "Loss: 0.29454149337915275\n",
      "Loss: 0.2697225161928397\n",
      "Loss: 0.24114964205485123\n",
      "Loss: 0.22101982784958987\n",
      "Loss: 0.20549661114811898\n",
      "______\n",
      "Iteration t=8\n",
      "all:  cs/acc_i=82.09 cs/acc_c=82.96 os/recall_knw=74.04 os/recall_unk=89.15 total/acc_i=75.42 total/acc_c=71.08 total/h_score=78.53\n",
      "selected:  cs/acc_i=82.09 cs/acc_c=82.96 os/recall_knw=74.04 os/recall_unk=89.15 total/acc_i=75.42 total/acc_c=71.08 total/h_score=78.53\n",
      "Loss: 1.9813913304381576\n",
      "Loss: 0.6089626970283825\n",
      "Loss: 0.44407764776535563\n",
      "Loss: 0.37215015157325865\n",
      "Loss: 0.30156639387453993\n",
      "Loss: 0.2812979584502662\n",
      "Loss: 0.2686178714174069\n",
      "Loss: 0.23939520528574296\n",
      "Loss: 0.22398972360451527\n",
      "Loss: 0.20327749114163632\n",
      "______\n",
      "Iteration t=9\n",
      "all:  cs/acc_i=82.27 cs/acc_c=83.07 os/recall_knw=74.04 os/recall_unk=89.15 total/acc_i=75.42 total/acc_c=71.08 total/h_score=78.53\n",
      "selected:  cs/acc_i=82.27 cs/acc_c=83.07 os/recall_knw=74.04 os/recall_unk=89.15 total/acc_i=75.42 total/acc_c=71.08 total/h_score=78.53\n",
      "tensor(0)\n",
      "all:  cs/acc_i=82.27 cs/acc_c=83.07 os/recall_knw=74.04 os/recall_unk=89.15 total/acc_i=75.42 total/acc_c=71.08 total/h_score=78.53\n",
      "painting -> real lr= 0.001 seed= 1\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19]\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20]\n",
      "Loss: 2.3806677495439845\n",
      "Loss: 0.9985032305121422\n",
      "Loss: 0.6379147780438265\n",
      "Loss: 0.5416148576885462\n",
      "Loss: 0.46933202842871347\n",
      "Loss: 0.4019393406187495\n",
      "Loss: 0.39559720599402987\n",
      "Loss: 0.3560704939067364\n",
      "Loss: 0.3428199588942031\n",
      "Loss: 0.3046377550034473\n",
      "tensor(True) tensor(True)\n",
      "______\n",
      "Iteration t=1\n",
      "all:  cs/acc_i=80.89 cs/acc_c=81.62 os/recall_knw=97.30 os/recall_unk=26.25 total/acc_i=63.63 total/acc_c=78.51 total/h_score=39.67\n",
      "selected:  cs/acc_i=88.20 cs/acc_c=87.90 os/recall_knw=85.78 os/recall_unk=99.76 total/acc_i=90.94 total/acc_c=85.66 total/h_score=91.77\n",
      "Loss: 2.267700423103894\n",
      "Loss: 0.8554230035506478\n",
      "Loss: 0.5719844924156056\n",
      "Loss: 0.4751631127771481\n",
      "Loss: 0.42067483650852544\n",
      "Loss: 0.3904214563469092\n",
      "Loss: 0.35509397274301957\n",
      "Loss: 0.30674416970374974\n",
      "Loss: 0.296515620667343\n",
      "Loss: 0.275220412631021\n",
      "______\n",
      "Iteration t=2\n",
      "all:  cs/acc_i=81.29 cs/acc_c=82.10 os/recall_knw=79.68 os/recall_unk=82.86 total/acc_i=75.72 total/acc_c=74.01 total/h_score=77.94\n",
      "selected:  cs/acc_i=76.83 cs/acc_c=79.43 os/recall_knw=61.28 os/recall_unk=99.23 total/acc_i=76.40 total/acc_c=64.99 total/h_score=77.27\n",
      "Loss: 2.1639311023191974\n",
      "Loss: 0.7714032217589292\n",
      "Loss: 0.5264031738584691\n",
      "Loss: 0.43640843689441683\n",
      "Loss: 0.3940565925565633\n",
      "Loss: 0.3552331980791959\n",
      "Loss: 0.31046065891330893\n",
      "Loss: 0.30185189894654535\n",
      "Loss: 0.27502027068625795\n",
      "Loss: 0.25632408475333995\n",
      "______\n",
      "Iteration t=3\n",
      "all:  cs/acc_i=81.69 cs/acc_c=82.25 os/recall_knw=74.82 os/recall_unk=89.35 total/acc_i=75.68 total/acc_c=71.38 total/h_score=78.80\n",
      "selected:  cs/acc_i=79.64 cs/acc_c=80.90 os/recall_knw=65.10 os/recall_unk=97.21 total/acc_i=75.32 total/acc_c=66.05 total/h_score=77.54\n",
      "Loss: 2.112029388342818\n",
      "Loss: 0.7066596976085885\n",
      "Loss: 0.48304729025861987\n",
      "Loss: 0.4276521129865352\n",
      "Loss: 0.3690259503838542\n",
      "Loss: 0.32991402662576064\n",
      "Loss: 0.2943046425201305\n",
      "Loss: 0.278268315637969\n",
      "Loss: 0.24976855557258815\n",
      "Loss: 0.24484306723134566\n",
      "______\n",
      "Iteration t=4\n",
      "all:  cs/acc_i=82.41 cs/acc_c=83.02 os/recall_knw=73.93 os/recall_unk=89.99 total/acc_i=75.40 total/acc_c=70.65 total/h_score=78.54\n",
      "selected:  cs/acc_i=81.65 cs/acc_c=82.60 os/recall_knw=69.00 os/recall_unk=94.22 total/acc_i=75.22 total/acc_c=68.08 total/h_score=78.16\n",
      "Loss: 2.0426039954805684\n",
      "Loss: 0.6717133700263267\n",
      "Loss: 0.4629551632926355\n",
      "Loss: 0.39198351379946555\n",
      "Loss: 0.3346761070386647\n",
      "Loss: 0.3068575724423711\n",
      "Loss: 0.27361804074029517\n",
      "Loss: 0.26706105050649126\n",
      "Loss: 0.24572028218482445\n",
      "Loss: 0.22807452934824562\n",
      "______\n",
      "Iteration t=5\n",
      "all:  cs/acc_i=82.12 cs/acc_c=82.62 os/recall_knw=73.38 os/recall_unk=90.24 total/acc_i=75.24 total/acc_c=70.25 total/h_score=78.37\n",
      "selected:  cs/acc_i=81.81 cs/acc_c=82.35 os/recall_knw=70.76 os/recall_unk=91.90 total/acc_i=75.03 total/acc_c=68.92 total/h_score=78.01\n",
      "Loss: 2.0331431103360122\n",
      "Loss: 0.6368408592263605\n",
      "Loss: 0.45176876089565315\n",
      "Loss: 0.3915483463247111\n",
      "Loss: 0.32703932621486625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.30487400782146273\n",
      "Loss: 0.27983648885207574\n",
      "Loss: 0.2454421179380956\n",
      "Loss: 0.22892486433362125\n",
      "Loss: 0.22328901074969085\n",
      "______\n",
      "Iteration t=6\n",
      "all:  cs/acc_i=82.61 cs/acc_c=83.24 os/recall_knw=73.35 os/recall_unk=90.31 total/acc_i=75.24 total/acc_c=70.24 total/h_score=78.38\n",
      "selected:  cs/acc_i=82.82 cs/acc_c=83.46 os/recall_knw=72.54 os/recall_unk=91.07 total/acc_i=75.43 total/acc_c=70.09 total/h_score=78.54\n",
      "Loss: 2.0123362823438793\n",
      "Loss: 0.640509269040693\n",
      "Loss: 0.44840688437130594\n",
      "Loss: 0.3629547416049743\n",
      "Loss: 0.33052726384728126\n",
      "Loss: 0.29418901341308684\n",
      "Loss: 0.26477024913112696\n",
      "Loss: 0.24927408771583595\n",
      "Loss: 0.22720946220686875\n",
      "Loss: 0.2046236396648245\n",
      "______\n",
      "Iteration t=7\n",
      "all:  cs/acc_i=82.64 cs/acc_c=83.18 os/recall_knw=73.15 os/recall_unk=90.50 total/acc_i=75.18 total/acc_c=70.08 total/h_score=78.34\n",
      "selected:  cs/acc_i=82.69 cs/acc_c=83.25 os/recall_knw=73.06 os/recall_unk=90.62 total/acc_i=75.23 total/acc_c=70.10 total/h_score=78.39\n",
      "Loss: 1.9794232534405627\n",
      "Loss: 0.6380144894858937\n",
      "Loss: 0.44513966359290075\n",
      "Loss: 0.36642173599497774\n",
      "Loss: 0.3259572391570718\n",
      "Loss: 0.2862950510540862\n",
      "Loss: 0.2625815249795531\n",
      "Loss: 0.245397052405701\n",
      "Loss: 0.22555709193334167\n",
      "Loss: 0.2151730313529203\n",
      "______\n",
      "Iteration t=8\n",
      "all:  cs/acc_i=82.09 cs/acc_c=82.79 os/recall_knw=73.12 os/recall_unk=90.50 total/acc_i=75.16 total/acc_c=70.06 total/h_score=78.32\n",
      "selected:  cs/acc_i=82.09 cs/acc_c=82.79 os/recall_knw=73.12 os/recall_unk=90.50 total/acc_i=75.16 total/acc_c=70.06 total/h_score=78.32\n",
      "Loss: 1.9758826426149887\n",
      "Loss: 0.6339087203880887\n",
      "Loss: 0.44411198224550413\n",
      "Loss: 0.3649995635597058\n",
      "Loss: 0.3282507132439886\n",
      "Loss: 0.29595127756948825\n",
      "Loss: 0.2672261121786303\n",
      "Loss: 0.2614091128156877\n",
      "Loss: 0.23637691754157897\n",
      "Loss: 0.20960506234593965\n",
      "______\n",
      "Iteration t=9\n",
      "all:  cs/acc_i=82.87 cs/acc_c=83.60 os/recall_knw=73.12 os/recall_unk=90.50 total/acc_i=75.16 total/acc_c=70.06 total/h_score=78.32\n",
      "selected:  cs/acc_i=82.87 cs/acc_c=83.60 os/recall_knw=73.12 os/recall_unk=90.50 total/acc_i=75.16 total/acc_c=70.06 total/h_score=78.32\n",
      "tensor(0)\n",
      "all:  cs/acc_i=82.87 cs/acc_c=83.60 os/recall_knw=73.12 os/recall_unk=90.50 total/acc_i=75.16 total/acc_c=70.06 total/h_score=78.32\n",
      "painting -> real lr= 0.001 seed= 2\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19]\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20]\n",
      "Loss: 2.36215717146794\n",
      "Loss: 0.995400619879365\n",
      "Loss: 0.6417584204425414\n",
      "Loss: 0.5284242840483785\n",
      "Loss: 0.4521017207453648\n",
      "Loss: 0.43624556719635926\n",
      "Loss: 0.3751078249886632\n",
      "Loss: 0.3565298583668967\n",
      "Loss: 0.33117623524740336\n",
      "Loss: 0.30566349206492305\n",
      "tensor(True) tensor(True)\n",
      "______\n",
      "Iteration t=1\n",
      "all:  cs/acc_i=80.80 cs/acc_c=81.41 os/recall_knw=97.53 os/recall_unk=26.77 total/acc_i=63.87 total/acc_c=78.53 total/h_score=40.25\n",
      "selected:  cs/acc_i=87.71 cs/acc_c=86.99 os/recall_knw=86.79 os/recall_unk=99.05 total/acc_i=91.14 total/acc_c=85.92 total/h_score=91.64\n",
      "Loss: 2.26986360318901\n",
      "Loss: 0.8757506919692654\n",
      "Loss: 0.5701638365438743\n",
      "Loss: 0.4861759525514388\n",
      "Loss: 0.42446447625871775\n",
      "Loss: 0.3879920986964721\n",
      "Loss: 0.3424546220448128\n",
      "Loss: 0.3227695868487737\n",
      "Loss: 0.3026182088394498\n",
      "Loss: 0.2917557421985061\n",
      "______\n",
      "Iteration t=2\n",
      "all:  cs/acc_i=82.04 cs/acc_c=82.62 os/recall_knw=73.44 os/recall_unk=88.58 total/acc_i=74.77 total/acc_c=70.48 total/h_score=77.93\n",
      "selected:  cs/acc_i=76.76 cs/acc_c=79.48 os/recall_knw=54.71 os/recall_unk=98.92 total/acc_i=72.14 total/acc_c=59.48 total/h_score=72.73\n",
      "Loss: 2.174345240809701\n",
      "Loss: 0.7650061841444535\n",
      "Loss: 0.5226336786421862\n",
      "Loss: 0.44156652824445203\n",
      "Loss: 0.39083711190657183\n",
      "Loss: 0.3486807358264923\n",
      "Loss: 0.3360978717966513\n",
      "Loss: 0.28251898646354673\n",
      "Loss: 0.2788175718757239\n",
      "Loss: 0.2527717589790171\n",
      "______\n",
      "Iteration t=3\n",
      "all:  cs/acc_i=82.01 cs/acc_c=82.73 os/recall_knw=71.03 os/recall_unk=91.46 total/acc_i=74.57 total/acc_c=69.06 total/h_score=77.97\n",
      "selected:  cs/acc_i=79.79 cs/acc_c=81.55 os/recall_knw=61.57 os/recall_unk=97.47 total/acc_i=73.34 total/acc_c=63.53 total/h_score=75.67\n",
      "Loss: 2.102132199765885\n",
      "Loss: 0.7229818200615987\n",
      "Loss: 0.4835744496588021\n",
      "Loss: 0.4045818989509589\n",
      "Loss: 0.36708202322766387\n",
      "Loss: 0.3099067541706848\n",
      "Loss: 0.3089408536556445\n",
      "Loss: 0.2795439414833098\n",
      "Loss: 0.2618482412438687\n",
      "Loss: 0.23466638785672106\n",
      "______\n",
      "Iteration t=4\n",
      "all:  cs/acc_i=81.81 cs/acc_c=82.49 os/recall_knw=70.57 os/recall_unk=91.85 total/acc_i=74.47 total/acc_c=68.81 total/h_score=77.92\n",
      "selected:  cs/acc_i=80.98 cs/acc_c=82.26 os/recall_knw=65.96 os/recall_unk=94.96 total/acc_i=74.00 total/acc_c=66.50 total/h_score=77.23\n",
      "Loss: 2.049158765297187\n",
      "Loss: 0.6722679645999482\n",
      "Loss: 0.46928994367389304\n",
      "Loss: 0.3864356340644391\n",
      "Loss: 0.35957789256874667\n",
      "Loss: 0.3140714690334311\n",
      "Loss: 0.2843148761036757\n",
      "Loss: 0.2636558485928139\n",
      "Loss: 0.2445128256160962\n",
      "Loss: 0.2258783308789134\n",
      "______\n",
      "Iteration t=5\n",
      "all:  cs/acc_i=82.35 cs/acc_c=83.11 os/recall_knw=70.45 os/recall_unk=92.23 total/acc_i=74.57 total/acc_c=68.80 total/h_score=78.04\n",
      "selected:  cs/acc_i=82.04 cs/acc_c=83.09 os/recall_knw=68.27 os/recall_unk=93.07 total/acc_i=74.18 total/acc_c=67.82 total/h_score=77.61\n",
      "Loss: 2.0067180398947153\n",
      "Loss: 0.6566524037565941\n",
      "Loss: 0.45389149906352544\n",
      "Loss: 0.3842294800262421\n",
      "Loss: 0.32648085181911785\n",
      "Loss: 0.29840970228020197\n",
      "Loss: 0.2755401980322905\n",
      "Loss: 0.25709003121711504\n",
      "Loss: 0.23392075919904387\n",
      "Loss: 0.2235443202468256\n",
      "______\n",
      "Iteration t=6\n",
      "all:  cs/acc_i=82.84 cs/acc_c=83.47 os/recall_knw=70.39 os/recall_unk=92.30 total/acc_i=74.59 total/acc_c=68.80 total/h_score=78.06\n",
      "selected:  cs/acc_i=82.90 cs/acc_c=83.59 os/recall_knw=69.94 os/recall_unk=92.77 total/acc_i=74.66 total/acc_c=68.70 total/h_score=78.14\n",
      "Loss: 2.0193099788149946\n",
      "Loss: 0.6477657994196849\n",
      "Loss: 0.4643574483552069\n",
      "Loss: 0.36371454076384596\n",
      "Loss: 0.32713274660069236\n",
      "Loss: 0.29569306299558973\n",
      "Loss: 0.27354112989122764\n",
      "Loss: 0.2524804692926272\n",
      "Loss: 0.23673424034514143\n",
      "Loss: 0.2208305920046643\n",
      "______\n",
      "Iteration t=7\n",
      "all:  cs/acc_i=82.67 cs/acc_c=83.37 os/recall_knw=70.39 os/recall_unk=92.30 total/acc_i=74.59 total/acc_c=68.80 total/h_score=78.06\n",
      "selected:  cs/acc_i=82.66 cs/acc_c=83.37 os/recall_knw=70.39 os/recall_unk=92.36 total/acc_i=74.60 total/acc_c=68.80 total/h_score=78.08\n",
      "Loss: 2.0083788482472302\n",
      "Loss: 0.6446743571665138\n",
      "Loss: 0.45063150259666146\n",
      "Loss: 0.3815105974674225\n",
      "Loss: 0.3385224983328953\n",
      "Loss: 0.2903085651807487\n",
      "Loss: 0.26531377766514197\n",
      "Loss: 0.25227901625912635\n",
      "Loss: 0.23434138267766685\n",
      "Loss: 0.21354051406378857\n",
      "______\n",
      "Iteration t=8\n",
      "all:  cs/acc_i=82.21 cs/acc_c=82.83 os/recall_knw=70.39 os/recall_unk=92.30 total/acc_i=74.59 total/acc_c=68.80 total/h_score=78.06\n",
      "selected:  cs/acc_i=82.21 cs/acc_c=82.83 os/recall_knw=70.39 os/recall_unk=92.30 total/acc_i=74.59 total/acc_c=68.80 total/h_score=78.06\n",
      "Loss: 1.9871254604309798\n",
      "Loss: 0.6381595295388252\n",
      "Loss: 0.4559916970320046\n",
      "Loss: 0.3758613834623247\n",
      "Loss: 0.3240609996952116\n",
      "Loss: 0.28700239341706035\n",
      "Loss: 0.2742289236513898\n",
      "Loss: 0.24438331928104162\n",
      "Loss: 0.22489186170278117\n",
      "Loss: 0.20282455856213347\n",
      "______\n",
      "Iteration t=9\n",
      "all:  cs/acc_i=82.15 cs/acc_c=82.99 os/recall_knw=70.39 os/recall_unk=92.30 total/acc_i=74.59 total/acc_c=68.80 total/h_score=78.06\n",
      "selected:  cs/acc_i=82.15 cs/acc_c=82.99 os/recall_knw=70.39 os/recall_unk=92.30 total/acc_i=74.59 total/acc_c=68.80 total/h_score=78.06\n",
      "tensor(0)\n",
      "all:  cs/acc_i=82.15 cs/acc_c=82.99 os/recall_knw=70.39 os/recall_unk=92.30 total/acc_i=74.59 total/acc_c=68.80 total/h_score=78.06\n",
      "painting -> real lr= 0.001 seed= 3\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19]\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20]\n",
      "Loss: 2.3616566201051077\n",
      "Loss: 1.0015417244285345\n",
      "Loss: 0.6503123697514336\n",
      "Loss: 0.5392070283492406\n",
      "Loss: 0.4623440978427728\n",
      "Loss: 0.41942924770216145\n",
      "Loss: 0.3757954115048051\n",
      "Loss: 0.3437829559358458\n",
      "Loss: 0.3222755071396629\n",
      "Loss: 0.3121597494619588\n",
      "tensor(True) tensor(True)\n",
      "______\n",
      "Iteration t=1\n",
      "all:  cs/acc_i=81.40 cs/acc_c=82.23 os/recall_knw=97.53 os/recall_unk=26.77 total/acc_i=64.20 total/acc_c=79.18 total/h_score=40.33\n",
      "selected:  cs/acc_i=88.17 cs/acc_c=87.80 os/recall_knw=86.79 os/recall_unk=99.52 total/acc_i=91.21 total/acc_c=86.15 total/h_score=91.97\n",
      "Loss: 2.2656403729157852\n",
      "Loss: 0.8710210895122483\n",
      "Loss: 0.5716244052777919\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.47579046350347903\n",
      "Loss: 0.4228583871163139\n",
      "Loss: 0.3752481179355189\n",
      "Loss: 0.3427464843604916\n",
      "Loss: 0.30685041111338046\n",
      "Loss: 0.2905245838296968\n",
      "Loss: 0.2853914946317673\n",
      "______\n",
      "Iteration t=2\n",
      "all:  cs/acc_i=81.78 cs/acc_c=82.56 os/recall_knw=78.82 os/recall_unk=83.44 total/acc_i=75.56 total/acc_c=73.54 total/h_score=77.90\n",
      "selected:  cs/acc_i=77.73 cs/acc_c=80.37 os/recall_knw=60.16 os/recall_unk=98.93 total/acc_i=75.82 total/acc_c=64.30 total/h_score=76.66\n",
      "Loss: 2.1933763298121365\n",
      "Loss: 0.7739205344156785\n",
      "Loss: 0.5320512227036737\n",
      "Loss: 0.4222916717691855\n",
      "Loss: 0.3885117314078591\n",
      "Loss: 0.36030735934322533\n",
      "Loss: 0.31940572941845113\n",
      "Loss: 0.29245178574865516\n",
      "Loss: 0.27537241117520767\n",
      "Loss: 0.25580928351391446\n",
      "______\n",
      "Iteration t=3\n",
      "all:  cs/acc_i=81.89 cs/acc_c=82.50 os/recall_knw=72.81 os/recall_unk=89.67 total/acc_i=74.87 total/acc_c=70.14 total/h_score=78.09\n",
      "selected:  cs/acc_i=79.25 cs/acc_c=80.94 os/recall_knw=63.25 os/recall_unk=96.61 total/acc_i=73.68 total/acc_c=64.51 total/h_score=76.19\n",
      "Loss: 2.1101522092541605\n",
      "Loss: 0.7092965288113241\n",
      "Loss: 0.496159183703465\n",
      "Loss: 0.4113592286020109\n",
      "Loss: 0.37041542957192414\n",
      "Loss: 0.3211313711402759\n",
      "Loss: 0.3112266467858667\n",
      "Loss: 0.2752475246327789\n",
      "Loss: 0.253219221093475\n",
      "Loss: 0.244840296725296\n",
      "______\n",
      "Iteration t=4\n",
      "all:  cs/acc_i=82.06 cs/acc_c=82.76 os/recall_knw=72.43 os/recall_unk=89.86 total/acc_i=74.77 total/acc_c=69.92 total/h_score=78.01\n",
      "selected:  cs/acc_i=80.92 cs/acc_c=82.20 os/recall_knw=67.09 os/recall_unk=94.02 total/acc_i=74.24 total/acc_c=67.09 total/h_score=77.38\n",
      "Loss: 2.0410676914218224\n",
      "Loss: 0.6629938810671631\n",
      "Loss: 0.4765825717170772\n",
      "Loss: 0.3899189372743039\n",
      "Loss: 0.3447676472561924\n",
      "Loss: 0.32070594834850025\n",
      "Loss: 0.29008024451813025\n",
      "Loss: 0.269097609911114\n",
      "Loss: 0.23593020652371802\n",
      "Loss: 0.22855319893967949\n",
      "______\n",
      "Iteration t=5\n",
      "all:  cs/acc_i=82.12 cs/acc_c=82.79 os/recall_knw=72.41 os/recall_unk=89.86 total/acc_i=74.77 total/acc_c=69.92 total/h_score=78.01\n",
      "selected:  cs/acc_i=81.66 cs/acc_c=82.64 os/recall_knw=69.90 os/recall_unk=91.15 total/acc_i=74.35 total/acc_c=68.74 total/h_score=77.64\n",
      "Loss: 2.0207704859934035\n",
      "Loss: 0.6365220486453385\n",
      "Loss: 0.46071029791406765\n",
      "Loss: 0.3910240907767776\n",
      "Loss: 0.3284716277982399\n",
      "Loss: 0.30347990671730346\n",
      "Loss: 0.272169922520021\n",
      "Loss: 0.26249500613208787\n",
      "Loss: 0.22732486416864547\n",
      "Loss: 0.22412314142581005\n",
      "______\n",
      "Iteration t=6\n",
      "all:  cs/acc_i=82.09 cs/acc_c=82.84 os/recall_knw=72.18 os/recall_unk=89.86 total/acc_i=74.63 total/acc_c=69.74 total/h_score=77.89\n",
      "selected:  cs/acc_i=82.17 cs/acc_c=83.00 os/recall_knw=71.34 os/recall_unk=90.50 total/acc_i=74.70 total/acc_c=69.57 total/h_score=77.99\n",
      "Loss: 1.9880017098039389\n",
      "Loss: 0.6566852239891887\n",
      "Loss: 0.45087106293067336\n",
      "Loss: 0.3838367892894894\n",
      "Loss: 0.33401442640461027\n",
      "Loss: 0.28982490812195466\n",
      "Loss: 0.2755055135581642\n",
      "Loss: 0.2386281269369647\n",
      "Loss: 0.2282621700549498\n",
      "Loss: 0.21038236849126407\n",
      "______\n",
      "Iteration t=7\n",
      "all:  cs/acc_i=82.44 cs/acc_c=83.08 os/recall_knw=72.06 os/recall_unk=89.86 total/acc_i=74.63 total/acc_c=69.74 total/h_score=77.89\n",
      "selected:  cs/acc_i=82.50 cs/acc_c=83.14 os/recall_knw=71.92 os/recall_unk=89.97 total/acc_i=74.67 total/acc_c=69.74 total/h_score=77.93\n",
      "Loss: 1.9925716207492463\n",
      "Loss: 0.6495509973435948\n",
      "Loss: 0.44856637208823447\n",
      "Loss: 0.36985105036212934\n",
      "Loss: 0.3338659173425506\n",
      "Loss: 0.2926850981848897\n",
      "Loss: 0.2733018394363554\n",
      "Loss: 0.25311108436377794\n",
      "Loss: 0.23571139163461632\n",
      "Loss: 0.2042649055805184\n",
      "______\n",
      "Iteration t=8\n",
      "all:  cs/acc_i=82.09 cs/acc_c=82.67 os/recall_knw=72.06 os/recall_unk=89.86 total/acc_i=74.63 total/acc_c=69.74 total/h_score=77.89\n",
      "selected:  cs/acc_i=82.09 cs/acc_c=82.67 os/recall_knw=72.06 os/recall_unk=89.86 total/acc_i=74.63 total/acc_c=69.74 total/h_score=77.89\n",
      "Loss: 2.0059251244592224\n",
      "Loss: 0.6310213836538533\n",
      "Loss: 0.44556954872128396\n",
      "Loss: 0.3717223475499788\n",
      "Loss: 0.32580079209786084\n",
      "Loss: 0.2916270071761711\n",
      "Loss: 0.27255656827391117\n",
      "Loss: 0.24681445358799706\n",
      "Loss: 0.2318066502503197\n",
      "Loss: 0.2198201200287593\n",
      "______\n",
      "Iteration t=9\n",
      "all:  cs/acc_i=82.70 cs/acc_c=83.36 os/recall_knw=72.06 os/recall_unk=89.86 total/acc_i=74.63 total/acc_c=69.74 total/h_score=77.89\n",
      "selected:  cs/acc_i=82.70 cs/acc_c=83.36 os/recall_knw=72.06 os/recall_unk=89.86 total/acc_i=74.63 total/acc_c=69.74 total/h_score=77.89\n",
      "tensor(0)\n",
      "all:  cs/acc_i=82.70 cs/acc_c=83.36 os/recall_knw=72.06 os/recall_unk=89.86 total/acc_i=74.63 total/acc_c=69.74 total/h_score=77.89\n",
      "painting -> real lr= 0.001 seed= 4\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19]\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20]\n",
      "Loss: 2.3654841408133507\n",
      "Loss: 0.9800677376488844\n",
      "Loss: 0.6427941881120205\n",
      "Loss: 0.5227654129266739\n",
      "Loss: 0.46016225013881923\n",
      "Loss: 0.4319511679932475\n",
      "Loss: 0.38798254197463394\n",
      "Loss: 0.35827105194330217\n",
      "Loss: 0.3291039165730278\n",
      "Loss: 0.31132998342315354\n",
      "tensor(True) tensor(True)\n",
      "______\n",
      "Iteration t=1\n",
      "all:  cs/acc_i=81.03 cs/acc_c=81.74 os/recall_knw=97.18 os/recall_unk=25.99 total/acc_i=63.53 total/acc_c=78.40 total/h_score=39.36\n",
      "selected:  cs/acc_i=87.95 cs/acc_c=86.99 os/recall_knw=85.24 os/recall_unk=99.26 total/acc_i=90.02 total/acc_c=84.12 total/h_score=90.62\n",
      "Loss: 2.2811843198399213\n",
      "Loss: 0.8597606831742811\n",
      "Loss: 0.5653319496286008\n",
      "Loss: 0.4834091745952303\n",
      "Loss: 0.43297551139149554\n",
      "Loss: 0.3805335124795751\n",
      "Loss: 0.3445042100294616\n",
      "Loss: 0.3061903513852478\n",
      "Loss: 0.3103469872717248\n",
      "Loss: 0.26872245909631715\n",
      "______\n",
      "Iteration t=2\n",
      "all:  cs/acc_i=81.26 cs/acc_c=82.08 os/recall_knw=79.48 os/recall_unk=82.99 total/acc_i=75.86 total/acc_c=74.14 total/h_score=78.07\n",
      "selected:  cs/acc_i=76.21 cs/acc_c=79.08 os/recall_knw=60.77 os/recall_unk=98.48 total/acc_i=76.00 total/acc_c=64.90 total/h_score=77.00\n",
      "Loss: 2.1804827107082714\n",
      "Loss: 0.783637146949768\n",
      "Loss: 0.5102702496810393\n",
      "Loss: 0.44072291428392585\n",
      "Loss: 0.3960615508122878\n",
      "Loss: 0.36719954588196496\n",
      "Loss: 0.3163421594825658\n",
      "Loss: 0.2913608796759085\n",
      "Loss: 0.27093752040104435\n",
      "Loss: 0.2504554222930561\n",
      "______\n",
      "Iteration t=3\n",
      "all:  cs/acc_i=81.86 cs/acc_c=82.57 os/recall_knw=75.57 os/recall_unk=87.42 total/acc_i=75.42 total/acc_c=71.84 total/h_score=78.39\n",
      "selected:  cs/acc_i=80.05 cs/acc_c=81.66 os/recall_knw=65.60 os/recall_unk=97.15 total/acc_i=75.63 total/acc_c=66.99 total/h_score=78.23\n",
      "Loss: 2.1059350406062114\n",
      "Loss: 0.6945614581544922\n",
      "Loss: 0.4982735767246109\n",
      "Loss: 0.41266933706117004\n",
      "Loss: 0.3597472086293648\n",
      "Loss: 0.3342052770599927\n",
      "Loss: 0.30695628820063725\n",
      "Loss: 0.2654013216036232\n",
      "Loss: 0.2528433871825468\n",
      "Loss: 0.23605791173160892\n",
      "______\n",
      "Iteration t=4\n",
      "all:  cs/acc_i=82.52 cs/acc_c=83.18 os/recall_knw=74.39 os/recall_unk=88.51 total/acc_i=75.20 total/acc_c=71.14 total/h_score=78.34\n",
      "selected:  cs/acc_i=82.07 cs/acc_c=83.20 os/recall_knw=69.11 os/recall_unk=93.68 total/acc_i=75.39 total/acc_c=68.94 total/h_score=78.60\n",
      "Loss: 2.049068519131082\n",
      "Loss: 0.694749368507354\n",
      "Loss: 0.466030626023402\n",
      "Loss: 0.4096210306296583\n",
      "Loss: 0.3340300197972626\n",
      "Loss: 0.30828144721320416\n",
      "Loss: 0.29208560721551785\n",
      "Loss: 0.2698643925737162\n",
      "Loss: 0.23570517049949677\n",
      "Loss: 0.21675659608645517\n",
      "______\n",
      "Iteration t=5\n",
      "all:  cs/acc_i=82.67 cs/acc_c=83.41 os/recall_knw=74.16 os/recall_unk=88.83 total/acc_i=75.24 total/acc_c=71.09 total/h_score=78.43\n",
      "selected:  cs/acc_i=82.55 cs/acc_c=83.54 os/recall_knw=71.53 os/recall_unk=91.47 total/acc_i=75.38 total/acc_c=70.15 total/h_score=78.72\n",
      "Loss: 2.0018113281991745\n",
      "Loss: 0.658886518554082\n",
      "Loss: 0.46313944099441406\n",
      "Loss: 0.3737931374992643\n",
      "Loss: 0.3334079194636572\n",
      "Loss: 0.3045778716958705\n",
      "Loss: 0.2634764457032794\n",
      "Loss: 0.25016813640083585\n",
      "Loss: 0.22528172909976943\n",
      "Loss: 0.19810212604583255\n",
      "______\n",
      "Iteration t=6\n",
      "all:  cs/acc_i=82.70 cs/acc_c=83.52 os/recall_knw=73.90 os/recall_unk=89.02 total/acc_i=75.16 total/acc_c=70.90 total/h_score=78.37\n",
      "selected:  cs/acc_i=82.78 cs/acc_c=83.72 os/recall_knw=73.05 os/recall_unk=90.12 total/acc_i=75.35 total/acc_c=70.76 total/h_score=78.66\n",
      "Loss: 2.0223351165374615\n",
      "Loss: 0.6477051243556212\n",
      "Loss: 0.43904978467255645\n",
      "Loss: 0.376924848103005\n",
      "Loss: 0.3217246003032471\n",
      "Loss: 0.3071507425944072\n",
      "Loss: 0.2673645262369273\n",
      "Loss: 0.2535366989001169\n",
      "Loss: 0.2187647212597524\n",
      "Loss: 0.2037042862567935\n",
      "______\n",
      "Iteration t=7\n",
      "all:  cs/acc_i=82.58 cs/acc_c=83.32 os/recall_knw=73.87 os/recall_unk=89.02 total/acc_i=75.14 total/acc_c=70.88 total/h_score=78.35\n",
      "selected:  cs/acc_i=82.64 cs/acc_c=83.40 os/recall_knw=73.74 os/recall_unk=89.31 total/acc_i=75.23 total/acc_c=70.91 total/h_score=78.48\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 1.9659312213384188\n",
      "Loss: 0.6284122043389541\n",
      "Loss: 0.4344106307167273\n",
      "Loss: 0.3689773131104616\n",
      "Loss: 0.3302215097959225\n",
      "Loss: 0.2913307379300778\n",
      "Loss: 0.2620822162582324\n",
      "Loss: 0.2436273753299163\n",
      "Loss: 0.2345709114922927\n",
      "Loss: 0.19750774236825797\n",
      "______\n",
      "Iteration t=8\n",
      "all:  cs/acc_i=82.32 cs/acc_c=83.08 os/recall_knw=73.87 os/recall_unk=89.02 total/acc_i=75.14 total/acc_c=70.88 total/h_score=78.35\n",
      "selected:  cs/acc_i=82.32 cs/acc_c=83.08 os/recall_knw=73.87 os/recall_unk=89.08 total/acc_i=75.16 total/acc_c=70.88 total/h_score=78.38\n",
      "Loss: 1.9876101680694183\n",
      "Loss: 0.633257417271108\n",
      "Loss: 0.4324569931608036\n",
      "Loss: 0.35724813929913235\n",
      "Loss: 0.3150945503744611\n",
      "Loss: 0.29732719603126034\n",
      "Loss: 0.2797164919506187\n",
      "Loss: 0.2372019213447176\n",
      "Loss: 0.22742962183579346\n",
      "Loss: 0.2038729531759042\n",
      "______\n",
      "Iteration t=9\n",
      "all:  cs/acc_i=82.44 cs/acc_c=83.24 os/recall_knw=73.87 os/recall_unk=89.02 total/acc_i=75.14 total/acc_c=70.88 total/h_score=78.35\n",
      "selected:  cs/acc_i=82.44 cs/acc_c=83.24 os/recall_knw=73.87 os/recall_unk=89.02 total/acc_i=75.14 total/acc_c=70.88 total/h_score=78.35\n",
      "tensor(0)\n",
      "all:  cs/acc_i=82.44 cs/acc_c=83.24 os/recall_knw=73.87 os/recall_unk=89.02 total/acc_i=75.14 total/acc_c=70.88 total/h_score=78.35\n",
      "painting -> real lr= 0.001 seed= 0\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19]\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20]\n",
      "Loss: 2.3618322918812433\n",
      "Loss: 0.998059327652057\n",
      "Loss: 0.6555997510751088\n",
      "Loss: 0.5392922316988309\n",
      "Loss: 0.4795578104133407\n",
      "Loss: 0.41333353128284217\n",
      "Loss: 0.39090102321157855\n",
      "Loss: 0.3491203309968114\n",
      "Loss: 0.3335712570386628\n",
      "Loss: 0.3199567678694924\n",
      "tensor(True) tensor(True)\n",
      "______\n",
      "Iteration t=1\n",
      "all:  cs/acc_i=79.99 cs/acc_c=80.79 os/recall_knw=97.24 os/recall_unk=26.12 total/acc_i=62.78 total/acc_c=77.46 total/h_score=39.39\n",
      "selected:  cs/acc_i=88.79 cs/acc_c=88.23 os/recall_knw=85.45 os/recall_unk=99.03 total/acc_i=90.10 total/acc_c=84.58 total/h_score=90.81\n",
      "Loss: 2.2601748210515162\n",
      "Loss: 0.8769894812920297\n",
      "Loss: 0.5834732644779738\n",
      "Loss: 0.48366557396659554\n",
      "Loss: 0.43365088053220924\n",
      "Loss: 0.3731590958759766\n",
      "Loss: 0.3543118101566337\n",
      "Loss: 0.32143784926612246\n",
      "Loss: 0.28981126143142233\n",
      "Loss: 0.27254270048913104\n",
      "______\n",
      "Iteration t=2\n",
      "all:  cs/acc_i=81.37 cs/acc_c=81.95 os/recall_knw=72.52 os/recall_unk=90.76 total/acc_i=74.77 total/acc_c=69.34 total/h_score=77.92\n",
      "selected:  cs/acc_i=75.67 cs/acc_c=78.67 os/recall_knw=53.66 os/recall_unk=98.40 total/acc_i=71.31 total/acc_c=57.53 total/h_score=70.96\n",
      "Loss: 2.1748774901303376\n",
      "Loss: 0.7842940179868177\n",
      "Loss: 0.5237344229221343\n",
      "Loss: 0.43816658919507806\n",
      "Loss: 0.4067174850810658\n",
      "Loss: 0.34684161123904317\n",
      "Loss: 0.3264887515523217\n",
      "Loss: 0.29512834240089764\n",
      "Loss: 0.26849130004644395\n",
      "Loss: 0.24501314596696333\n",
      "______\n",
      "Iteration t=3\n",
      "all:  cs/acc_i=81.98 cs/acc_c=82.74 os/recall_knw=69.96 os/recall_unk=92.11 total/acc_i=74.01 total/acc_c=67.86 total/h_score=77.34\n",
      "selected:  cs/acc_i=79.31 cs/acc_c=81.39 os/recall_knw=60.11 os/recall_unk=96.05 total/acc_i=71.80 total/acc_c=61.84 total/h_score=73.96\n",
      "Loss: 2.084424035655674\n",
      "Loss: 0.7061080234157261\n",
      "Loss: 0.4893261931094107\n",
      "Loss: 0.41492700796971205\n",
      "Loss: 0.36249501542332246\n",
      "Loss: 0.32719578960097534\n",
      "Loss: 0.30078386040436444\n",
      "Loss: 0.2742368966801879\n",
      "Loss: 0.25309418531013106\n",
      "Loss: 0.22925324412862869\n",
      "______\n",
      "Iteration t=4\n",
      "all:  cs/acc_i=82.29 cs/acc_c=82.99 os/recall_knw=69.45 os/recall_unk=92.36 total/acc_i=73.89 total/acc_c=67.63 total/h_score=77.25\n",
      "selected:  cs/acc_i=81.43 cs/acc_c=82.41 os/recall_knw=65.37 os/recall_unk=95.17 total/acc_i=73.31 total/acc_c=65.11 total/h_score=76.25\n",
      "Loss: 2.060158055532174\n",
      "Loss: 0.6660281778847585\n",
      "Loss: 0.45612432609816067\n",
      "Loss: 0.3874545957709922\n",
      "Loss: 0.3494598220606319\n",
      "Loss: 0.32033627062547404\n",
      "Loss: 0.2775225472132691\n",
      "Loss: 0.2619189283398331\n",
      "Loss: 0.2400585790882345\n",
      "Loss: 0.22382428357835676\n",
      "______\n",
      "Iteration t=5\n",
      "all:  cs/acc_i=81.58 cs/acc_c=82.37 os/recall_knw=69.39 os/recall_unk=92.43 total/acc_i=73.89 total/acc_c=67.59 total/h_score=77.25\n",
      "selected:  cs/acc_i=81.09 cs/acc_c=82.21 os/recall_knw=67.41 os/recall_unk=93.39 total/acc_i=73.47 total/acc_c=66.56 total/h_score=76.80\n",
      "Loss: 2.019096165895462\n",
      "Loss: 0.653006280079866\n",
      "Loss: 0.45313098673255015\n",
      "Loss: 0.3800597182021309\n",
      "Loss: 0.3469669655060921\n",
      "Loss: 0.30486778817020166\n",
      "Loss: 0.2790021177691718\n",
      "Loss: 0.2667524428226245\n",
      "Loss: 0.2406289477665455\n",
      "Loss: 0.21453268218260163\n",
      "______\n",
      "Iteration t=6\n",
      "all:  cs/acc_i=82.06 cs/acc_c=82.67 os/recall_knw=69.36 os/recall_unk=92.49 total/acc_i=73.89 total/acc_c=67.56 total/h_score=77.24\n",
      "selected:  cs/acc_i=82.06 cs/acc_c=82.72 os/recall_knw=68.66 os/recall_unk=93.03 total/acc_i=73.90 total/acc_c=67.32 total/h_score=77.24\n",
      "Loss: 2.0070466927335233\n",
      "Loss: 0.6516175608186028\n",
      "Loss: 0.44934372405839873\n",
      "Loss: 0.37137191570540773\n",
      "Loss: 0.32657313903298557\n",
      "Loss: 0.2974032125188203\n",
      "Loss: 0.2774948203771175\n",
      "Loss: 0.2512628059197642\n",
      "Loss: 0.2338610988204615\n",
      "Loss: 0.20340590221406538\n",
      "______\n",
      "Iteration t=7\n",
      "all:  cs/acc_i=81.95 cs/acc_c=82.73 os/recall_knw=69.36 os/recall_unk=92.49 total/acc_i=73.89 total/acc_c=67.56 total/h_score=77.24\n",
      "selected:  cs/acc_i=81.95 cs/acc_c=82.73 os/recall_knw=69.36 os/recall_unk=92.55 total/acc_i=73.91 total/acc_c=67.56 total/h_score=77.26\n",
      "Loss: 2.0013329149413632\n",
      "Loss: 0.6587848617552217\n",
      "Loss: 0.44977706883301183\n",
      "Loss: 0.3781395036738868\n",
      "Loss: 0.3357729796191742\n",
      "Loss: 0.29446327735357525\n",
      "Loss: 0.28173932371234817\n",
      "Loss: 0.24811601644632958\n",
      "Loss: 0.2375041250735054\n",
      "Loss: 0.2074467704330679\n",
      "______\n",
      "Iteration t=8\n",
      "all:  cs/acc_i=81.78 cs/acc_c=82.58 os/recall_knw=69.36 os/recall_unk=92.49 total/acc_i=73.89 total/acc_c=67.56 total/h_score=77.24\n",
      "selected:  cs/acc_i=81.78 cs/acc_c=82.58 os/recall_knw=69.36 os/recall_unk=92.49 total/acc_i=73.89 total/acc_c=67.56 total/h_score=77.24\n",
      "Loss: 2.0048237271069733\n",
      "Loss: 0.6465617984439885\n",
      "Loss: 0.43416383526168273\n",
      "Loss: 0.3785210373726758\n",
      "Loss: 0.3335180063513005\n",
      "Loss: 0.2906626680614806\n",
      "Loss: 0.2693636215709407\n",
      "Loss: 0.24133576379160523\n",
      "Loss: 0.23322591782316893\n",
      "Loss: 0.2076112896869642\n",
      "______\n",
      "Iteration t=9\n",
      "all:  cs/acc_i=81.92 cs/acc_c=82.73 os/recall_knw=69.36 os/recall_unk=92.49 total/acc_i=73.89 total/acc_c=67.56 total/h_score=77.24\n",
      "selected:  cs/acc_i=81.92 cs/acc_c=82.73 os/recall_knw=69.36 os/recall_unk=92.49 total/acc_i=73.89 total/acc_c=67.56 total/h_score=77.24\n",
      "tensor(0)\n",
      "all:  cs/acc_i=81.92 cs/acc_c=82.73 os/recall_knw=69.36 os/recall_unk=92.49 total/acc_i=73.89 total/acc_c=67.56 total/h_score=77.24\n",
      "painting -> real lr= 0.001 seed= 1\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19]\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20]\n",
      "Loss: 2.379691697160403\n",
      "Loss: 0.9989447029928367\n",
      "Loss: 0.6385284973929326\n",
      "Loss: 0.5416469901800156\n",
      "Loss: 0.46966822985559703\n",
      "Loss: 0.4015366809442639\n",
      "Loss: 0.3955348880961537\n",
      "Loss: 0.35682029239833357\n",
      "Loss: 0.34305553197239835\n",
      "Loss: 0.3042723570019007\n",
      "tensor(True) tensor(True)\n",
      "______\n",
      "Iteration t=1\n",
      "all:  cs/acc_i=80.94 cs/acc_c=81.57 os/recall_knw=96.87 os/recall_unk=25.29 total/acc_i=63.19 total/acc_c=78.19 total/h_score=38.52\n",
      "selected:  cs/acc_i=87.57 cs/acc_c=87.55 os/recall_knw=83.88 os/recall_unk=99.75 total/acc_i=89.54 total/acc_c=84.04 total/h_score=90.76\n",
      "Loss: 2.268047090186629\n",
      "Loss: 0.8669953531073046\n",
      "Loss: 0.5922267467014549\n",
      "Loss: 0.4825923036812812\n",
      "Loss: 0.41486224867114724\n",
      "Loss: 0.3858737004415471\n",
      "Loss: 0.347322094492441\n",
      "Loss: 0.30769562963829483\n",
      "Loss: 0.3057027820411117\n",
      "Loss: 0.2819837239650331\n",
      "______\n",
      "Iteration t=2\n",
      "all:  cs/acc_i=81.32 cs/acc_c=81.90 os/recall_knw=79.65 os/recall_unk=79.72 total/acc_i=74.79 total/acc_c=73.75 total/h_score=76.45\n",
      "selected:  cs/acc_i=76.69 cs/acc_c=78.64 os/recall_knw=61.16 os/recall_unk=98.96 total/acc_i=75.89 total/acc_c=64.29 total/h_score=76.65\n",
      "Loss: 2.1742066155780444\n",
      "Loss: 0.7725383967703039\n",
      "Loss: 0.5368537446856498\n",
      "Loss: 0.45285168962045147\n",
      "Loss: 0.39211136408827524\n",
      "Loss: 0.3468691665746949\n",
      "Loss: 0.31780018616806377\n",
      "Loss: 0.2907106632536108\n",
      "Loss: 0.26601084915074436\n",
      "Loss: 0.24726346891034734\n",
      "______\n",
      "Iteration t=3\n",
      "all:  cs/acc_i=81.83 cs/acc_c=82.57 os/recall_knw=74.04 os/recall_unk=89.22 total/acc_i=75.20 total/acc_c=70.78 total/h_score=78.36\n",
      "selected:  cs/acc_i=80.22 cs/acc_c=81.93 os/recall_knw=64.49 os/recall_unk=97.13 total/acc_i=75.01 total/acc_c=65.95 total/h_score=77.45\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 2.108272791929441\n",
      "Loss: 0.7116521991891404\n",
      "Loss: 0.4943717685974624\n",
      "Loss: 0.4130488032449598\n",
      "Loss: 0.3585861752651734\n",
      "Loss: 0.31728415545841604\n",
      "Loss: 0.2940736646980864\n",
      "Loss: 0.2771428368016057\n",
      "Loss: 0.24258920986664623\n",
      "Loss: 0.25253614718222045\n",
      "______\n",
      "Iteration t=4\n",
      "all:  cs/acc_i=82.81 cs/acc_c=83.47 os/recall_knw=73.04 os/recall_unk=90.18 total/acc_i=75.10 total/acc_c=70.24 total/h_score=78.34\n",
      "selected:  cs/acc_i=82.08 cs/acc_c=83.35 os/recall_knw=67.74 os/recall_unk=94.36 total/acc_i=74.80 total/acc_c=67.88 total/h_score=78.05\n",
      "Loss: 2.0531376733591684\n",
      "Loss: 0.6803971454501152\n",
      "Loss: 0.4782730232139951\n",
      "Loss: 0.3969991437012428\n",
      "Loss: 0.34002031461874904\n",
      "Loss: 0.3004672350484486\n",
      "Loss: 0.2873239954320812\n",
      "Loss: 0.26594186559515565\n",
      "Loss: 0.24158193171024323\n",
      "Loss: 0.22410140829896064\n",
      "______\n",
      "Iteration t=5\n",
      "all:  cs/acc_i=82.87 cs/acc_c=83.50 os/recall_knw=72.89 os/recall_unk=90.37 total/acc_i=75.10 total/acc_c=70.18 total/h_score=78.36\n",
      "selected:  cs/acc_i=82.71 cs/acc_c=83.53 os/recall_knw=70.24 os/recall_unk=91.97 total/acc_i=74.91 total/acc_c=69.11 total/h_score=78.17\n",
      "Loss: 2.027249896869111\n",
      "Loss: 0.6595733208587756\n",
      "Loss: 0.45701556390942855\n",
      "Loss: 0.38662780371432104\n",
      "Loss: 0.32220055593754915\n",
      "Loss: 0.3060706800546128\n",
      "Loss: 0.265223745399485\n",
      "Loss: 0.2565047864477855\n",
      "Loss: 0.2390335458702744\n",
      "Loss: 0.21077665872276782\n",
      "______\n",
      "Iteration t=6\n",
      "all:  cs/acc_i=82.61 cs/acc_c=83.17 os/recall_knw=72.58 os/recall_unk=90.76 total/acc_i=75.06 total/acc_c=69.93 total/h_score=78.32\n",
      "selected:  cs/acc_i=82.74 cs/acc_c=83.36 os/recall_knw=71.66 os/recall_unk=91.34 total/acc_i=75.13 total/acc_c=69.73 total/h_score=78.39\n",
      "Loss: 2.0176444175101373\n",
      "Loss: 0.6509065017057437\n",
      "Loss: 0.4442158773494738\n",
      "Loss: 0.37988602935240184\n",
      "Loss: 0.3189084318270878\n",
      "Loss: 0.29368910132717563\n",
      "Loss: 0.2694000634233406\n",
      "Loss: 0.25284765918847163\n",
      "Loss: 0.24014991381699016\n",
      "Loss: 0.2134197420180778\n",
      "______\n",
      "Iteration t=7\n",
      "all:  cs/acc_i=82.32 cs/acc_c=82.98 os/recall_knw=72.46 os/recall_unk=90.76 total/acc_i=75.00 total/acc_c=69.86 total/h_score=78.28\n",
      "selected:  cs/acc_i=82.36 cs/acc_c=83.04 os/recall_knw=72.34 os/recall_unk=90.87 total/acc_i=75.03 total/acc_c=69.86 total/h_score=78.32\n",
      "Loss: 1.993688373004689\n",
      "Loss: 0.6436110610378785\n",
      "Loss: 0.44669187913184566\n",
      "Loss: 0.3617578170293994\n",
      "Loss: 0.32746463109834273\n",
      "Loss: 0.2990957407667172\n",
      "Loss: 0.2642258929763416\n",
      "Loss: 0.23917917669649832\n",
      "Loss: 0.21607537900930956\n",
      "Loss: 0.21027185901099868\n",
      "______\n",
      "Iteration t=8\n",
      "all:  cs/acc_i=82.38 cs/acc_c=83.14 os/recall_knw=72.46 os/recall_unk=90.76 total/acc_i=75.00 total/acc_c=69.86 total/h_score=78.28\n",
      "selected:  cs/acc_i=82.38 cs/acc_c=83.14 os/recall_knw=72.46 os/recall_unk=90.76 total/acc_i=75.00 total/acc_c=69.86 total/h_score=78.28\n",
      "Loss: 1.9949245875464874\n",
      "Loss: 0.6310790153479797\n",
      "Loss: 0.44665912598740576\n",
      "Loss: 0.36906117071677286\n",
      "Loss: 0.33053281988614114\n",
      "Loss: 0.29080938478649215\n",
      "Loss: 0.2722798545294133\n",
      "Loss: 0.2448532902765385\n",
      "Loss: 0.23268422107255496\n",
      "Loss: 0.21277396234427073\n",
      "______\n",
      "Iteration t=9\n",
      "all:  cs/acc_i=82.32 cs/acc_c=83.15 os/recall_knw=72.46 os/recall_unk=90.76 total/acc_i=75.00 total/acc_c=69.86 total/h_score=78.28\n",
      "selected:  cs/acc_i=82.32 cs/acc_c=83.15 os/recall_knw=72.46 os/recall_unk=90.76 total/acc_i=75.00 total/acc_c=69.86 total/h_score=78.28\n",
      "tensor(0)\n",
      "all:  cs/acc_i=82.32 cs/acc_c=83.15 os/recall_knw=72.46 os/recall_unk=90.76 total/acc_i=75.00 total/acc_c=69.86 total/h_score=78.28\n",
      "painting -> real lr= 0.001 seed= 2\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19]\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20]\n",
      "Loss: 2.3605916827917097\n",
      "Loss: 0.9942957756419977\n",
      "Loss: 0.6417452865590652\n",
      "Loss: 0.5289598494768143\n",
      "Loss: 0.45237160151203476\n",
      "Loss: 0.4364836651210984\n",
      "Loss: 0.37474260379870733\n",
      "Loss: 0.35672667836770416\n",
      "Loss: 0.33133041163285576\n",
      "Loss: 0.30564857898280023\n",
      "tensor(True) tensor(True)\n",
      "______\n",
      "Iteration t=1\n",
      "all:  cs/acc_i=80.77 cs/acc_c=81.42 os/recall_knw=97.33 os/recall_unk=26.32 total/acc_i=63.53 total/acc_c=78.26 total/h_score=39.71\n",
      "selected:  cs/acc_i=88.30 cs/acc_c=88.31 os/recall_knw=85.87 os/recall_unk=99.03 total/acc_i=90.58 total/acc_c=85.72 total/h_score=91.51\n",
      "Loss: 2.272688765858495\n",
      "Loss: 0.8774311921393224\n",
      "Loss: 0.5871916033269823\n",
      "Loss: 0.48892945374629293\n",
      "Loss: 0.41900091572094333\n",
      "Loss: 0.39174337835274925\n",
      "Loss: 0.35591982460992283\n",
      "Loss: 0.3208337660965531\n",
      "Loss: 0.30068587390489354\n",
      "Loss: 0.2967344994346301\n",
      "______\n",
      "Iteration t=2\n",
      "all:  cs/acc_i=81.46 cs/acc_c=82.10 os/recall_knw=80.02 os/recall_unk=80.10 total/acc_i=74.83 total/acc_c=73.78 total/h_score=76.64\n",
      "selected:  cs/acc_i=77.78 cs/acc_c=79.87 os/recall_knw=61.50 os/recall_unk=98.73 total/acc_i=76.21 total/acc_c=65.06 total/h_score=77.20\n",
      "Loss: 2.17860741333528\n",
      "Loss: 0.774472596320239\n",
      "Loss: 0.5320639419013804\n",
      "Loss: 0.43076231853528457\n",
      "Loss: 0.3854198670116338\n",
      "Loss: 0.33489524921233005\n",
      "Loss: 0.3165097534114664\n",
      "Loss: 0.302641385874965\n",
      "Loss: 0.2759715655446053\n",
      "Loss: 0.24719088456847452\n",
      "______\n",
      "Iteration t=3\n",
      "all:  cs/acc_i=82.24 cs/acc_c=82.86 os/recall_knw=75.65 os/recall_unk=87.68 total/acc_i=75.68 total/acc_c=71.99 total/h_score=78.58\n",
      "selected:  cs/acc_i=80.16 cs/acc_c=81.80 os/recall_knw=65.78 os/recall_unk=96.67 total/acc_i=75.49 total/acc_c=66.79 total/h_score=77.95\n",
      "Loss: 2.080752815285774\n",
      "Loss: 0.7225482109678935\n",
      "Loss: 0.47879739478230476\n",
      "Loss: 0.40756260978746905\n",
      "Loss: 0.36977886574419394\n",
      "Loss: 0.32439124181050144\n",
      "Loss: 0.29917240608483553\n",
      "Loss: 0.2693826698072969\n",
      "Loss: 0.24967074010214985\n",
      "Loss: 0.23225686775699053\n",
      "______\n",
      "Iteration t=4\n",
      "all:  cs/acc_i=82.15 cs/acc_c=82.92 os/recall_knw=74.73 os/recall_unk=88.06 total/acc_i=75.36 total/acc_c=71.43 total/h_score=78.37\n",
      "selected:  cs/acc_i=81.65 cs/acc_c=82.85 os/recall_knw=69.63 os/recall_unk=93.65 total/acc_i=75.73 total/acc_c=69.14 total/h_score=78.74\n",
      "Loss: 2.049625284336751\n",
      "Loss: 0.6817449055173818\n",
      "Loss: 0.4645807188418176\n",
      "Loss: 0.378150755259531\n",
      "Loss: 0.34869853027311026\n",
      "Loss: 0.31908351974257454\n",
      "Loss: 0.27943807856173686\n",
      "Loss: 0.2662338221482202\n",
      "Loss: 0.2326168313719868\n",
      "Loss: 0.22286668834367804\n",
      "______\n",
      "Iteration t=5\n",
      "all:  cs/acc_i=82.09 cs/acc_c=82.85 os/recall_knw=74.50 os/recall_unk=88.45 total/acc_i=75.38 total/acc_c=71.32 total/h_score=78.44\n",
      "selected:  cs/acc_i=81.83 cs/acc_c=82.94 os/recall_knw=71.78 os/recall_unk=90.24 total/acc_i=75.22 total/acc_c=70.32 total/h_score=78.41\n",
      "Loss: 2.0141359221367607\n",
      "Loss: 0.6515453503245399\n",
      "Loss: 0.4392009579473072\n",
      "Loss: 0.37948618455538674\n",
      "Loss: 0.3354030584532117\n",
      "Loss: 0.30105291363738834\n",
      "Loss: 0.27644619845918245\n",
      "Loss: 0.2564331084844612\n",
      "Loss: 0.2360119628646071\n",
      "Loss: 0.21748184902327403\n",
      "______\n",
      "Iteration t=6\n",
      "all:  cs/acc_i=82.29 cs/acc_c=82.97 os/recall_knw=74.36 os/recall_unk=88.77 total/acc_i=75.42 total/acc_c=71.27 total/h_score=78.52\n",
      "selected:  cs/acc_i=82.29 cs/acc_c=83.10 os/recall_knw=73.44 os/recall_unk=89.86 total/acc_i=75.54 total/acc_c=71.09 total/h_score=78.79\n",
      "Loss: 1.9939249331906717\n",
      "Loss: 0.6319481397267455\n",
      "Loss: 0.44064749115557406\n",
      "Loss: 0.3689968160683324\n",
      "Loss: 0.32119556099916835\n",
      "Loss: 0.30100042743157157\n",
      "Loss: 0.2682009825008626\n",
      "Loss: 0.24347683056170896\n",
      "Loss: 0.22172073783896726\n",
      "Loss: 0.20767817859138762\n",
      "______\n",
      "Iteration t=7\n",
      "all:  cs/acc_i=82.47 cs/acc_c=83.16 os/recall_knw=74.33 os/recall_unk=88.77 total/acc_i=75.40 total/acc_c=71.24 total/h_score=78.50\n",
      "selected:  cs/acc_i=82.59 cs/acc_c=83.35 os/recall_knw=74.05 os/recall_unk=89.17 total/acc_i=75.54 total/acc_c=71.34 total/h_score=78.71\n",
      "Loss: 1.980622986646799\n",
      "Loss: 0.6237031484567203\n",
      "Loss: 0.43661815982598523\n",
      "Loss: 0.3732265348617847\n",
      "Loss: 0.32662714722064823\n",
      "Loss: 0.29016834809229924\n",
      "Loss: 0.26210215295736605\n",
      "Loss: 0.2482094522164418\n",
      "Loss: 0.2173464888678147\n",
      "Loss: 0.2053997264458583\n",
      "______\n",
      "Iteration t=8\n",
      "all:  cs/acc_i=82.15 cs/acc_c=83.01 os/recall_knw=74.33 os/recall_unk=88.77 total/acc_i=75.40 total/acc_c=71.24 total/h_score=78.50\n",
      "selected:  cs/acc_i=82.15 cs/acc_c=83.01 os/recall_knw=74.33 os/recall_unk=88.77 total/acc_i=75.40 total/acc_c=71.24 total/h_score=78.50\n",
      "Loss: 1.9911519477338147\n",
      "Loss: 0.6190414237189878\n",
      "Loss: 0.44622911055760883\n",
      "Loss: 0.35182716052956375\n",
      "Loss: 0.3213501585864582\n",
      "Loss: 0.2826661826597035\n",
      "Loss: 0.26111356652358925\n",
      "Loss: 0.24533995655736673\n",
      "Loss: 0.2238939318897351\n",
      "Loss: 0.20525864347175587\n",
      "______\n",
      "Iteration t=9\n",
      "all:  cs/acc_i=82.93 cs/acc_c=83.61 os/recall_knw=74.33 os/recall_unk=88.77 total/acc_i=75.40 total/acc_c=71.24 total/h_score=78.50\n",
      "selected:  cs/acc_i=82.93 cs/acc_c=83.61 os/recall_knw=74.33 os/recall_unk=88.77 total/acc_i=75.40 total/acc_c=71.24 total/h_score=78.50\n",
      "tensor(0)\n",
      "all:  cs/acc_i=82.93 cs/acc_c=83.61 os/recall_knw=74.33 os/recall_unk=88.77 total/acc_i=75.40 total/acc_c=71.24 total/h_score=78.50\n",
      "painting -> real lr= 0.001 seed= 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19]\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20]\n",
      "Loss: 2.361064197619756\n",
      "Loss: 1.0006607805689176\n",
      "Loss: 0.6501539790381988\n",
      "Loss: 0.5389690157026052\n",
      "Loss: 0.46240832650413116\n",
      "Loss: 0.41913829557597637\n",
      "Loss: 0.3755353888186316\n",
      "Loss: 0.3436248815928896\n",
      "Loss: 0.3221260724589229\n",
      "Loss: 0.31213610535487535\n",
      "tensor(True) tensor(True)\n",
      "______\n",
      "Iteration t=1\n",
      "all:  cs/acc_i=81.43 cs/acc_c=82.25 os/recall_knw=97.27 os/recall_unk=26.19 total/acc_i=63.91 total/acc_c=79.02 total/h_score=39.66\n",
      "selected:  cs/acc_i=88.05 cs/acc_c=87.90 os/recall_knw=85.63 os/recall_unk=99.51 total/acc_i=90.38 total/acc_c=85.45 total/h_score=91.54\n",
      "Loss: 2.269534004751102\n",
      "Loss: 0.8618298423613688\n",
      "Loss: 0.5671047225825546\n",
      "Loss: 0.47934657352608306\n",
      "Loss: 0.425171279543361\n",
      "Loss: 0.36574051067117574\n",
      "Loss: 0.35252928650078846\n",
      "Loss: 0.31523633167840714\n",
      "Loss: 0.29165124070159226\n",
      "Loss: 0.29869999132992686\n",
      "______\n",
      "Iteration t=2\n",
      "all:  cs/acc_i=82.09 cs/acc_c=82.85 os/recall_knw=79.62 os/recall_unk=79.85 total/acc_i=74.91 total/acc_c=73.95 total/h_score=76.63\n",
      "selected:  cs/acc_i=78.05 cs/acc_c=80.68 os/recall_knw=61.09 os/recall_unk=98.73 total/acc_i=75.89 total/acc_c=64.90 total/h_score=77.07\n",
      "Loss: 2.177190434932709\n",
      "Loss: 0.7870063907449896\n",
      "Loss: 0.5301958789066835\n",
      "Loss: 0.4392279375141317\n",
      "Loss: 0.39028204413977535\n",
      "Loss: 0.35060657929290423\n",
      "Loss: 0.3168461438471621\n",
      "Loss: 0.29200714019211854\n",
      "Loss: 0.27965143536979503\n",
      "Loss: 0.2475952981547876\n",
      "______\n",
      "Iteration t=3\n",
      "all:  cs/acc_i=81.52 cs/acc_c=82.25 os/recall_knw=75.17 os/recall_unk=86.78 total/acc_i=75.06 total/acc_c=71.56 total/h_score=77.98\n",
      "selected:  cs/acc_i=78.97 cs/acc_c=80.51 os/recall_knw=65.38 os/recall_unk=96.64 total/acc_i=74.87 total/acc_c=65.88 total/h_score=77.25\n",
      "Loss: 2.121213935213546\n",
      "Loss: 0.7268968401094006\n",
      "Loss: 0.4991050170709009\n",
      "Loss: 0.3965967385327979\n",
      "Loss: 0.3551039135670417\n",
      "Loss: 0.32093063200989813\n",
      "Loss: 0.2934774520156318\n",
      "Loss: 0.2707463507476735\n",
      "Loss: 0.2576858567660802\n",
      "Loss: 0.23160760154411808\n",
      "______\n",
      "Iteration t=4\n",
      "all:  cs/acc_i=82.04 cs/acc_c=82.75 os/recall_knw=74.62 os/recall_unk=87.74 total/acc_i=75.20 total/acc_c=71.38 total/h_score=78.22\n",
      "selected:  cs/acc_i=81.24 cs/acc_c=82.59 os/recall_knw=69.27 os/recall_unk=92.87 total/acc_i=75.21 total/acc_c=69.03 total/h_score=78.40\n",
      "Loss: 2.048810465218591\n",
      "Loss: 0.6671863387842647\n",
      "Loss: 0.46716903650858366\n",
      "Loss: 0.4021986877087687\n",
      "Loss: 0.33588423645887217\n",
      "Loss: 0.31035497987368066\n",
      "Loss: 0.288602637340788\n",
      "Loss: 0.267559497131676\n",
      "Loss: 0.2394343345135939\n",
      "Loss: 0.22107219169618653\n",
      "______\n",
      "Iteration t=5\n",
      "all:  cs/acc_i=82.55 cs/acc_c=83.20 os/recall_knw=74.30 os/recall_unk=88.38 total/acc_i=75.30 total/acc_c=71.24 total/h_score=78.36\n",
      "selected:  cs/acc_i=82.11 cs/acc_c=83.02 os/recall_knw=71.74 os/recall_unk=90.41 total/acc_i=75.08 total/acc_c=70.00 total/h_score=78.26\n",
      "Loss: 2.009235426168593\n",
      "Loss: 0.6276997439918064\n",
      "Loss: 0.4481600876838442\n",
      "Loss: 0.3799376416774023\n",
      "Loss: 0.34310518254836403\n",
      "Loss: 0.2962301553714843\n",
      "Loss: 0.26224761803944907\n",
      "Loss: 0.24733959571236655\n",
      "Loss: 0.2215549894505077\n",
      "Loss: 0.2071249462427601\n",
      "______\n",
      "Iteration t=6\n",
      "all:  cs/acc_i=82.06 cs/acc_c=82.77 os/recall_knw=74.13 os/recall_unk=88.51 total/acc_i=75.26 total/acc_c=71.14 total/h_score=78.34\n",
      "selected:  cs/acc_i=81.90 cs/acc_c=82.76 os/recall_knw=72.99 os/recall_unk=89.66 total/acc_i=75.26 total/acc_c=70.75 total/h_score=78.50\n",
      "Loss: 1.991615883286497\n",
      "Loss: 0.637824467409437\n",
      "Loss: 0.43729283639760774\n",
      "Loss: 0.3710635022443032\n",
      "Loss: 0.32001743437809366\n",
      "Loss: 0.29393541441528226\n",
      "Loss: 0.27014715790841437\n",
      "Loss: 0.25059943049681893\n",
      "Loss: 0.22540851754377192\n",
      "Loss: 0.20055997719831556\n",
      "______\n",
      "Iteration t=7\n",
      "all:  cs/acc_i=82.47 cs/acc_c=83.13 os/recall_knw=74.10 os/recall_unk=88.51 total/acc_i=75.24 total/acc_c=71.11 total/h_score=78.32\n",
      "selected:  cs/acc_i=82.47 cs/acc_c=83.15 os/recall_knw=73.93 os/recall_unk=88.68 total/acc_i=75.25 total/acc_c=71.07 total/h_score=78.36\n",
      "Loss: 1.996083678465623\n",
      "Loss: 0.6283635061520797\n",
      "Loss: 0.4503322146947567\n",
      "Loss: 0.3590640834890879\n",
      "Loss: 0.31876558173161285\n",
      "Loss: 0.28316870428048646\n",
      "Loss: 0.2642066380610833\n",
      "Loss: 0.23144012404175904\n",
      "Loss: 0.22714237583371308\n",
      "Loss: 0.2040471732845673\n",
      "______\n",
      "Iteration t=8\n",
      "all:  cs/acc_i=82.06 cs/acc_c=82.89 os/recall_knw=74.10 os/recall_unk=88.51 total/acc_i=75.24 total/acc_c=71.11 total/h_score=78.32\n",
      "selected:  cs/acc_i=82.06 cs/acc_c=82.89 os/recall_knw=74.10 os/recall_unk=88.51 total/acc_i=75.24 total/acc_c=71.11 total/h_score=78.32\n",
      "Loss: 1.9783421465955628\n",
      "Loss: 0.6402742215003704\n",
      "Loss: 0.4445401873051023\n",
      "Loss: 0.3528511869304019\n",
      "Loss: 0.3180122429196454\n",
      "Loss: 0.28073118793909535\n",
      "Loss: 0.26318550442396865\n",
      "Loss: 0.2451368526332766\n",
      "Loss: 0.21900537014693205\n",
      "Loss: 0.19761557302272026\n",
      "______\n",
      "Iteration t=9\n",
      "all:  cs/acc_i=82.44 cs/acc_c=83.12 os/recall_knw=74.10 os/recall_unk=88.51 total/acc_i=75.24 total/acc_c=71.11 total/h_score=78.32\n",
      "selected:  cs/acc_i=82.44 cs/acc_c=83.12 os/recall_knw=74.10 os/recall_unk=88.51 total/acc_i=75.24 total/acc_c=71.11 total/h_score=78.32\n",
      "tensor(0)\n",
      "all:  cs/acc_i=82.44 cs/acc_c=83.12 os/recall_knw=74.10 os/recall_unk=88.51 total/acc_i=75.24 total/acc_c=71.11 total/h_score=78.32\n",
      "painting -> real lr= 0.001 seed= 4\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19]\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20]\n",
      "Loss: 2.366750194132328\n",
      "Loss: 0.9812813696761926\n",
      "Loss: 0.6442153873542945\n",
      "Loss: 0.5244619732101758\n",
      "Loss: 0.4615503791719675\n",
      "Loss: 0.4325500840321183\n",
      "Loss: 0.38922146999587615\n",
      "Loss: 0.3595638994127512\n",
      "Loss: 0.33074568302060164\n",
      "Loss: 0.31247828174382447\n",
      "tensor(True) tensor(True)\n",
      "______\n",
      "Iteration t=1\n",
      "all:  cs/acc_i=81.06 cs/acc_c=81.74 os/recall_knw=96.92 os/recall_unk=25.42 total/acc_i=63.27 total/acc_c=78.24 total/h_score=38.68\n",
      "selected:  cs/acc_i=87.69 cs/acc_c=86.63 os/recall_knw=84.12 os/recall_unk=99.25 total/acc_i=89.28 total/acc_c=83.01 total/h_score=89.92\n",
      "Loss: 2.2712925496951555\n",
      "Loss: 0.8502965354642202\n",
      "Loss: 0.5724090231481449\n",
      "Loss: 0.49253064180298367\n",
      "Loss: 0.41870592606737633\n",
      "Loss: 0.3829722125227599\n",
      "Loss: 0.3483237706182539\n",
      "Loss: 0.31482611371334207\n",
      "Loss: 0.3074184410678324\n",
      "Loss: 0.2752092563828757\n",
      "______\n",
      "Iteration t=2\n",
      "all:  cs/acc_i=81.66 cs/acc_c=82.31 os/recall_knw=81.12 os/recall_unk=79.78 total/acc_i=75.40 total/acc_c=74.67 total/h_score=77.00\n",
      "selected:  cs/acc_i=78.01 cs/acc_c=79.96 os/recall_knw=62.86 os/recall_unk=98.65 total/acc_i=77.15 total/acc_c=65.92 total/h_score=77.85\n",
      "Loss: 2.1844784086400812\n",
      "Loss: 0.7871545948765495\n",
      "Loss: 0.5192367262190039\n",
      "Loss: 0.4496129486777566\n",
      "Loss: 0.3968437759171833\n",
      "Loss: 0.3541135737570849\n",
      "Loss: 0.3199352831461213\n",
      "Loss: 0.28750832414085215\n",
      "Loss: 0.2666069203073328\n",
      "Loss: 0.2571314782175151\n",
      "______\n",
      "Iteration t=3\n",
      "all:  cs/acc_i=81.89 cs/acc_c=82.55 os/recall_knw=75.37 os/recall_unk=87.80 total/acc_i=75.34 total/acc_c=71.47 total/h_score=78.30\n",
      "selected:  cs/acc_i=79.99 cs/acc_c=81.64 os/recall_knw=65.43 os/recall_unk=96.54 total/acc_i=75.18 total/acc_c=66.40 total/h_score=77.62\n",
      "Loss: 2.0981137548407465\n",
      "Loss: 0.7041652857849042\n",
      "Loss: 0.48231230043385126\n",
      "Loss: 0.4210816061711066\n",
      "Loss: 0.3653277227374381\n",
      "Loss: 0.31986891608430096\n",
      "Loss: 0.3038082405899281\n",
      "Loss: 0.2636969451320498\n",
      "Loss: 0.2568331502173861\n",
      "Loss: 0.2257055697375781\n",
      "______\n",
      "Iteration t=4\n",
      "all:  cs/acc_i=81.92 cs/acc_c=82.54 os/recall_knw=74.62 os/recall_unk=88.38 total/acc_i=75.24 total/acc_c=71.12 total/h_score=78.28\n",
      "selected:  cs/acc_i=80.90 cs/acc_c=82.01 os/recall_knw=69.06 os/recall_unk=93.17 total/acc_i=75.00 total/acc_c=68.33 total/h_score=78.01\n",
      "Loss: 2.0508775822451857\n",
      "Loss: 0.681650752122285\n",
      "Loss: 0.4629253085030884\n",
      "Loss: 0.3837686844047953\n",
      "Loss: 0.34273102019653945\n",
      "Loss: 0.3141052916646004\n",
      "Loss: 0.2750461029346849\n",
      "Loss: 0.25976175108893973\n",
      "Loss: 0.2464368066460383\n",
      "Loss: 0.2168395769644956\n",
      "______\n",
      "Iteration t=5\n",
      "all:  cs/acc_i=82.01 cs/acc_c=82.65 os/recall_knw=74.25 os/recall_unk=88.77 total/acc_i=75.18 total/acc_c=70.93 total/h_score=78.30\n",
      "selected:  cs/acc_i=81.75 cs/acc_c=82.71 os/recall_knw=71.46 os/recall_unk=91.59 total/acc_i=75.29 total/acc_c=69.96 total/h_score=78.63\n",
      "Loss: 2.0210800592307074\n",
      "Loss: 0.6491351943866462\n",
      "Loss: 0.45905935863970193\n",
      "Loss: 0.3798860902571754\n",
      "Loss: 0.3422720426349503\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.30511192507614754\n",
      "Loss: 0.27063808454924326\n",
      "Loss: 0.23848107304115584\n",
      "Loss: 0.23655355667137795\n",
      "Loss: 0.20977516956390088\n",
      "______\n",
      "Iteration t=6\n",
      "all:  cs/acc_i=82.67 cs/acc_c=83.28 os/recall_knw=74.13 os/recall_unk=88.83 total/acc_i=75.14 total/acc_c=70.85 total/h_score=78.27\n",
      "selected:  cs/acc_i=82.79 cs/acc_c=83.49 os/recall_knw=73.15 os/recall_unk=89.70 total/acc_i=75.26 total/acc_c=70.66 total/h_score=78.45\n",
      "Loss: 2.005504719936216\n",
      "Loss: 0.6490856403502349\n",
      "Loss: 0.44834757148291093\n",
      "Loss: 0.3632732696158121\n",
      "Loss: 0.3237945384047113\n",
      "Loss: 0.3055285958579025\n",
      "Loss: 0.26034018735044473\n",
      "Loss: 0.2518306688008093\n",
      "Loss: 0.2254324103952197\n",
      "Loss: 0.2028161806875486\n",
      "______\n",
      "Iteration t=7\n",
      "all:  cs/acc_i=82.98 cs/acc_c=83.73 os/recall_knw=74.10 os/recall_unk=88.83 total/acc_i=75.14 total/acc_c=70.85 total/h_score=78.27\n",
      "selected:  cs/acc_i=83.09 cs/acc_c=83.86 os/recall_knw=73.95 os/recall_unk=89.00 total/acc_i=75.23 total/acc_c=70.91 total/h_score=78.37\n",
      "Loss: 1.9869693932166466\n",
      "Loss: 0.620848114490509\n",
      "Loss: 0.44161394043610647\n",
      "Loss: 0.36284098544946086\n",
      "Loss: 0.32271775495547517\n",
      "Loss: 0.2922152161368957\n",
      "Loss: 0.26342126089792983\n",
      "Loss: 0.24249872886217558\n",
      "Loss: 0.22589046333844845\n",
      "Loss: 0.20945915501851303\n",
      "______\n",
      "Iteration t=8\n",
      "all:  cs/acc_i=82.98 cs/acc_c=83.64 os/recall_knw=74.10 os/recall_unk=88.83 total/acc_i=75.14 total/acc_c=70.85 total/h_score=78.27\n",
      "selected:  cs/acc_i=83.00 cs/acc_c=83.66 os/recall_knw=74.09 os/recall_unk=88.83 total/acc_i=75.15 total/acc_c=70.86 total/h_score=78.28\n",
      "Loss: 1.9924989392055323\n",
      "Loss: 0.6296295757674001\n",
      "Loss: 0.44584213311504\n",
      "Loss: 0.3758894173325571\n",
      "Loss: 0.318757939192415\n",
      "Loss: 0.2950359831101324\n",
      "Loss: 0.2739252544413864\n",
      "Loss: 0.2394610795826634\n",
      "Loss: 0.22724454616842094\n",
      "Loss: 0.21292530528721085\n",
      "______\n",
      "Iteration t=9\n",
      "all:  cs/acc_i=82.24 cs/acc_c=82.86 os/recall_knw=74.10 os/recall_unk=88.83 total/acc_i=75.14 total/acc_c=70.85 total/h_score=78.27\n",
      "selected:  cs/acc_i=82.24 cs/acc_c=82.86 os/recall_knw=74.10 os/recall_unk=88.83 total/acc_i=75.14 total/acc_c=70.85 total/h_score=78.27\n",
      "tensor(0)\n",
      "all:  cs/acc_i=82.24 cs/acc_c=82.86 os/recall_knw=74.10 os/recall_unk=88.83 total/acc_i=75.14 total/acc_c=70.85 total/h_score=78.27\n",
      "painting -> real lr= 0.001 seed= 0\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19]\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20]\n",
      "Loss: 2.3607537358999253\n",
      "Loss: 0.9999435041099787\n",
      "Loss: 0.6558715492486954\n",
      "Loss: 0.539168107137084\n",
      "Loss: 0.4790625070842604\n",
      "Loss: 0.4128556671241919\n",
      "Loss: 0.3902237913571298\n",
      "Loss: 0.3478820443774263\n",
      "Loss: 0.3324078074656427\n",
      "Loss: 0.31848648469895124\n",
      "tensor(True) tensor(True)\n",
      "______\n",
      "Iteration t=1\n",
      "all:  cs/acc_i=79.56 cs/acc_c=80.25 os/recall_knw=97.38 os/recall_unk=26.44 total/acc_i=62.89 total/acc_c=77.38 total/h_score=39.74\n",
      "selected:  cs/acc_i=87.02 cs/acc_c=86.09 os/recall_knw=86.11 os/recall_unk=99.52 total/acc_i=90.74 total/acc_c=84.87 total/h_score=91.18\n",
      "Loss: 2.2637351233829826\n",
      "Loss: 0.8855551619862401\n",
      "Loss: 0.5743774278450382\n",
      "Loss: 0.46948622247969457\n",
      "Loss: 0.42487630519525027\n",
      "Loss: 0.3897569101852502\n",
      "Loss: 0.3432955819564734\n",
      "Loss: 0.32123466968074327\n",
      "Loss: 0.30759097537560054\n",
      "Loss: 0.2745693923486758\n",
      "______\n",
      "Iteration t=2\n",
      "all:  cs/acc_i=81.09 cs/acc_c=81.86 os/recall_knw=77.21 os/recall_unk=85.43 total/acc_i=75.40 total/acc_c=72.46 total/h_score=78.03\n",
      "selected:  cs/acc_i=76.04 cs/acc_c=78.89 os/recall_knw=58.42 os/recall_unk=98.89 total/acc_i=74.61 total/acc_c=62.58 total/h_score=75.28\n",
      "Loss: 2.171863025968725\n",
      "Loss: 0.7885997805812142\n",
      "Loss: 0.5141089674559507\n",
      "Loss: 0.43895012056285687\n",
      "Loss: 0.3875177738341418\n",
      "Loss: 0.35139352465217766\n",
      "Loss: 0.3122798003120856\n",
      "Loss: 0.29195057077841324\n",
      "Loss: 0.27875551183115355\n",
      "Loss: 0.257007440965284\n",
      "______\n",
      "Iteration t=3\n",
      "all:  cs/acc_i=81.14 cs/acc_c=81.75 os/recall_knw=74.45 os/recall_unk=87.80 total/acc_i=74.99 total/acc_c=70.97 total/h_score=77.98\n",
      "selected:  cs/acc_i=78.39 cs/acc_c=80.27 os/recall_knw=64.30 os/recall_unk=96.07 total/acc_i=74.25 total/acc_c=65.47 total/h_score=76.78\n",
      "Loss: 2.1071798052281547\n",
      "Loss: 0.7138899618836299\n",
      "Loss: 0.49972943185943447\n",
      "Loss: 0.4096857365220785\n",
      "Loss: 0.3718371480856448\n",
      "Loss: 0.3251983665236055\n",
      "Loss: 0.3033418041488079\n",
      "Loss: 0.27033736231443406\n",
      "Loss: 0.2544954713842232\n",
      "Loss: 0.23135613504644126\n",
      "______\n",
      "Iteration t=4\n",
      "all:  cs/acc_i=81.95 cs/acc_c=82.54 os/recall_knw=73.58 os/recall_unk=88.90 total/acc_i=74.91 total/acc_c=70.49 total/h_score=78.05\n",
      "selected:  cs/acc_i=80.89 cs/acc_c=81.83 os/recall_knw=68.63 os/recall_unk=93.45 total/acc_i=74.61 total/acc_c=67.77 total/h_score=77.70\n",
      "Loss: 2.0538218693405974\n",
      "Loss: 0.6621344183979471\n",
      "Loss: 0.4725692992896036\n",
      "Loss: 0.40301981551292676\n",
      "Loss: 0.34838911004705364\n",
      "Loss: 0.3183316096931306\n",
      "Loss: 0.27463144969706443\n",
      "Loss: 0.24712417199233777\n",
      "Loss: 0.22589558737924675\n",
      "Loss: 0.2199040144389751\n",
      "______\n",
      "Iteration t=5\n",
      "all:  cs/acc_i=82.21 cs/acc_c=82.84 os/recall_knw=73.35 os/recall_unk=89.09 total/acc_i=74.89 total/acc_c=70.41 total/h_score=78.07\n",
      "selected:  cs/acc_i=81.74 cs/acc_c=82.67 os/recall_knw=70.96 os/recall_unk=90.72 total/acc_i=74.57 total/acc_c=69.28 total/h_score=77.87\n",
      "Loss: 2.0161464689269897\n",
      "Loss: 0.6427734320125883\n",
      "Loss: 0.4631476563120645\n",
      "Loss: 0.3815111790384565\n",
      "Loss: 0.3462691200867532\n",
      "Loss: 0.30634493177372313\n",
      "Loss: 0.25997837681382424\n",
      "Loss: 0.24013415344414257\n",
      "Loss: 0.243024129053903\n",
      "Loss: 0.2178069010849983\n",
      "______\n",
      "Iteration t=6\n",
      "all:  cs/acc_i=81.92 cs/acc_c=82.79 os/recall_knw=73.35 os/recall_unk=89.09 total/acc_i=74.89 total/acc_c=70.41 total/h_score=78.07\n",
      "selected:  cs/acc_i=82.07 cs/acc_c=83.04 os/recall_knw=72.61 os/recall_unk=90.07 total/acc_i=75.11 total/acc_c=70.38 total/h_score=78.39\n",
      "Loss: 2.0010102506367216\n",
      "Loss: 0.6353031990127028\n",
      "Loss: 0.4297174668850557\n",
      "Loss: 0.3658132358364227\n",
      "Loss: 0.3157137051642498\n",
      "Loss: 0.29649660931290867\n",
      "Loss: 0.2723712040186857\n",
      "Loss: 0.24878689393726094\n",
      "Loss: 0.23357429007224947\n",
      "Loss: 0.21045036446825366\n",
      "______\n",
      "Iteration t=7\n",
      "all:  cs/acc_i=81.86 cs/acc_c=82.85 os/recall_knw=73.35 os/recall_unk=89.09 total/acc_i=74.89 total/acc_c=70.41 total/h_score=78.07\n",
      "selected:  cs/acc_i=81.94 cs/acc_c=82.93 os/recall_knw=73.21 os/recall_unk=89.43 total/acc_i=75.00 total/acc_c=70.43 total/h_score=78.20\n",
      "Loss: 1.9787828085231192\n",
      "Loss: 0.6294398958116402\n",
      "Loss: 0.4467733657378473\n",
      "Loss: 0.35389340213603443\n",
      "Loss: 0.32790120638171094\n",
      "Loss: 0.2956636657961357\n",
      "Loss: 0.26251013873627893\n",
      "Loss: 0.2510159271021868\n",
      "Loss: 0.22321074493919257\n",
      "Loss: 0.21255766846423532\n",
      "______\n",
      "Iteration t=8\n",
      "all:  cs/acc_i=82.67 cs/acc_c=83.38 os/recall_knw=73.35 os/recall_unk=89.09 total/acc_i=74.89 total/acc_c=70.41 total/h_score=78.07\n",
      "selected:  cs/acc_i=82.67 cs/acc_c=83.38 os/recall_knw=73.35 os/recall_unk=89.09 total/acc_i=74.89 total/acc_c=70.41 total/h_score=78.07\n",
      "Loss: 2.0035405866916363\n",
      "Loss: 0.6252235825703695\n",
      "Loss: 0.4423687792282838\n",
      "Loss: 0.3589794636460451\n",
      "Loss: 0.31124371638664833\n",
      "Loss: 0.29048393013385626\n",
      "Loss: 0.25896537331434394\n",
      "Loss: 0.24548567155232795\n",
      "Loss: 0.22657967227009626\n",
      "Loss: 0.20652367115020753\n",
      "______\n",
      "Iteration t=9\n",
      "all:  cs/acc_i=82.29 cs/acc_c=82.92 os/recall_knw=73.35 os/recall_unk=89.09 total/acc_i=74.89 total/acc_c=70.41 total/h_score=78.07\n",
      "selected:  cs/acc_i=82.29 cs/acc_c=82.92 os/recall_knw=73.35 os/recall_unk=89.09 total/acc_i=74.89 total/acc_c=70.41 total/h_score=78.07\n",
      "tensor(0)\n",
      "all:  cs/acc_i=82.29 cs/acc_c=82.92 os/recall_knw=73.35 os/recall_unk=89.09 total/acc_i=74.89 total/acc_c=70.41 total/h_score=78.07\n",
      "painting -> real lr= 0.001 seed= 1\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19]\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20]\n",
      "Loss: 2.37931713561217\n",
      "Loss: 0.9967751548935969\n",
      "Loss: 0.6376453671604395\n",
      "Loss: 0.5411968514323234\n",
      "Loss: 0.46919574129084746\n",
      "Loss: 0.40093176203469433\n",
      "Loss: 0.3947384105374416\n",
      "Loss: 0.3557715385531386\n",
      "Loss: 0.342407220415771\n",
      "Loss: 0.3043037818744779\n",
      "tensor(True) tensor(True)\n",
      "______\n",
      "Iteration t=1\n",
      "all:  cs/acc_i=80.94 cs/acc_c=81.65 os/recall_knw=97.18 os/recall_unk=25.99 total/acc_i=63.49 total/acc_c=78.37 total/h_score=39.36\n",
      "selected:  cs/acc_i=88.42 cs/acc_c=87.98 os/recall_knw=85.26 os/recall_unk=99.51 total/acc_i=90.49 total/acc_c=85.05 total/h_score=91.29\n",
      "Loss: 2.271312672038411\n",
      "Loss: 0.8596854526405187\n",
      "Loss: 0.5727306302896765\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.47885324690462083\n",
      "Loss: 0.430061148234116\n",
      "Loss: 0.38491578186436215\n",
      "Loss: 0.3548355815831081\n",
      "Loss: 0.3109676083910835\n",
      "Loss: 0.29755718174368834\n",
      "Loss: 0.27582152824588985\n",
      "______\n",
      "Iteration t=2\n",
      "all:  cs/acc_i=81.26 cs/acc_c=81.99 os/recall_knw=82.18 os/recall_unk=76.12 total/acc_i=74.67 total/acc_c=75.02 total/h_score=75.54\n",
      "selected:  cs/acc_i=77.82 cs/acc_c=80.07 os/recall_knw=64.29 os/recall_unk=98.92 total/acc_i=77.85 total/acc_c=67.75 total/h_score=79.31\n",
      "Loss: 2.1869287250258704\n",
      "Loss: 0.7700489414821972\n",
      "Loss: 0.5231012415885925\n",
      "Loss: 0.44709516953338274\n",
      "Loss: 0.3857650777426633\n",
      "Loss: 0.34682006058367815\n",
      "Loss: 0.3116334342143752\n",
      "Loss: 0.2917044137282805\n",
      "Loss: 0.262966043732383\n",
      "Loss: 0.2585354926369407\n",
      "______\n",
      "Iteration t=3\n",
      "all:  cs/acc_i=81.92 cs/acc_c=82.55 os/recall_knw=74.96 os/recall_unk=87.74 total/acc_i=75.18 total/acc_c=71.37 total/h_score=78.22\n",
      "selected:  cs/acc_i=80.02 cs/acc_c=81.44 os/recall_knw=65.27 os/recall_unk=96.95 total/acc_i=75.14 total/acc_c=66.18 total/h_score=77.57\n",
      "Loss: 2.1136249109898526\n",
      "Loss: 0.7156145869664949\n",
      "Loss: 0.5064362473785877\n",
      "Loss: 0.42477768133968524\n",
      "Loss: 0.356575802580951\n",
      "Loss: 0.3246896699683307\n",
      "Loss: 0.29921342968328357\n",
      "Loss: 0.2766737924148775\n",
      "Loss: 0.25014575815772355\n",
      "Loss: 0.230947462548438\n",
      "______\n",
      "Iteration t=4\n",
      "all:  cs/acc_i=82.32 cs/acc_c=83.00 os/recall_knw=74.59 os/recall_unk=88.77 total/acc_i=75.38 total/acc_c=71.25 total/h_score=78.51\n",
      "selected:  cs/acc_i=81.64 cs/acc_c=82.63 os/recall_knw=69.08 os/recall_unk=93.57 total/acc_i=75.33 total/acc_c=68.54 total/h_score=78.29\n",
      "Loss: 2.0516789477379596\n",
      "Loss: 0.6626248074359581\n",
      "Loss: 0.46648592499435926\n",
      "Loss: 0.3909897217007934\n",
      "Loss: 0.3384480434607287\n",
      "Loss: 0.29616776719445087\n",
      "Loss: 0.285371206908441\n",
      "Loss: 0.2781126918973493\n",
      "Loss: 0.24725471785078285\n",
      "Loss: 0.22093272565818223\n",
      "______\n",
      "Iteration t=5\n",
      "all:  cs/acc_i=82.38 cs/acc_c=83.11 os/recall_knw=74.13 os/recall_unk=89.60 total/acc_i=75.48 total/acc_c=71.05 total/h_score=78.67\n",
      "selected:  cs/acc_i=82.05 cs/acc_c=82.96 os/recall_knw=71.65 os/recall_unk=90.94 total/acc_i=75.18 total/acc_c=69.81 total/h_score=78.31\n",
      "Loss: 2.015677431273082\n",
      "Loss: 0.6428090545866224\n",
      "Loss: 0.44575412878914483\n",
      "Loss: 0.3873455520896685\n",
      "Loss: 0.33981136589769334\n",
      "Loss: 0.30671102002499595\n",
      "Loss: 0.2678685397382766\n",
      "Loss: 0.25095699526487836\n",
      "Loss: 0.22939930098160866\n",
      "Loss: 0.22199066429147646\n",
      "______\n",
      "Iteration t=6\n",
      "all:  cs/acc_i=82.70 cs/acc_c=83.34 os/recall_knw=73.99 os/recall_unk=89.79 total/acc_i=75.48 total/acc_c=70.96 total/h_score=78.68\n",
      "selected:  cs/acc_i=82.82 cs/acc_c=83.57 os/recall_knw=73.15 os/recall_unk=90.20 total/acc_i=75.51 total/acc_c=70.82 total/h_score=78.73\n",
      "Loss: 1.9915258858514868\n",
      "Loss: 0.6250727787058546\n",
      "Loss: 0.4464741772191125\n",
      "Loss: 0.3659650696360547\n",
      "Loss: 0.32681483097420716\n",
      "Loss: 0.30138948279785815\n",
      "Loss: 0.26275088142904435\n",
      "Loss: 0.2349814997627313\n",
      "Loss: 0.22816024514736596\n",
      "Loss: 0.20940558898106496\n",
      "______\n",
      "Iteration t=7\n",
      "all:  cs/acc_i=82.70 cs/acc_c=83.45 os/recall_knw=73.90 os/recall_unk=89.79 total/acc_i=75.46 total/acc_c=70.94 total/h_score=78.67\n",
      "selected:  cs/acc_i=82.67 cs/acc_c=83.44 os/recall_knw=73.81 os/recall_unk=89.85 total/acc_i=75.44 total/acc_c=70.90 total/h_score=78.66\n",
      "Loss: 1.9890950443194462\n",
      "Loss: 0.6309375772109398\n",
      "Loss: 0.44246255970918213\n",
      "Loss: 0.3666076959784214\n",
      "Loss: 0.33139933487543694\n",
      "Loss: 0.2910103323826423\n",
      "Loss: 0.2537862941622734\n",
      "Loss: 0.24743908299849585\n",
      "Loss: 0.2139931686566426\n",
      "Loss: 0.20813968494534493\n",
      "______\n",
      "Iteration t=8\n",
      "all:  cs/acc_i=83.01 cs/acc_c=83.56 os/recall_knw=73.90 os/recall_unk=89.79 total/acc_i=75.46 total/acc_c=70.94 total/h_score=78.67\n",
      "selected:  cs/acc_i=83.01 cs/acc_c=83.56 os/recall_knw=73.90 os/recall_unk=89.79 total/acc_i=75.46 total/acc_c=70.94 total/h_score=78.67\n",
      "Loss: 1.9840535602202782\n",
      "Loss: 0.6321405120079334\n",
      "Loss: 0.4369058213325647\n",
      "Loss: 0.35945368124888494\n",
      "Loss: 0.3197857608474218\n",
      "Loss: 0.29180247839826806\n",
      "Loss: 0.2679503071308136\n",
      "Loss: 0.23990577277082664\n",
      "Loss: 0.22500619322061538\n",
      "Loss: 0.20856362614494103\n",
      "______\n",
      "Iteration t=9\n",
      "all:  cs/acc_i=82.90 cs/acc_c=83.62 os/recall_knw=73.90 os/recall_unk=89.79 total/acc_i=75.46 total/acc_c=70.94 total/h_score=78.67\n",
      "selected:  cs/acc_i=82.90 cs/acc_c=83.62 os/recall_knw=73.90 os/recall_unk=89.79 total/acc_i=75.46 total/acc_c=70.94 total/h_score=78.67\n",
      "tensor(0)\n",
      "all:  cs/acc_i=82.90 cs/acc_c=83.62 os/recall_knw=73.90 os/recall_unk=89.79 total/acc_i=75.46 total/acc_c=70.94 total/h_score=78.67\n",
      "painting -> real lr= 0.001 seed= 2\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19]\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20]\n",
      "Loss: 2.3610493287444116\n",
      "Loss: 0.9946971230208874\n",
      "Loss: 0.642328466847539\n",
      "Loss: 0.5294779965033134\n",
      "Loss: 0.4527933873857061\n",
      "Loss: 0.4370209908423324\n",
      "Loss: 0.3751684485313793\n",
      "Loss: 0.35662761504451435\n",
      "Loss: 0.3317236299316088\n",
      "Loss: 0.3055882557295263\n",
      "tensor(True) tensor(True)\n",
      "______\n",
      "Iteration t=1\n",
      "all:  cs/acc_i=80.80 cs/acc_c=81.44 os/recall_knw=97.56 os/recall_unk=26.83 total/acc_i=63.85 total/acc_c=78.49 total/h_score=40.32\n",
      "selected:  cs/acc_i=88.12 cs/acc_c=87.97 os/recall_knw=86.88 os/recall_unk=98.82 total/acc_i=91.13 total/acc_c=86.33 total/h_score=91.80\n",
      "Loss: 2.273979458235955\n",
      "Loss: 0.8759699172751848\n",
      "Loss: 0.5868616008250288\n",
      "Loss: 0.47716043791336604\n",
      "Loss: 0.4187307356632957\n",
      "Loss: 0.3879745711767396\n",
      "Loss: 0.34644558324023733\n",
      "Loss: 0.31322245962571266\n",
      "Loss: 0.2949517879837243\n",
      "Loss: 0.2830631938264814\n",
      "______\n",
      "Iteration t=2\n",
      "all:  cs/acc_i=81.69 cs/acc_c=82.35 os/recall_knw=81.06 os/recall_unk=78.75 total/acc_i=75.28 total/acc_c=74.89 total/h_score=76.67\n",
      "selected:  cs/acc_i=77.18 cs/acc_c=79.53 os/recall_knw=62.68 os/recall_unk=98.40 total/acc_i=76.77 total/acc_c=66.07 total/h_score=77.89\n",
      "Loss: 2.175698549530723\n",
      "Loss: 0.7768189995939081\n",
      "Loss: 0.5304537352648648\n",
      "Loss: 0.44054005086421966\n",
      "Loss: 0.3846425194090063\n",
      "Loss: 0.3559030646085739\n",
      "Loss: 0.32516920217058876\n",
      "Loss: 0.31386324256658554\n",
      "Loss: 0.2681544302674857\n",
      "Loss: 0.24610966285521335\n",
      "______\n",
      "Iteration t=3\n",
      "all:  cs/acc_i=81.43 cs/acc_c=82.20 os/recall_knw=77.58 os/recall_unk=85.75 total/acc_i=75.98 total/acc_c=73.24 total/h_score=78.64\n",
      "selected:  cs/acc_i=79.73 cs/acc_c=81.58 os/recall_knw=67.73 os/recall_unk=96.60 total/acc_i=76.87 total/acc_c=69.09 total/h_score=79.62\n",
      "Loss: 2.0792918917262107\n",
      "Loss: 0.7167310852036134\n",
      "Loss: 0.48337161703728165\n",
      "Loss: 0.4004522910907407\n",
      "Loss: 0.3536705492960715\n",
      "Loss: 0.32284703670203074\n",
      "Loss: 0.30250942051003815\n",
      "Loss: 0.26694994129927085\n",
      "Loss: 0.2517142524694827\n",
      "Loss: 0.23991420258586724\n",
      "______\n",
      "Iteration t=4\n",
      "all:  cs/acc_i=82.44 cs/acc_c=83.09 os/recall_knw=76.29 os/recall_unk=86.97 total/acc_i=75.88 total/acc_c=72.60 total/h_score=78.71\n",
      "selected:  cs/acc_i=81.76 cs/acc_c=82.89 os/recall_knw=70.89 os/recall_unk=93.00 total/acc_i=76.23 total/acc_c=70.25 total/h_score=79.29\n",
      "Loss: 2.047579350035175\n",
      "Loss: 0.6664683374704099\n",
      "Loss: 0.4664322882403735\n",
      "Loss: 0.3830141953003952\n",
      "Loss: 0.34579751000197884\n",
      "Loss: 0.3086534799898372\n",
      "Loss: 0.28267202715030293\n",
      "Loss: 0.25345373087946105\n",
      "Loss: 0.23015864098481104\n",
      "Loss: 0.2107892474950918\n",
      "______\n",
      "Iteration t=5\n",
      "all:  cs/acc_i=82.12 cs/acc_c=82.94 os/recall_knw=75.65 os/recall_unk=88.13 total/acc_i=75.96 total/acc_c=72.28 total/h_score=78.94\n",
      "selected:  cs/acc_i=81.72 cs/acc_c=82.85 os/recall_knw=72.74 os/recall_unk=90.51 total/acc_i=75.87 total/acc_c=71.08 total/h_score=79.01\n",
      "Loss: 2.0056174168511043\n",
      "Loss: 0.6615305875974988\n",
      "Loss: 0.4494219122898011\n",
      "Loss: 0.3704527077693788\n",
      "Loss: 0.3239936702071674\n",
      "Loss: 0.2992414045428473\n",
      "Loss: 0.2761978871292538\n",
      "Loss: 0.24145164953337775\n",
      "Loss: 0.23254163511215695\n",
      "Loss: 0.2166645463733446\n",
      "______\n",
      "Iteration t=6\n",
      "all:  cs/acc_i=82.01 cs/acc_c=82.78 os/recall_knw=75.48 os/recall_unk=88.32 total/acc_i=75.96 total/acc_c=72.18 total/h_score=78.95\n",
      "selected:  cs/acc_i=82.02 cs/acc_c=82.89 os/recall_knw=74.39 os/recall_unk=89.23 total/acc_i=76.03 total/acc_c=71.90 total/h_score=79.10\n",
      "Loss: 2.0016886741384265\n",
      "Loss: 0.641363497858077\n",
      "Loss: 0.4367790215247925\n",
      "Loss: 0.3807367926965188\n",
      "Loss: 0.3179867579241286\n",
      "Loss: 0.2844747882855381\n",
      "Loss: 0.2754557863938919\n",
      "Loss: 0.2517260481998463\n",
      "Loss: 0.22260955399357868\n",
      "Loss: 0.1980524429757344\n",
      "______\n",
      "Iteration t=7\n",
      "all:  cs/acc_i=83.04 cs/acc_c=83.75 os/recall_knw=75.42 os/recall_unk=88.32 total/acc_i=75.94 total/acc_c=72.16 total/h_score=78.93\n",
      "selected:  cs/acc_i=83.14 cs/acc_c=83.84 os/recall_knw=75.31 os/recall_unk=88.49 total/acc_i=76.03 total/acc_c=72.21 total/h_score=79.03\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 1.9595082298331303\n",
      "Loss: 0.6235796283326747\n",
      "Loss: 0.44230036642573295\n",
      "Loss: 0.36822517829112683\n",
      "Loss: 0.31983880083495325\n",
      "Loss: 0.2871569537697218\n",
      "Loss: 0.25551834899578985\n",
      "Loss: 0.24829209445539965\n",
      "Loss: 0.23263389579040378\n",
      "Loss: 0.2091399874845776\n",
      "______\n",
      "Iteration t=8\n",
      "all:  cs/acc_i=82.72 cs/acc_c=83.36 os/recall_knw=75.42 os/recall_unk=88.32 total/acc_i=75.94 total/acc_c=72.16 total/h_score=78.93\n",
      "selected:  cs/acc_i=82.72 cs/acc_c=83.36 os/recall_knw=75.42 os/recall_unk=88.32 total/acc_i=75.94 total/acc_c=72.16 total/h_score=78.93\n",
      "Loss: 1.9777761765006112\n",
      "Loss: 0.625195791535988\n",
      "Loss: 0.43283868949042587\n",
      "Loss: 0.36994143309662253\n",
      "Loss: 0.3382800280275505\n",
      "Loss: 0.2748592424819746\n",
      "Loss: 0.2626979459054405\n",
      "Loss: 0.24351019656467365\n",
      "Loss: 0.22511848518852054\n",
      "Loss: 0.20359410309777937\n",
      "______\n",
      "Iteration t=9\n",
      "all:  cs/acc_i=82.58 cs/acc_c=83.34 os/recall_knw=75.42 os/recall_unk=88.32 total/acc_i=75.94 total/acc_c=72.16 total/h_score=78.93\n",
      "selected:  cs/acc_i=82.58 cs/acc_c=83.34 os/recall_knw=75.42 os/recall_unk=88.32 total/acc_i=75.94 total/acc_c=72.16 total/h_score=78.93\n",
      "tensor(0)\n",
      "all:  cs/acc_i=82.58 cs/acc_c=83.34 os/recall_knw=75.42 os/recall_unk=88.32 total/acc_i=75.94 total/acc_c=72.16 total/h_score=78.93\n",
      "painting -> real lr= 0.001 seed= 3\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19]\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20]\n",
      "Loss: 2.3620336219668387\n",
      "Loss: 1.001093160485228\n",
      "Loss: 0.6494201618557175\n",
      "Loss: 0.538291750413676\n",
      "Loss: 0.4614768961444497\n",
      "Loss: 0.4184263457854589\n",
      "Loss: 0.37511534712587796\n",
      "Loss: 0.34322857471803825\n",
      "Loss: 0.3212578445672989\n",
      "Loss: 0.3118107959938546\n",
      "tensor(True) tensor(True)\n",
      "______\n",
      "Iteration t=1\n",
      "all:  cs/acc_i=81.32 cs/acc_c=82.13 os/recall_knw=97.76 os/recall_unk=27.28 total/acc_i=64.22 total/acc_c=79.01 total/h_score=40.89\n",
      "selected:  cs/acc_i=89.89 cs/acc_c=89.47 os/recall_knw=87.87 os/recall_unk=99.53 total/acc_i=91.96 total/acc_c=87.20 total/h_score=92.61\n",
      "Loss: 2.2603661251622578\n",
      "Loss: 0.8580291831447172\n",
      "Loss: 0.5823016596394915\n",
      "Loss: 0.48742327839136124\n",
      "Loss: 0.42099562339311425\n",
      "Loss: 0.369160091692163\n",
      "Loss: 0.3521207076056983\n",
      "Loss: 0.31548450422263885\n",
      "Loss: 0.2927063155428384\n",
      "Loss: 0.27607706336434495\n",
      "______\n",
      "Iteration t=2\n",
      "all:  cs/acc_i=80.74 cs/acc_c=81.54 os/recall_knw=72.72 os/recall_unk=88.77 total/acc_i=74.29 total/acc_c=69.89 total/h_score=77.61\n",
      "selected:  cs/acc_i=74.50 cs/acc_c=78.03 os/recall_knw=53.91 os/recall_unk=98.79 total/acc_i=71.32 total/acc_c=58.58 total/h_score=71.94\n",
      "Loss: 2.1905142016844317\n",
      "Loss: 0.7694817230918191\n",
      "Loss: 0.5357002481005408\n",
      "Loss: 0.4497415750676935\n",
      "Loss: 0.39671263830228287\n",
      "Loss: 0.352178019231016\n",
      "Loss: 0.3225335754589601\n",
      "Loss: 0.2957318260723894\n",
      "Loss: 0.27384494891220873\n",
      "Loss: 0.25122014099901374\n",
      "______\n",
      "Iteration t=3\n",
      "all:  cs/acc_i=80.94 cs/acc_c=81.58 os/recall_knw=71.83 os/recall_unk=90.37 total/acc_i=74.43 total/acc_c=69.44 total/h_score=77.86\n",
      "selected:  cs/acc_i=78.29 cs/acc_c=80.18 os/recall_knw=62.28 os/recall_unk=97.51 total/acc_i=73.40 total/acc_c=64.02 total/h_score=76.06\n",
      "Loss: 2.114475825265662\n",
      "Loss: 0.6997092167196208\n",
      "Loss: 0.48978897587281384\n",
      "Loss: 0.4016839609264511\n",
      "Loss: 0.34680805503301426\n",
      "Loss: 0.3237972118930049\n",
      "Loss: 0.3059123980825486\n",
      "Loss: 0.26927175869756975\n",
      "Loss: 0.25932385683161757\n",
      "Loss: 0.23600846173063125\n",
      "______\n",
      "Iteration t=4\n",
      "all:  cs/acc_i=81.37 cs/acc_c=82.24 os/recall_knw=71.51 os/recall_unk=90.76 total/acc_i=74.41 total/acc_c=69.26 total/h_score=77.87\n",
      "selected:  cs/acc_i=80.30 cs/acc_c=81.92 os/recall_knw=66.52 os/recall_unk=94.33 total/acc_i=73.87 total/acc_c=66.72 total/h_score=77.20\n",
      "Loss: 2.062362417578697\n",
      "Loss: 0.6642494022258019\n",
      "Loss: 0.46813878716018636\n",
      "Loss: 0.3913841009826252\n",
      "Loss: 0.3502295511333566\n",
      "Loss: 0.3117311531432757\n",
      "Loss: 0.2845539997184747\n",
      "Loss: 0.2704993130418619\n",
      "Loss: 0.25274202825599595\n",
      "Loss: 0.23149986420512983\n",
      "______\n",
      "Iteration t=5\n",
      "all:  cs/acc_i=82.21 cs/acc_c=82.94 os/recall_knw=71.37 os/recall_unk=90.76 total/acc_i=74.35 total/acc_c=69.18 total/h_score=77.82\n",
      "selected:  cs/acc_i=81.88 cs/acc_c=82.86 os/recall_knw=69.14 os/recall_unk=92.06 total/acc_i=74.06 total/acc_c=68.14 total/h_score=77.52\n",
      "Loss: 2.029317862500017\n",
      "Loss: 0.6513623741868967\n",
      "Loss: 0.4583585021880488\n",
      "Loss: 0.3947413939113815\n",
      "Loss: 0.3518467419825423\n",
      "Loss: 0.29993298139196994\n",
      "Loss: 0.2746361211275521\n",
      "Loss: 0.2510164626799643\n",
      "Loss: 0.22856688610138223\n",
      "Loss: 0.21525579648086438\n",
      "______\n",
      "Iteration t=6\n",
      "all:  cs/acc_i=81.35 cs/acc_c=82.20 os/recall_knw=71.08 os/recall_unk=90.82 total/acc_i=74.21 total/acc_c=68.99 total/h_score=77.70\n",
      "selected:  cs/acc_i=81.43 cs/acc_c=82.41 os/recall_knw=70.31 os/recall_unk=91.47 total/acc_i=74.31 total/acc_c=68.87 total/h_score=77.84\n",
      "Loss: 1.9955620632606483\n",
      "Loss: 0.6515377059860049\n",
      "Loss: 0.45265377533135925\n",
      "Loss: 0.3702151928120439\n",
      "Loss: 0.34276922370465296\n",
      "Loss: 0.2886310950530775\n",
      "Loss: 0.27360147768455856\n",
      "Loss: 0.2458293466776047\n",
      "Loss: 0.23777197959756702\n",
      "Loss: 0.21402871031196988\n",
      "______\n",
      "Iteration t=7\n",
      "all:  cs/acc_i=82.12 cs/acc_c=82.97 os/recall_knw=70.88 os/recall_unk=90.82 total/acc_i=74.11 total/acc_c=68.87 total/h_score=77.62\n",
      "selected:  cs/acc_i=82.14 cs/acc_c=83.00 os/recall_knw=70.82 os/recall_unk=90.82 total/acc_i=74.12 total/acc_c=68.87 total/h_score=77.62\n",
      "Loss: 1.9908917960348158\n",
      "Loss: 0.6355220396013647\n",
      "Loss: 0.43584475942489886\n",
      "Loss: 0.3867654699217122\n",
      "Loss: 0.33433730986166593\n",
      "Loss: 0.2956775138241665\n",
      "Loss: 0.2729874677561525\n",
      "Loss: 0.24643266590956214\n",
      "Loss: 0.22879675192021506\n",
      "Loss: 0.21290558379294344\n",
      "______\n",
      "Iteration t=8\n",
      "all:  cs/acc_i=82.01 cs/acc_c=82.76 os/recall_knw=70.88 os/recall_unk=90.82 total/acc_i=74.11 total/acc_c=68.87 total/h_score=77.62\n",
      "selected:  cs/acc_i=82.01 cs/acc_c=82.76 os/recall_knw=70.88 os/recall_unk=90.82 total/acc_i=74.11 total/acc_c=68.87 total/h_score=77.62\n",
      "Loss: 2.00346795755012\n",
      "Loss: 0.6340320763001189\n",
      "Loss: 0.43703820038807356\n",
      "Loss: 0.36775137936679003\n",
      "Loss: 0.32615454076003064\n",
      "Loss: 0.29052683198099194\n",
      "Loss: 0.26003111307030524\n",
      "Loss: 0.2639117604382684\n",
      "Loss: 0.23164133188485914\n",
      "Loss: 0.2073567923843118\n",
      "______\n",
      "Iteration t=9\n",
      "all:  cs/acc_i=81.69 cs/acc_c=82.60 os/recall_knw=70.88 os/recall_unk=90.82 total/acc_i=74.11 total/acc_c=68.87 total/h_score=77.62\n",
      "selected:  cs/acc_i=81.69 cs/acc_c=82.60 os/recall_knw=70.88 os/recall_unk=90.82 total/acc_i=74.11 total/acc_c=68.87 total/h_score=77.62\n",
      "tensor(0)\n",
      "all:  cs/acc_i=81.69 cs/acc_c=82.60 os/recall_knw=70.88 os/recall_unk=90.82 total/acc_i=74.11 total/acc_c=68.87 total/h_score=77.62\n",
      "painting -> real lr= 0.001 seed= 4\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19]\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20]\n",
      "Loss: 2.366756667693456\n",
      "Loss: 0.980186677724123\n",
      "Loss: 0.6433948767681916\n",
      "Loss: 0.5235182826717695\n",
      "Loss: 0.4605739106734594\n",
      "Loss: 0.43246302163849276\n",
      "Loss: 0.388362485387673\n",
      "Loss: 0.35919235143810513\n",
      "Loss: 0.3300094258971512\n",
      "Loss: 0.31214696938792863\n",
      "tensor(True) tensor(True)\n",
      "______\n",
      "Iteration t=1\n",
      "all:  cs/acc_i=81.00 cs/acc_c=81.75 os/recall_knw=97.38 os/recall_unk=26.44 total/acc_i=63.63 total/acc_c=78.40 total/h_score=39.87\n",
      "selected:  cs/acc_i=89.36 cs/acc_c=88.72 os/recall_knw=86.17 os/recall_unk=99.28 total/acc_i=90.87 total/acc_c=85.36 total/h_score=91.39\n",
      "Loss: 2.2585333659667377\n",
      "Loss: 0.8552599186583083\n",
      "Loss: 0.577551983932192\n",
      "Loss: 0.49740536210610886\n",
      "Loss: 0.4282578719101211\n",
      "Loss: 0.36539127128992893\n",
      "Loss: 0.3406771028977494\n",
      "Loss: 0.31536719298293425\n",
      "Loss: 0.2994198424582796\n",
      "Loss: 0.27352161252105883\n",
      "______\n",
      "Iteration t=2\n",
      "all:  cs/acc_i=81.60 cs/acc_c=82.28 os/recall_knw=82.44 os/recall_unk=76.06 total/acc_i=74.63 total/acc_c=74.95 total/h_score=75.47\n",
      "selected:  cs/acc_i=78.71 cs/acc_c=80.78 os/recall_knw=64.56 os/recall_unk=98.67 total/acc_i=77.85 total/acc_c=67.39 total/h_score=78.97\n",
      "Loss: 2.181051605831493\n",
      "Loss: 0.7706869117780165\n",
      "Loss: 0.5241129136085511\n",
      "Loss: 0.44738301439718764\n",
      "Loss: 0.39321881939064374\n",
      "Loss: 0.3515187526291067\n",
      "Loss: 0.32254455504092305\n",
      "Loss: 0.30276534621011125\n",
      "Loss: 0.27975782028653406\n",
      "Loss: 0.2640665482391011\n",
      "______\n",
      "Iteration t=3\n",
      "all:  cs/acc_i=81.63 cs/acc_c=82.46 os/recall_knw=77.95 os/recall_unk=85.11 total/acc_i=75.60 total/acc_c=72.97 total/h_score=78.22\n",
      "selected:  cs/acc_i=80.57 cs/acc_c=82.06 os/recall_knw=68.16 os/recall_unk=96.93 total/acc_i=77.02 total/acc_c=68.67 total/h_score=79.41\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 2.0860943458592933\n",
      "Loss: 0.6989761393631685\n",
      "Loss: 0.4861299055326514\n",
      "Loss: 0.40676181804096334\n",
      "Loss: 0.3539774357357123\n",
      "Loss: 0.3235860504337138\n",
      "Loss: 0.3082870275748468\n",
      "Loss: 0.2638639495310726\n",
      "Loss: 0.24634545637173863\n",
      "Loss: 0.2221377177017744\n",
      "______\n",
      "Iteration t=4\n",
      "all:  cs/acc_i=82.35 cs/acc_c=82.99 os/recall_knw=76.80 os/recall_unk=86.78 total/acc_i=75.68 total/acc_c=72.46 total/h_score=78.55\n",
      "selected:  cs/acc_i=82.15 cs/acc_c=83.04 os/recall_knw=71.58 os/recall_unk=92.29 total/acc_i=76.19 total/acc_c=70.30 total/h_score=79.10\n",
      "Loss: 2.0438158253893404\n",
      "Loss: 0.6966252423070541\n",
      "Loss: 0.4587748277847464\n",
      "Loss: 0.39380078551629466\n",
      "Loss: 0.3458880626320451\n",
      "Loss: 0.29939682985555854\n",
      "Loss: 0.28953712181179064\n",
      "Loss: 0.26304131209947385\n",
      "Loss: 0.23048451268614698\n",
      "Loss: 0.22160718079158848\n",
      "______\n",
      "Iteration t=5\n",
      "all:  cs/acc_i=82.75 cs/acc_c=83.39 os/recall_knw=76.29 os/recall_unk=87.36 total/acc_i=75.68 total/acc_c=72.21 total/h_score=78.61\n",
      "selected:  cs/acc_i=82.81 cs/acc_c=83.78 os/recall_knw=73.68 os/recall_unk=89.78 total/acc_i=75.88 total/acc_c=71.59 total/h_score=79.09\n",
      "Loss: 2.006593739760787\n",
      "Loss: 0.64832101832805\n",
      "Loss: 0.44990472180610197\n",
      "Loss: 0.37486412669958\n",
      "Loss: 0.3297440313061329\n",
      "Loss: 0.29605677230313\n",
      "Loss: 0.2674681560521246\n",
      "Loss: 0.2464224196006823\n",
      "Loss: 0.22929697745841007\n",
      "Loss: 0.20019373807715315\n",
      "______\n",
      "Iteration t=6\n",
      "all:  cs/acc_i=82.12 cs/acc_c=82.93 os/recall_knw=76.17 os/recall_unk=87.55 total/acc_i=75.70 total/acc_c=72.17 total/h_score=78.66\n",
      "selected:  cs/acc_i=82.36 cs/acc_c=83.29 os/recall_knw=75.33 os/recall_unk=88.69 total/acc_i=76.02 total/acc_c=72.22 total/h_score=79.11\n",
      "Loss: 2.0089610209803523\n",
      "Loss: 0.6113908813783416\n",
      "Loss: 0.44607833179610745\n",
      "Loss: 0.3640998083362241\n",
      "Loss: 0.31335637555170204\n",
      "Loss: 0.28860385101978425\n",
      "Loss: 0.26397972234329325\n",
      "Loss: 0.24877977090669268\n",
      "Loss: 0.22809321393063406\n",
      "Loss: 0.21268348338910276\n",
      "______\n",
      "Iteration t=7\n",
      "all:  cs/acc_i=82.49 cs/acc_c=83.20 os/recall_knw=76.17 os/recall_unk=87.55 total/acc_i=75.70 total/acc_c=72.17 total/h_score=78.66\n",
      "selected:  cs/acc_i=82.61 cs/acc_c=83.38 os/recall_knw=75.97 os/recall_unk=87.83 total/acc_i=75.81 total/acc_c=72.26 total/h_score=78.82\n",
      "Loss: 1.9787998141312018\n",
      "Loss: 0.6292636960563136\n",
      "Loss: 0.4139640232002953\n",
      "Loss: 0.3682883585598774\n",
      "Loss: 0.3295761821337226\n",
      "Loss: 0.28769429670873936\n",
      "Loss: 0.2659106501491695\n",
      "Loss: 0.2446028905261944\n",
      "Loss: 0.22299765835220858\n",
      "Loss: 0.20059871119333478\n",
      "______\n",
      "Iteration t=8\n",
      "all:  cs/acc_i=83.21 cs/acc_c=83.94 os/recall_knw=76.14 os/recall_unk=87.55 total/acc_i=75.68 total/acc_c=72.15 total/h_score=78.64\n",
      "selected:  cs/acc_i=83.21 cs/acc_c=83.94 os/recall_knw=76.14 os/recall_unk=87.55 total/acc_i=75.68 total/acc_c=72.15 total/h_score=78.64\n",
      "Loss: 1.986133492101652\n",
      "Loss: 0.6211118088033062\n",
      "Loss: 0.4293393678623492\n",
      "Loss: 0.3521077005832391\n",
      "Loss: 0.32089947152735615\n",
      "Loss: 0.2992586929317122\n",
      "Loss: 0.2685384783995731\n",
      "Loss: 0.23858977387741345\n",
      "Loss: 0.21274452118661627\n",
      "Loss: 0.21227088277327252\n",
      "______\n",
      "Iteration t=9\n",
      "all:  cs/acc_i=82.38 cs/acc_c=83.09 os/recall_knw=76.14 os/recall_unk=87.55 total/acc_i=75.68 total/acc_c=72.15 total/h_score=78.64\n",
      "selected:  cs/acc_i=82.38 cs/acc_c=83.09 os/recall_knw=76.14 os/recall_unk=87.55 total/acc_i=75.68 total/acc_c=72.15 total/h_score=78.64\n",
      "tensor(0)\n",
      "all:  cs/acc_i=82.38 cs/acc_c=83.09 os/recall_knw=76.14 os/recall_unk=87.55 total/acc_i=75.68 total/acc_c=72.15 total/h_score=78.64\n",
      "painting -> real lr= 0.001 seed= 0\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19]\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20]\n",
      "Loss: 2.360679017504056\n",
      "Loss: 0.9985385504861672\n",
      "Loss: 0.6565840107699236\n",
      "Loss: 0.5403248131275177\n",
      "Loss: 0.4795884711047014\n",
      "Loss: 0.4137326162929336\n",
      "Loss: 0.3913413834137221\n",
      "Loss: 0.34880416753391424\n",
      "Loss: 0.3327427526935935\n",
      "Loss: 0.319451335662355\n",
      "tensor(True) tensor(True)\n",
      "______\n",
      "Iteration t=1\n",
      "all:  cs/acc_i=80.11 cs/acc_c=80.90 os/recall_knw=97.61 os/recall_unk=26.96 total/acc_i=63.29 total/acc_c=77.80 total/h_score=40.37\n",
      "selected:  cs/acc_i=89.40 cs/acc_c=88.42 os/recall_knw=87.25 os/recall_unk=99.53 total/acc_i=91.61 total/acc_c=85.87 total/h_score=91.80\n",
      "Loss: 2.2576485668966013\n",
      "Loss: 0.8743105864571047\n",
      "Loss: 0.589797146445097\n",
      "Loss: 0.47954622557921\n",
      "Loss: 0.42774249653714574\n",
      "Loss: 0.37181409979744473\n",
      "Loss: 0.35071214369332143\n",
      "Loss: 0.3136457991172639\n",
      "Loss: 0.28846714726483175\n",
      "Loss: 0.2694208819650171\n",
      "______\n",
      "Iteration t=2\n",
      "all:  cs/acc_i=81.43 cs/acc_c=81.95 os/recall_knw=79.68 os/recall_unk=82.03 total/acc_i=75.56 total/acc_c=73.84 total/h_score=77.49\n",
      "selected:  cs/acc_i=76.83 cs/acc_c=79.06 os/recall_knw=61.00 os/recall_unk=98.38 total/acc_i=76.03 total/acc_c=64.70 total/h_score=76.83\n",
      "Loss: 2.184648446819999\n",
      "Loss: 0.7785413057153875\n",
      "Loss: 0.5177461011843247\n",
      "Loss: 0.4403261356462132\n",
      "Loss: 0.39400100694461304\n",
      "Loss: 0.3501107627424327\n",
      "Loss: 0.32465376127849926\n",
      "Loss: 0.2950055941126563\n",
      "Loss: 0.27512038577686654\n",
      "Loss: 0.25100453701886266\n",
      "______\n",
      "Iteration t=3\n",
      "all:  cs/acc_i=81.86 cs/acc_c=82.57 os/recall_knw=74.42 os/recall_unk=87.42 total/acc_i=74.93 total/acc_c=71.00 total/h_score=77.86\n",
      "selected:  cs/acc_i=79.46 cs/acc_c=81.35 os/recall_knw=64.44 os/recall_unk=95.92 total/acc_i=74.31 total/acc_c=65.65 total/h_score=76.87\n",
      "Loss: 2.10026176355473\n",
      "Loss: 0.6917119360949895\n",
      "Loss: 0.5098112124490412\n",
      "Loss: 0.40642112143950104\n",
      "Loss: 0.36598733218055063\n",
      "Loss: 0.3324372038653452\n",
      "Loss: 0.29589690504059807\n",
      "Loss: 0.2575101558221121\n",
      "Loss: 0.24597493083254524\n",
      "Loss: 0.23764787600311923\n",
      "______\n",
      "Iteration t=4\n",
      "all:  cs/acc_i=82.35 cs/acc_c=82.94 os/recall_knw=74.25 os/recall_unk=87.74 total/acc_i=74.93 total/acc_c=70.89 total/h_score=77.91\n",
      "selected:  cs/acc_i=81.61 cs/acc_c=82.89 os/recall_knw=68.43 os/recall_unk=93.95 total/acc_i=75.12 total/acc_c=68.67 total/h_score=78.50\n",
      "Loss: 2.066618289097701\n",
      "Loss: 0.6927153268466295\n",
      "Loss: 0.47181634167240005\n",
      "Loss: 0.393667280821517\n",
      "Loss: 0.34043742878602284\n",
      "Loss: 0.3058894255472095\n",
      "Loss: 0.2889886271860143\n",
      "Loss: 0.25959603085179533\n",
      "Loss: 0.2423545880114088\n",
      "Loss: 0.22452381701998586\n",
      "______\n",
      "Iteration t=5\n",
      "all:  cs/acc_i=81.69 cs/acc_c=82.43 os/recall_knw=73.81 os/recall_unk=88.13 total/acc_i=74.79 total/acc_c=70.58 total/h_score=77.84\n",
      "selected:  cs/acc_i=81.06 cs/acc_c=82.13 os/recall_knw=71.15 os/recall_unk=89.56 total/acc_i=74.29 total/acc_c=69.25 total/h_score=77.46\n",
      "Loss: 2.0071856939603414\n",
      "Loss: 0.6419557342926662\n",
      "Loss: 0.4460541617539194\n",
      "Loss: 0.3858680985040135\n",
      "Loss: 0.3346034772812374\n",
      "Loss: 0.3056022946914983\n",
      "Loss: 0.2782039201094045\n",
      "Loss: 0.25836533570573444\n",
      "Loss: 0.22890296928466314\n",
      "Loss: 0.2082981629504098\n",
      "______\n",
      "Iteration t=6\n",
      "all:  cs/acc_i=82.47 cs/acc_c=83.30 os/recall_knw=73.73 os/recall_unk=88.19 total/acc_i=74.79 total/acc_c=70.56 total/h_score=77.85\n",
      "selected:  cs/acc_i=82.61 cs/acc_c=83.64 os/recall_knw=72.88 os/recall_unk=89.05 total/acc_i=74.94 total/acc_c=70.59 total/h_score=78.17\n",
      "Loss: 2.0040632658493447\n",
      "Loss: 0.6355594565039095\n",
      "Loss: 0.44187995365687777\n",
      "Loss: 0.35856059741992385\n",
      "Loss: 0.31490874676878405\n",
      "Loss: 0.29328854025706\n",
      "Loss: 0.2743976689319803\n",
      "Loss: 0.25323638975944207\n",
      "Loss: 0.2308166411051654\n",
      "Loss: 0.20787578493773196\n",
      "______\n",
      "Iteration t=7\n",
      "all:  cs/acc_i=81.81 cs/acc_c=82.54 os/recall_knw=73.67 os/recall_unk=88.25 total/acc_i=74.79 total/acc_c=70.54 total/h_score=77.86\n",
      "selected:  cs/acc_i=81.92 cs/acc_c=82.67 os/recall_knw=73.50 os/recall_unk=88.54 total/acc_i=74.91 total/acc_c=70.62 total/h_score=78.01\n",
      "Loss: 2.0008805474868185\n",
      "Loss: 0.6391875641162579\n",
      "Loss: 0.4376655149918336\n",
      "Loss: 0.35874464232188\n",
      "Loss: 0.3202676200178953\n",
      "Loss: 0.2867445167669883\n",
      "Loss: 0.26477994547440453\n",
      "Loss: 0.2412779785348819\n",
      "Loss: 0.22444420656332603\n",
      "Loss: 0.20314249413517804\n",
      "______\n",
      "Iteration t=8\n",
      "all:  cs/acc_i=82.24 cs/acc_c=83.02 os/recall_knw=73.67 os/recall_unk=88.25 total/acc_i=74.79 total/acc_c=70.54 total/h_score=77.86\n",
      "selected:  cs/acc_i=82.24 cs/acc_c=83.02 os/recall_knw=73.67 os/recall_unk=88.25 total/acc_i=74.79 total/acc_c=70.54 total/h_score=77.86\n",
      "Loss: 1.9880904617485093\n",
      "Loss: 0.6217909876280036\n",
      "Loss: 0.44181870902242837\n",
      "Loss: 0.36764547050547747\n",
      "Loss: 0.32411782150985274\n",
      "Loss: 0.2966336988346891\n",
      "Loss: 0.25871875476480627\n",
      "Loss: 0.24746591774918184\n",
      "Loss: 0.20772912875503485\n",
      "Loss: 0.20565990943095983\n",
      "______\n",
      "Iteration t=9\n",
      "all:  cs/acc_i=82.06 cs/acc_c=82.89 os/recall_knw=73.67 os/recall_unk=88.25 total/acc_i=74.79 total/acc_c=70.54 total/h_score=77.86\n",
      "selected:  cs/acc_i=82.06 cs/acc_c=82.89 os/recall_knw=73.67 os/recall_unk=88.25 total/acc_i=74.79 total/acc_c=70.54 total/h_score=77.86\n",
      "tensor(0)\n",
      "all:  cs/acc_i=82.06 cs/acc_c=82.89 os/recall_knw=73.67 os/recall_unk=88.25 total/acc_i=74.79 total/acc_c=70.54 total/h_score=77.86\n",
      "painting -> real lr= 0.001 seed= 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19]\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20]\n",
      "Loss: 2.3806192855040234\n",
      "Loss: 0.9958789778252443\n",
      "Loss: 0.6367719622949759\n",
      "Loss: 0.54017712790519\n",
      "Loss: 0.46835831347852946\n",
      "Loss: 0.4002790883804361\n",
      "Loss: 0.39407932149867214\n",
      "Loss: 0.3556086798819403\n",
      "Loss: 0.34151303259034954\n",
      "Loss: 0.3034198956719289\n",
      "tensor(True) tensor(True)\n",
      "______\n",
      "Iteration t=1\n",
      "all:  cs/acc_i=80.86 cs/acc_c=81.53 os/recall_knw=97.70 os/recall_unk=27.15 total/acc_i=63.93 total/acc_c=78.52 total/h_score=40.68\n",
      "selected:  cs/acc_i=89.80 cs/acc_c=89.37 os/recall_knw=87.64 os/recall_unk=99.76 total/acc_i=92.25 total/acc_c=87.35 total/h_score=92.79\n",
      "Loss: 2.2693232649056485\n",
      "Loss: 0.8559323293987171\n",
      "Loss: 0.5807656134630359\n",
      "Loss: 0.4907674971939057\n",
      "Loss: 0.41778235241424205\n",
      "Loss: 0.3862880067538845\n",
      "Loss: 0.3481538320292336\n",
      "Loss: 0.31197676129003826\n",
      "Loss: 0.2938187969054363\n",
      "Loss: 0.26598392437074997\n",
      "______\n",
      "Iteration t=2\n",
      "all:  cs/acc_i=81.20 cs/acc_c=81.95 os/recall_knw=79.30 os/recall_unk=82.99 total/acc_i=75.68 total/acc_c=73.90 total/h_score=77.93\n",
      "selected:  cs/acc_i=76.36 cs/acc_c=78.82 os/recall_knw=60.78 os/recall_unk=99.08 total/acc_i=76.06 total/acc_c=64.48 total/h_score=76.84\n",
      "Loss: 2.164037729176608\n",
      "Loss: 0.7745353828776966\n",
      "Loss: 0.5282675115628676\n",
      "Loss: 0.4375445833260363\n",
      "Loss: 0.3925095414031636\n",
      "Loss: 0.3528748816522685\n",
      "Loss: 0.31133527293801305\n",
      "Loss: 0.29706735062328254\n",
      "Loss: 0.2693235032666813\n",
      "Loss: 0.2623698887770826\n",
      "______\n",
      "Iteration t=3\n",
      "all:  cs/acc_i=81.63 cs/acc_c=82.28 os/recall_knw=75.94 os/recall_unk=87.68 total/acc_i=75.60 total/acc_c=71.99 total/h_score=78.59\n",
      "selected:  cs/acc_i=80.07 cs/acc_c=81.10 os/recall_knw=66.24 os/recall_unk=97.36 total/acc_i=76.07 total/acc_c=66.95 total/h_score=78.27\n",
      "Loss: 2.1085602338999916\n",
      "Loss: 0.7212879348495235\n",
      "Loss: 0.5006996265114987\n",
      "Loss: 0.41615555708436935\n",
      "Loss: 0.3643954550362613\n",
      "Loss: 0.32723683675062165\n",
      "Loss: 0.3034272258718536\n",
      "Loss: 0.27883192036964305\n",
      "Loss: 0.26195230021154225\n",
      "Loss: 0.24547928016734857\n",
      "______\n",
      "Iteration t=4\n",
      "all:  cs/acc_i=82.44 cs/acc_c=83.04 os/recall_knw=75.28 os/recall_unk=88.77 total/acc_i=75.64 total/acc_c=71.58 total/h_score=78.72\n",
      "selected:  cs/acc_i=82.01 cs/acc_c=82.72 os/recall_knw=70.13 os/recall_unk=93.32 total/acc_i=75.74 total/acc_c=69.03 total/h_score=78.55\n",
      "Loss: 2.0583735273944006\n",
      "Loss: 0.663885355190514\n",
      "Loss: 0.46484142225357444\n",
      "Loss: 0.3907802777450069\n",
      "Loss: 0.3484780740698958\n",
      "Loss: 0.31660834108205405\n",
      "Loss: 0.28822187037249797\n",
      "Loss: 0.2598581490125142\n",
      "Loss: 0.2528797435312489\n",
      "Loss: 0.21990719152724042\n",
      "______\n",
      "Iteration t=5\n",
      "all:  cs/acc_i=82.81 cs/acc_c=83.34 os/recall_knw=74.79 os/recall_unk=89.28 total/acc_i=75.58 total/acc_c=71.26 total/h_score=78.70\n",
      "selected:  cs/acc_i=82.97 cs/acc_c=83.64 os/recall_knw=72.14 os/recall_unk=91.27 total/acc_i=75.73 total/acc_c=70.43 total/h_score=78.84\n",
      "Loss: 2.0245353237030996\n",
      "Loss: 0.6511650872608972\n",
      "Loss: 0.45595178462210156\n",
      "Loss: 0.3796406228864004\n",
      "Loss: 0.32436888735918773\n",
      "Loss: 0.2998950153589249\n",
      "Loss: 0.2720714455440877\n",
      "Loss: 0.25217019873006\n",
      "Loss: 0.22175660833479865\n",
      "Loss: 0.21865467153607854\n",
      "______\n",
      "Iteration t=6\n",
      "all:  cs/acc_i=82.35 cs/acc_c=82.91 os/recall_knw=74.65 os/recall_unk=89.47 total/acc_i=75.60 total/acc_c=71.23 total/h_score=78.75\n",
      "selected:  cs/acc_i=82.57 cs/acc_c=83.19 os/recall_knw=73.54 os/recall_unk=90.46 total/acc_i=75.81 total/acc_c=71.10 total/h_score=79.01\n",
      "Loss: 2.0074649859811657\n",
      "Loss: 0.6523380158846253\n",
      "Loss: 0.4415560578724306\n",
      "Loss: 0.3657845825049736\n",
      "Loss: 0.3354591971431566\n",
      "Loss: 0.29408643217148067\n",
      "Loss: 0.268864351223191\n",
      "Loss: 0.24114194905785757\n",
      "Loss: 0.23173187322612865\n",
      "Loss: 0.20773648318611201\n",
      "______\n",
      "Iteration t=7\n",
      "all:  cs/acc_i=82.58 cs/acc_c=83.36 os/recall_knw=74.62 os/recall_unk=89.47 total/acc_i=75.58 total/acc_c=71.21 total/h_score=78.74\n",
      "selected:  cs/acc_i=82.66 cs/acc_c=83.45 os/recall_knw=74.49 os/recall_unk=89.70 total/acc_i=75.67 total/acc_c=71.24 total/h_score=78.84\n",
      "Loss: 1.9915932666338407\n",
      "Loss: 0.6377969581347246\n",
      "Loss: 0.4263901909956565\n",
      "Loss: 0.3606377332714888\n",
      "Loss: 0.3300910575573261\n",
      "Loss: 0.2951267052155275\n",
      "Loss: 0.2674909456418111\n",
      "Loss: 0.246742647427779\n",
      "Loss: 0.22103085836538902\n",
      "Loss: 0.20164912027808335\n",
      "______\n",
      "Iteration t=8\n",
      "all:  cs/acc_i=82.81 cs/acc_c=83.44 os/recall_knw=74.62 os/recall_unk=89.47 total/acc_i=75.58 total/acc_c=71.21 total/h_score=78.74\n",
      "selected:  cs/acc_i=82.81 cs/acc_c=83.44 os/recall_knw=74.62 os/recall_unk=89.47 total/acc_i=75.58 total/acc_c=71.21 total/h_score=78.74\n",
      "Loss: 1.980882871370374\n",
      "Loss: 0.6297919920251414\n",
      "Loss: 0.44347688576286554\n",
      "Loss: 0.36762009951874525\n",
      "Loss: 0.3277701627623084\n",
      "Loss: 0.2812152641933937\n",
      "Loss: 0.26373885994765656\n",
      "Loss: 0.24401721880525534\n",
      "Loss: 0.23042401392584197\n",
      "Loss: 0.2019517249627713\n",
      "______\n",
      "Iteration t=9\n",
      "all:  cs/acc_i=82.64 cs/acc_c=83.39 os/recall_knw=74.62 os/recall_unk=89.47 total/acc_i=75.58 total/acc_c=71.21 total/h_score=78.74\n",
      "selected:  cs/acc_i=82.64 cs/acc_c=83.39 os/recall_knw=74.62 os/recall_unk=89.47 total/acc_i=75.58 total/acc_c=71.21 total/h_score=78.74\n",
      "tensor(0)\n",
      "all:  cs/acc_i=82.64 cs/acc_c=83.39 os/recall_knw=74.62 os/recall_unk=89.47 total/acc_i=75.58 total/acc_c=71.21 total/h_score=78.74\n",
      "painting -> real lr= 0.001 seed= 2\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19]\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20]\n",
      "Loss: 2.3611330171426137\n",
      "Loss: 0.9950064559777577\n",
      "Loss: 0.6422484093656142\n",
      "Loss: 0.5290479092548291\n",
      "Loss: 0.4526846507564187\n",
      "Loss: 0.4363577970303595\n",
      "Loss: 0.374863207153976\n",
      "Loss: 0.35588118496040505\n",
      "Loss: 0.3314067713605861\n",
      "Loss: 0.30509329459940393\n",
      "tensor(True) tensor(True)\n",
      "______\n",
      "Iteration t=1\n",
      "all:  cs/acc_i=81.00 cs/acc_c=81.67 os/recall_knw=97.73 os/recall_unk=27.21 total/acc_i=64.11 total/acc_c=78.69 total/h_score=40.77\n",
      "selected:  cs/acc_i=89.11 cs/acc_c=88.28 os/recall_knw=87.71 os/recall_unk=98.83 total/acc_i=91.79 total/acc_c=86.84 total/h_score=92.11\n",
      "Loss: 2.280264904794767\n",
      "Loss: 0.881726847831593\n",
      "Loss: 0.5820992080740226\n",
      "Loss: 0.49510621914798897\n",
      "Loss: 0.416939118978127\n",
      "Loss: 0.39710863281128017\n",
      "Loss: 0.3557269717025202\n",
      "Loss: 0.32049311966050503\n",
      "Loss: 0.30424849494078826\n",
      "Loss: 0.2905986452576264\n",
      "______\n",
      "Iteration t=2\n",
      "all:  cs/acc_i=81.60 cs/acc_c=82.34 os/recall_knw=79.02 os/recall_unk=82.09 total/acc_i=75.16 total/acc_c=73.52 total/h_score=77.33\n",
      "selected:  cs/acc_i=77.41 cs/acc_c=80.05 os/recall_knw=60.46 os/recall_unk=98.99 total/acc_i=75.72 total/acc_c=64.25 total/h_score=76.63\n",
      "Loss: 2.1796941614151\n",
      "Loss: 0.7740693610364741\n",
      "Loss: 0.5194757504354823\n",
      "Loss: 0.43056467825716194\n",
      "Loss: 0.38388460202650593\n",
      "Loss: 0.34775434214960443\n",
      "Loss: 0.3258874260566451\n",
      "Loss: 0.29507404869252984\n",
      "Loss: 0.24975552653724498\n",
      "Loss: 0.25871315505016934\n",
      "______\n",
      "Iteration t=3\n",
      "all:  cs/acc_i=81.83 cs/acc_c=82.46 os/recall_knw=74.68 os/recall_unk=89.47 total/acc_i=75.80 total/acc_c=71.55 total/h_score=78.95\n",
      "selected:  cs/acc_i=79.90 cs/acc_c=81.34 os/recall_knw=65.00 os/recall_unk=97.35 total/acc_i=75.51 total/acc_c=66.45 total/h_score=77.89\n",
      "Loss: 2.097430769303074\n",
      "Loss: 0.7206064687199789\n",
      "Loss: 0.4894293154755684\n",
      "Loss: 0.39926416983139024\n",
      "Loss: 0.3686963968387205\n",
      "Loss: 0.32782809694029696\n",
      "Loss: 0.297421229977722\n",
      "Loss: 0.26751542764983766\n",
      "Loss: 0.2605232189167036\n",
      "Loss: 0.23723186097069554\n",
      "______\n",
      "Iteration t=4\n",
      "all:  cs/acc_i=81.92 cs/acc_c=82.61 os/recall_knw=74.19 os/recall_unk=89.67 total/acc_i=75.64 total/acc_c=71.28 total/h_score=78.85\n",
      "selected:  cs/acc_i=80.95 cs/acc_c=81.78 os/recall_knw=69.07 os/recall_unk=94.20 total/acc_i=75.47 total/acc_c=68.43 total/h_score=78.40\n",
      "Loss: 2.0478519078160895\n",
      "Loss: 0.6721482330658397\n",
      "Loss: 0.471933000742412\n",
      "Loss: 0.3872687242558745\n",
      "Loss: 0.35923494508520504\n",
      "Loss: 0.31286519909979865\n",
      "Loss: 0.2888502154193941\n",
      "Loss: 0.2600319537227271\n",
      "Loss: 0.23668001777813083\n",
      "Loss: 0.21646097943675321\n",
      "______\n",
      "Iteration t=5\n",
      "all:  cs/acc_i=82.09 cs/acc_c=82.72 os/recall_knw=73.99 os/recall_unk=89.67 total/acc_i=75.56 total/acc_c=71.17 total/h_score=78.78\n",
      "selected:  cs/acc_i=81.92 cs/acc_c=82.62 os/recall_knw=71.64 os/recall_unk=91.43 total/acc_i=75.52 total/acc_c=70.18 total/h_score=78.73\n",
      "Loss: 2.0113967055366153\n",
      "Loss: 0.6519164447746579\n",
      "Loss: 0.4424573669830958\n",
      "Loss: 0.37398066558535137\n",
      "Loss: 0.3385657763433835\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.30268338294256303\n",
      "Loss: 0.2815531529840969\n",
      "Loss: 0.2541848875877876\n",
      "Loss: 0.2260850307369043\n",
      "Loss: 0.21621329204903708\n",
      "______\n",
      "Iteration t=6\n",
      "all:  cs/acc_i=82.55 cs/acc_c=83.19 os/recall_knw=73.79 os/recall_unk=89.79 total/acc_i=75.54 total/acc_c=71.10 total/h_score=78.77\n",
      "selected:  cs/acc_i=82.45 cs/acc_c=83.14 os/recall_knw=73.05 os/recall_unk=90.61 total/acc_i=75.55 total/acc_c=70.79 total/h_score=78.85\n",
      "Loss: 1.9903202079097677\n",
      "Loss: 0.6364269946117579\n",
      "Loss: 0.44766409274028696\n",
      "Loss: 0.3652924461903409\n",
      "Loss: 0.32750512717395835\n",
      "Loss: 0.2984060742979094\n",
      "Loss: 0.28038261734782166\n",
      "Loss: 0.24381843898792444\n",
      "Loss: 0.2385783216435902\n",
      "Loss: 0.21824574877178263\n",
      "______\n",
      "Iteration t=7\n",
      "all:  cs/acc_i=82.87 cs/acc_c=83.49 os/recall_knw=73.79 os/recall_unk=89.99 total/acc_i=75.60 total/acc_c=71.11 total/h_score=78.85\n",
      "selected:  cs/acc_i=82.85 cs/acc_c=83.49 os/recall_knw=73.72 os/recall_unk=90.04 total/acc_i=75.59 total/acc_c=71.08 total/h_score=78.85\n",
      "Loss: 1.9719721161402188\n",
      "Loss: 0.6238274479370851\n",
      "Loss: 0.45373017361530893\n",
      "Loss: 0.37611511065409736\n",
      "Loss: 0.3323191464635042\n",
      "Loss: 0.27904628192002956\n",
      "Loss: 0.2593157618894027\n",
      "Loss: 0.25686280425924524\n",
      "Loss: 0.22912650923316297\n",
      "Loss: 0.20627278564067988\n",
      "______\n",
      "Iteration t=8\n",
      "all:  cs/acc_i=83.30 cs/acc_c=83.90 os/recall_knw=73.79 os/recall_unk=89.99 total/acc_i=75.60 total/acc_c=71.11 total/h_score=78.85\n",
      "selected:  cs/acc_i=83.30 cs/acc_c=83.90 os/recall_knw=73.79 os/recall_unk=89.99 total/acc_i=75.60 total/acc_c=71.11 total/h_score=78.85\n",
      "Loss: 1.958264255615381\n",
      "Loss: 0.6311630439758301\n",
      "Loss: 0.43765117906607115\n",
      "Loss: 0.3682392823696137\n",
      "Loss: 0.3254235472816687\n",
      "Loss: 0.29885278133245613\n",
      "Loss: 0.26745462214717497\n",
      "Loss: 0.24353006541728972\n",
      "Loss: 0.22542789194446344\n",
      "Loss: 0.20604100860655308\n",
      "______\n",
      "Iteration t=9\n",
      "all:  cs/acc_i=82.87 cs/acc_c=83.67 os/recall_knw=73.79 os/recall_unk=89.99 total/acc_i=75.60 total/acc_c=71.11 total/h_score=78.85\n",
      "selected:  cs/acc_i=82.87 cs/acc_c=83.67 os/recall_knw=73.79 os/recall_unk=89.99 total/acc_i=75.60 total/acc_c=71.11 total/h_score=78.85\n",
      "tensor(0)\n",
      "all:  cs/acc_i=82.87 cs/acc_c=83.67 os/recall_knw=73.79 os/recall_unk=89.99 total/acc_i=75.60 total/acc_c=71.11 total/h_score=78.85\n",
      "painting -> real lr= 0.001 seed= 3\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19]\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20]\n",
      "Loss: 2.3623363345861437\n",
      "Loss: 1.000534466157357\n",
      "Loss: 0.649861513885359\n",
      "Loss: 0.5388863313943147\n",
      "Loss: 0.4622022588426868\n",
      "Loss: 0.4195046691844861\n",
      "Loss: 0.37521396232768894\n",
      "Loss: 0.34376814557860297\n",
      "Loss: 0.32209490360692145\n",
      "Loss: 0.312490579392761\n",
      "tensor(True) tensor(True)\n",
      "______\n",
      "Iteration t=1\n",
      "all:  cs/acc_i=81.32 cs/acc_c=82.13 os/recall_knw=97.79 os/recall_unk=27.34 total/acc_i=64.32 total/acc_c=79.13 total/h_score=40.98\n",
      "selected:  cs/acc_i=89.39 cs/acc_c=89.13 os/recall_knw=87.99 os/recall_unk=99.53 total/acc_i=92.05 total/acc_c=87.46 total/h_score=92.76\n",
      "Loss: 2.2607392349908517\n",
      "Loss: 0.8642547648082408\n",
      "Loss: 0.5895498787709909\n",
      "Loss: 0.46451839313719623\n",
      "Loss: 0.42363462279471314\n",
      "Loss: 0.37457365086374356\n",
      "Loss: 0.35437816404557043\n",
      "Loss: 0.32151202603366025\n",
      "Loss: 0.29101636893180916\n",
      "Loss: 0.27859188269737156\n",
      "______\n",
      "Iteration t=2\n",
      "all:  cs/acc_i=81.37 cs/acc_c=82.14 os/recall_knw=74.94 os/recall_unk=88.51 total/acc_i=75.28 total/acc_c=71.27 total/h_score=78.43\n",
      "selected:  cs/acc_i=76.39 cs/acc_c=79.25 os/recall_knw=56.20 os/recall_unk=99.21 total/acc_i=73.41 total/acc_c=60.68 total/h_score=73.80\n",
      "Loss: 2.1742175802317534\n",
      "Loss: 0.7650575378808109\n",
      "Loss: 0.5352468106421557\n",
      "Loss: 0.42662858892570843\n",
      "Loss: 0.3861343812671575\n",
      "Loss: 0.3370781983299689\n",
      "Loss: 0.31714009396054527\n",
      "Loss: 0.293970602479848\n",
      "Loss: 0.28269253221425145\n",
      "Loss: 0.2610585876621983\n",
      "______\n",
      "Iteration t=3\n",
      "all:  cs/acc_i=81.58 cs/acc_c=82.28 os/recall_knw=73.18 os/recall_unk=89.67 total/acc_i=74.95 total/acc_c=70.32 total/h_score=78.21\n",
      "selected:  cs/acc_i=79.24 cs/acc_c=80.75 os/recall_knw=63.53 os/recall_unk=97.35 total/acc_i=74.23 total/acc_c=64.66 total/h_score=76.52\n",
      "Loss: 2.107151916378165\n",
      "Loss: 0.7027311691478507\n",
      "Loss: 0.4871965843214564\n",
      "Loss: 0.41848943517734744\n",
      "Loss: 0.37344789818847834\n",
      "Loss: 0.32471401823608026\n",
      "Loss: 0.29527314201201477\n",
      "Loss: 0.2684903969248272\n",
      "Loss: 0.25499599878612444\n",
      "Loss: 0.22627776461870294\n",
      "______\n",
      "Iteration t=4\n",
      "all:  cs/acc_i=81.95 cs/acc_c=82.73 os/recall_knw=72.87 os/recall_unk=90.05 total/acc_i=75.00 total/acc_c=70.24 total/h_score=78.29\n",
      "selected:  cs/acc_i=81.11 cs/acc_c=82.62 os/recall_knw=67.57 os/recall_unk=93.91 total/acc_i=74.64 total/acc_c=67.80 total/h_score=77.86\n",
      "Loss: 2.055872936782084\n",
      "Loss: 0.673417456938248\n",
      "Loss: 0.474141294969932\n",
      "Loss: 0.40025304549520735\n",
      "Loss: 0.331938215041239\n",
      "Loss: 0.3121704200503269\n",
      "Loss: 0.27920213601502936\n",
      "Loss: 0.2626626243765809\n",
      "Loss: 0.24059067145725221\n",
      "Loss: 0.22682880052659465\n",
      "______\n",
      "Iteration t=5\n",
      "all:  cs/acc_i=82.41 cs/acc_c=82.96 os/recall_knw=72.69 os/recall_unk=90.24 total/acc_i=74.95 total/acc_c=70.05 total/h_score=78.23\n",
      "selected:  cs/acc_i=81.86 cs/acc_c=82.77 os/recall_knw=70.08 os/recall_unk=91.60 total/acc_i=74.46 total/acc_c=68.78 total/h_score=77.82\n",
      "Loss: 2.0561802653839796\n",
      "Loss: 0.6626354598770507\n",
      "Loss: 0.4474040160354334\n",
      "Loss: 0.3894172254414223\n",
      "Loss: 0.34819557382085453\n",
      "Loss: 0.31976264258162285\n",
      "Loss: 0.257507086835635\n",
      "Loss: 0.2549328934579802\n",
      "Loss: 0.2433518041579868\n",
      "Loss: 0.2187463956507155\n",
      "______\n",
      "Iteration t=6\n",
      "all:  cs/acc_i=81.66 cs/acc_c=82.47 os/recall_knw=72.61 os/recall_unk=90.37 total/acc_i=74.95 total/acc_c=70.00 total/h_score=78.24\n",
      "selected:  cs/acc_i=81.77 cs/acc_c=82.71 os/recall_knw=71.70 os/recall_unk=91.07 total/acc_i=75.05 total/acc_c=69.94 total/h_score=78.44\n",
      "Loss: 1.9902690781280399\n",
      "Loss: 0.6413545872084796\n",
      "Loss: 0.443940876564011\n",
      "Loss: 0.3791186532471329\n",
      "Loss: 0.3334652447607368\n",
      "Loss: 0.29919793460285293\n",
      "Loss: 0.2705126204993576\n",
      "Loss: 0.2538078345125541\n",
      "Loss: 0.23226594252046198\n",
      "Loss: 0.21357450240757317\n",
      "______\n",
      "Iteration t=7\n",
      "all:  cs/acc_i=82.52 cs/acc_c=83.08 os/recall_knw=72.55 os/recall_unk=90.37 total/acc_i=74.93 total/acc_c=69.98 total/h_score=78.23\n",
      "selected:  cs/acc_i=82.54 cs/acc_c=83.13 os/recall_knw=72.45 os/recall_unk=90.43 total/acc_i=74.94 total/acc_c=70.00 total/h_score=78.26\n",
      "Loss: 1.9973249088499938\n",
      "Loss: 0.6354199192103218\n",
      "Loss: 0.44173229252775387\n",
      "Loss: 0.3653779078517167\n",
      "Loss: 0.3186493645142476\n",
      "Loss: 0.2945395740954315\n",
      "Loss: 0.2624622765847773\n",
      "Loss: 0.24626029698010937\n",
      "Loss: 0.22544087003628166\n",
      "Loss: 0.20669536608568287\n",
      "______\n",
      "Iteration t=8\n",
      "all:  cs/acc_i=82.64 cs/acc_c=83.21 os/recall_knw=72.55 os/recall_unk=90.37 total/acc_i=74.93 total/acc_c=69.98 total/h_score=78.23\n",
      "selected:  cs/acc_i=82.64 cs/acc_c=83.21 os/recall_knw=72.55 os/recall_unk=90.37 total/acc_i=74.93 total/acc_c=69.98 total/h_score=78.23\n",
      "Loss: 1.9945299145607018\n",
      "Loss: 0.6380098282183656\n",
      "Loss: 0.45008612790897534\n",
      "Loss: 0.359106662749506\n",
      "Loss: 0.3364443853266837\n",
      "Loss: 0.29304059935105103\n",
      "Loss: 0.2653690999368027\n",
      "Loss: 0.24480659337051144\n",
      "Loss: 0.23011468490441517\n",
      "Loss: 0.20183274760011918\n",
      "______\n",
      "Iteration t=9\n",
      "all:  cs/acc_i=82.15 cs/acc_c=82.86 os/recall_knw=72.55 os/recall_unk=90.37 total/acc_i=74.93 total/acc_c=69.98 total/h_score=78.23\n",
      "selected:  cs/acc_i=82.15 cs/acc_c=82.86 os/recall_knw=72.55 os/recall_unk=90.37 total/acc_i=74.93 total/acc_c=69.98 total/h_score=78.23\n",
      "tensor(0)\n",
      "all:  cs/acc_i=82.15 cs/acc_c=82.86 os/recall_knw=72.55 os/recall_unk=90.37 total/acc_i=74.93 total/acc_c=69.98 total/h_score=78.23\n",
      "painting -> real lr= 0.001 seed= 4\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19]\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20]\n",
      "Loss: 2.367851060132186\n",
      "Loss: 0.9810416468729576\n",
      "Loss: 0.6432139036556085\n",
      "Loss: 0.5239030584692955\n",
      "Loss: 0.46087267187734443\n",
      "Loss: 0.4325261810794473\n",
      "Loss: 0.3891145346996685\n",
      "Loss: 0.35954597902794677\n",
      "Loss: 0.3303254338291784\n",
      "Loss: 0.3120728936046362\n",
      "tensor(True) tensor(True)\n",
      "______\n",
      "Iteration t=1\n",
      "all:  cs/acc_i=80.83 cs/acc_c=81.49 os/recall_knw=97.61 os/recall_unk=26.96 total/acc_i=63.85 total/acc_c=78.44 total/h_score=40.45\n",
      "selected:  cs/acc_i=88.91 cs/acc_c=88.25 os/recall_knw=87.21 os/recall_unk=99.29 total/acc_i=91.51 total/acc_c=86.13 total/h_score=91.87\n",
      "Loss: 2.2693454119586205\n",
      "Loss: 0.8595821899037028\n",
      "Loss: 0.5586608671980311\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.47335879545110143\n",
      "Loss: 0.43102145489565163\n",
      "Loss: 0.39235795774432114\n",
      "Loss: 0.3491099202759968\n",
      "Loss: 0.3086849511709324\n",
      "Loss: 0.30498752104797106\n",
      "Loss: 0.268520855019952\n",
      "______\n",
      "Iteration t=2\n",
      "all:  cs/acc_i=81.17 cs/acc_c=81.86 os/recall_knw=80.63 os/recall_unk=81.51 total/acc_i=75.50 total/acc_c=74.16 total/h_score=77.46\n",
      "selected:  cs/acc_i=77.37 cs/acc_c=79.80 os/recall_knw=62.24 os/recall_unk=98.68 total/acc_i=76.82 total/acc_c=65.71 total/h_score=77.69\n",
      "Loss: 2.1808573803034697\n",
      "Loss: 0.7663436303355478\n",
      "Loss: 0.5179198632727969\n",
      "Loss: 0.4480027115345001\n",
      "Loss: 0.3936388910087672\n",
      "Loss: 0.3529508858377283\n",
      "Loss: 0.32865249465812335\n",
      "Loss: 0.28819787217812104\n",
      "Loss: 0.268919949314811\n",
      "Loss: 0.26283024061809884\n",
      "______\n",
      "Iteration t=3\n",
      "all:  cs/acc_i=81.69 cs/acc_c=82.30 os/recall_knw=75.54 os/recall_unk=89.28 total/acc_i=75.82 total/acc_c=71.68 total/h_score=78.97\n",
      "selected:  cs/acc_i=80.10 cs/acc_c=81.54 os/recall_knw=65.73 os/recall_unk=97.20 total/acc_i=75.78 total/acc_c=66.89 total/h_score=78.17\n",
      "Loss: 2.0981223328064567\n",
      "Loss: 0.7099582520249772\n",
      "Loss: 0.4854859042249314\n",
      "Loss: 0.4054520881339295\n",
      "Loss: 0.3668644711477299\n",
      "Loss: 0.32546986841073594\n",
      "Loss: 0.29834371774572216\n",
      "Loss: 0.26716188346482306\n",
      "Loss: 0.2595884132466904\n",
      "Loss: 0.23305902848249838\n",
      "______\n",
      "Iteration t=4\n",
      "all:  cs/acc_i=82.04 cs/acc_c=82.67 os/recall_knw=73.58 os/recall_unk=89.79 total/acc_i=75.22 total/acc_c=70.74 total/h_score=78.53\n",
      "selected:  cs/acc_i=81.11 cs/acc_c=82.35 os/recall_knw=68.38 os/recall_unk=94.85 total/acc_i=75.14 total/acc_c=68.27 total/h_score=78.49\n",
      "Loss: 2.0528897219582607\n",
      "Loss: 0.6857662240141317\n",
      "Loss: 0.455875588580966\n",
      "Loss: 0.4011641182985745\n",
      "Loss: 0.34190642353343337\n",
      "Loss: 0.3148758218035494\n",
      "Loss: 0.27733665735362784\n",
      "Loss: 0.26060230527563316\n",
      "Loss: 0.24080498958937824\n",
      "Loss: 0.21210023445861512\n",
      "______\n",
      "Iteration t=5\n",
      "all:  cs/acc_i=81.83 cs/acc_c=82.55 os/recall_knw=73.38 os/recall_unk=90.05 total/acc_i=75.24 total/acc_c=70.66 total/h_score=78.57\n",
      "selected:  cs/acc_i=81.37 cs/acc_c=82.34 os/recall_knw=70.85 os/recall_unk=91.94 total/acc_i=75.02 total/acc_c=69.46 total/h_score=78.40\n",
      "Loss: 2.017821145285467\n",
      "Loss: 0.6504902727664656\n",
      "Loss: 0.4636332381303143\n",
      "Loss: 0.3932243072587973\n",
      "Loss: 0.34086588698967246\n",
      "Loss: 0.3054663615574123\n",
      "Loss: 0.27508337874036687\n",
      "Loss: 0.25373162895108864\n",
      "Loss: 0.2353581370323137\n",
      "Loss: 0.20766858449265077\n",
      "______\n",
      "Iteration t=6\n",
      "all:  cs/acc_i=82.09 cs/acc_c=82.81 os/recall_knw=73.21 os/recall_unk=90.37 total/acc_i=75.26 total/acc_c=70.59 total/h_score=78.64\n",
      "selected:  cs/acc_i=82.00 cs/acc_c=82.82 os/recall_knw=72.32 os/recall_unk=91.13 total/acc_i=75.24 total/acc_c=70.26 total/h_score=78.67\n",
      "Loss: 2.0060174545273184\n",
      "Loss: 0.6511402707081289\n",
      "Loss: 0.4372015042230487\n",
      "Loss: 0.3709105231333524\n",
      "Loss: 0.3225387073820457\n",
      "Loss: 0.29206438292749226\n",
      "Loss: 0.277664097037632\n",
      "Loss: 0.2485630090930499\n",
      "Loss: 0.23495903582079336\n",
      "Loss: 0.2141963382717222\n",
      "______\n",
      "Iteration t=7\n",
      "all:  cs/acc_i=82.44 cs/acc_c=83.18 os/recall_knw=73.18 os/recall_unk=90.44 total/acc_i=75.26 total/acc_c=70.57 total/h_score=78.65\n",
      "selected:  cs/acc_i=82.47 cs/acc_c=83.21 os/recall_knw=73.10 os/recall_unk=90.55 total/acc_i=75.30 total/acc_c=70.56 total/h_score=78.68\n",
      "Loss: 1.9848309070975692\n",
      "Loss: 0.6316519101828705\n",
      "Loss: 0.4452079413113771\n",
      "Loss: 0.38068687546722313\n",
      "Loss: 0.32889284793701434\n",
      "Loss: 0.29385395352671173\n",
      "Loss: 0.27377469271973326\n",
      "Loss: 0.2394837940019774\n",
      "Loss: 0.22867343096453466\n",
      "Loss: 0.20725171505990955\n",
      "______\n",
      "Iteration t=8\n",
      "all:  cs/acc_i=82.24 cs/acc_c=83.01 os/recall_knw=73.18 os/recall_unk=90.44 total/acc_i=75.26 total/acc_c=70.57 total/h_score=78.65\n",
      "selected:  cs/acc_i=82.24 cs/acc_c=83.01 os/recall_knw=73.18 os/recall_unk=90.44 total/acc_i=75.26 total/acc_c=70.57 total/h_score=78.65\n",
      "Loss: 1.982064242532224\n",
      "Loss: 0.6265074395471149\n",
      "Loss: 0.44502444797551927\n",
      "Loss: 0.37326880429445963\n",
      "Loss: 0.32861239543575566\n",
      "Loss: 0.29084212372056495\n",
      "Loss: 0.2668924074574017\n",
      "Loss: 0.24084439525311743\n",
      "Loss: 0.23717755762239298\n",
      "Loss: 0.20321644750642187\n",
      "______\n",
      "Iteration t=9\n",
      "all:  cs/acc_i=82.38 cs/acc_c=83.18 os/recall_knw=73.18 os/recall_unk=90.44 total/acc_i=75.26 total/acc_c=70.57 total/h_score=78.65\n",
      "selected:  cs/acc_i=82.38 cs/acc_c=83.18 os/recall_knw=73.18 os/recall_unk=90.44 total/acc_i=75.26 total/acc_c=70.57 total/h_score=78.65\n",
      "tensor(0)\n",
      "all:  cs/acc_i=82.38 cs/acc_c=83.18 os/recall_knw=73.18 os/recall_unk=90.44 total/acc_i=75.26 total/acc_c=70.57 total/h_score=78.65\n",
      "painting -> real lr= 0.001 seed= 0\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19]\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20]\n",
      "Loss: 2.361319314936797\n",
      "Loss: 1.0006608278801044\n",
      "Loss: 0.6566268607974053\n",
      "Loss: 0.5398766341308753\n",
      "Loss: 0.47893851237992446\n",
      "Loss: 0.4130050664146741\n",
      "Loss: 0.39031797445689637\n",
      "Loss: 0.3484986615677675\n",
      "Loss: 0.3315985562590261\n",
      "Loss: 0.3186928364137808\n",
      "tensor(True) tensor(True)\n",
      "______\n",
      "Iteration t=1\n",
      "all:  cs/acc_i=80.08 cs/acc_c=80.88 os/recall_knw=89.11 os/recall_unk=56.48 total/acc_i=70.26 total/acc_c=76.36 total/h_score=65.29\n",
      "selected:  cs/acc_i=72.86 cs/acc_c=76.10 os/recall_knw=59.98 os/recall_unk=99.77 total/acc_i=78.90 total/acc_c=65.20 total/h_score=77.58\n",
      "Loss: 2.252502088860948\n",
      "Loss: 0.8651535245337227\n",
      "Loss: 0.5816754221685173\n",
      "Loss: 0.4808697052473246\n",
      "Loss: 0.4299851411650347\n",
      "Loss: 0.37109982638165007\n",
      "Loss: 0.3484302878148796\n",
      "Loss: 0.32152690596936284\n",
      "Loss: 0.29331113346094306\n",
      "Loss: 0.2784234841260337\n",
      "______\n",
      "Iteration t=2\n",
      "all:  cs/acc_i=81.52 cs/acc_c=82.20 os/recall_knw=72.69 os/recall_unk=90.37 total/acc_i=74.79 total/acc_c=69.65 total/h_score=78.00\n",
      "selected:  cs/acc_i=75.96 cs/acc_c=79.08 os/recall_knw=53.86 os/recall_unk=98.74 total/acc_i=71.59 total/acc_c=58.37 total/h_score=71.75\n",
      "Loss: 2.182749247984453\n",
      "Loss: 0.786714859008789\n",
      "Loss: 0.5306582705541091\n",
      "Loss: 0.4460312697562304\n",
      "Loss: 0.37956686388362537\n",
      "Loss: 0.355434795320034\n",
      "Loss: 0.33292455703020096\n",
      "Loss: 0.30425717042251066\n",
      "Loss: 0.2778073525157842\n",
      "Loss: 0.24280566323887218\n",
      "______\n",
      "Iteration t=3\n",
      "all:  cs/acc_i=81.03 cs/acc_c=81.80 os/recall_knw=70.71 os/recall_unk=91.72 total/acc_i=74.21 total/acc_c=68.34 total/h_score=77.55\n",
      "selected:  cs/acc_i=78.24 cs/acc_c=80.29 os/recall_knw=61.09 os/recall_unk=96.62 total/acc_i=72.43 total/acc_c=62.40 total/h_score=74.55\n",
      "Loss: 2.0987947536088347\n",
      "Loss: 0.7191235245912755\n",
      "Loss: 0.488516803101166\n",
      "Loss: 0.4120449867496376\n",
      "Loss: 0.3730682798779707\n",
      "Loss: 0.33209057336615533\n",
      "Loss: 0.28207898821003247\n",
      "Loss: 0.2656193216974588\n",
      "Loss: 0.25031102807149036\n",
      "Loss: 0.23991009521320514\n",
      "______\n",
      "Iteration t=4\n",
      "all:  cs/acc_i=81.92 cs/acc_c=82.49 os/recall_knw=70.48 os/recall_unk=91.85 total/acc_i=74.17 total/acc_c=68.22 total/h_score=77.50\n",
      "selected:  cs/acc_i=81.04 cs/acc_c=81.89 os/recall_knw=65.83 os/recall_unk=95.15 total/acc_i=73.66 total/acc_c=65.60 total/h_score=76.61\n",
      "Loss: 2.0756748395138667\n",
      "Loss: 0.6823217064436329\n",
      "Loss: 0.47344971154081195\n",
      "Loss: 0.3954661856405437\n",
      "Loss: 0.3519650846474657\n",
      "Loss: 0.3137115651594573\n",
      "Loss: 0.28678385619270175\n",
      "Loss: 0.2594647752733803\n",
      "Loss: 0.24739568187291489\n",
      "Loss: 0.22732103580461913\n",
      "______\n",
      "Iteration t=5\n",
      "all:  cs/acc_i=81.89 cs/acc_c=82.75 os/recall_knw=70.25 os/recall_unk=91.98 total/acc_i=74.15 total/acc_c=68.15 total/h_score=77.50\n",
      "selected:  cs/acc_i=81.46 cs/acc_c=82.52 os/recall_knw=68.07 os/recall_unk=92.81 total/acc_i=73.69 total/acc_c=66.97 total/h_score=76.92\n",
      "Loss: 2.016592333714167\n",
      "Loss: 0.6691491194069386\n",
      "Loss: 0.4540330662081639\n",
      "Loss: 0.37494628532574725\n",
      "Loss: 0.35017199124185705\n",
      "Loss: 0.2987463207533344\n",
      "Loss: 0.2844028877189908\n",
      "Loss: 0.2629491074774892\n",
      "Loss: 0.228876406685091\n",
      "Loss: 0.21020318578498867\n",
      "______\n",
      "Iteration t=6\n",
      "all:  cs/acc_i=81.89 cs/acc_c=82.76 os/recall_knw=70.05 os/recall_unk=92.17 total/acc_i=74.07 total/acc_c=68.00 total/h_score=77.46\n",
      "selected:  cs/acc_i=81.90 cs/acc_c=82.90 os/recall_knw=69.23 os/recall_unk=92.47 total/acc_i=74.00 total/acc_c=67.78 total/h_score=77.39\n",
      "Loss: 2.0177763662879777\n",
      "Loss: 0.6492282981376166\n",
      "Loss: 0.44340412967400594\n",
      "Loss: 0.3768376229736331\n",
      "Loss: 0.3238987248590692\n",
      "Loss: 0.3123168805937286\n",
      "Loss: 0.28800636210276126\n",
      "Loss: 0.25136964406218815\n",
      "Loss: 0.22904265446335736\n",
      "Loss: 0.21154737461957646\n",
      "______\n",
      "Iteration t=7\n",
      "all:  cs/acc_i=82.21 cs/acc_c=82.86 os/recall_knw=70.05 os/recall_unk=92.17 total/acc_i=74.07 total/acc_c=68.00 total/h_score=77.46\n",
      "selected:  cs/acc_i=82.21 cs/acc_c=82.90 os/recall_knw=69.91 os/recall_unk=92.17 total/acc_i=74.05 total/acc_c=67.98 total/h_score=77.44\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 2.02089511526042\n",
      "Loss: 0.6473462043511082\n",
      "Loss: 0.4529288886436101\n",
      "Loss: 0.37428521680233995\n",
      "Loss: 0.32622414028569824\n",
      "Loss: 0.29343433988785667\n",
      "Loss: 0.26435413048091727\n",
      "Loss: 0.24330184628550536\n",
      "Loss: 0.24118504384795325\n",
      "Loss: 0.20740285391998142\n",
      "______\n",
      "Iteration t=8\n",
      "all:  cs/acc_i=82.64 cs/acc_c=83.31 os/recall_knw=70.05 os/recall_unk=92.17 total/acc_i=74.07 total/acc_c=68.00 total/h_score=77.46\n",
      "selected:  cs/acc_i=82.64 cs/acc_c=83.31 os/recall_knw=70.05 os/recall_unk=92.17 total/acc_i=74.07 total/acc_c=68.00 total/h_score=77.46\n",
      "Loss: 1.9909640664234758\n",
      "Loss: 0.6501075240783394\n",
      "Loss: 0.4548382345121354\n",
      "Loss: 0.36259075193665924\n",
      "Loss: 0.3235450717387721\n",
      "Loss: 0.2917285438859835\n",
      "Loss: 0.27132347694132475\n",
      "Loss: 0.2367100297473371\n",
      "Loss: 0.233826733159367\n",
      "Loss: 0.20080478836316615\n",
      "______\n",
      "Iteration t=9\n",
      "all:  cs/acc_i=82.35 cs/acc_c=83.09 os/recall_knw=70.05 os/recall_unk=92.17 total/acc_i=74.07 total/acc_c=68.00 total/h_score=77.46\n",
      "selected:  cs/acc_i=82.35 cs/acc_c=83.09 os/recall_knw=70.05 os/recall_unk=92.17 total/acc_i=74.07 total/acc_c=68.00 total/h_score=77.46\n",
      "tensor(0)\n",
      "all:  cs/acc_i=82.35 cs/acc_c=83.09 os/recall_knw=70.05 os/recall_unk=92.17 total/acc_i=74.07 total/acc_c=68.00 total/h_score=77.46\n",
      "painting -> real lr= 0.001 seed= 1\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19]\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20]\n",
      "Loss: 2.3821720237533253\n",
      "Loss: 0.9974462160219749\n",
      "Loss: 0.636954752355814\n",
      "Loss: 0.5404549308121205\n",
      "Loss: 0.4685191916922728\n",
      "Loss: 0.40054394900798795\n",
      "Loss: 0.39458035454154017\n",
      "Loss: 0.3561428834373752\n",
      "Loss: 0.3424665742553771\n",
      "Loss: 0.3033297411787013\n",
      "tensor(True) tensor(True)\n",
      "______\n",
      "Iteration t=1\n",
      "all:  cs/acc_i=80.91 cs/acc_c=81.58 os/recall_knw=89.36 os/recall_unk=57.06 total/acc_i=71.33 total/acc_c=77.48 total/h_score=66.08\n",
      "selected:  cs/acc_i=72.23 cs/acc_c=76.13 os/recall_knw=60.64 os/recall_unk=99.89 total/acc_i=79.62 total/acc_c=66.76 total/h_score=78.83\n",
      "Loss: 2.268252443897632\n",
      "Loss: 0.8672556979942692\n",
      "Loss: 0.5794734504333762\n",
      "Loss: 0.46444556925647945\n",
      "Loss: 0.41834287143261856\n",
      "Loss: 0.36051438491820365\n",
      "Loss: 0.3490636692663958\n",
      "Loss: 0.30798066109996436\n",
      "Loss: 0.2975193243906942\n",
      "Loss: 0.27456294826065847\n",
      "______\n",
      "Iteration t=2\n",
      "all:  cs/acc_i=81.37 cs/acc_c=82.06 os/recall_knw=73.58 os/recall_unk=88.96 total/acc_i=74.85 total/acc_c=70.39 total/h_score=78.01\n",
      "selected:  cs/acc_i=75.91 cs/acc_c=78.84 os/recall_knw=54.91 os/recall_unk=99.21 total/acc_i=72.37 total/acc_c=59.32 total/h_score=72.66\n",
      "Loss: 2.166588012738661\n",
      "Loss: 0.7658396273309535\n",
      "Loss: 0.5289381894198331\n",
      "Loss: 0.42893881050023164\n",
      "Loss: 0.3861118992350318\n",
      "Loss: 0.3509583686698567\n",
      "Loss: 0.31757530328902334\n",
      "Loss: 0.29916704446077347\n",
      "Loss: 0.2728687692501328\n",
      "Loss: 0.2512624961815097\n",
      "______\n",
      "Iteration t=3\n",
      "all:  cs/acc_i=81.46 cs/acc_c=82.07 os/recall_knw=72.06 os/recall_unk=90.50 total/acc_i=74.61 total/acc_c=69.43 total/h_score=77.90\n",
      "selected:  cs/acc_i=79.15 cs/acc_c=80.58 os/recall_knw=62.60 os/recall_unk=97.51 total/acc_i=73.70 total/acc_c=63.75 total/h_score=75.85\n",
      "Loss: 2.116481279061265\n",
      "Loss: 0.7131613304149614\n",
      "Loss: 0.491204463047524\n",
      "Loss: 0.4124654354400014\n",
      "Loss: 0.3637866490609842\n",
      "Loss: 0.3217992532539041\n",
      "Loss: 0.30843720960188403\n",
      "Loss: 0.28183774430661984\n",
      "Loss: 0.2510738052070549\n",
      "Loss: 0.2439944719104734\n",
      "______\n",
      "Iteration t=4\n",
      "all:  cs/acc_i=82.49 cs/acc_c=83.15 os/recall_knw=71.49 os/recall_unk=90.82 total/acc_i=74.47 total/acc_c=69.10 total/h_score=77.78\n",
      "selected:  cs/acc_i=81.83 cs/acc_c=83.00 os/recall_knw=66.50 os/recall_unk=94.78 total/acc_i=74.18 total/acc_c=66.70 total/h_score=77.32\n",
      "Loss: 2.042452274772682\n",
      "Loss: 0.6675355407458387\n",
      "Loss: 0.46162808255145427\n",
      "Loss: 0.3951426889306228\n",
      "Loss: 0.34586933157161664\n",
      "Loss: 0.30352188837959576\n",
      "Loss: 0.28100236419490293\n",
      "Loss: 0.2583041338397092\n",
      "Loss: 0.23481804291766725\n",
      "Loss: 0.23102745389271723\n",
      "______\n",
      "Iteration t=5\n",
      "all:  cs/acc_i=82.15 cs/acc_c=83.07 os/recall_knw=71.43 os/recall_unk=91.01 total/acc_i=74.51 total/acc_c=69.08 total/h_score=77.83\n",
      "selected:  cs/acc_i=81.76 cs/acc_c=82.97 os/recall_knw=69.37 os/recall_unk=91.90 total/acc_i=74.10 total/acc_c=68.11 total/h_score=77.44\n",
      "Loss: 2.0295363546936374\n",
      "Loss: 0.6437149798604334\n",
      "Loss: 0.44985981321164\n",
      "Loss: 0.3783679303422475\n",
      "Loss: 0.3219532695877704\n",
      "Loss: 0.30144277423810045\n",
      "Loss: 0.2846030653068784\n",
      "Loss: 0.2472657360207693\n",
      "Loss: 0.22982493445134847\n",
      "Loss: 0.2204697472369595\n",
      "______\n",
      "Iteration t=6\n",
      "all:  cs/acc_i=82.29 cs/acc_c=83.04 os/recall_knw=71.43 os/recall_unk=91.01 total/acc_i=74.51 total/acc_c=69.08 total/h_score=77.83\n",
      "selected:  cs/acc_i=82.36 cs/acc_c=83.23 os/recall_knw=70.68 os/recall_unk=91.48 total/acc_i=74.53 total/acc_c=68.99 total/h_score=77.92\n",
      "Loss: 1.9893385239155688\n",
      "Loss: 0.6384699520739642\n",
      "Loss: 0.44543559246676095\n",
      "Loss: 0.37244241500162406\n",
      "Loss: 0.32336478790145684\n",
      "Loss: 0.3070197605694349\n",
      "Loss: 0.26346890204425516\n",
      "Loss: 0.25852202269070573\n",
      "Loss: 0.23800263771069088\n",
      "Loss: 0.21607393181669673\n",
      "______\n",
      "Iteration t=7\n",
      "all:  cs/acc_i=82.04 cs/acc_c=82.95 os/recall_knw=71.40 os/recall_unk=91.01 total/acc_i=74.49 total/acc_c=69.06 total/h_score=77.82\n",
      "selected:  cs/acc_i=82.04 cs/acc_c=82.98 os/recall_knw=71.32 os/recall_unk=91.01 total/acc_i=74.48 total/acc_c=69.05 total/h_score=77.81\n",
      "Loss: 1.9937156605424349\n",
      "Loss: 0.6423266769751258\n",
      "Loss: 0.4451574749365356\n",
      "Loss: 0.3627727496096436\n",
      "Loss: 0.33311622050700723\n",
      "Loss: 0.2895860525299303\n",
      "Loss: 0.26990845436172456\n",
      "Loss: 0.2591892543324032\n",
      "Loss: 0.23670181303475954\n",
      "Loss: 0.20850167469763609\n",
      "______\n",
      "Iteration t=8\n",
      "all:  cs/acc_i=82.24 cs/acc_c=83.02 os/recall_knw=71.40 os/recall_unk=91.01 total/acc_i=74.49 total/acc_c=69.06 total/h_score=77.82\n",
      "selected:  cs/acc_i=82.24 cs/acc_c=83.02 os/recall_knw=71.40 os/recall_unk=91.01 total/acc_i=74.49 total/acc_c=69.06 total/h_score=77.82\n",
      "Loss: 1.9830386599768763\n",
      "Loss: 0.6299836800335357\n",
      "Loss: 0.45782049495426025\n",
      "Loss: 0.3621284475098856\n",
      "Loss: 0.32369315677455496\n",
      "Loss: 0.29132434549909203\n",
      "Loss: 0.2635889118710845\n",
      "Loss: 0.24119889842612402\n",
      "Loss: 0.2286933582993398\n",
      "Loss: 0.20792264111849093\n",
      "______\n",
      "Iteration t=9\n",
      "all:  cs/acc_i=82.09 cs/acc_c=82.86 os/recall_knw=71.40 os/recall_unk=91.01 total/acc_i=74.49 total/acc_c=69.06 total/h_score=77.82\n",
      "selected:  cs/acc_i=82.09 cs/acc_c=82.86 os/recall_knw=71.40 os/recall_unk=91.01 total/acc_i=74.49 total/acc_c=69.06 total/h_score=77.82\n",
      "tensor(0)\n",
      "all:  cs/acc_i=82.09 cs/acc_c=82.86 os/recall_knw=71.40 os/recall_unk=91.01 total/acc_i=74.49 total/acc_c=69.06 total/h_score=77.82\n",
      "painting -> real lr= 0.001 seed= 2\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19]\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20]\n",
      "Loss: 2.3609789609909058\n",
      "Loss: 0.9951118173698584\n",
      "Loss: 0.6422210056334734\n",
      "Loss: 0.5288379901399215\n",
      "Loss: 0.45241261223951973\n",
      "Loss: 0.43663962235053383\n",
      "Loss: 0.37489150545249383\n",
      "Loss: 0.3566112228979667\n",
      "Loss: 0.33162544543544453\n",
      "Loss: 0.3066134462443491\n",
      "tensor(True) tensor(True)\n",
      "______\n",
      "Iteration t=1\n",
      "all:  cs/acc_i=80.94 cs/acc_c=81.61 os/recall_knw=89.02 os/recall_unk=56.29 total/acc_i=70.92 total/acc_c=77.15 total/h_score=65.46\n",
      "selected:  cs/acc_i=72.02 cs/acc_c=76.15 os/recall_knw=59.66 os/recall_unk=99.55 total/acc_i=78.67 total/acc_c=65.72 total/h_score=77.93\n",
      "Loss: 2.278079487556635\n",
      "Loss: 0.8745810487704684\n",
      "Loss: 0.5837907412255458\n",
      "Loss: 0.4933955359251\n",
      "Loss: 0.41208572131256727\n",
      "Loss: 0.3949885180061178\n",
      "Loss: 0.35669960592721783\n",
      "Loss: 0.3199938715601614\n",
      "Loss: 0.3057819859435161\n",
      "Loss: 0.29209100790033043\n",
      "______\n",
      "Iteration t=2\n",
      "all:  cs/acc_i=81.40 cs/acc_c=82.12 os/recall_knw=73.53 os/recall_unk=88.90 total/acc_i=74.75 total/acc_c=70.32 total/h_score=77.94\n",
      "selected:  cs/acc_i=75.84 cs/acc_c=78.88 os/recall_knw=54.68 os/recall_unk=98.72 total/acc_i=72.02 total/acc_c=59.26 total/h_score=72.50\n",
      "Loss: 2.180678539492867\n",
      "Loss: 0.7684346047314731\n",
      "Loss: 0.5242441813512282\n",
      "Loss: 0.4390016173774546\n",
      "Loss: 0.38102239641276275\n",
      "Loss: 0.35523238385265526\n",
      "Loss: 0.3276892930269241\n",
      "Loss: 0.3103421721675179\n",
      "Loss: 0.27810948287898846\n",
      "Loss: 0.2523831174725836\n",
      "______\n",
      "Iteration t=3\n",
      "all:  cs/acc_i=82.09 cs/acc_c=82.63 os/recall_knw=71.60 os/recall_unk=90.95 total/acc_i=74.55 total/acc_c=69.22 total/h_score=77.91\n",
      "selected:  cs/acc_i=80.05 cs/acc_c=81.53 os/recall_knw=61.79 os/recall_unk=96.92 total/acc_i=73.34 total/acc_c=63.88 total/h_score=75.80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 2.0976591636634776\n",
      "Loss: 0.7239535288097932\n",
      "Loss: 0.49676309059985313\n",
      "Loss: 0.41862233213542666\n",
      "Loss: 0.36606743056135077\n",
      "Loss: 0.32565609227443476\n",
      "Loss: 0.31222813474046407\n",
      "Loss: 0.2859148819678018\n",
      "Loss: 0.2529354011351915\n",
      "Loss: 0.23070105533931673\n",
      "______\n",
      "Iteration t=4\n",
      "all:  cs/acc_i=81.98 cs/acc_c=82.76 os/recall_knw=71.34 os/recall_unk=91.34 total/acc_i=74.59 total/acc_c=69.15 total/h_score=77.98\n",
      "selected:  cs/acc_i=80.99 cs/acc_c=82.40 os/recall_knw=66.28 os/recall_unk=94.36 total/acc_i=73.91 total/acc_c=66.57 total/h_score=77.10\n",
      "Loss: 2.0734573161523593\n",
      "Loss: 0.6803521798237374\n",
      "Loss: 0.47825683192595053\n",
      "Loss: 0.3824957817498791\n",
      "Loss: 0.35970895560948474\n",
      "Loss: 0.31350410479660096\n",
      "Loss: 0.2849578485505557\n",
      "Loss: 0.26203819800560413\n",
      "Loss: 0.24252075439711152\n",
      "Loss: 0.2221211020123998\n",
      "______\n",
      "Iteration t=5\n",
      "all:  cs/acc_i=81.95 cs/acc_c=82.72 os/recall_knw=70.85 os/recall_unk=91.46 total/acc_i=74.37 total/acc_c=68.78 total/h_score=77.77\n",
      "selected:  cs/acc_i=81.52 cs/acc_c=82.47 os/recall_knw=68.40 os/recall_unk=92.53 total/acc_i=73.93 total/acc_c=67.50 total/h_score=77.22\n",
      "Loss: 2.0160844199932537\n",
      "Loss: 0.6622368901585921\n",
      "Loss: 0.4588686926051592\n",
      "Loss: 0.37924019658030605\n",
      "Loss: 0.33403019353938407\n",
      "Loss: 0.2954662370686539\n",
      "Loss: 0.2794072853687864\n",
      "Loss: 0.2618189754251104\n",
      "Loss: 0.23661833193200904\n",
      "Loss: 0.2100250563608148\n",
      "______\n",
      "Iteration t=6\n",
      "all:  cs/acc_i=82.70 cs/acc_c=83.41 os/recall_knw=70.82 os/recall_unk=91.46 total/acc_i=74.37 total/acc_c=68.78 total/h_score=77.77\n",
      "selected:  cs/acc_i=82.77 cs/acc_c=83.60 os/recall_knw=70.11 os/recall_unk=91.94 total/acc_i=74.40 total/acc_c=68.68 total/h_score=77.86\n",
      "Loss: 2.007002595835512\n",
      "Loss: 0.6517880476495754\n",
      "Loss: 0.45099576110453726\n",
      "Loss: 0.37654433146400274\n",
      "Loss: 0.332253246281132\n",
      "Loss: 0.2934955838575678\n",
      "Loss: 0.27155021157514\n",
      "Loss: 0.2565883753950116\n",
      "Loss: 0.2359716923579386\n",
      "Loss: 0.215215949985966\n",
      "______\n",
      "Iteration t=7\n",
      "all:  cs/acc_i=81.75 cs/acc_c=82.48 os/recall_knw=70.68 os/recall_unk=91.46 total/acc_i=74.31 total/acc_c=68.72 total/h_score=77.73\n",
      "selected:  cs/acc_i=81.75 cs/acc_c=82.50 os/recall_knw=70.59 os/recall_unk=91.64 total/acc_i=74.34 total/acc_c=68.71 total/h_score=77.78\n",
      "Loss: 2.009561718814075\n",
      "Loss: 0.6416865072213114\n",
      "Loss: 0.4467568112071604\n",
      "Loss: 0.37495702705346046\n",
      "Loss: 0.32646348532289265\n",
      "Loss: 0.30088751460425556\n",
      "Loss: 0.2833871491486207\n",
      "Loss: 0.2521409122971818\n",
      "Loss: 0.2303073013550602\n",
      "Loss: 0.2181620484450832\n",
      "______\n",
      "Iteration t=8\n",
      "all:  cs/acc_i=82.32 cs/acc_c=83.03 os/recall_knw=70.68 os/recall_unk=91.46 total/acc_i=74.31 total/acc_c=68.72 total/h_score=77.73\n",
      "selected:  cs/acc_i=82.32 cs/acc_c=83.03 os/recall_knw=70.68 os/recall_unk=91.46 total/acc_i=74.31 total/acc_c=68.72 total/h_score=77.73\n",
      "Loss: 2.0149626425493543\n",
      "Loss: 0.637438604579165\n",
      "Loss: 0.4501755604305743\n",
      "Loss: 0.3705241176244626\n",
      "Loss: 0.3283883857996293\n",
      "Loss: 0.30036400000904206\n",
      "Loss: 0.27520592900637153\n",
      "Loss: 0.2431950544433616\n",
      "Loss: 0.22923297833105857\n",
      "Loss: 0.2183365133762174\n",
      "______\n",
      "Iteration t=9\n",
      "all:  cs/acc_i=82.29 cs/acc_c=82.85 os/recall_knw=70.68 os/recall_unk=91.46 total/acc_i=74.31 total/acc_c=68.72 total/h_score=77.73\n",
      "selected:  cs/acc_i=82.29 cs/acc_c=82.85 os/recall_knw=70.68 os/recall_unk=91.46 total/acc_i=74.31 total/acc_c=68.72 total/h_score=77.73\n",
      "tensor(0)\n",
      "all:  cs/acc_i=82.29 cs/acc_c=82.85 os/recall_knw=70.68 os/recall_unk=91.46 total/acc_i=74.31 total/acc_c=68.72 total/h_score=77.73\n",
      "painting -> real lr= 0.001 seed= 3\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19]\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20]\n",
      "Loss: 2.362370107571284\n",
      "Loss: 1.000518881281217\n",
      "Loss: 0.6495255323126912\n",
      "Loss: 0.5389508643498023\n",
      "Loss: 0.4622741335382064\n",
      "Loss: 0.4188136840860049\n",
      "Loss: 0.3756397079055508\n",
      "Loss: 0.34370539023851354\n",
      "Loss: 0.32185201983277995\n",
      "Loss: 0.31216312842443583\n",
      "tensor(True) tensor(True)\n",
      "______\n",
      "Iteration t=1\n",
      "all:  cs/acc_i=81.52 cs/acc_c=82.35 os/recall_knw=89.48 os/recall_unk=57.32 total/acc_i=71.47 total/acc_c=77.79 total/h_score=66.37\n",
      "selected:  cs/acc_i=73.95 cs/acc_c=77.89 os/recall_knw=60.77 os/recall_unk=99.78 total/acc_i=79.54 total/acc_c=66.92 total/h_score=78.92\n",
      "Loss: 2.269450090190237\n",
      "Loss: 0.8621374619330546\n",
      "Loss: 0.5703165723487388\n",
      "Loss: 0.4699208243179691\n",
      "Loss: 0.42689072179008825\n",
      "Loss: 0.37244342697798744\n",
      "Loss: 0.35908695535604346\n",
      "Loss: 0.32114522470984347\n",
      "Loss: 0.29772890985820644\n",
      "Loss: 0.29160539574863376\n",
      "______\n",
      "Iteration t=2\n",
      "all:  cs/acc_i=81.66 cs/acc_c=82.34 os/recall_knw=70.31 os/recall_unk=91.85 total/acc_i=74.15 total/acc_c=68.40 total/h_score=77.63\n",
      "selected:  cs/acc_i=76.09 cs/acc_c=79.28 os/recall_knw=51.95 os/recall_unk=99.24 total/acc_i=70.43 total/acc_c=57.20 total/h_score=70.86\n",
      "Loss: 2.185146704370325\n",
      "Loss: 0.7807755554806103\n",
      "Loss: 0.5279786490310322\n",
      "Loss: 0.43493757822296836\n",
      "Loss: 0.3917764527689327\n",
      "Loss: 0.35742485493421555\n",
      "Loss: 0.31956526523286644\n",
      "Loss: 0.29290440119125627\n",
      "Loss: 0.28774129707704893\n",
      "Loss: 0.25392576393756\n",
      "______\n",
      "Iteration t=3\n",
      "all:  cs/acc_i=81.75 cs/acc_c=82.42 os/recall_knw=67.75 os/recall_unk=93.97 total/acc_i=73.71 total/acc_c=66.96 total/h_score=77.27\n",
      "selected:  cs/acc_i=78.87 cs/acc_c=80.58 os/recall_knw=58.70 os/recall_unk=98.06 total/acc_i=71.54 total/acc_c=61.16 total/h_score=73.91\n",
      "Loss: 2.100944621251621\n",
      "Loss: 0.714037764420624\n",
      "Loss: 0.5016577851116862\n",
      "Loss: 0.4215705051147651\n",
      "Loss: 0.37247276992322653\n",
      "Loss: 0.3288016235551883\n",
      "Loss: 0.29800904790560406\n",
      "Loss: 0.2632829678017659\n",
      "Loss: 0.26857802367855593\n",
      "Loss: 0.23398840619423955\n",
      "______\n",
      "Iteration t=4\n",
      "all:  cs/acc_i=81.66 cs/acc_c=82.33 os/recall_knw=67.00 os/recall_unk=94.48 total/acc_i=73.52 total/acc_c=66.48 total/h_score=77.07\n",
      "selected:  cs/acc_i=80.37 cs/acc_c=81.52 os/recall_knw=62.26 os/recall_unk=96.15 total/acc_i=72.32 total/acc_c=63.52 total/h_score=75.30\n",
      "Loss: 2.0547526688670796\n",
      "Loss: 0.6805139559249941\n",
      "Loss: 0.48836339822045194\n",
      "Loss: 0.3992019830599576\n",
      "Loss: 0.35499646546832747\n",
      "Loss: 0.3320668243193547\n",
      "Loss: 0.2983959686766035\n",
      "Loss: 0.27100108925290284\n",
      "Loss: 0.2619045164151445\n",
      "Loss: 0.22742896840174331\n",
      "______\n",
      "Iteration t=5\n",
      "all:  cs/acc_i=82.35 cs/acc_c=83.08 os/recall_knw=66.77 os/recall_unk=94.54 total/acc_i=73.42 total/acc_c=66.31 total/h_score=76.96\n",
      "selected:  cs/acc_i=82.03 cs/acc_c=82.95 os/recall_knw=65.09 os/recall_unk=94.79 total/acc_i=72.95 total/acc_c=65.37 total/h_score=76.33\n",
      "Loss: 2.029630910773431\n",
      "Loss: 0.6609948419755505\n",
      "Loss: 0.4654069635656572\n",
      "Loss: 0.37719578803066284\n",
      "Loss: 0.3542434634460557\n",
      "Loss: 0.29894757439051906\n",
      "Loss: 0.2872681979450487\n",
      "Loss: 0.25523039150622584\n",
      "Loss: 0.2351828777862172\n",
      "Loss: 0.21583717932864543\n",
      "______\n",
      "Iteration t=6\n",
      "all:  cs/acc_i=81.86 cs/acc_c=82.70 os/recall_knw=66.74 os/recall_unk=94.54 total/acc_i=73.40 total/acc_c=66.28 total/h_score=76.95\n",
      "selected:  cs/acc_i=81.76 cs/acc_c=82.66 os/recall_knw=66.24 os/recall_unk=94.61 total/acc_i=73.25 total/acc_c=66.01 total/h_score=76.76\n",
      "Loss: 2.0223860995838057\n",
      "Loss: 0.6520990633640807\n",
      "Loss: 0.45355864935599194\n",
      "Loss: 0.38317165283349375\n",
      "Loss: 0.33597305695564983\n",
      "Loss: 0.3028540412505595\n",
      "Loss: 0.27811354993821713\n",
      "Loss: 0.24882269820894676\n",
      "Loss: 0.2338500894225253\n",
      "Loss: 0.21544032583173853\n",
      "______\n",
      "Iteration t=7\n",
      "all:  cs/acc_i=81.83 cs/acc_c=82.71 os/recall_knw=66.74 os/recall_unk=94.54 total/acc_i=73.40 total/acc_c=66.28 total/h_score=76.95\n",
      "selected:  cs/acc_i=81.83 cs/acc_c=82.71 os/recall_knw=66.73 os/recall_unk=94.54 total/acc_i=73.39 total/acc_c=66.28 total/h_score=76.94\n",
      "Loss: 2.0115404359878055\n",
      "Loss: 0.6592089222537146\n",
      "Loss: 0.449236308345719\n",
      "Loss: 0.3813301506733138\n",
      "Loss: 0.3469334034456147\n",
      "Loss: 0.3032752237740963\n",
      "Loss: 0.27646616910185134\n",
      "Loss: 0.26538438851398133\n",
      "Loss: 0.23068002020082776\n",
      "Loss: 0.21564627426957328\n",
      "______\n",
      "Iteration t=8\n",
      "all:  cs/acc_i=82.52 cs/acc_c=83.34 os/recall_knw=66.74 os/recall_unk=94.54 total/acc_i=73.40 total/acc_c=66.28 total/h_score=76.95\n",
      "selected:  cs/acc_i=82.52 cs/acc_c=83.34 os/recall_knw=66.74 os/recall_unk=94.54 total/acc_i=73.40 total/acc_c=66.28 total/h_score=76.95\n",
      "Loss: 2.017296454263112\n",
      "Loss: 0.6465810332979475\n",
      "Loss: 0.4525237977977783\n",
      "Loss: 0.37352575352267614\n",
      "Loss: 0.33726246874956856\n",
      "Loss: 0.30757484023296644\n",
      "Loss: 0.2795053892901966\n",
      "Loss: 0.2544371211930873\n",
      "Loss: 0.23265200985802545\n",
      "Loss: 0.2257022872094124\n",
      "______\n",
      "Iteration t=9\n",
      "all:  cs/acc_i=82.38 cs/acc_c=83.12 os/recall_knw=66.74 os/recall_unk=94.54 total/acc_i=73.40 total/acc_c=66.28 total/h_score=76.95\n",
      "selected:  cs/acc_i=82.38 cs/acc_c=83.12 os/recall_knw=66.74 os/recall_unk=94.54 total/acc_i=73.40 total/acc_c=66.28 total/h_score=76.95\n",
      "tensor(0)\n",
      "all:  cs/acc_i=82.38 cs/acc_c=83.12 os/recall_knw=66.74 os/recall_unk=94.54 total/acc_i=73.40 total/acc_c=66.28 total/h_score=76.95\n",
      "painting -> real lr= 0.001 seed= 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19]\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20]\n",
      "Loss: 2.3688050945599874\n",
      "Loss: 0.9810183615734179\n",
      "Loss: 0.6439494039863348\n",
      "Loss: 0.5240466012929876\n",
      "Loss: 0.46150034287323555\n",
      "Loss: 0.43278845157474277\n",
      "Loss: 0.38901668156807623\n",
      "Loss: 0.35891093440974753\n",
      "Loss: 0.3306399684709807\n",
      "Loss: 0.31243047655249634\n",
      "tensor(True) tensor(True)\n",
      "______\n",
      "Iteration t=1\n",
      "all:  cs/acc_i=80.68 cs/acc_c=81.33 os/recall_knw=88.93 os/recall_unk=56.10 total/acc_i=70.82 total/acc_c=77.06 total/h_score=65.30\n",
      "selected:  cs/acc_i=71.14 cs/acc_c=74.95 os/recall_knw=59.60 os/recall_unk=99.66 total/acc_i=78.58 total/acc_c=65.44 total/h_score=77.75\n",
      "Loss: 2.2736685793529183\n",
      "Loss: 0.8550628219233003\n",
      "Loss: 0.5645189023064089\n",
      "Loss: 0.4801715484192205\n",
      "Loss: 0.4296921030726544\n",
      "Loss: 0.38677231095326964\n",
      "Loss: 0.35525190099611764\n",
      "Loss: 0.31093577434157216\n",
      "Loss: 0.3078969049650107\n",
      "Loss: 0.2795802937863871\n",
      "______\n",
      "Iteration t=2\n",
      "all:  cs/acc_i=81.75 cs/acc_c=82.58 os/recall_knw=74.42 os/recall_unk=88.77 total/acc_i=75.36 total/acc_c=71.33 total/h_score=78.56\n",
      "selected:  cs/acc_i=76.00 cs/acc_c=79.13 os/recall_knw=55.50 os/recall_unk=98.72 total/acc_i=72.68 total/acc_c=59.78 total/h_score=72.93\n",
      "Loss: 2.185182960250161\n",
      "Loss: 0.7668260664289648\n",
      "Loss: 0.5219026337970387\n",
      "Loss: 0.45217782134359535\n",
      "Loss: 0.3917692286859859\n",
      "Loss: 0.3440547025745565\n",
      "Loss: 0.3268301043185321\n",
      "Loss: 0.28562744507735427\n",
      "Loss: 0.28250784635543824\n",
      "Loss: 0.25862874590537765\n",
      "______\n",
      "Iteration t=3\n",
      "all:  cs/acc_i=81.83 cs/acc_c=82.46 os/recall_knw=70.97 os/recall_unk=91.46 total/acc_i=74.57 total/acc_c=69.16 total/h_score=78.03\n",
      "selected:  cs/acc_i=78.75 cs/acc_c=80.39 os/recall_knw=61.26 os/recall_unk=96.94 total/acc_i=72.65 total/acc_c=62.71 total/h_score=74.88\n",
      "Loss: 2.0920277711042425\n",
      "Loss: 0.7038837799296755\n",
      "Loss: 0.48851327710749765\n",
      "Loss: 0.4140770398976467\n",
      "Loss: 0.3600754397841254\n",
      "Loss: 0.34173661462732197\n",
      "Loss: 0.3069671859702294\n",
      "Loss: 0.2762101214519891\n",
      "Loss: 0.2651507468618888\n",
      "Loss: 0.22957592178456152\n",
      "______\n",
      "Iteration t=4\n",
      "all:  cs/acc_i=81.46 cs/acc_c=82.16 os/recall_knw=70.88 os/recall_unk=91.66 total/acc_i=74.61 total/acc_c=69.14 total/h_score=78.09\n",
      "selected:  cs/acc_i=80.03 cs/acc_c=81.19 os/recall_knw=66.06 os/recall_unk=94.01 total/acc_i=73.56 total/acc_c=66.02 total/h_score=76.59\n",
      "Loss: 2.0639765709638596\n",
      "Loss: 0.688512531550307\n",
      "Loss: 0.4697967411852197\n",
      "Loss: 0.39999038728542236\n",
      "Loss: 0.35683892951592017\n",
      "Loss: 0.30702636993833277\n",
      "Loss: 0.2800716732285525\n",
      "Loss: 0.2627635185459727\n",
      "Loss: 0.22644862204201913\n",
      "Loss: 0.2298090863409207\n",
      "______\n",
      "Iteration t=5\n",
      "all:  cs/acc_i=81.81 cs/acc_c=82.65 os/recall_knw=70.74 os/recall_unk=91.98 total/acc_i=74.63 total/acc_c=69.04 total/h_score=78.12\n",
      "selected:  cs/acc_i=81.31 cs/acc_c=82.45 os/recall_knw=68.55 os/recall_unk=92.81 total/acc_i=74.15 total/acc_c=67.90 total/h_score=77.59\n",
      "Loss: 2.0300420128499357\n",
      "Loss: 0.6553100818833604\n",
      "Loss: 0.4629717962905622\n",
      "Loss: 0.37525912990775734\n",
      "Loss: 0.34253497540760347\n",
      "Loss: 0.2983584508966333\n",
      "Loss: 0.2645832315658609\n",
      "Loss: 0.25673244036019993\n",
      "Loss: 0.23676448704573674\n",
      "Loss: 0.21890377773406405\n",
      "______\n",
      "Iteration t=6\n",
      "all:  cs/acc_i=82.55 cs/acc_c=83.30 os/recall_knw=70.71 os/recall_unk=91.98 total/acc_i=74.61 total/acc_c=69.02 total/h_score=78.11\n",
      "selected:  cs/acc_i=82.69 cs/acc_c=83.51 os/recall_knw=70.15 os/recall_unk=92.45 total/acc_i=74.72 total/acc_c=68.98 total/h_score=78.24\n",
      "Loss: 2.011411336795339\n",
      "Loss: 0.6524301319377227\n",
      "Loss: 0.446347934551209\n",
      "Loss: 0.3682633952805831\n",
      "Loss: 0.32827973218177847\n",
      "Loss: 0.28984673379820847\n",
      "Loss: 0.2788473614052219\n",
      "Loss: 0.2556712876583608\n",
      "Loss: 0.23680346063777524\n",
      "Loss: 0.21287263739479226\n",
      "______\n",
      "Iteration t=7\n",
      "all:  cs/acc_i=81.66 cs/acc_c=82.61 os/recall_knw=70.71 os/recall_unk=91.98 total/acc_i=74.61 total/acc_c=69.02 total/h_score=78.11\n",
      "selected:  cs/acc_i=81.71 cs/acc_c=82.68 os/recall_knw=70.64 os/recall_unk=92.04 total/acc_i=74.64 total/acc_c=69.06 total/h_score=78.15\n",
      "Loss: 2.0023724559694527\n",
      "Loss: 0.6480709980241954\n",
      "Loss: 0.45955595639534297\n",
      "Loss: 0.3760526217520237\n",
      "Loss: 0.3333770917030051\n",
      "Loss: 0.3040831174934283\n",
      "Loss: 0.2611414409475401\n",
      "Loss: 0.24316324669634923\n",
      "Loss: 0.23812921470962464\n",
      "Loss: 0.20427922097733245\n",
      "______\n",
      "Iteration t=8\n",
      "all:  cs/acc_i=82.18 cs/acc_c=82.98 os/recall_knw=70.71 os/recall_unk=91.98 total/acc_i=74.61 total/acc_c=69.02 total/h_score=78.11\n",
      "selected:  cs/acc_i=82.18 cs/acc_c=82.98 os/recall_knw=70.71 os/recall_unk=91.98 total/acc_i=74.61 total/acc_c=69.02 total/h_score=78.11\n",
      "Loss: 1.9814182518055876\n",
      "Loss: 0.6424161156761312\n",
      "Loss: 0.4516581638579799\n",
      "Loss: 0.3696562195214156\n",
      "Loss: 0.33604423636773667\n",
      "Loss: 0.30999472101343756\n",
      "Loss: 0.27056543740249495\n",
      "Loss: 0.2565478240357381\n",
      "Loss: 0.23056281435758896\n",
      "Loss: 0.2083821918269927\n",
      "______\n",
      "Iteration t=9\n",
      "all:  cs/acc_i=81.89 cs/acc_c=82.75 os/recall_knw=70.71 os/recall_unk=91.98 total/acc_i=74.61 total/acc_c=69.02 total/h_score=78.11\n",
      "selected:  cs/acc_i=81.89 cs/acc_c=82.75 os/recall_knw=70.71 os/recall_unk=91.98 total/acc_i=74.61 total/acc_c=69.02 total/h_score=78.11\n",
      "tensor(0)\n",
      "all:  cs/acc_i=81.89 cs/acc_c=82.75 os/recall_knw=70.71 os/recall_unk=91.98 total/acc_i=74.61 total/acc_c=69.02 total/h_score=78.11\n",
      "painting -> real lr= 0.001 seed= 0\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19]\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20]\n",
      "Loss: 2.360780828197797\n",
      "Loss: 0.999645405386885\n",
      "Loss: 0.655633502950271\n",
      "Loss: 0.5386607730140288\n",
      "Loss: 0.477714426536113\n",
      "Loss: 0.41174865992118914\n",
      "Loss: 0.38908686861395836\n",
      "Loss: 0.3471541777253151\n",
      "Loss: 0.33115588103731475\n",
      "Loss: 0.31728888920818765\n",
      "tensor(True) tensor(True)\n",
      "______\n",
      "Iteration t=1\n",
      "all:  cs/acc_i=79.99 cs/acc_c=80.72 os/recall_knw=88.82 os/recall_unk=55.84 total/acc_i=69.98 total/acc_c=76.17 total/h_score=64.80\n",
      "selected:  cs/acc_i=72.09 cs/acc_c=75.25 os/recall_knw=59.18 os/recall_unk=99.66 total/acc_i=78.26 total/acc_c=64.19 total/h_score=76.76\n",
      "Loss: 2.259312583494556\n",
      "Loss: 0.877270018176515\n",
      "Loss: 0.5937274440891983\n",
      "Loss: 0.4811997867023298\n",
      "Loss: 0.43334407977355544\n",
      "Loss: 0.36558339204783585\n",
      "Loss: 0.33673881352409835\n",
      "Loss: 0.32631937939991323\n",
      "Loss: 0.27956304274672683\n",
      "Loss: 0.27393817061255143\n",
      "______\n",
      "Iteration t=2\n",
      "all:  cs/acc_i=81.37 cs/acc_c=82.09 os/recall_knw=71.74 os/recall_unk=90.63 total/acc_i=74.51 total/acc_c=69.23 total/h_score=77.80\n",
      "selected:  cs/acc_i=75.61 cs/acc_c=78.51 os/recall_knw=53.08 os/recall_unk=98.81 total/acc_i=71.11 total/acc_c=57.54 total/h_score=71.06\n",
      "Loss: 2.1755022488940847\n",
      "Loss: 0.7884803748130799\n",
      "Loss: 0.5153358823602849\n",
      "Loss: 0.4325400393659418\n",
      "Loss: 0.3896736184033481\n",
      "Loss: 0.3416803177107464\n",
      "Loss: 0.325425318479538\n",
      "Loss: 0.3015073689005592\n",
      "Loss: 0.26912341967225073\n",
      "Loss: 0.2537045884132385\n",
      "______\n",
      "Iteration t=3\n",
      "all:  cs/acc_i=82.18 cs/acc_c=82.81 os/recall_knw=70.91 os/recall_unk=91.01 total/acc_i=74.23 total/acc_c=68.71 total/h_score=77.58\n",
      "selected:  cs/acc_i=79.64 cs/acc_c=81.26 os/recall_knw=61.05 os/recall_unk=96.40 total/acc_i=72.47 total/acc_c=62.52 total/h_score=74.59\n",
      "Loss: 2.1134157272958265\n",
      "Loss: 0.7122003171349719\n",
      "Loss: 0.4844412455444074\n",
      "Loss: 0.4098221225939256\n",
      "Loss: 0.36230431727527346\n",
      "Loss: 0.32599213433890406\n",
      "Loss: 0.3077885636810175\n",
      "Loss: 0.26718283598263237\n",
      "Loss: 0.26327151710429963\n",
      "Loss: 0.23191774610903665\n",
      "______\n",
      "Iteration t=4\n",
      "all:  cs/acc_i=81.89 cs/acc_c=82.38 os/recall_knw=70.16 os/recall_unk=91.72 total/acc_i=74.17 total/acc_c=68.32 total/h_score=77.53\n",
      "selected:  cs/acc_i=80.46 cs/acc_c=81.45 os/recall_knw=64.79 os/recall_unk=95.01 total/acc_i=73.20 total/acc_c=65.07 total/h_score=76.18\n",
      "Loss: 2.069883429451494\n",
      "Loss: 0.6830343247841526\n",
      "Loss: 0.4789835222016107\n",
      "Loss: 0.3981401450833343\n",
      "Loss: 0.36027644044220053\n",
      "Loss: 0.32219199123268094\n",
      "Loss: 0.29202527989516197\n",
      "Loss: 0.2632170804091637\n",
      "Loss: 0.24012384382354107\n",
      "Loss: 0.22580424329845716\n",
      "______\n",
      "Iteration t=5\n",
      "all:  cs/acc_i=81.81 cs/acc_c=82.47 os/recall_knw=69.82 os/recall_unk=91.98 total/acc_i=74.09 total/acc_c=68.13 total/h_score=77.49\n",
      "selected:  cs/acc_i=81.37 cs/acc_c=82.28 os/recall_knw=67.61 os/recall_unk=93.48 total/acc_i=73.80 total/acc_c=67.01 total/h_score=77.16\n",
      "Loss: 2.014470755480803\n",
      "Loss: 0.6614069749529545\n",
      "Loss: 0.4490249256292979\n",
      "Loss: 0.3719620807096362\n",
      "Loss: 0.35669734453161556\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.29888329705080163\n",
      "Loss: 0.265295237601281\n",
      "Loss: 0.2541583430929444\n",
      "Loss: 0.2362046693571103\n",
      "Loss: 0.21256059576542333\n",
      "______\n",
      "Iteration t=6\n",
      "all:  cs/acc_i=81.69 cs/acc_c=82.43 os/recall_knw=69.82 os/recall_unk=92.04 total/acc_i=74.11 total/acc_c=68.14 total/h_score=77.51\n",
      "selected:  cs/acc_i=81.83 cs/acc_c=82.63 os/recall_knw=69.24 os/recall_unk=92.64 total/acc_i=74.26 total/acc_c=68.07 total/h_score=77.65\n",
      "Loss: 2.002587124940349\n",
      "Loss: 0.6490138373352375\n",
      "Loss: 0.4512000380536359\n",
      "Loss: 0.377672167935582\n",
      "Loss: 0.33312162803926676\n",
      "Loss: 0.297414821922215\n",
      "Loss: 0.2778730844426606\n",
      "Loss: 0.25414149855683654\n",
      "Loss: 0.22595094503946483\n",
      "Loss: 0.20630561365314087\n",
      "______\n",
      "Iteration t=7\n",
      "all:  cs/acc_i=82.58 cs/acc_c=83.15 os/recall_knw=69.82 os/recall_unk=92.04 total/acc_i=74.11 total/acc_c=68.14 total/h_score=77.51\n",
      "selected:  cs/acc_i=82.59 cs/acc_c=83.16 os/recall_knw=69.79 os/recall_unk=92.10 total/acc_i=74.13 total/acc_c=68.13 total/h_score=77.53\n",
      "Loss: 2.0209498431533577\n",
      "Loss: 0.660006539709866\n",
      "Loss: 0.44578905557282267\n",
      "Loss: 0.3762327564880252\n",
      "Loss: 0.3299514195648953\n",
      "Loss: 0.30582516991999\n",
      "Loss: 0.2778406584169716\n",
      "Loss: 0.24793979675741867\n",
      "Loss: 0.22446784620406107\n",
      "Loss: 0.20464281571330503\n",
      "______\n",
      "Iteration t=8\n",
      "all:  cs/acc_i=82.15 cs/acc_c=82.88 os/recall_knw=69.82 os/recall_unk=92.04 total/acc_i=74.11 total/acc_c=68.14 total/h_score=77.51\n",
      "selected:  cs/acc_i=82.15 cs/acc_c=82.88 os/recall_knw=69.82 os/recall_unk=92.04 total/acc_i=74.11 total/acc_c=68.14 total/h_score=77.51\n",
      "Loss: 2.010153565555811\n",
      "Loss: 0.652027194481343\n",
      "Loss: 0.44053689592983575\n",
      "Loss: 0.3690708709647879\n",
      "Loss: 0.32053418674040585\n",
      "Loss: 0.2931378950015642\n",
      "Loss: 0.27748427430633454\n",
      "Loss: 0.24145986168878153\n",
      "Loss: 0.2237019200110808\n",
      "Loss: 0.19580273820320143\n",
      "______\n",
      "Iteration t=9\n",
      "all:  cs/acc_i=82.98 cs/acc_c=83.83 os/recall_knw=69.82 os/recall_unk=92.04 total/acc_i=74.11 total/acc_c=68.14 total/h_score=77.51\n",
      "selected:  cs/acc_i=82.98 cs/acc_c=83.83 os/recall_knw=69.82 os/recall_unk=92.04 total/acc_i=74.11 total/acc_c=68.14 total/h_score=77.51\n",
      "tensor(0)\n",
      "all:  cs/acc_i=82.98 cs/acc_c=83.83 os/recall_knw=69.82 os/recall_unk=92.04 total/acc_i=74.11 total/acc_c=68.14 total/h_score=77.51\n",
      "painting -> real lr= 0.001 seed= 1\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19]\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20]\n",
      "Loss: 2.379484054942926\n",
      "Loss: 0.9968410521745682\n",
      "Loss: 0.6369324129074811\n",
      "Loss: 0.5408555765325824\n",
      "Loss: 0.46853575961043437\n",
      "Loss: 0.400347492347161\n",
      "Loss: 0.3940537236010035\n",
      "Loss: 0.3555734921867649\n",
      "Loss: 0.341670945007354\n",
      "Loss: 0.3025633997749537\n",
      "tensor(True) tensor(True)\n",
      "______\n",
      "Iteration t=1\n",
      "all:  cs/acc_i=81.06 cs/acc_c=81.80 os/recall_knw=88.85 os/recall_unk=55.91 total/acc_i=70.68 total/acc_c=77.00 total/h_score=65.15\n",
      "selected:  cs/acc_i=72.96 cs/acc_c=76.93 os/recall_knw=59.50 os/recall_unk=99.89 total/acc_i=78.63 total/acc_c=65.24 total/h_score=77.65\n",
      "Loss: 2.267915580623834\n",
      "Loss: 0.8815340071685555\n",
      "Loss: 0.5783478127315987\n",
      "Loss: 0.4715251712373985\n",
      "Loss: 0.4062153145439865\n",
      "Loss: 0.37866168376780296\n",
      "Loss: 0.3696545164945514\n",
      "Loss: 0.3131895918081435\n",
      "Loss: 0.2912890975789506\n",
      "Loss: 0.27572776209707406\n",
      "______\n",
      "Iteration t=2\n",
      "all:  cs/acc_i=81.23 cs/acc_c=81.96 os/recall_knw=69.96 os/recall_unk=91.66 total/acc_i=73.85 total/acc_c=68.00 total/h_score=77.29\n",
      "selected:  cs/acc_i=75.66 cs/acc_c=78.57 os/recall_knw=51.73 os/recall_unk=99.30 total/acc_i=70.27 total/acc_c=56.62 total/h_score=70.36\n",
      "Loss: 2.1968373888189143\n",
      "Loss: 0.767854969068007\n",
      "Loss: 0.5260131659832867\n",
      "Loss: 0.4366604665192691\n",
      "Loss: 0.39515384636142037\n",
      "Loss: 0.35349758671088655\n",
      "Loss: 0.3111902772567489\n",
      "Loss: 0.2896324545415965\n",
      "Loss: 0.27558954680507836\n",
      "Loss: 0.2626294287497347\n",
      "______\n",
      "Iteration t=3\n",
      "all:  cs/acc_i=81.32 cs/acc_c=81.99 os/recall_knw=69.62 os/recall_unk=92.11 total/acc_i=73.81 total/acc_c=67.75 total/h_score=77.26\n",
      "selected:  cs/acc_i=78.76 cs/acc_c=80.74 os/recall_knw=59.98 os/recall_unk=97.62 total/acc_i=72.22 total/acc_c=62.28 total/h_score=74.71\n",
      "Loss: 2.135676739544704\n",
      "Loss: 0.7394485261933557\n",
      "Loss: 0.4960969942397085\n",
      "Loss: 0.41044873913814284\n",
      "Loss: 0.37531232047697594\n",
      "Loss: 0.3323817372065166\n",
      "Loss: 0.3064914858289834\n",
      "Loss: 0.2803265051081263\n",
      "Loss: 0.2530309989791492\n",
      "Loss: 0.245145304475365\n",
      "______\n",
      "Iteration t=4\n",
      "all:  cs/acc_i=81.58 cs/acc_c=82.22 os/recall_knw=69.24 os/recall_unk=92.23 total/acc_i=73.67 total/acc_c=67.48 total/h_score=77.11\n",
      "selected:  cs/acc_i=80.53 cs/acc_c=81.60 os/recall_knw=64.33 os/recall_unk=95.23 total/acc_i=72.94 total/acc_c=64.61 total/h_score=75.89\n",
      "Loss: 2.0560439154012315\n",
      "Loss: 0.686335116032733\n",
      "Loss: 0.4673016253883476\n",
      "Loss: 0.3920546285561378\n",
      "Loss: 0.34693984324667626\n",
      "Loss: 0.3021500466872525\n",
      "Loss: 0.28440998704326864\n",
      "Loss: 0.2635351667143651\n",
      "Loss: 0.24966277036544504\n",
      "Loss: 0.23185863801037634\n",
      "______\n",
      "Iteration t=5\n",
      "all:  cs/acc_i=81.72 cs/acc_c=82.52 os/recall_knw=69.16 os/recall_unk=92.36 total/acc_i=73.69 total/acc_c=67.46 total/h_score=77.13\n",
      "selected:  cs/acc_i=81.48 cs/acc_c=82.57 os/recall_knw=67.21 os/recall_unk=93.50 total/acc_i=73.48 total/acc_c=66.62 total/h_score=76.88\n",
      "Loss: 2.0445744204215512\n",
      "Loss: 0.6553044156768383\n",
      "Loss: 0.45554523614163583\n",
      "Loss: 0.39176757227724945\n",
      "Loss: 0.3285794992429706\n",
      "Loss: 0.31311383131795967\n",
      "Loss: 0.277771586432862\n",
      "Loss: 0.26812007042985314\n",
      "Loss: 0.23297851357179192\n",
      "Loss: 0.22395584288124853\n",
      "______\n",
      "Iteration t=6\n",
      "all:  cs/acc_i=82.06 cs/acc_c=82.82 os/recall_knw=69.07 os/recall_unk=92.43 total/acc_i=73.67 total/acc_c=67.41 total/h_score=77.12\n",
      "selected:  cs/acc_i=82.18 cs/acc_c=83.04 os/recall_knw=68.26 os/recall_unk=92.84 total/acc_i=73.71 total/acc_c=67.28 total/h_score=77.15\n",
      "Loss: 2.006273428850536\n",
      "Loss: 0.645829396723192\n",
      "Loss: 0.44567668683166745\n",
      "Loss: 0.36392411151075665\n",
      "Loss: 0.3367399542910766\n",
      "Loss: 0.29865034450364264\n",
      "Loss: 0.2823596648353187\n",
      "Loss: 0.2528978782599863\n",
      "Loss: 0.2257179918970111\n",
      "Loss: 0.2151561934689555\n",
      "______\n",
      "Iteration t=7\n",
      "all:  cs/acc_i=81.95 cs/acc_c=82.62 os/recall_knw=69.01 os/recall_unk=92.43 total/acc_i=73.65 total/acc_c=67.39 total/h_score=77.11\n",
      "selected:  cs/acc_i=81.97 cs/acc_c=82.64 os/recall_knw=69.00 os/recall_unk=92.49 total/acc_i=73.68 total/acc_c=67.41 total/h_score=77.14\n",
      "Loss: 2.01941937170806\n",
      "Loss: 0.6643806926695904\n",
      "Loss: 0.4531461036410825\n",
      "Loss: 0.3783192519904304\n",
      "Loss: 0.32362171418988217\n",
      "Loss: 0.3021809117967806\n",
      "Loss: 0.26209181711825086\n",
      "Loss: 0.26014860539600765\n",
      "Loss: 0.22940856650424976\n",
      "Loss: 0.19952615114588723\n",
      "______\n",
      "Iteration t=8\n",
      "all:  cs/acc_i=82.58 cs/acc_c=83.22 os/recall_knw=69.01 os/recall_unk=92.43 total/acc_i=73.65 total/acc_c=67.39 total/h_score=77.11\n",
      "selected:  cs/acc_i=82.58 cs/acc_c=83.22 os/recall_knw=69.01 os/recall_unk=92.43 total/acc_i=73.65 total/acc_c=67.39 total/h_score=77.11\n",
      "Loss: 1.9935117505934545\n",
      "Loss: 0.6393340383203799\n",
      "Loss: 0.4506352425649248\n",
      "Loss: 0.37999093499863784\n",
      "Loss: 0.32520234483209526\n",
      "Loss: 0.30324149110754456\n",
      "Loss: 0.2682305977309012\n",
      "Loss: 0.2555524564835719\n",
      "Loss: 0.2224892442666438\n",
      "Loss: 0.2154934110125778\n",
      "______\n",
      "Iteration t=9\n",
      "all:  cs/acc_i=82.58 cs/acc_c=83.36 os/recall_knw=69.01 os/recall_unk=92.43 total/acc_i=73.65 total/acc_c=67.39 total/h_score=77.11\n",
      "selected:  cs/acc_i=82.58 cs/acc_c=83.36 os/recall_knw=69.01 os/recall_unk=92.43 total/acc_i=73.65 total/acc_c=67.39 total/h_score=77.11\n",
      "tensor(0)\n",
      "all:  cs/acc_i=82.58 cs/acc_c=83.36 os/recall_knw=69.01 os/recall_unk=92.43 total/acc_i=73.65 total/acc_c=67.39 total/h_score=77.11\n",
      "painting -> real lr= 0.001 seed= 2\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19]\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20]\n",
      "Loss: 2.3613687723875048\n",
      "Loss: 0.9948608666658402\n",
      "Loss: 0.6419974599033594\n",
      "Loss: 0.5285712592924635\n",
      "Loss: 0.45173817401130995\n",
      "Loss: 0.43585748244076966\n",
      "Loss: 0.37448988457520804\n",
      "Loss: 0.35593244144693015\n",
      "Loss: 0.33058534848193327\n",
      "Loss: 0.3059519213624299\n",
      "tensor(True) tensor(True)\n",
      "______\n",
      "Iteration t=1\n",
      "all:  cs/acc_i=80.86 cs/acc_c=81.48 os/recall_knw=88.50 os/recall_unk=55.13 total/acc_i=70.44 total/acc_c=77.00 total/h_score=64.64\n",
      "selected:  cs/acc_i=70.88 cs/acc_c=74.33 os/recall_knw=58.55 os/recall_unk=99.54 total/acc_i=77.63 total/acc_c=64.49 total/h_score=76.97\n",
      "Loss: 2.272959339064221\n",
      "Loss: 0.8700345784656761\n",
      "Loss: 0.5913861748553062\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.47771550969097965\n",
      "Loss: 0.42716134917135384\n",
      "Loss: 0.3914202911447185\n",
      "Loss: 0.3454647355590218\n",
      "Loss: 0.3206073087892791\n",
      "Loss: 0.30210764524202016\n",
      "Loss: 0.29183562021962434\n",
      "______\n",
      "Iteration t=2\n",
      "all:  cs/acc_i=81.78 cs/acc_c=82.49 os/recall_knw=69.93 os/recall_unk=91.14 total/acc_i=73.83 total/acc_c=68.25 total/h_score=77.30\n",
      "selected:  cs/acc_i=75.97 cs/acc_c=78.97 os/recall_knw=51.48 os/recall_unk=98.95 total/acc_i=69.95 total/acc_c=56.79 total/h_score=70.44\n",
      "Loss: 2.1668279366059737\n",
      "Loss: 0.7527852553129196\n",
      "Loss: 0.5338148881088604\n",
      "Loss: 0.4453886160525409\n",
      "Loss: 0.3930105136199431\n",
      "Loss: 0.3437341407483274\n",
      "Loss: 0.3144744079763239\n",
      "Loss: 0.29652808079665355\n",
      "Loss: 0.2674436349218542\n",
      "Loss: 0.24385537830266085\n",
      "______\n",
      "Iteration t=3\n",
      "all:  cs/acc_i=82.21 cs/acc_c=82.83 os/recall_knw=68.04 os/recall_unk=93.39 total/acc_i=73.73 total/acc_c=67.14 total/h_score=77.23\n",
      "selected:  cs/acc_i=79.78 cs/acc_c=81.50 os/recall_knw=58.74 os/recall_unk=97.59 total/acc_i=71.76 total/acc_c=61.56 total/h_score=74.12\n",
      "Loss: 2.119811737537384\n",
      "Loss: 0.7302031238531245\n",
      "Loss: 0.49004364558335006\n",
      "Loss: 0.39687175293420923\n",
      "Loss: 0.36930057167493063\n",
      "Loss: 0.32773950367138305\n",
      "Loss: 0.3076952778059861\n",
      "Loss: 0.27724127134886284\n",
      "Loss: 0.24809128148802395\n",
      "Loss: 0.24668590903025248\n",
      "______\n",
      "Iteration t=4\n",
      "all:  cs/acc_i=82.04 cs/acc_c=82.68 os/recall_knw=67.81 os/recall_unk=93.52 total/acc_i=73.67 total/acc_c=66.99 total/h_score=77.15\n",
      "selected:  cs/acc_i=80.92 cs/acc_c=81.94 os/recall_knw=63.22 os/recall_unk=95.29 total/acc_i=72.61 total/acc_c=64.18 total/h_score=75.58\n",
      "Loss: 2.076670667588316\n",
      "Loss: 0.6998694332328853\n",
      "Loss: 0.48090202173847235\n",
      "Loss: 0.3980256915585884\n",
      "Loss: 0.3552687480453624\n",
      "Loss: 0.3134882966586888\n",
      "Loss: 0.2912944580570159\n",
      "Loss: 0.25664881836400916\n",
      "Loss: 0.241379548493304\n",
      "Loss: 0.23194489899455317\n",
      "______\n",
      "Iteration t=5\n",
      "all:  cs/acc_i=82.12 cs/acc_c=82.91 os/recall_knw=67.78 os/recall_unk=93.52 total/acc_i=73.67 total/acc_c=66.99 total/h_score=77.15\n",
      "selected:  cs/acc_i=81.61 cs/acc_c=82.66 os/recall_knw=65.75 os/recall_unk=94.30 total/acc_i=73.16 total/acc_c=65.90 total/h_score=76.59\n",
      "Loss: 2.027214438492252\n",
      "Loss: 0.6514092655912522\n",
      "Loss: 0.44358803802920926\n",
      "Loss: 0.3803215293393981\n",
      "Loss: 0.3370442343214827\n",
      "Loss: 0.3012645626020047\n",
      "Loss: 0.29503640224856714\n",
      "Loss: 0.2617963513419513\n",
      "Loss: 0.23019267919082795\n",
      "Loss: 0.22161865350940535\n",
      "______\n",
      "Iteration t=6\n",
      "all:  cs/acc_i=82.55 cs/acc_c=83.26 os/recall_knw=67.66 os/recall_unk=93.52 total/acc_i=73.62 total/acc_c=66.92 total/h_score=77.10\n",
      "selected:  cs/acc_i=82.51 cs/acc_c=83.29 os/recall_knw=67.14 os/recall_unk=93.76 total/acc_i=73.54 total/acc_c=66.75 total/h_score=77.05\n",
      "Loss: 2.0136741585201685\n",
      "Loss: 0.6424563277335394\n",
      "Loss: 0.4560269120193663\n",
      "Loss: 0.3775165087410382\n",
      "Loss: 0.34039097279310226\n",
      "Loss: 0.2987058190835847\n",
      "Loss: 0.2786594683925311\n",
      "Loss: 0.24549587368965148\n",
      "Loss: 0.2363292441836425\n",
      "Loss: 0.21251573415975722\n",
      "______\n",
      "Iteration t=7\n",
      "all:  cs/acc_i=82.38 cs/acc_c=83.06 os/recall_knw=67.63 os/recall_unk=93.58 total/acc_i=73.62 total/acc_c=66.90 total/h_score=77.11\n",
      "selected:  cs/acc_i=82.39 cs/acc_c=83.09 os/recall_knw=67.60 os/recall_unk=93.58 total/acc_i=73.61 total/acc_c=66.91 total/h_score=77.11\n",
      "Loss: 2.021638028795206\n",
      "Loss: 0.6439010505623455\n",
      "Loss: 0.46104084624897074\n",
      "Loss: 0.35882174447650395\n",
      "Loss: 0.3370593432808601\n",
      "Loss: 0.2992314571113903\n",
      "Loss: 0.279853548241567\n",
      "Loss: 0.253322574168538\n",
      "Loss: 0.23970652974057424\n",
      "Loss: 0.23182976584221365\n",
      "______\n",
      "Iteration t=8\n",
      "all:  cs/acc_i=82.90 cs/acc_c=83.49 os/recall_knw=67.63 os/recall_unk=93.58 total/acc_i=73.62 total/acc_c=66.90 total/h_score=77.11\n",
      "selected:  cs/acc_i=82.90 cs/acc_c=83.49 os/recall_knw=67.63 os/recall_unk=93.58 total/acc_i=73.62 total/acc_c=66.90 total/h_score=77.11\n",
      "Loss: 2.004599321715839\n",
      "Loss: 0.666116189928461\n",
      "Loss: 0.45498988516511224\n",
      "Loss: 0.372754178259651\n",
      "Loss: 0.3281467968968187\n",
      "Loss: 0.3163312790850736\n",
      "Loss: 0.26885120592987877\n",
      "Loss: 0.25875374248210187\n",
      "Loss: 0.23223609058920894\n",
      "Loss: 0.21558933963628973\n",
      "______\n",
      "Iteration t=9\n",
      "all:  cs/acc_i=82.38 cs/acc_c=83.14 os/recall_knw=67.63 os/recall_unk=93.58 total/acc_i=73.62 total/acc_c=66.90 total/h_score=77.11\n",
      "selected:  cs/acc_i=82.38 cs/acc_c=83.14 os/recall_knw=67.63 os/recall_unk=93.58 total/acc_i=73.62 total/acc_c=66.90 total/h_score=77.11\n",
      "tensor(0)\n",
      "all:  cs/acc_i=82.38 cs/acc_c=83.14 os/recall_knw=67.63 os/recall_unk=93.58 total/acc_i=73.62 total/acc_c=66.90 total/h_score=77.11\n",
      "painting -> real lr= 0.001 seed= 3\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19]\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20]\n",
      "Loss: 2.3628484229246776\n",
      "Loss: 1.0011039117972056\n",
      "Loss: 0.6496963266283273\n",
      "Loss: 0.5388361537829042\n",
      "Loss: 0.46170688327401876\n",
      "Loss: 0.4187438840046525\n",
      "Loss: 0.37505741069714227\n",
      "Loss: 0.34325334345921876\n",
      "Loss: 0.32104285809521876\n",
      "Loss: 0.3115947698863844\n",
      "tensor(True) tensor(True)\n",
      "______\n",
      "Iteration t=1\n",
      "all:  cs/acc_i=81.60 cs/acc_c=82.41 os/recall_knw=89.13 os/recall_unk=56.55 total/acc_i=71.17 total/acc_c=77.66 total/h_score=65.82\n",
      "selected:  cs/acc_i=73.59 cs/acc_c=77.16 os/recall_knw=59.92 os/recall_unk=99.77 total/acc_i=78.86 total/acc_c=65.72 total/h_score=77.99\n",
      "Loss: 2.2584784737853116\n",
      "Loss: 0.868738320100215\n",
      "Loss: 0.581820892617684\n",
      "Loss: 0.47214700322049535\n",
      "Loss: 0.4257420839727387\n",
      "Loss: 0.3734159293447354\n",
      "Loss: 0.34642408626486165\n",
      "Loss: 0.3258011198003394\n",
      "Loss: 0.29131231630264326\n",
      "Loss: 0.2830465912183588\n",
      "______\n",
      "Iteration t=2\n",
      "all:  cs/acc_i=81.58 cs/acc_c=82.40 os/recall_knw=71.11 os/recall_unk=90.69 total/acc_i=74.29 total/acc_c=69.23 total/h_score=77.83\n",
      "selected:  cs/acc_i=75.82 cs/acc_c=79.27 os/recall_knw=52.64 os/recall_unk=99.23 total/acc_i=70.87 total/acc_c=58.09 total/h_score=71.63\n",
      "Loss: 2.177475015250119\n",
      "Loss: 0.767143276496367\n",
      "Loss: 0.531641186855056\n",
      "Loss: 0.42575220322067087\n",
      "Loss: 0.38164882627400487\n",
      "Loss: 0.3479270397804\n",
      "Loss: 0.32197969550436195\n",
      "Loss: 0.28887422621250153\n",
      "Loss: 0.29018116731535304\n",
      "Loss: 0.2560404004562985\n",
      "______\n",
      "Iteration t=3\n",
      "all:  cs/acc_i=82.01 cs/acc_c=82.71 os/recall_knw=68.84 os/recall_unk=92.55 total/acc_i=73.75 total/acc_c=67.65 total/h_score=77.33\n",
      "selected:  cs/acc_i=78.97 cs/acc_c=80.89 os/recall_knw=59.37 os/recall_unk=97.43 total/acc_i=71.58 total/acc_c=61.66 total/h_score=74.17\n",
      "Loss: 2.099368383384652\n",
      "Loss: 0.7118201724852073\n",
      "Loss: 0.500081371042327\n",
      "Loss: 0.40047798986799527\n",
      "Loss: 0.3588173523084405\n",
      "Loss: 0.31787242020937995\n",
      "Loss: 0.28944879125074013\n",
      "Loss: 0.2676804672376192\n",
      "Loss: 0.2587024823496841\n",
      "Loss: 0.2347643928557532\n",
      "______\n",
      "Iteration t=4\n",
      "all:  cs/acc_i=82.27 cs/acc_c=83.05 os/recall_knw=68.47 os/recall_unk=92.81 total/acc_i=73.62 total/acc_c=67.37 total/h_score=77.21\n",
      "selected:  cs/acc_i=81.08 cs/acc_c=82.57 os/recall_knw=63.52 os/recall_unk=95.70 total/acc_i=72.69 total/acc_c=64.60 total/h_score=76.01\n",
      "Loss: 2.0540680930709208\n",
      "Loss: 0.6797986348338475\n",
      "Loss: 0.4712776613748626\n",
      "Loss: 0.40422920877767715\n",
      "Loss: 0.35589608934936146\n",
      "Loss: 0.3158962701182097\n",
      "Loss: 0.2914454157630734\n",
      "Loss: 0.2750169066157167\n",
      "Loss: 0.24977849520101453\n",
      "Loss: 0.22734258241260683\n",
      "______\n",
      "Iteration t=5\n",
      "all:  cs/acc_i=82.55 cs/acc_c=83.23 os/recall_knw=68.41 os/recall_unk=92.94 total/acc_i=73.64 total/acc_c=67.36 total/h_score=77.24\n",
      "selected:  cs/acc_i=82.22 cs/acc_c=83.13 os/recall_knw=66.37 os/recall_unk=93.84 total/acc_i=73.25 total/acc_c=66.34 total/h_score=76.78\n",
      "Loss: 2.042607634780491\n",
      "Loss: 0.6587214052581327\n",
      "Loss: 0.46650902304043723\n",
      "Loss: 0.3889654827127503\n",
      "Loss: 0.3432899996207075\n",
      "Loss: 0.3155087447842026\n",
      "Loss: 0.27369192661867264\n",
      "Loss: 0.2606589867946036\n",
      "Loss: 0.2368732762382249\n",
      "Loss: 0.2220037987521607\n",
      "______\n",
      "Iteration t=6\n",
      "all:  cs/acc_i=82.44 cs/acc_c=83.29 os/recall_knw=68.41 os/recall_unk=92.94 total/acc_i=73.64 total/acc_c=67.36 total/h_score=77.24\n",
      "selected:  cs/acc_i=82.43 cs/acc_c=83.37 os/recall_knw=67.92 os/recall_unk=93.24 total/acc_i=73.61 total/acc_c=67.24 total/h_score=77.25\n",
      "Loss: 1.998129909362974\n",
      "Loss: 0.6601781517361538\n",
      "Loss: 0.46133943878208533\n",
      "Loss: 0.37881108368687993\n",
      "Loss: 0.33772259620548806\n",
      "Loss: 0.3037136371801548\n",
      "Loss: 0.27115954333751263\n",
      "Loss: 0.24939499862633552\n",
      "Loss: 0.23033862835668686\n",
      "Loss: 0.21598913907250272\n",
      "______\n",
      "Iteration t=7\n",
      "all:  cs/acc_i=82.32 cs/acc_c=83.12 os/recall_knw=68.41 os/recall_unk=92.94 total/acc_i=73.64 total/acc_c=67.36 total/h_score=77.24\n",
      "selected:  cs/acc_i=82.35 cs/acc_c=83.15 os/recall_knw=68.36 os/recall_unk=93.00 total/acc_i=73.66 total/acc_c=67.36 total/h_score=77.26\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 2.0158158971828484\n",
      "Loss: 0.6544254209447957\n",
      "Loss: 0.45467678748024337\n",
      "Loss: 0.38867216615838074\n",
      "Loss: 0.3223794956439696\n",
      "Loss: 0.28757476285334277\n",
      "Loss: 0.2695972339584018\n",
      "Loss: 0.25567178200906926\n",
      "Loss: 0.2246073582356081\n",
      "Loss: 0.22682619559924183\n",
      "______\n",
      "Iteration t=8\n",
      "all:  cs/acc_i=82.29 cs/acc_c=83.20 os/recall_knw=68.41 os/recall_unk=92.94 total/acc_i=73.64 total/acc_c=67.36 total/h_score=77.24\n",
      "selected:  cs/acc_i=82.29 cs/acc_c=83.20 os/recall_knw=68.41 os/recall_unk=92.94 total/acc_i=73.64 total/acc_c=67.36 total/h_score=77.24\n",
      "Loss: 2.002615307861904\n",
      "Loss: 0.652511365149381\n",
      "Loss: 0.4580018295900627\n",
      "Loss: 0.3861959429938088\n",
      "Loss: 0.3334942429367476\n",
      "Loss: 0.30238659012148966\n",
      "Loss: 0.2662815481728915\n",
      "Loss: 0.25189771043991893\n",
      "Loss: 0.22974535464397017\n",
      "Loss: 0.21597576441840743\n",
      "______\n",
      "Iteration t=9\n",
      "all:  cs/acc_i=82.72 cs/acc_c=83.52 os/recall_knw=68.41 os/recall_unk=92.94 total/acc_i=73.64 total/acc_c=67.36 total/h_score=77.24\n",
      "selected:  cs/acc_i=82.72 cs/acc_c=83.52 os/recall_knw=68.41 os/recall_unk=92.94 total/acc_i=73.64 total/acc_c=67.36 total/h_score=77.24\n",
      "tensor(0)\n",
      "all:  cs/acc_i=82.72 cs/acc_c=83.52 os/recall_knw=68.41 os/recall_unk=92.94 total/acc_i=73.64 total/acc_c=67.36 total/h_score=77.24\n",
      "painting -> real lr= 0.001 seed= 4\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19]\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20]\n",
      "Loss: 2.3683815851807593\n",
      "Loss: 0.9792163795481126\n",
      "Loss: 0.6427760357658069\n",
      "Loss: 0.5225721118971706\n",
      "Loss: 0.45990679853906236\n",
      "Loss: 0.43155152052640916\n",
      "Loss: 0.3875532208010554\n",
      "Loss: 0.3581352568541964\n",
      "Loss: 0.32891531866043805\n",
      "Loss: 0.3107946989747385\n",
      "tensor(True) tensor(True)\n",
      "______\n",
      "Iteration t=1\n",
      "all:  cs/acc_i=81.12 cs/acc_c=81.83 os/recall_knw=88.62 os/recall_unk=55.39 total/acc_i=70.44 total/acc_c=76.84 total/h_score=64.75\n",
      "selected:  cs/acc_i=72.63 cs/acc_c=76.56 os/recall_knw=58.79 os/recall_unk=99.65 total/acc_i=77.94 total/acc_c=64.74 total/h_score=77.19\n",
      "Loss: 2.2582128034081568\n",
      "Loss: 0.8497912705868713\n",
      "Loss: 0.5656076233054317\n",
      "Loss: 0.4977398076953814\n",
      "Loss: 0.41934261037859805\n",
      "Loss: 0.3702441132519134\n",
      "Loss: 0.3507332784203134\n",
      "Loss: 0.32789219500020494\n",
      "Loss: 0.2935877081959747\n",
      "Loss: 0.28284027421659275\n",
      "______\n",
      "Iteration t=2\n",
      "all:  cs/acc_i=80.97 cs/acc_c=81.85 os/recall_knw=74.07 os/recall_unk=88.32 total/acc_i=74.83 total/acc_c=70.75 total/h_score=78.02\n",
      "selected:  cs/acc_i=75.14 cs/acc_c=78.28 os/recall_knw=55.32 os/recall_unk=98.99 total/acc_i=72.43 total/acc_c=59.26 total/h_score=72.56\n",
      "Loss: 2.19569885709069\n",
      "Loss: 0.7857962562821128\n",
      "Loss: 0.523144605809992\n",
      "Loss: 0.447917335358533\n",
      "Loss: 0.3841509874300523\n",
      "Loss: 0.3577152669429779\n",
      "Loss: 0.32517765240235763\n",
      "Loss: 0.28115013301372527\n",
      "Loss: 0.27078000523827295\n",
      "Loss: 0.2575878222015771\n",
      "______\n",
      "Iteration t=3\n",
      "all:  cs/acc_i=80.89 cs/acc_c=81.68 os/recall_knw=71.03 os/recall_unk=91.14 total/acc_i=74.09 total/acc_c=68.59 total/h_score=77.53\n",
      "selected:  cs/acc_i=78.33 cs/acc_c=80.23 os/recall_knw=61.61 os/recall_unk=97.26 total/acc_i=72.81 total/acc_c=62.88 total/h_score=75.10\n",
      "Loss: 2.0804647431798178\n",
      "Loss: 0.7173202823694438\n",
      "Loss: 0.48662424985676594\n",
      "Loss: 0.414513304217221\n",
      "Loss: 0.3669951254986737\n",
      "Loss: 0.3374481988585975\n",
      "Loss: 0.3035648119291418\n",
      "Loss: 0.2668975558999467\n",
      "Loss: 0.2590240276839635\n",
      "Loss: 0.23296102378772546\n",
      "______\n",
      "Iteration t=4\n",
      "all:  cs/acc_i=80.97 cs/acc_c=81.70 os/recall_knw=69.88 os/recall_unk=91.98 total/acc_i=73.79 total/acc_c=67.82 total/h_score=77.27\n",
      "selected:  cs/acc_i=79.84 cs/acc_c=80.99 os/recall_knw=65.54 os/recall_unk=94.90 total/acc_i=73.13 total/acc_c=65.15 total/h_score=76.21\n",
      "Loss: 2.0627257087191597\n",
      "Loss: 0.6914139685083608\n",
      "Loss: 0.46069198998271443\n",
      "Loss: 0.39003954585946976\n",
      "Loss: 0.3416860353262698\n",
      "Loss: 0.3082919079016467\n",
      "Loss: 0.2881022046091127\n",
      "Loss: 0.25604336664813465\n",
      "Loss: 0.24274042065514892\n",
      "Loss: 0.220769573980179\n",
      "______\n",
      "Iteration t=5\n",
      "all:  cs/acc_i=81.78 cs/acc_c=82.54 os/recall_knw=69.79 os/recall_unk=92.11 total/acc_i=73.81 total/acc_c=67.81 total/h_score=77.30\n",
      "selected:  cs/acc_i=81.52 cs/acc_c=82.43 os/recall_knw=67.69 os/recall_unk=93.06 total/acc_i=73.51 total/acc_c=66.74 total/h_score=76.83\n",
      "Loss: 2.0270945431712346\n",
      "Loss: 0.643065139842339\n",
      "Loss: 0.45619006407184476\n",
      "Loss: 0.38622143707023215\n",
      "Loss: 0.3410760542759911\n",
      "Loss: 0.3050738145143558\n",
      "Loss: 0.2754052309319377\n",
      "Loss: 0.25838518893728274\n",
      "Loss: 0.23684339587075207\n",
      "Loss: 0.21029504337228644\n",
      "______\n",
      "Iteration t=6\n",
      "all:  cs/acc_i=81.95 cs/acc_c=82.80 os/recall_knw=69.79 os/recall_unk=92.17 total/acc_i=73.83 total/acc_c=67.81 total/h_score=77.32\n",
      "selected:  cs/acc_i=82.11 cs/acc_c=83.01 os/recall_knw=69.22 os/recall_unk=92.76 total/acc_i=73.99 total/acc_c=67.76 total/h_score=77.47\n",
      "Loss: 2.011582128633084\n",
      "Loss: 0.6408746214319103\n",
      "Loss: 0.4485395218859712\n",
      "Loss: 0.3728687480233069\n",
      "Loss: 0.3278205579011598\n",
      "Loss: 0.30271421008587635\n",
      "Loss: 0.284487458457142\n",
      "Loss: 0.25041047115854287\n",
      "Loss: 0.2317392942774747\n",
      "Loss: 0.20721120460176318\n",
      "______\n",
      "Iteration t=7\n",
      "all:  cs/acc_i=81.81 cs/acc_c=82.54 os/recall_knw=69.79 os/recall_unk=92.17 total/acc_i=73.83 total/acc_c=67.81 total/h_score=77.32\n",
      "selected:  cs/acc_i=81.84 cs/acc_c=82.57 os/recall_knw=69.76 os/recall_unk=92.17 total/acc_i=73.85 total/acc_c=67.81 total/h_score=77.32\n",
      "Loss: 1.9914282220284394\n",
      "Loss: 0.6473136753497827\n",
      "Loss: 0.44918250570476614\n",
      "Loss: 0.3663641035463369\n",
      "Loss: 0.3300491691009378\n",
      "Loss: 0.2973634641278874\n",
      "Loss: 0.26160329265000304\n",
      "Loss: 0.26209895291765656\n",
      "Loss: 0.2216845672799502\n",
      "Loss: 0.21137198080603606\n",
      "______\n",
      "Iteration t=8\n",
      "all:  cs/acc_i=81.81 cs/acc_c=82.67 os/recall_knw=69.79 os/recall_unk=92.17 total/acc_i=73.83 total/acc_c=67.81 total/h_score=77.32\n",
      "selected:  cs/acc_i=81.81 cs/acc_c=82.67 os/recall_knw=69.79 os/recall_unk=92.17 total/acc_i=73.83 total/acc_c=67.81 total/h_score=77.32\n",
      "Loss: 1.9970894742757082\n",
      "Loss: 0.6454760699067265\n",
      "Loss: 0.45332030383870003\n",
      "Loss: 0.3762198087060824\n",
      "Loss: 0.33675004621036353\n",
      "Loss: 0.30026143474970013\n",
      "Loss: 0.2723650553147309\n",
      "Loss: 0.2552099960506894\n",
      "Loss: 0.23173051955527627\n",
      "Loss: 0.20804651925573125\n",
      "______\n",
      "Iteration t=9\n",
      "all:  cs/acc_i=82.38 cs/acc_c=83.07 os/recall_knw=69.79 os/recall_unk=92.17 total/acc_i=73.83 total/acc_c=67.81 total/h_score=77.32\n",
      "selected:  cs/acc_i=82.38 cs/acc_c=83.07 os/recall_knw=69.79 os/recall_unk=92.17 total/acc_i=73.83 total/acc_c=67.81 total/h_score=77.32\n",
      "tensor(0)\n",
      "all:  cs/acc_i=82.38 cs/acc_c=83.07 os/recall_knw=69.79 os/recall_unk=92.17 total/acc_i=73.83 total/acc_c=67.81 total/h_score=77.32\n",
      "painting -> real lr= 0.001 seed= 0\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19]\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20]\n",
      "Loss: 2.3610634649793307\n",
      "Loss: 0.9993157677352429\n",
      "Loss: 0.6559835717082023\n",
      "Loss: 0.5393801376223564\n",
      "Loss: 0.47934073007976014\n",
      "Loss: 0.41247847688694794\n",
      "Loss: 0.39040344757959244\n",
      "Loss: 0.3490369419567287\n",
      "Loss: 0.3323675043880939\n",
      "Loss: 0.31882775748769443\n",
      "tensor(True) tensor(True)\n",
      "______\n",
      "Iteration t=1\n",
      "all:  cs/acc_i=80.22 cs/acc_c=81.03 os/recall_knw=89.22 os/recall_unk=56.74 total/acc_i=70.48 total/acc_c=76.51 total/h_score=65.51\n",
      "selected:  cs/acc_i=72.98 cs/acc_c=76.76 os/recall_knw=60.11 os/recall_unk=99.55 total/acc_i=79.05 total/acc_c=65.26 total/h_score=77.57\n",
      "Loss: 2.2622848582822224\n",
      "Loss: 0.8931098914192629\n",
      "Loss: 0.5749475240938423\n",
      "Loss: 0.4866207395066587\n",
      "Loss: 0.41993777794662374\n",
      "Loss: 0.3651609266277894\n",
      "Loss: 0.3426792426684568\n",
      "Loss: 0.3145789340889269\n",
      "Loss: 0.2857521580344485\n",
      "Loss: 0.2748262693080329\n",
      "______\n",
      "Iteration t=2\n",
      "all:  cs/acc_i=80.77 cs/acc_c=81.55 os/recall_knw=73.38 os/recall_unk=89.86 total/acc_i=74.87 total/acc_c=70.06 total/h_score=78.11\n",
      "selected:  cs/acc_i=75.09 cs/acc_c=78.09 os/recall_knw=54.50 os/recall_unk=98.73 total/acc_i=72.08 total/acc_c=58.67 total/h_score=72.00\n",
      "Loss: 2.1838241715864704\n",
      "Loss: 0.784346834637902\n",
      "Loss: 0.5135853118246252\n",
      "Loss: 0.4435869954390959\n",
      "Loss: 0.40645666948773645\n",
      "Loss: 0.36369213087992236\n",
      "Loss: 0.3171754579110579\n",
      "Loss: 0.3098711865327575\n",
      "Loss: 0.270031906014139\n",
      "Loss: 0.25746076521548356\n",
      "______\n",
      "Iteration t=3\n",
      "all:  cs/acc_i=82.15 cs/acc_c=82.99 os/recall_knw=71.31 os/recall_unk=91.46 total/acc_i=74.51 total/acc_c=68.95 total/h_score=77.89\n",
      "selected:  cs/acc_i=80.29 cs/acc_c=82.28 os/recall_knw=61.81 os/recall_unk=97.74 total/acc_i=73.52 total/acc_c=63.89 total/h_score=76.02\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 2.092680060781564\n",
      "Loss: 0.711642354214724\n",
      "Loss: 0.49268547084528147\n",
      "Loss: 0.4044150115083583\n",
      "Loss: 0.3601923920086159\n",
      "Loss: 0.34774589262057826\n",
      "Loss: 0.2940995915444036\n",
      "Loss: 0.27476052043773874\n",
      "Loss: 0.2505351384890448\n",
      "Loss: 0.23312754601342572\n",
      "______\n",
      "Iteration t=4\n",
      "all:  cs/acc_i=82.49 cs/acc_c=83.14 os/recall_knw=70.59 os/recall_unk=91.85 total/acc_i=74.41 total/acc_c=68.68 total/h_score=77.83\n",
      "selected:  cs/acc_i=81.37 cs/acc_c=82.66 os/recall_knw=66.04 os/recall_unk=95.08 total/acc_i=73.70 total/acc_c=66.27 total/h_score=77.09\n",
      "Loss: 2.0616817735135555\n",
      "Loss: 0.676048041860524\n",
      "Loss: 0.4714434684107178\n",
      "Loss: 0.39078414518582194\n",
      "Loss: 0.3473830736291252\n",
      "Loss: 0.31391204552921026\n",
      "Loss: 0.3007744619696352\n",
      "Loss: 0.26828638606361654\n",
      "Loss: 0.23846884717625616\n",
      "Loss: 0.21280507834040022\n",
      "______\n",
      "Iteration t=5\n",
      "all:  cs/acc_i=81.78 cs/acc_c=82.68 os/recall_knw=70.39 os/recall_unk=92.11 total/acc_i=74.37 total/acc_c=68.52 total/h_score=77.80\n",
      "selected:  cs/acc_i=81.23 cs/acc_c=82.45 os/recall_knw=68.20 os/recall_unk=93.06 total/acc_i=73.88 total/acc_c=67.41 total/h_score=77.31\n",
      "Loss: 2.0248005997676115\n",
      "Loss: 0.6669667123410946\n",
      "Loss: 0.4601792732779032\n",
      "Loss: 0.3916126742767982\n",
      "Loss: 0.34168467675455105\n",
      "Loss: 0.310432015106273\n",
      "Loss: 0.2731196267100481\n",
      "Loss: 0.2541730091548883\n",
      "Loss: 0.23450027448005784\n",
      "Loss: 0.2175333851423019\n",
      "______\n",
      "Iteration t=6\n",
      "all:  cs/acc_i=81.92 cs/acc_c=82.81 os/recall_knw=70.37 os/recall_unk=92.11 total/acc_i=74.35 total/acc_c=68.50 total/h_score=77.79\n",
      "selected:  cs/acc_i=81.90 cs/acc_c=82.93 os/recall_knw=69.65 os/recall_unk=92.46 total/acc_i=74.30 total/acc_c=68.36 total/h_score=77.80\n",
      "Loss: 2.0083959926190063\n",
      "Loss: 0.6598124127094678\n",
      "Loss: 0.44166112928548446\n",
      "Loss: 0.3875514985729091\n",
      "Loss: 0.3209037879241002\n",
      "Loss: 0.2953790208847741\n",
      "Loss: 0.26949978311919265\n",
      "Loss: 0.24960981906400495\n",
      "Loss: 0.23872754142299435\n",
      "Loss: 0.21371577683636442\n",
      "______\n",
      "Iteration t=7\n",
      "all:  cs/acc_i=82.15 cs/acc_c=82.77 os/recall_knw=70.37 os/recall_unk=92.11 total/acc_i=74.35 total/acc_c=68.50 total/h_score=77.79\n",
      "selected:  cs/acc_i=82.12 cs/acc_c=82.75 os/recall_knw=70.32 os/recall_unk=92.16 total/acc_i=74.34 total/acc_c=68.47 total/h_score=77.78\n",
      "Loss: 2.006355223990977\n",
      "Loss: 0.6558887740597129\n",
      "Loss: 0.4503347873222083\n",
      "Loss: 0.3794205294223502\n",
      "Loss: 0.3400975787779316\n",
      "Loss: 0.29504891771357505\n",
      "Loss: 0.2760239612078294\n",
      "Loss: 0.23353195853997022\n",
      "Loss: 0.24253982444060967\n",
      "Loss: 0.21638768182019702\n",
      "______\n",
      "Iteration t=8\n",
      "all:  cs/acc_i=82.01 cs/acc_c=82.87 os/recall_knw=70.37 os/recall_unk=92.11 total/acc_i=74.35 total/acc_c=68.50 total/h_score=77.79\n",
      "selected:  cs/acc_i=82.01 cs/acc_c=82.87 os/recall_knw=70.37 os/recall_unk=92.11 total/acc_i=74.35 total/acc_c=68.50 total/h_score=77.79\n",
      "Loss: 1.9897028570994735\n",
      "Loss: 0.6324394686147571\n",
      "Loss: 0.4417915786150843\n",
      "Loss: 0.37020891681313517\n",
      "Loss: 0.33405643394216894\n",
      "Loss: 0.29291746406815944\n",
      "Loss: 0.2655959366238676\n",
      "Loss: 0.24593070449773222\n",
      "Loss: 0.23312377267284318\n",
      "Loss: 0.20762716822791843\n",
      "______\n",
      "Iteration t=9\n",
      "all:  cs/acc_i=82.35 cs/acc_c=83.26 os/recall_knw=70.37 os/recall_unk=92.11 total/acc_i=74.35 total/acc_c=68.50 total/h_score=77.79\n",
      "selected:  cs/acc_i=82.35 cs/acc_c=83.26 os/recall_knw=70.37 os/recall_unk=92.11 total/acc_i=74.35 total/acc_c=68.50 total/h_score=77.79\n",
      "tensor(0)\n",
      "all:  cs/acc_i=82.35 cs/acc_c=83.26 os/recall_knw=70.37 os/recall_unk=92.11 total/acc_i=74.35 total/acc_c=68.50 total/h_score=77.79\n",
      "painting -> real lr= 0.001 seed= 1\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19]\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20]\n",
      "Loss: 2.3798931166529655\n",
      "Loss: 0.9973608318716287\n",
      "Loss: 0.637513430416584\n",
      "Loss: 0.5411548479149739\n",
      "Loss: 0.46879895639916264\n",
      "Loss: 0.40036175853262346\n",
      "Loss: 0.39480016343295576\n",
      "Loss: 0.35570540139451623\n",
      "Loss: 0.34220177919293443\n",
      "Loss: 0.3039160477773597\n",
      "tensor(True) tensor(True)\n",
      "______\n",
      "Iteration t=1\n",
      "all:  cs/acc_i=80.94 cs/acc_c=81.65 os/recall_knw=88.96 os/recall_unk=56.16 total/acc_i=70.82 total/acc_c=77.09 total/h_score=65.35\n",
      "selected:  cs/acc_i=72.48 cs/acc_c=76.53 os/recall_knw=59.66 os/recall_unk=99.77 total/acc_i=78.79 total/acc_c=65.69 total/h_score=77.97\n",
      "Loss: 2.2809662758841993\n",
      "Loss: 0.8728887875412785\n",
      "Loss: 0.5813182756420254\n",
      "Loss: 0.48078044896671013\n",
      "Loss: 0.4312553994299829\n",
      "Loss: 0.3866964528380438\n",
      "Loss: 0.3521616558233897\n",
      "Loss: 0.3167519161347733\n",
      "Loss: 0.2983031284150689\n",
      "Loss: 0.27758677465509074\n",
      "______\n",
      "Iteration t=2\n",
      "all:  cs/acc_i=81.32 cs/acc_c=81.94 os/recall_knw=72.32 os/recall_unk=89.99 total/acc_i=74.51 total/acc_c=69.52 total/h_score=77.78\n",
      "selected:  cs/acc_i=75.97 cs/acc_c=78.69 os/recall_knw=53.72 os/recall_unk=99.22 total/acc_i=71.69 total/acc_c=58.26 total/h_score=71.77\n",
      "Loss: 2.169272689602592\n",
      "Loss: 0.7563041138648987\n",
      "Loss: 0.5341460199247707\n",
      "Loss: 0.4374150527607311\n",
      "Loss: 0.3985498168251731\n",
      "Loss: 0.3397251357815482\n",
      "Loss: 0.32250579395077444\n",
      "Loss: 0.28186462052843786\n",
      "Loss: 0.27319504835388875\n",
      "Loss: 0.2415719972686334\n",
      "______\n",
      "Iteration t=3\n",
      "all:  cs/acc_i=82.35 cs/acc_c=82.93 os/recall_knw=69.62 os/recall_unk=92.62 total/acc_i=74.23 total/acc_c=68.17 total/h_score=77.71\n",
      "selected:  cs/acc_i=80.07 cs/acc_c=81.70 os/recall_knw=60.56 os/recall_unk=98.03 total/acc_i=72.74 total/acc_c=62.76 total/h_score=75.20\n",
      "Loss: 2.109823233256601\n",
      "Loss: 0.7188364427587758\n",
      "Loss: 0.5043510836995628\n",
      "Loss: 0.4259838269997949\n",
      "Loss: 0.3564987364033722\n",
      "Loss: 0.32897165959879554\n",
      "Loss: 0.30792286155158527\n",
      "Loss: 0.2703234616616001\n",
      "Loss: 0.2622023398082142\n",
      "Loss: 0.22195730082792778\n",
      "______\n",
      "Iteration t=4\n",
      "all:  cs/acc_i=82.21 cs/acc_c=82.80 os/recall_knw=69.27 os/recall_unk=92.94 total/acc_i=74.15 total/acc_c=67.94 total/h_score=77.66\n",
      "selected:  cs/acc_i=81.27 cs/acc_c=82.33 os/recall_knw=64.87 os/recall_unk=95.58 total/acc_i=73.45 total/acc_c=65.41 total/h_score=76.60\n",
      "Loss: 2.039391230595739\n",
      "Loss: 0.6706609380872626\n",
      "Loss: 0.4719844409509709\n",
      "Loss: 0.38480861521767157\n",
      "Loss: 0.34346253696927115\n",
      "Loss: 0.31213217857293785\n",
      "Loss: 0.2897332365943217\n",
      "Loss: 0.25674062403605175\n",
      "Loss: 0.24040735780114406\n",
      "Loss: 0.2291417841885337\n",
      "______\n",
      "Iteration t=5\n",
      "all:  cs/acc_i=82.38 cs/acc_c=83.21 os/recall_knw=69.01 os/recall_unk=93.32 total/acc_i=74.21 total/acc_c=67.87 total/h_score=77.73\n",
      "selected:  cs/acc_i=81.99 cs/acc_c=83.00 os/recall_knw=67.09 os/recall_unk=94.17 total/acc_i=73.82 total/acc_c=66.83 total/h_score=77.23\n",
      "Loss: 2.043240661023131\n",
      "Loss: 0.6454916494835611\n",
      "Loss: 0.4536860596232859\n",
      "Loss: 0.3835245979368878\n",
      "Loss: 0.3271233347690757\n",
      "Loss: 0.30237885166881934\n",
      "Loss: 0.2760712493606319\n",
      "Loss: 0.267118773851364\n",
      "Loss: 0.23546129103354702\n",
      "Loss: 0.21309954002260012\n",
      "______\n",
      "Iteration t=6\n",
      "all:  cs/acc_i=82.75 cs/acc_c=83.39 os/recall_knw=68.99 os/recall_unk=93.32 total/acc_i=74.19 total/acc_c=67.84 total/h_score=77.70\n",
      "selected:  cs/acc_i=82.76 cs/acc_c=83.45 os/recall_knw=68.37 os/recall_unk=93.75 total/acc_i=74.18 total/acc_c=67.66 total/h_score=77.71\n",
      "Loss: 2.023020387450351\n",
      "Loss: 0.6566235907847369\n",
      "Loss: 0.4567264378353765\n",
      "Loss: 0.36361691966369936\n",
      "Loss: 0.32817832312157635\n",
      "Loss: 0.30403130579315407\n",
      "Loss: 0.27490283769284246\n",
      "Loss: 0.2384667584696148\n",
      "Loss: 0.22786462380067457\n",
      "Loss: 0.20731681864708662\n",
      "______\n",
      "Iteration t=7\n",
      "all:  cs/acc_i=82.38 cs/acc_c=83.22 os/recall_knw=68.96 os/recall_unk=93.32 total/acc_i=74.19 total/acc_c=67.84 total/h_score=77.70\n",
      "selected:  cs/acc_i=82.37 cs/acc_c=83.22 os/recall_knw=68.94 os/recall_unk=93.50 total/acc_i=74.22 total/acc_c=67.83 total/h_score=77.76\n",
      "Loss: 1.9919347504399858\n",
      "Loss: 0.6396974139618423\n",
      "Loss: 0.4624160363707902\n",
      "Loss: 0.360428327425096\n",
      "Loss: 0.3191745842824567\n",
      "Loss: 0.29915949421108895\n",
      "Loss: 0.27887645607474465\n",
      "Loss: 0.23662326869162373\n",
      "Loss: 0.23225981313383803\n",
      "Loss: 0.2056762396398955\n",
      "______\n",
      "Iteration t=8\n",
      "all:  cs/acc_i=82.15 cs/acc_c=82.72 os/recall_knw=68.96 os/recall_unk=93.32 total/acc_i=74.19 total/acc_c=67.84 total/h_score=77.70\n",
      "selected:  cs/acc_i=82.15 cs/acc_c=82.72 os/recall_knw=68.96 os/recall_unk=93.32 total/acc_i=74.19 total/acc_c=67.84 total/h_score=77.70\n",
      "Loss: 1.9821342947722982\n",
      "Loss: 0.631809597120345\n",
      "Loss: 0.4379707318525644\n",
      "Loss: 0.3747100671460419\n",
      "Loss: 0.32962070232104956\n",
      "Loss: 0.29421653884386867\n",
      "Loss: 0.27600110364410113\n",
      "Loss: 0.25225258292923186\n",
      "Loss: 0.23629357758323727\n",
      "Loss: 0.221092982006804\n",
      "______\n",
      "Iteration t=9\n",
      "all:  cs/acc_i=83.04 cs/acc_c=83.81 os/recall_knw=68.96 os/recall_unk=93.32 total/acc_i=74.19 total/acc_c=67.84 total/h_score=77.70\n",
      "selected:  cs/acc_i=83.04 cs/acc_c=83.81 os/recall_knw=68.96 os/recall_unk=93.32 total/acc_i=74.19 total/acc_c=67.84 total/h_score=77.70\n",
      "tensor(0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all:  cs/acc_i=83.04 cs/acc_c=83.81 os/recall_knw=68.96 os/recall_unk=93.32 total/acc_i=74.19 total/acc_c=67.84 total/h_score=77.70\n",
      "painting -> real lr= 0.001 seed= 2\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19]\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20]\n",
      "Loss: 2.361146968106429\n",
      "Loss: 0.9944388960798581\n",
      "Loss: 0.6416718643158674\n",
      "Loss: 0.5286842061206698\n",
      "Loss: 0.4524672037611405\n",
      "Loss: 0.43657453193639717\n",
      "Loss: 0.3754879340529442\n",
      "Loss: 0.35598462264363967\n",
      "Loss: 0.33114132763197024\n",
      "Loss: 0.3059792855133613\n",
      "tensor(True) tensor(True)\n",
      "______\n",
      "Iteration t=1\n",
      "all:  cs/acc_i=81.09 cs/acc_c=81.78 os/recall_knw=88.88 os/recall_unk=55.97 total/acc_i=70.84 total/acc_c=77.25 total/h_score=65.28\n",
      "selected:  cs/acc_i=72.09 cs/acc_c=76.00 os/recall_knw=59.39 os/recall_unk=99.66 total/acc_i=78.45 total/acc_c=65.31 total/h_score=77.64\n",
      "Loss: 2.268520167631696\n",
      "Loss: 0.873707580473996\n",
      "Loss: 0.5858243284530418\n",
      "Loss: 0.4931702371831088\n",
      "Loss: 0.4140012323163276\n",
      "Loss: 0.3885101917986722\n",
      "Loss: 0.34362149905673295\n",
      "Loss: 0.3247319816272388\n",
      "Loss: 0.3047223673310391\n",
      "Loss: 0.291031953322795\n",
      "______\n",
      "Iteration t=2\n",
      "all:  cs/acc_i=80.97 cs/acc_c=81.65 os/recall_knw=71.23 os/recall_unk=90.82 total/acc_i=74.33 total/acc_c=68.79 total/h_score=77.56\n",
      "selected:  cs/acc_i=74.63 cs/acc_c=77.74 os/recall_knw=52.63 os/recall_unk=98.81 total/acc_i=70.63 total/acc_c=56.93 total/h_score=70.53\n",
      "Loss: 2.1692358088493346\n",
      "Loss: 0.7824513500387018\n",
      "Loss: 0.5284382697127082\n",
      "Loss: 0.4302861881797964\n",
      "Loss: 0.3940050212361596\n",
      "Loss: 0.34778385926376687\n",
      "Loss: 0.32940448159521274\n",
      "Loss: 0.2908982549065893\n",
      "Loss: 0.26367910442027176\n",
      "Loss: 0.25959183864972807\n",
      "______\n",
      "Iteration t=3\n",
      "all:  cs/acc_i=82.38 cs/acc_c=83.00 os/recall_knw=68.84 os/recall_unk=93.26 total/acc_i=73.93 total/acc_c=67.31 total/h_score=77.31\n",
      "selected:  cs/acc_i=79.86 cs/acc_c=81.64 os/recall_knw=59.57 os/recall_unk=97.26 total/acc_i=71.83 total/acc_c=61.68 total/h_score=74.14\n",
      "Loss: 2.1045357072885915\n",
      "Loss: 0.7227584060115093\n",
      "Loss: 0.4903670700964649\n",
      "Loss: 0.40776790023054865\n",
      "Loss: 0.364495424470541\n",
      "Loss: 0.319358812267428\n",
      "Loss: 0.3111482061368903\n",
      "Loss: 0.2652919715161586\n",
      "Loss: 0.25459259121176303\n",
      "Loss: 0.2372300451512599\n",
      "______\n",
      "Iteration t=4\n",
      "all:  cs/acc_i=82.41 cs/acc_c=83.08 os/recall_knw=68.21 os/recall_unk=93.71 total/acc_i=73.81 total/acc_c=67.00 total/h_score=77.22\n",
      "selected:  cs/acc_i=81.40 cs/acc_c=82.57 os/recall_knw=63.71 os/recall_unk=95.93 total/acc_i=72.91 total/acc_c=64.38 total/h_score=75.91\n",
      "Loss: 2.0443281346421824\n",
      "Loss: 0.6721231944293472\n",
      "Loss: 0.4717796351945046\n",
      "Loss: 0.3902900329861704\n",
      "Loss: 0.35350873513091907\n",
      "Loss: 0.3282999988805146\n",
      "Loss: 0.28974051864528816\n",
      "Loss: 0.26080993892434406\n",
      "Loss: 0.24094209040548936\n",
      "Loss: 0.23008426912005978\n",
      "______\n",
      "Iteration t=5\n",
      "all:  cs/acc_i=81.52 cs/acc_c=82.41 os/recall_knw=68.21 os/recall_unk=93.71 total/acc_i=73.81 total/acc_c=67.00 total/h_score=77.22\n",
      "selected:  cs/acc_i=80.98 cs/acc_c=82.25 os/recall_knw=66.06 os/recall_unk=94.38 total/acc_i=73.26 total/acc_c=65.95 total/h_score=76.65\n",
      "Loss: 2.0282280877713235\n",
      "Loss: 0.6635425220093419\n",
      "Loss: 0.44743767448009986\n",
      "Loss: 0.38743894213149627\n",
      "Loss: 0.32782359089582197\n",
      "Loss: 0.30554571194994834\n",
      "Loss: 0.2803674709893042\n",
      "Loss: 0.26878094887060505\n",
      "Loss: 0.23624532924544428\n",
      "Loss: 0.2238447131769311\n",
      "______\n",
      "Iteration t=6\n",
      "all:  cs/acc_i=82.32 cs/acc_c=82.99 os/recall_knw=68.21 os/recall_unk=93.84 total/acc_i=73.85 total/acc_c=67.01 total/h_score=77.26\n",
      "selected:  cs/acc_i=82.34 cs/acc_c=83.09 os/recall_knw=67.72 os/recall_unk=94.08 total/acc_i=73.84 total/acc_c=66.88 total/h_score=77.25\n",
      "Loss: 2.0331136565359813\n",
      "Loss: 0.6570672148749942\n",
      "Loss: 0.4530345617305665\n",
      "Loss: 0.3803553258852353\n",
      "Loss: 0.3348922171526485\n",
      "Loss: 0.30277123640454007\n",
      "Loss: 0.2761576057426513\n",
      "Loss: 0.2605417265068917\n",
      "Loss: 0.2354361001934324\n",
      "Loss: 0.2099730166769217\n",
      "______\n",
      "Iteration t=7\n",
      "all:  cs/acc_i=81.86 cs/acc_c=82.58 os/recall_knw=68.21 os/recall_unk=93.90 total/acc_i=73.87 total/acc_c=67.01 total/h_score=77.28\n",
      "selected:  cs/acc_i=81.85 cs/acc_c=82.57 os/recall_knw=68.14 os/recall_unk=93.96 total/acc_i=73.87 total/acc_c=66.98 total/h_score=77.28\n",
      "Loss: 2.0232309031561724\n",
      "Loss: 0.6400207001892174\n",
      "Loss: 0.4498320251985303\n",
      "Loss: 0.3801904975991896\n",
      "Loss: 0.3266738521446377\n",
      "Loss: 0.3093735731973633\n",
      "Loss: 0.2746408921828029\n",
      "Loss: 0.24779882432440478\n",
      "Loss: 0.22860678045625565\n",
      "Loss: 0.21562262401219798\n",
      "______\n",
      "Iteration t=8\n",
      "all:  cs/acc_i=82.44 cs/acc_c=83.26 os/recall_knw=68.21 os/recall_unk=93.90 total/acc_i=73.87 total/acc_c=67.01 total/h_score=77.28\n",
      "selected:  cs/acc_i=82.44 cs/acc_c=83.26 os/recall_knw=68.21 os/recall_unk=93.90 total/acc_i=73.87 total/acc_c=67.01 total/h_score=77.28\n",
      "Loss: 1.9859633611203744\n",
      "Loss: 0.6523659584650106\n",
      "Loss: 0.4543231476086547\n",
      "Loss: 0.37960763153405597\n",
      "Loss: 0.32397155231011776\n",
      "Loss: 0.2922654880169626\n",
      "Loss: 0.2698990001874955\n",
      "Loss: 0.2527619674449275\n",
      "Loss: 0.23537269722353021\n",
      "Loss: 0.21577463934803234\n",
      "______\n",
      "Iteration t=9\n",
      "all:  cs/acc_i=82.61 cs/acc_c=83.25 os/recall_knw=68.21 os/recall_unk=93.90 total/acc_i=73.87 total/acc_c=67.01 total/h_score=77.28\n",
      "selected:  cs/acc_i=82.61 cs/acc_c=83.25 os/recall_knw=68.21 os/recall_unk=93.90 total/acc_i=73.87 total/acc_c=67.01 total/h_score=77.28\n",
      "tensor(0)\n",
      "all:  cs/acc_i=82.61 cs/acc_c=83.25 os/recall_knw=68.21 os/recall_unk=93.90 total/acc_i=73.87 total/acc_c=67.01 total/h_score=77.28\n",
      "painting -> real lr= 0.001 seed= 3\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19]\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20]\n",
      "Loss: 2.3629763836661977\n",
      "Loss: 1.0012465932716925\n",
      "Loss: 0.6498804145803054\n",
      "Loss: 0.5390750417485833\n",
      "Loss: 0.46276297376801573\n",
      "Loss: 0.419917997221152\n",
      "Loss: 0.37624870824317136\n",
      "Loss: 0.34479167135432365\n",
      "Loss: 0.3231082626308004\n",
      "Loss: 0.3135604090988636\n",
      "tensor(True) tensor(True)\n",
      "______\n",
      "Iteration t=1\n",
      "all:  cs/acc_i=81.43 cs/acc_c=82.28 os/recall_knw=89.28 os/recall_unk=56.87 total/acc_i=71.11 total/acc_c=77.42 total/h_score=65.94\n",
      "selected:  cs/acc_i=74.20 cs/acc_c=77.99 os/recall_knw=60.23 os/recall_unk=99.77 total/acc_i=79.13 total/acc_c=66.12 total/h_score=78.30\n",
      "Loss: 2.2580020088095996\n",
      "Loss: 0.8677006589118824\n",
      "Loss: 0.5902942383820696\n",
      "Loss: 0.48991329517475396\n",
      "Loss: 0.4245330907346666\n",
      "Loss: 0.3763556424961534\n",
      "Loss: 0.3539859729046507\n",
      "Loss: 0.31491137180448503\n",
      "Loss: 0.2915192318343839\n",
      "Loss: 0.27919518586623576\n",
      "______\n",
      "Iteration t=2\n",
      "all:  cs/acc_i=81.20 cs/acc_c=82.00 os/recall_knw=71.05 os/recall_unk=91.14 total/acc_i=74.37 total/acc_c=68.97 total/h_score=77.79\n",
      "selected:  cs/acc_i=75.04 cs/acc_c=78.62 os/recall_knw=52.57 os/recall_unk=99.02 total/acc_i=70.68 total/acc_c=57.52 total/h_score=71.09\n",
      "Loss: 2.190444368665869\n",
      "Loss: 0.7745320785045624\n",
      "Loss: 0.5198518567193638\n",
      "Loss: 0.4340689858252352\n",
      "Loss: 0.3867001586881551\n",
      "Loss: 0.3434562321549112\n",
      "Loss: 0.3254173757271333\n",
      "Loss: 0.2952512296763333\n",
      "Loss: 0.2751136232235215\n",
      "Loss: 0.2691428199952299\n",
      "______\n",
      "Iteration t=3\n",
      "all:  cs/acc_i=81.49 cs/acc_c=82.22 os/recall_knw=69.47 os/recall_unk=92.36 total/acc_i=74.05 total/acc_c=68.08 total/h_score=77.57\n",
      "selected:  cs/acc_i=78.75 cs/acc_c=80.70 os/recall_knw=60.19 os/recall_unk=97.89 total/acc_i=72.40 total/acc_c=62.56 total/h_score=75.00\n",
      "Loss: 2.110215521555176\n",
      "Loss: 0.7074681968008939\n",
      "Loss: 0.5029016563675248\n",
      "Loss: 0.42453497223223197\n",
      "Loss: 0.3639313312074573\n",
      "Loss: 0.31585835993187533\n",
      "Loss: 0.30506923106015754\n",
      "Loss: 0.26917825009405\n",
      "Loss: 0.26247065025301736\n",
      "Loss: 0.24056427159004196\n",
      "______\n",
      "Iteration t=4\n",
      "all:  cs/acc_i=82.38 cs/acc_c=83.13 os/recall_knw=68.99 os/recall_unk=92.75 total/acc_i=73.97 total/acc_c=67.84 total/h_score=77.52\n",
      "selected:  cs/acc_i=81.27 cs/acc_c=82.69 os/recall_knw=64.24 os/recall_unk=94.75 total/acc_i=72.92 total/acc_c=65.19 total/h_score=76.19\n",
      "Loss: 2.072603642547091\n",
      "Loss: 0.684785203817654\n",
      "Loss: 0.4638654720960277\n",
      "Loss: 0.4081772197001051\n",
      "Loss: 0.3412979934917818\n",
      "Loss: 0.3191349873497541\n",
      "Loss: 0.288603943173248\n",
      "Loss: 0.2582829641331934\n",
      "Loss: 0.2389784207684372\n",
      "Loss: 0.21718810131103292\n",
      "______\n",
      "Iteration t=5\n",
      "all:  cs/acc_i=82.06 cs/acc_c=82.83 os/recall_knw=68.90 os/recall_unk=92.81 total/acc_i=73.95 total/acc_c=67.79 total/h_score=77.51\n",
      "selected:  cs/acc_i=81.73 cs/acc_c=82.68 os/recall_knw=66.99 os/recall_unk=93.53 total/acc_i=73.57 total/acc_c=66.77 total/h_score=77.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 2.03082483739425\n",
      "Loss: 0.6375523682397145\n",
      "Loss: 0.466801073640967\n",
      "Loss: 0.37404435369162226\n",
      "Loss: 0.34328652252084935\n",
      "Loss: 0.2989831239176102\n",
      "Loss: 0.27432261493343574\n",
      "Loss: 0.2546153691454002\n",
      "Loss: 0.23181613180069968\n",
      "Loss: 0.22278541893674395\n",
      "______\n",
      "Iteration t=6\n",
      "all:  cs/acc_i=82.35 cs/acc_c=83.06 os/recall_knw=68.81 os/recall_unk=92.81 total/acc_i=73.93 total/acc_c=67.76 total/h_score=77.49\n",
      "selected:  cs/acc_i=82.20 cs/acc_c=83.03 os/recall_knw=68.24 os/recall_unk=93.29 total/acc_i=73.84 total/acc_c=67.50 total/h_score=77.45\n",
      "Loss: 1.987129889711549\n",
      "Loss: 0.6314879410629031\n",
      "Loss: 0.444704535499781\n",
      "Loss: 0.3720226610385919\n",
      "Loss: 0.34543405053547666\n",
      "Loss: 0.29412411938456795\n",
      "Loss: 0.277354045040151\n",
      "Loss: 0.25321616701593125\n",
      "Loss: 0.22759289938154853\n",
      "Loss: 0.21249104832310842\n",
      "______\n",
      "Iteration t=7\n",
      "all:  cs/acc_i=82.29 cs/acc_c=82.96 os/recall_knw=68.76 os/recall_unk=92.88 total/acc_i=73.91 total/acc_c=67.71 total/h_score=77.47\n",
      "selected:  cs/acc_i=82.31 cs/acc_c=82.98 os/recall_knw=68.67 os/recall_unk=92.94 total/acc_i=73.92 total/acc_c=67.69 total/h_score=77.48\n",
      "Loss: 2.0085321117497092\n",
      "Loss: 0.6486113370402055\n",
      "Loss: 0.4666150393163633\n",
      "Loss: 0.3921582303332083\n",
      "Loss: 0.32710351614550975\n",
      "Loss: 0.30263762137378164\n",
      "Loss: 0.2767721953678806\n",
      "Loss: 0.2553384725660461\n",
      "Loss: 0.2254926216489864\n",
      "Loss: 0.22415603912851345\n",
      "______\n",
      "Iteration t=8\n",
      "all:  cs/acc_i=82.49 cs/acc_c=83.18 os/recall_knw=68.76 os/recall_unk=92.88 total/acc_i=73.91 total/acc_c=67.71 total/h_score=77.47\n",
      "selected:  cs/acc_i=82.49 cs/acc_c=83.18 os/recall_knw=68.76 os/recall_unk=92.88 total/acc_i=73.91 total/acc_c=67.71 total/h_score=77.47\n",
      "Loss: 2.014537249158763\n",
      "Loss: 0.6543903518585289\n",
      "Loss: 0.4386870402303882\n",
      "Loss: 0.37782386976218074\n",
      "Loss: 0.3251137982046454\n",
      "Loss: 0.3013069099459633\n",
      "Loss: 0.27001569805514514\n",
      "Loss: 0.24281149420816944\n",
      "Loss: 0.23527688400691035\n",
      "Loss: 0.21153988019100525\n",
      "______\n",
      "Iteration t=9\n",
      "all:  cs/acc_i=82.09 cs/acc_c=82.87 os/recall_knw=68.76 os/recall_unk=92.88 total/acc_i=73.91 total/acc_c=67.71 total/h_score=77.47\n",
      "selected:  cs/acc_i=82.09 cs/acc_c=82.87 os/recall_knw=68.76 os/recall_unk=92.88 total/acc_i=73.91 total/acc_c=67.71 total/h_score=77.47\n",
      "tensor(0)\n",
      "all:  cs/acc_i=82.09 cs/acc_c=82.87 os/recall_knw=68.76 os/recall_unk=92.88 total/acc_i=73.91 total/acc_c=67.71 total/h_score=77.47\n",
      "painting -> real lr= 0.001 seed= 4\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19]\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20]\n",
      "Loss: 2.3681852628787357\n",
      "Loss: 0.9797646217048168\n",
      "Loss: 0.642498217150569\n",
      "Loss: 0.5227559062341849\n",
      "Loss: 0.4603137445325653\n",
      "Loss: 0.43234141419331235\n",
      "Loss: 0.388226886279881\n",
      "Loss: 0.35825645591442784\n",
      "Loss: 0.32954608018820486\n",
      "Loss: 0.3122542496149739\n",
      "tensor(True) tensor(True)\n",
      "______\n",
      "Iteration t=1\n",
      "all:  cs/acc_i=81.20 cs/acc_c=81.86 os/recall_knw=88.82 os/recall_unk=55.84 total/acc_i=70.70 total/acc_c=76.98 total/h_score=65.10\n",
      "selected:  cs/acc_i=72.75 cs/acc_c=76.82 os/recall_knw=59.22 os/recall_unk=99.66 total/acc_i=78.27 total/acc_c=64.99 total/h_score=77.39\n",
      "Loss: 2.262614243021307\n",
      "Loss: 0.8570572549058485\n",
      "Loss: 0.5836232167112735\n",
      "Loss: 0.4857889659587265\n",
      "Loss: 0.4259127222810143\n",
      "Loss: 0.3679653801774794\n",
      "Loss: 0.3367581863909267\n",
      "Loss: 0.33065827482546023\n",
      "Loss: 0.2944406826020211\n",
      "Loss: 0.2822491740591304\n",
      "______\n",
      "Iteration t=2\n",
      "all:  cs/acc_i=81.78 cs/acc_c=82.61 os/recall_knw=71.72 os/recall_unk=90.50 total/acc_i=74.51 total/acc_c=69.33 total/h_score=77.83\n",
      "selected:  cs/acc_i=75.89 cs/acc_c=79.34 os/recall_knw=53.03 os/recall_unk=98.81 total/acc_i=70.93 total/acc_c=57.77 total/h_score=71.25\n",
      "Loss: 2.1789618132331157\n",
      "Loss: 0.7798938434774225\n",
      "Loss: 0.535620583079078\n",
      "Loss: 0.44284783298319036\n",
      "Loss: 0.38821379734711214\n",
      "Loss: 0.3522916147925637\n",
      "Loss: 0.3083616649291732\n",
      "Loss: 0.29644413365559147\n",
      "Loss: 0.2726726810498671\n",
      "Loss: 0.25173460629853334\n",
      "______\n",
      "Iteration t=3\n",
      "all:  cs/acc_i=81.23 cs/acc_c=81.98 os/recall_knw=68.76 os/recall_unk=92.23 total/acc_i=73.52 total/acc_c=67.23 total/h_score=76.93\n",
      "selected:  cs/acc_i=78.13 cs/acc_c=80.03 os/recall_knw=59.44 os/recall_unk=96.77 total/acc_i=71.33 total/acc_c=60.81 total/h_score=73.31\n",
      "Loss: 2.0993592245472255\n",
      "Loss: 0.713272436275515\n",
      "Loss: 0.4920972123281243\n",
      "Loss: 0.40258255887687\n",
      "Loss: 0.3607776530624665\n",
      "Loss: 0.320162971468828\n",
      "Loss: 0.30712886108565574\n",
      "Loss: 0.2730959904767394\n",
      "Loss: 0.2667594449370587\n",
      "Loss: 0.23897497276567511\n",
      "______\n",
      "Iteration t=4\n",
      "all:  cs/acc_i=81.92 cs/acc_c=82.60 os/recall_knw=68.27 os/recall_unk=92.68 total/acc_i=73.46 total/acc_c=66.98 total/h_score=76.89\n",
      "selected:  cs/acc_i=80.60 cs/acc_c=81.69 os/recall_knw=63.71 os/recall_unk=95.25 total/acc_i=72.44 total/acc_c=64.03 total/h_score=75.45\n",
      "Loss: 2.0540436104972764\n",
      "Loss: 0.6885339754446111\n",
      "Loss: 0.4765526961670457\n",
      "Loss: 0.39300909825284097\n",
      "Loss: 0.34697494670601176\n",
      "Loss: 0.31998874092161067\n",
      "Loss: 0.29718381144327694\n",
      "Loss: 0.2659077245508484\n",
      "Loss: 0.2500596736794454\n",
      "Loss: 0.22178069821777124\n",
      "______\n",
      "Iteration t=5\n",
      "all:  cs/acc_i=81.92 cs/acc_c=82.47 os/recall_knw=68.07 os/recall_unk=92.88 total/acc_i=73.44 total/acc_c=66.85 total/h_score=76.85\n",
      "selected:  cs/acc_i=81.55 cs/acc_c=82.09 os/recall_knw=66.46 os/recall_unk=93.48 total/acc_i=73.05 total/acc_c=65.78 total/h_score=76.26\n",
      "Loss: 2.0091392497221627\n",
      "Loss: 0.65418024150989\n",
      "Loss: 0.4551960712728592\n",
      "Loss: 0.3879250973606339\n",
      "Loss: 0.34299950707608307\n",
      "Loss: 0.3013908384749905\n",
      "Loss: 0.2736485661604466\n",
      "Loss: 0.2636683793165363\n",
      "Loss: 0.2252370012112153\n",
      "Loss: 0.20786308098393372\n",
      "______\n",
      "Iteration t=6\n",
      "all:  cs/acc_i=81.95 cs/acc_c=82.58 os/recall_knw=68.01 os/recall_unk=92.94 total/acc_i=73.42 total/acc_c=66.80 total/h_score=76.84\n",
      "selected:  cs/acc_i=81.93 cs/acc_c=82.57 os/recall_knw=67.40 os/recall_unk=93.48 total/acc_i=73.42 total/acc_c=66.53 total/h_score=76.81\n",
      "Loss: 2.013539400554839\n",
      "Loss: 0.653358059743094\n",
      "Loss: 0.47664866655591936\n",
      "Loss: 0.3747412724154336\n",
      "Loss: 0.3161232696166114\n",
      "Loss: 0.3129737795345367\n",
      "Loss: 0.28462820469386996\n",
      "Loss: 0.2600294090334385\n",
      "Loss: 0.24121993424163923\n",
      "Loss: 0.2206579634003223\n",
      "______\n",
      "Iteration t=7\n",
      "all:  cs/acc_i=81.78 cs/acc_c=82.45 os/recall_knw=67.98 os/recall_unk=92.94 total/acc_i=73.40 total/acc_c=66.75 total/h_score=76.81\n",
      "selected:  cs/acc_i=81.77 cs/acc_c=82.46 os/recall_knw=67.91 os/recall_unk=93.00 total/acc_i=73.39 total/acc_c=66.75 total/h_score=76.82\n",
      "Loss: 1.9923028613114582\n",
      "Loss: 0.6499617213518462\n",
      "Loss: 0.442634222729349\n",
      "Loss: 0.3773902847610814\n",
      "Loss: 0.32524607626703633\n",
      "Loss: 0.29680389323351136\n",
      "Loss: 0.27093965339265785\n",
      "Loss: 0.25515642703425623\n",
      "Loss: 0.22987132099947719\n",
      "Loss: 0.21836288082956892\n",
      "______\n",
      "Iteration t=8\n",
      "all:  cs/acc_i=82.44 cs/acc_c=83.17 os/recall_knw=67.98 os/recall_unk=92.94 total/acc_i=73.40 total/acc_c=66.75 total/h_score=76.81\n",
      "selected:  cs/acc_i=82.44 cs/acc_c=83.17 os/recall_knw=67.98 os/recall_unk=92.94 total/acc_i=73.40 total/acc_c=66.75 total/h_score=76.81\n",
      "Loss: 1.9997291252816136\n",
      "Loss: 0.651867749563151\n",
      "Loss: 0.4473262405733957\n",
      "Loss: 0.3684778958559036\n",
      "Loss: 0.3326312927323561\n",
      "Loss: 0.30031518776804117\n",
      "Loss: 0.27175322769662186\n",
      "Loss: 0.25729117568359017\n",
      "Loss: 0.23254248456388993\n",
      "Loss: 0.21626556598895733\n",
      "______\n",
      "Iteration t=9\n",
      "all:  cs/acc_i=81.95 cs/acc_c=82.86 os/recall_knw=67.98 os/recall_unk=92.94 total/acc_i=73.40 total/acc_c=66.75 total/h_score=76.81\n",
      "selected:  cs/acc_i=81.95 cs/acc_c=82.86 os/recall_knw=67.98 os/recall_unk=92.94 total/acc_i=73.40 total/acc_c=66.75 total/h_score=76.81\n",
      "tensor(0)\n",
      "all:  cs/acc_i=81.95 cs/acc_c=82.86 os/recall_knw=67.98 os/recall_unk=92.94 total/acc_i=73.40 total/acc_c=66.75 total/h_score=76.81\n",
      "painting -> real lr= 0.001 seed= 0\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19]\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20]\n",
      "Loss: 2.3623350779215495\n",
      "Loss: 0.9996145141621431\n",
      "Loss: 0.6566799916327\n",
      "Loss: 0.5392470673347513\n",
      "Loss: 0.4790363651700318\n",
      "Loss: 0.41251322279373803\n",
      "Loss: 0.3894768564340969\n",
      "Loss: 0.34812325751408935\n",
      "Loss: 0.33192131789401175\n",
      "Loss: 0.31848366496463615\n",
      "tensor(True) tensor(True)\n",
      "______\n",
      "Iteration t=1\n",
      "all:  cs/acc_i=79.91 cs/acc_c=80.60 os/recall_knw=89.57 os/recall_unk=57.51 total/acc_i=70.72 total/acc_c=76.57 total/h_score=66.03\n",
      "selected:  cs/acc_i=72.50 cs/acc_c=75.75 os/recall_knw=61.01 os/recall_unk=99.78 total/acc_i=79.66 total/acc_c=66.37 total/h_score=78.50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 2.270579048136408\n",
      "Loss: 0.8905390108278556\n",
      "Loss: 0.5818168873241706\n",
      "Loss: 0.48038418874029043\n",
      "Loss: 0.41962476386580355\n",
      "Loss: 0.36652283491783366\n",
      "Loss: 0.3463211433832036\n",
      "Loss: 0.3190395027514576\n",
      "Loss: 0.2894839144838873\n",
      "Loss: 0.2772971603066422\n",
      "______\n",
      "Iteration t=2\n",
      "all:  cs/acc_i=80.91 cs/acc_c=81.76 os/recall_knw=73.56 os/recall_unk=89.73 total/acc_i=75.00 total/acc_c=70.30 total/h_score=78.22\n",
      "selected:  cs/acc_i=75.17 cs/acc_c=78.67 os/recall_knw=54.68 os/recall_unk=98.73 total/acc_i=72.23 total/acc_c=59.44 total/h_score=72.66\n",
      "Loss: 2.181053685058247\n",
      "Loss: 0.7809600502794439\n",
      "Loss: 0.5263439583778381\n",
      "Loss: 0.44229539096355436\n",
      "Loss: 0.3912988475777886\n",
      "Loss: 0.3459929724985903\n",
      "Loss: 0.31882528096437457\n",
      "Loss: 0.30100906193256377\n",
      "Loss: 0.2680483416806568\n",
      "Loss: 0.26201519137079066\n",
      "______\n",
      "Iteration t=3\n",
      "all:  cs/acc_i=81.98 cs/acc_c=82.88 os/recall_knw=71.26 os/recall_unk=91.78 total/acc_i=74.73 total/acc_c=69.08 total/h_score=78.08\n",
      "selected:  cs/acc_i=79.19 cs/acc_c=81.60 os/recall_knw=61.32 os/recall_unk=96.56 total/acc_i=72.77 total/acc_c=63.38 total/h_score=75.30\n",
      "Loss: 2.0843705739761957\n",
      "Loss: 0.7022398916101947\n",
      "Loss: 0.4900837464840551\n",
      "Loss: 0.4039570911438604\n",
      "Loss: 0.35590297075891003\n",
      "Loss: 0.3452469698598295\n",
      "Loss: 0.293486206161812\n",
      "Loss: 0.26928300191600296\n",
      "Loss: 0.25191874323329566\n",
      "Loss: 0.2328063103776822\n",
      "______\n",
      "Iteration t=4\n",
      "all:  cs/acc_i=82.38 cs/acc_c=83.16 os/recall_knw=70.68 os/recall_unk=92.04 total/acc_i=74.59 total/acc_c=68.81 total/h_score=77.98\n",
      "selected:  cs/acc_i=81.61 cs/acc_c=83.04 os/recall_knw=65.71 os/recall_unk=94.90 total/acc_i=73.99 total/acc_c=66.51 total/h_score=77.22\n",
      "Loss: 2.069532134942096\n",
      "Loss: 0.667934669421451\n",
      "Loss: 0.47564271780917355\n",
      "Loss: 0.3989715362736101\n",
      "Loss: 0.34002589517989174\n",
      "Loss: 0.29911843815160666\n",
      "Loss: 0.28286507391300136\n",
      "Loss: 0.2516456341413972\n",
      "Loss: 0.2408786034795514\n",
      "Loss: 0.22142352526484937\n",
      "______\n",
      "Iteration t=5\n",
      "all:  cs/acc_i=81.55 cs/acc_c=82.30 os/recall_knw=70.54 os/recall_unk=92.17 total/acc_i=74.57 total/acc_c=68.75 total/h_score=77.98\n",
      "selected:  cs/acc_i=80.88 cs/acc_c=81.91 os/recall_knw=67.71 os/recall_unk=93.19 total/acc_i=73.93 total/acc_c=67.20 total/h_score=77.20\n",
      "Loss: 2.0411890054902724\n",
      "Loss: 0.6685917881227309\n",
      "Loss: 0.46342775802458486\n",
      "Loss: 0.3734608604061988\n",
      "Loss: 0.347464772265765\n",
      "Loss: 0.3051315615013723\n",
      "Loss: 0.2636363470025601\n",
      "Loss: 0.27337946749983294\n",
      "Loss: 0.23845789164545075\n",
      "Loss: 0.2128198324011699\n",
      "______\n",
      "Iteration t=6\n",
      "all:  cs/acc_i=81.63 cs/acc_c=82.29 os/recall_knw=70.37 os/recall_unk=92.30 total/acc_i=74.51 total/acc_c=68.59 total/h_score=77.91\n",
      "selected:  cs/acc_i=81.47 cs/acc_c=82.25 os/recall_knw=69.73 os/recall_unk=92.59 total/acc_i=74.37 total/acc_c=68.32 total/h_score=77.81\n",
      "Loss: 2.016594427749046\n",
      "Loss: 0.6392184139797522\n",
      "Loss: 0.44659632411580413\n",
      "Loss: 0.3673642418060288\n",
      "Loss: 0.32694826640610425\n",
      "Loss: 0.29615974119343097\n",
      "Loss: 0.26570104283965984\n",
      "Loss: 0.2615862515339124\n",
      "Loss: 0.22865395602893154\n",
      "Loss: 0.20846279248384372\n",
      "______\n",
      "Iteration t=7\n",
      "all:  cs/acc_i=82.21 cs/acc_c=83.05 os/recall_knw=70.28 os/recall_unk=92.30 total/acc_i=74.47 total/acc_c=68.52 total/h_score=77.86\n",
      "selected:  cs/acc_i=82.22 cs/acc_c=83.06 os/recall_knw=70.24 os/recall_unk=92.30 total/acc_i=74.47 total/acc_c=68.52 total/h_score=77.86\n",
      "Loss: 2.02846266515553\n",
      "Loss: 0.6636942471377552\n",
      "Loss: 0.4409784395713359\n",
      "Loss: 0.3780091535532847\n",
      "Loss: 0.32533987145870924\n",
      "Loss: 0.2972219846909866\n",
      "Loss: 0.2727777298772708\n",
      "Loss: 0.24338791082846\n",
      "Loss: 0.23491838392801584\n",
      "Loss: 0.2123996654525399\n",
      "______\n",
      "Iteration t=8\n",
      "all:  cs/acc_i=81.98 cs/acc_c=82.73 os/recall_knw=70.28 os/recall_unk=92.30 total/acc_i=74.47 total/acc_c=68.52 total/h_score=77.86\n",
      "selected:  cs/acc_i=81.98 cs/acc_c=82.73 os/recall_knw=70.28 os/recall_unk=92.30 total/acc_i=74.47 total/acc_c=68.52 total/h_score=77.86\n",
      "Loss: 2.0170251313596963\n",
      "Loss: 0.6437256725504994\n",
      "Loss: 0.44672530991956594\n",
      "Loss: 0.3674533258890733\n",
      "Loss: 0.31802047754172236\n",
      "Loss: 0.2913719575386494\n",
      "Loss: 0.2685521000763401\n",
      "Loss: 0.24587324321037157\n",
      "Loss: 0.23694267062237487\n",
      "Loss: 0.20744860559352674\n",
      "______\n",
      "Iteration t=9\n",
      "all:  cs/acc_i=81.86 cs/acc_c=82.83 os/recall_knw=70.28 os/recall_unk=92.30 total/acc_i=74.47 total/acc_c=68.52 total/h_score=77.86\n",
      "selected:  cs/acc_i=81.86 cs/acc_c=82.83 os/recall_knw=70.28 os/recall_unk=92.30 total/acc_i=74.47 total/acc_c=68.52 total/h_score=77.86\n",
      "tensor(0)\n",
      "all:  cs/acc_i=81.86 cs/acc_c=82.83 os/recall_knw=70.28 os/recall_unk=92.30 total/acc_i=74.47 total/acc_c=68.52 total/h_score=77.86\n",
      "painting -> real lr= 0.001 seed= 1\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19]\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20]\n",
      "Loss: 2.379726973672708\n",
      "Loss: 0.9961237402011951\n",
      "Loss: 0.6370001820226511\n",
      "Loss: 0.5406910722454389\n",
      "Loss: 0.4684270936374863\n",
      "Loss: 0.40091299811999004\n",
      "Loss: 0.3944923598940174\n",
      "Loss: 0.3553454243578017\n",
      "Loss: 0.3422622410270075\n",
      "Loss: 0.30382590192991\n",
      "tensor(True) tensor(True)\n",
      "______\n",
      "Iteration t=1\n",
      "all:  cs/acc_i=80.91 cs/acc_c=81.66 os/recall_knw=89.51 os/recall_unk=57.38 total/acc_i=71.31 total/acc_c=77.36 total/h_score=66.25\n",
      "selected:  cs/acc_i=73.20 cs/acc_c=77.43 os/recall_knw=60.88 os/recall_unk=99.89 total/acc_i=79.87 total/acc_c=66.91 total/h_score=78.94\n",
      "Loss: 2.267937741538351\n",
      "Loss: 0.8681951436654541\n",
      "Loss: 0.5798781337433083\n",
      "Loss: 0.46754019730543905\n",
      "Loss: 0.42064886560389236\n",
      "Loss: 0.3757627584155678\n",
      "Loss: 0.36950161339816195\n",
      "Loss: 0.3065301285002583\n",
      "Loss: 0.30529293839552607\n",
      "Loss: 0.28724773447642954\n",
      "______\n",
      "Iteration t=2\n",
      "all:  cs/acc_i=81.32 cs/acc_c=82.00 os/recall_knw=72.72 os/recall_unk=91.40 total/acc_i=75.20 total/acc_c=69.97 total/h_score=78.57\n",
      "selected:  cs/acc_i=75.96 cs/acc_c=78.93 os/recall_knw=54.09 os/recall_unk=99.30 total/acc_i=72.24 total/acc_c=59.16 total/h_score=72.55\n",
      "Loss: 2.1909011858159846\n",
      "Loss: 0.7602054782347246\n",
      "Loss: 0.5333735307238319\n",
      "Loss: 0.4349793209812858\n",
      "Loss: 0.389798892844807\n",
      "Loss: 0.3547535685246641\n",
      "Loss: 0.31557433280077846\n",
      "Loss: 0.2789696732163429\n",
      "Loss: 0.2752254501797936\n",
      "Loss: 0.25982860788702966\n",
      "______\n",
      "Iteration t=3\n",
      "all:  cs/acc_i=82.15 cs/acc_c=82.78 os/recall_knw=69.53 os/recall_unk=92.94 total/acc_i=74.19 total/acc_c=67.85 total/h_score=77.59\n",
      "selected:  cs/acc_i=79.89 cs/acc_c=81.43 os/recall_knw=60.08 os/recall_unk=97.57 total/acc_i=72.48 total/acc_c=62.14 total/h_score=74.59\n",
      "Loss: 2.1155010543738033\n",
      "Loss: 0.7317936025124645\n",
      "Loss: 0.4930962737380844\n",
      "Loss: 0.4169343439574094\n",
      "Loss: 0.3779056175928755\n",
      "Loss: 0.31778029060548113\n",
      "Loss: 0.2961942218372093\n",
      "Loss: 0.2693680258166954\n",
      "Loss: 0.2537279438060993\n",
      "Loss: 0.23196117594018834\n",
      "______\n",
      "Iteration t=4\n",
      "all:  cs/acc_i=82.15 cs/acc_c=82.93 os/recall_knw=69.39 os/recall_unk=93.07 total/acc_i=74.17 total/acc_c=67.79 total/h_score=77.59\n",
      "selected:  cs/acc_i=81.19 cs/acc_c=82.68 os/recall_knw=64.55 os/recall_unk=95.84 total/acc_i=73.43 total/acc_c=65.37 total/h_score=76.63\n",
      "Loss: 2.051870731328497\n",
      "Loss: 0.6693634782603245\n",
      "Loss: 0.47044172133041534\n",
      "Loss: 0.3944331720866115\n",
      "Loss: 0.33682724974112005\n",
      "Loss: 0.3155865789643976\n",
      "Loss: 0.2840412605849915\n",
      "Loss: 0.2582114977355035\n",
      "Loss: 0.2392766032096566\n",
      "Loss: 0.22173467537523894\n",
      "______\n",
      "Iteration t=5\n",
      "all:  cs/acc_i=82.35 cs/acc_c=83.22 os/recall_knw=69.27 os/recall_unk=93.07 total/acc_i=74.13 total/acc_c=67.74 total/h_score=77.55\n",
      "selected:  cs/acc_i=82.04 cs/acc_c=83.20 os/recall_knw=67.13 os/recall_unk=94.03 total/acc_i=73.78 total/acc_c=66.78 total/h_score=77.16\n",
      "Loss: 2.041159438358626\n",
      "Loss: 0.6452170089126783\n",
      "Loss: 0.45696091594420063\n",
      "Loss: 0.3849666252301054\n",
      "Loss: 0.3219729943674094\n",
      "Loss: 0.29868467705521934\n",
      "Loss: 0.28130760792511067\n",
      "Loss: 0.26989682545807586\n",
      "Loss: 0.22144411194027427\n",
      "Loss: 0.2209853930009523\n",
      "______\n",
      "Iteration t=6\n",
      "all:  cs/acc_i=82.67 cs/acc_c=83.27 os/recall_knw=68.96 os/recall_unk=93.13 total/acc_i=73.99 total/acc_c=67.54 total/h_score=77.43\n",
      "selected:  cs/acc_i=82.68 cs/acc_c=83.35 os/recall_knw=68.41 os/recall_unk=93.61 total/acc_i=74.02 total/acc_c=67.39 total/h_score=77.47\n",
      "Loss: 2.0051686411039737\n",
      "Loss: 0.6581757262914996\n",
      "Loss: 0.4552669969823542\n",
      "Loss: 0.37442814938346797\n",
      "Loss: 0.33382032750339447\n",
      "Loss: 0.3115585111317378\n",
      "Loss: 0.2772731418143722\n",
      "Loss: 0.2543914335060723\n",
      "Loss: 0.21545770349381846\n",
      "Loss: 0.22241800140495163\n",
      "______\n",
      "Iteration t=7\n",
      "all:  cs/acc_i=82.35 cs/acc_c=83.17 os/recall_knw=68.93 os/recall_unk=93.13 total/acc_i=73.99 total/acc_c=67.54 total/h_score=77.43\n",
      "selected:  cs/acc_i=82.40 cs/acc_c=83.23 os/recall_knw=68.87 os/recall_unk=93.19 total/acc_i=74.03 total/acc_c=67.57 total/h_score=77.47\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 1.9998767181012616\n",
      "Loss: 0.6388519285422452\n",
      "Loss: 0.4431837681423193\n",
      "Loss: 0.3773757253990233\n",
      "Loss: 0.31821413433073825\n",
      "Loss: 0.30093129363449866\n",
      "Loss: 0.26611153008240573\n",
      "Loss: 0.24682926925473242\n",
      "Loss: 0.2352918184848514\n",
      "Loss: 0.20575348482285655\n",
      "______\n",
      "Iteration t=8\n",
      "all:  cs/acc_i=82.21 cs/acc_c=82.93 os/recall_knw=68.93 os/recall_unk=93.13 total/acc_i=73.99 total/acc_c=67.54 total/h_score=77.43\n",
      "selected:  cs/acc_i=82.21 cs/acc_c=82.93 os/recall_knw=68.93 os/recall_unk=93.13 total/acc_i=73.99 total/acc_c=67.54 total/h_score=77.43\n",
      "Loss: 2.0052435010109306\n",
      "Loss: 0.6331933984685244\n",
      "Loss: 0.45107767260018383\n",
      "Loss: 0.3730316342047925\n",
      "Loss: 0.31009175884976703\n",
      "Loss: 0.303560225445332\n",
      "Loss: 0.27159760256280313\n",
      "Loss: 0.2560970553624555\n",
      "Loss: 0.22987655584214242\n",
      "Loss: 0.20636670908791088\n",
      "______\n",
      "Iteration t=9\n",
      "all:  cs/acc_i=82.12 cs/acc_c=82.87 os/recall_knw=68.93 os/recall_unk=93.13 total/acc_i=73.99 total/acc_c=67.54 total/h_score=77.43\n",
      "selected:  cs/acc_i=82.12 cs/acc_c=82.87 os/recall_knw=68.93 os/recall_unk=93.13 total/acc_i=73.99 total/acc_c=67.54 total/h_score=77.43\n",
      "tensor(0)\n",
      "all:  cs/acc_i=82.12 cs/acc_c=82.87 os/recall_knw=68.93 os/recall_unk=93.13 total/acc_i=73.99 total/acc_c=67.54 total/h_score=77.43\n",
      "painting -> real lr= 0.001 seed= 2\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19]\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20]\n",
      "Loss: 2.361782053609689\n",
      "Loss: 0.9951542407274246\n",
      "Loss: 0.6417243923991919\n",
      "Loss: 0.5283643867820501\n",
      "Loss: 0.4522665968164802\n",
      "Loss: 0.4360424840201934\n",
      "Loss: 0.37504266140361625\n",
      "Loss: 0.3560662278905511\n",
      "Loss: 0.3315185940203567\n",
      "Loss: 0.30627253123869497\n",
      "tensor(True) tensor(True)\n",
      "______\n",
      "Iteration t=1\n",
      "all:  cs/acc_i=81.00 cs/acc_c=81.60 os/recall_knw=89.57 os/recall_unk=57.51 total/acc_i=71.57 total/acc_c=77.61 total/h_score=66.43\n",
      "selected:  cs/acc_i=72.31 cs/acc_c=75.76 os/recall_knw=60.88 os/recall_unk=99.56 total/acc_i=79.76 total/acc_c=66.85 total/h_score=78.81\n",
      "Loss: 2.2718320211698844\n",
      "Loss: 0.8758896116831506\n",
      "Loss: 0.5871799070705739\n",
      "Loss: 0.4933987881324088\n",
      "Loss: 0.4201364790399869\n",
      "Loss: 0.39594107560178105\n",
      "Loss: 0.34747164450990137\n",
      "Loss: 0.315498579235733\n",
      "Loss: 0.30356161048014957\n",
      "Loss: 0.3002331781294919\n",
      "______\n",
      "Iteration t=2\n",
      "all:  cs/acc_i=81.63 cs/acc_c=82.29 os/recall_knw=71.57 os/recall_unk=90.31 total/acc_i=74.37 total/acc_c=69.22 total/h_score=77.69\n",
      "selected:  cs/acc_i=75.75 cs/acc_c=78.86 os/recall_knw=52.88 os/recall_unk=98.74 total/acc_i=70.83 total/acc_c=57.70 total/h_score=71.18\n",
      "Loss: 2.1748819238489325\n",
      "Loss: 0.7596356150236997\n",
      "Loss: 0.5309655235572295\n",
      "Loss: 0.4353019876913591\n",
      "Loss: 0.4008273307301781\n",
      "Loss: 0.3536664352362806\n",
      "Loss: 0.32074244293299586\n",
      "Loss: 0.29513767965815285\n",
      "Loss: 0.2710895718498664\n",
      "Loss: 0.2541787014766173\n",
      "______\n",
      "Iteration t=3\n",
      "all:  cs/acc_i=81.86 cs/acc_c=82.48 os/recall_knw=70.85 os/recall_unk=91.14 total/acc_i=74.25 total/acc_c=68.73 total/h_score=77.63\n",
      "selected:  cs/acc_i=79.52 cs/acc_c=81.19 os/recall_knw=61.18 os/recall_unk=97.06 total/acc_i=72.86 total/acc_c=63.23 total/h_score=75.32\n",
      "Loss: 2.113189079097866\n",
      "Loss: 0.719891370315732\n",
      "Loss: 0.4963108602258348\n",
      "Loss: 0.3996993239290526\n",
      "Loss: 0.3707105181983246\n",
      "Loss: 0.31698259693343206\n",
      "Loss: 0.2967562219480059\n",
      "Loss: 0.27387279839194106\n",
      "Loss: 0.26395735439053924\n",
      "Loss: 0.23370681983447567\n",
      "______\n",
      "Iteration t=4\n",
      "all:  cs/acc_i=81.58 cs/acc_c=82.29 os/recall_knw=70.68 os/recall_unk=91.27 total/acc_i=74.23 total/acc_c=68.67 total/h_score=77.63\n",
      "selected:  cs/acc_i=80.34 cs/acc_c=81.43 os/recall_knw=65.55 os/recall_unk=94.30 total/acc_i=73.39 total/acc_c=65.61 total/h_score=76.37\n",
      "Loss: 2.0565807459378007\n",
      "Loss: 0.6736023339501308\n",
      "Loss: 0.4738324760112039\n",
      "Loss: 0.3891647011041641\n",
      "Loss: 0.3403735061486562\n",
      "Loss: 0.31521078702000893\n",
      "Loss: 0.2916854987591013\n",
      "Loss: 0.2628826267107485\n",
      "Loss: 0.23600229077508347\n",
      "Loss: 0.2169604359975349\n",
      "______\n",
      "Iteration t=5\n",
      "all:  cs/acc_i=81.86 cs/acc_c=82.50 os/recall_knw=70.14 os/recall_unk=91.72 total/acc_i=74.17 total/acc_c=68.34 total/h_score=77.55\n",
      "selected:  cs/acc_i=81.33 cs/acc_c=82.21 os/recall_knw=67.89 os/recall_unk=92.55 total/acc_i=73.64 total/acc_c=67.17 total/h_score=76.99\n",
      "Loss: 2.0289910804384794\n",
      "Loss: 0.6569631888698308\n",
      "Loss: 0.4395620957590066\n",
      "Loss: 0.37952574452337545\n",
      "Loss: 0.3319227507051367\n",
      "Loss: 0.2998482176126578\n",
      "Loss: 0.2829435589329268\n",
      "Loss: 0.25931476527013075\n",
      "Loss: 0.236192782349789\n",
      "Loss: 0.22198980787577918\n",
      "______\n",
      "Iteration t=6\n",
      "all:  cs/acc_i=82.87 cs/acc_c=83.41 os/recall_knw=70.02 os/recall_unk=91.72 total/acc_i=74.09 total/acc_c=68.22 total/h_score=77.46\n",
      "selected:  cs/acc_i=83.01 cs/acc_c=83.55 os/recall_knw=69.45 os/recall_unk=92.13 total/acc_i=74.18 total/acc_c=68.09 total/h_score=77.51\n",
      "Loss: 2.032054325881994\n",
      "Loss: 0.6623007545493683\n",
      "Loss: 0.466976653573648\n",
      "Loss: 0.3670559255816277\n",
      "Loss: 0.32494483520306133\n",
      "Loss: 0.31339948100723186\n",
      "Loss: 0.27942837248761326\n",
      "Loss: 0.2471447787804049\n",
      "Loss: 0.22922495363643333\n",
      "Loss: 0.21547701554197185\n",
      "______\n",
      "Iteration t=7\n",
      "all:  cs/acc_i=82.04 cs/acc_c=82.70 os/recall_knw=69.99 os/recall_unk=91.72 total/acc_i=74.09 total/acc_c=68.22 total/h_score=77.46\n",
      "selected:  cs/acc_i=82.08 cs/acc_c=82.75 os/recall_knw=69.97 os/recall_unk=91.72 total/acc_i=74.12 total/acc_c=68.26 total/h_score=77.49\n",
      "Loss: 2.0077757447957993\n",
      "Loss: 0.6455320306122303\n",
      "Loss: 0.4513691840227693\n",
      "Loss: 0.365132851456292\n",
      "Loss: 0.3296658161561936\n",
      "Loss: 0.3014573813648894\n",
      "Loss: 0.27104307401459665\n",
      "Loss: 0.25325253325281666\n",
      "Loss: 0.2370925069320947\n",
      "Loss: 0.21707876252476127\n",
      "______\n",
      "Iteration t=8\n",
      "all:  cs/acc_i=81.63 cs/acc_c=82.37 os/recall_knw=69.99 os/recall_unk=91.72 total/acc_i=74.09 total/acc_c=68.22 total/h_score=77.46\n",
      "selected:  cs/acc_i=81.63 cs/acc_c=82.37 os/recall_knw=69.99 os/recall_unk=91.72 total/acc_i=74.09 total/acc_c=68.22 total/h_score=77.46\n",
      "Loss: 2.0005448987707495\n",
      "Loss: 0.6470530372578651\n",
      "Loss: 0.4489711279980838\n",
      "Loss: 0.37037803092971444\n",
      "Loss: 0.31428587150294335\n",
      "Loss: 0.29400508558610455\n",
      "Loss: 0.2707090253708884\n",
      "Loss: 0.24548876786138862\n",
      "Loss: 0.22222076811594887\n",
      "Loss: 0.21333393739769235\n",
      "______\n",
      "Iteration t=9\n",
      "all:  cs/acc_i=82.75 cs/acc_c=83.33 os/recall_knw=69.99 os/recall_unk=91.72 total/acc_i=74.09 total/acc_c=68.22 total/h_score=77.46\n",
      "selected:  cs/acc_i=82.75 cs/acc_c=83.33 os/recall_knw=69.99 os/recall_unk=91.72 total/acc_i=74.09 total/acc_c=68.22 total/h_score=77.46\n",
      "tensor(0)\n",
      "all:  cs/acc_i=82.75 cs/acc_c=83.33 os/recall_knw=69.99 os/recall_unk=91.72 total/acc_i=74.09 total/acc_c=68.22 total/h_score=77.46\n",
      "painting -> real lr= 0.001 seed= 3\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19]\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20]\n",
      "Loss: 2.3633533626794816\n",
      "Loss: 1.00125726275146\n",
      "Loss: 0.6499184217924873\n",
      "Loss: 0.5388004535188278\n",
      "Loss: 0.46285486662139497\n",
      "Loss: 0.4196243135879437\n",
      "Loss: 0.37558303447440267\n",
      "Loss: 0.3439111021968226\n",
      "Loss: 0.3218793115268151\n",
      "Loss: 0.3129870764600734\n",
      "tensor(True) tensor(True)\n",
      "______\n",
      "Iteration t=1\n",
      "all:  cs/acc_i=81.23 cs/acc_c=82.04 os/recall_knw=89.94 os/recall_unk=58.34 total/acc_i=71.97 total/acc_c=78.01 total/h_score=67.11\n",
      "selected:  cs/acc_i=73.20 cs/acc_c=76.66 os/recall_knw=61.87 os/recall_unk=99.78 total/acc_i=80.43 total/acc_c=67.39 total/h_score=79.28\n",
      "Loss: 2.260976611181747\n",
      "Loss: 0.8716500232848086\n",
      "Loss: 0.5712187055122945\n",
      "Loss: 0.47734078805344976\n",
      "Loss: 0.420388418459153\n",
      "Loss: 0.37491785310382064\n",
      "Loss: 0.3588588197332944\n",
      "Loss: 0.30989591644484865\n",
      "Loss: 0.29218333826739656\n",
      "Loss: 0.29725933993278547\n",
      "______\n",
      "Iteration t=2\n",
      "all:  cs/acc_i=81.20 cs/acc_c=82.02 os/recall_knw=75.05 os/recall_unk=88.32 total/acc_i=75.30 total/acc_c=71.36 total/h_score=78.42\n",
      "selected:  cs/acc_i=75.82 cs/acc_c=78.97 os/recall_knw=56.27 os/recall_unk=98.99 total/acc_i=73.27 total/acc_c=60.71 total/h_score=73.78\n",
      "Loss: 2.1955420197140088\n",
      "Loss: 0.7785937844623219\n",
      "Loss: 0.5376866404034875\n",
      "Loss: 0.42788291882384905\n",
      "Loss: 0.38836290988055144\n",
      "Loss: 0.34832675660198387\n",
      "Loss: 0.31232831396839833\n",
      "Loss: 0.29052320924672215\n",
      "Loss: 0.2682134279337796\n",
      "Loss: 0.25790068233555014\n",
      "______\n",
      "Iteration t=3\n",
      "all:  cs/acc_i=80.77 cs/acc_c=81.44 os/recall_knw=73.79 os/recall_unk=89.22 total/acc_i=74.97 total/acc_c=70.53 total/h_score=78.19\n",
      "selected:  cs/acc_i=78.45 cs/acc_c=80.01 os/recall_knw=64.21 os/recall_unk=97.20 total/acc_i=74.53 total/acc_c=65.22 total/h_score=76.91\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 2.1070044736747873\n",
      "Loss: 0.7126167840132974\n",
      "Loss: 0.4922926514218115\n",
      "Loss: 0.4124766783406065\n",
      "Loss: 0.34700427538626\n",
      "Loss: 0.31864611645012275\n",
      "Loss: 0.2922820426166466\n",
      "Loss: 0.26393172571001805\n",
      "Loss: 0.26518760371493966\n",
      "Loss: 0.23733246434888203\n",
      "______\n",
      "Iteration t=4\n",
      "all:  cs/acc_i=81.52 cs/acc_c=82.34 os/recall_knw=73.44 os/recall_unk=89.54 total/acc_i=74.97 total/acc_c=70.40 total/h_score=78.22\n",
      "selected:  cs/acc_i=80.71 cs/acc_c=82.15 os/recall_knw=68.12 os/recall_unk=93.62 total/acc_i=74.73 total/acc_c=67.95 total/h_score=77.88\n",
      "Loss: 2.049661542743933\n",
      "Loss: 0.669515646090273\n",
      "Loss: 0.4679976798471857\n",
      "Loss: 0.4005881099183051\n",
      "Loss: 0.33663153470051094\n",
      "Loss: 0.3006334177783278\n",
      "Loss: 0.30127129606047615\n",
      "Loss: 0.26577711972545404\n",
      "Loss: 0.24683520933155154\n",
      "Loss: 0.2198039217928394\n",
      "______\n",
      "Iteration t=5\n",
      "all:  cs/acc_i=81.86 cs/acc_c=82.67 os/recall_knw=72.92 os/recall_unk=90.05 total/acc_i=74.91 total/acc_c=70.13 total/h_score=78.22\n",
      "selected:  cs/acc_i=81.56 cs/acc_c=82.64 os/recall_knw=70.55 os/recall_unk=91.40 total/acc_i=74.65 total/acc_c=69.16 total/h_score=78.01\n",
      "Loss: 2.0141934474309284\n",
      "Loss: 0.6466653681463665\n",
      "Loss: 0.4485994930305178\n",
      "Loss: 0.36963914526360375\n",
      "Loss: 0.32245855411839863\n",
      "Loss: 0.3080916596547006\n",
      "Loss: 0.2636330854206804\n",
      "Loss: 0.2567315233073064\n",
      "Loss: 0.22027605939952155\n",
      "Loss: 0.2207012062744489\n",
      "______\n",
      "Iteration t=6\n",
      "all:  cs/acc_i=81.86 cs/acc_c=82.71 os/recall_knw=72.75 os/recall_unk=90.18 total/acc_i=74.87 total/acc_c=70.04 total/h_score=78.20\n",
      "selected:  cs/acc_i=82.07 cs/acc_c=83.04 os/recall_knw=72.08 os/recall_unk=90.82 total/acc_i=75.06 total/acc_c=70.09 total/h_score=78.45\n",
      "Loss: 1.9932993644865873\n",
      "Loss: 0.6434749631309806\n",
      "Loss: 0.45044505484750336\n",
      "Loss: 0.3672769521580678\n",
      "Loss: 0.3235437317614986\n",
      "Loss: 0.3062159471051344\n",
      "Loss: 0.25297283171168367\n",
      "Loss: 0.2550795213711039\n",
      "Loss: 0.23025137538850493\n",
      "Loss: 0.20109102586603425\n",
      "______\n",
      "Iteration t=7\n",
      "all:  cs/acc_i=81.86 cs/acc_c=82.61 os/recall_knw=72.69 os/recall_unk=90.24 total/acc_i=74.87 total/acc_c=70.02 total/h_score=78.21\n",
      "selected:  cs/acc_i=81.97 cs/acc_c=82.74 os/recall_knw=72.54 os/recall_unk=90.48 total/acc_i=74.97 total/acc_c=70.10 total/h_score=78.34\n",
      "Loss: 1.9942992265010397\n",
      "Loss: 0.6478807970004923\n",
      "Loss: 0.4570802836779839\n",
      "Loss: 0.366661766319083\n",
      "Loss: 0.333828436239585\n",
      "Loss: 0.2893354539923808\n",
      "Loss: 0.27067789341966064\n",
      "Loss: 0.2474112797286304\n",
      "Loss: 0.23159279664488217\n",
      "Loss: 0.20456035725264912\n",
      "______\n",
      "Iteration t=8\n",
      "all:  cs/acc_i=81.98 cs/acc_c=82.81 os/recall_knw=72.69 os/recall_unk=90.24 total/acc_i=74.87 total/acc_c=70.02 total/h_score=78.21\n",
      "selected:  cs/acc_i=81.98 cs/acc_c=82.81 os/recall_knw=72.69 os/recall_unk=90.24 total/acc_i=74.87 total/acc_c=70.02 total/h_score=78.21\n",
      "Loss: 2.0072691486573513\n",
      "Loss: 0.646450249961129\n",
      "Loss: 0.4295479168218595\n",
      "Loss: 0.37185276074357976\n",
      "Loss: 0.32209305674481536\n",
      "Loss: 0.2803151652584841\n",
      "Loss: 0.25759767922630283\n",
      "Loss: 0.2373855635523796\n",
      "Loss: 0.22208838139511186\n",
      "Loss: 0.2143281027789653\n",
      "______\n",
      "Iteration t=9\n",
      "all:  cs/acc_i=82.61 cs/acc_c=83.19 os/recall_knw=72.69 os/recall_unk=90.24 total/acc_i=74.87 total/acc_c=70.02 total/h_score=78.21\n",
      "selected:  cs/acc_i=82.61 cs/acc_c=83.19 os/recall_knw=72.69 os/recall_unk=90.24 total/acc_i=74.87 total/acc_c=70.02 total/h_score=78.21\n",
      "tensor(0)\n",
      "all:  cs/acc_i=82.61 cs/acc_c=83.19 os/recall_knw=72.69 os/recall_unk=90.24 total/acc_i=74.87 total/acc_c=70.02 total/h_score=78.21\n",
      "painting -> real lr= 0.001 seed= 4\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19]\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20]\n",
      "Loss: 2.3686558574438097\n",
      "Loss: 0.9814467654873927\n",
      "Loss: 0.6435805312047402\n",
      "Loss: 0.5238669784118731\n",
      "Loss: 0.4608505109945933\n",
      "Loss: 0.43238416152695813\n",
      "Loss: 0.38876573331654074\n",
      "Loss: 0.3592487871957322\n",
      "Loss: 0.3303532551663617\n",
      "Loss: 0.31233538516486686\n",
      "tensor(True) tensor(True)\n",
      "______\n",
      "Iteration t=1\n",
      "all:  cs/acc_i=81.32 cs/acc_c=81.97 os/recall_knw=89.48 os/recall_unk=57.32 total/acc_i=71.33 total/acc_c=77.35 total/h_score=66.20\n",
      "selected:  cs/acc_i=74.17 cs/acc_c=77.25 os/recall_knw=60.77 os/recall_unk=99.67 total/acc_i=79.61 total/acc_c=66.41 total/h_score=78.50\n",
      "Loss: 2.269152044325836\n",
      "Loss: 0.8497295444325883\n",
      "Loss: 0.5707042025503262\n",
      "Loss: 0.49545791774064074\n",
      "Loss: 0.42440791220165963\n",
      "Loss: 0.3769625161680602\n",
      "Loss: 0.34409813660868377\n",
      "Loss: 0.3147939460048842\n",
      "Loss: 0.30257618978850603\n",
      "Loss: 0.2744074328983015\n",
      "______\n",
      "Iteration t=2\n",
      "all:  cs/acc_i=81.69 cs/acc_c=82.48 os/recall_knw=71.03 os/recall_unk=91.85 total/acc_i=74.49 total/acc_c=68.74 total/h_score=77.87\n",
      "selected:  cs/acc_i=76.11 cs/acc_c=79.45 os/recall_knw=52.41 os/recall_unk=98.83 total/acc_i=70.72 total/acc_c=56.89 total/h_score=70.50\n",
      "Loss: 2.187042630369013\n",
      "Loss: 0.7841725535826249\n",
      "Loss: 0.5333110146089034\n",
      "Loss: 0.44811180553653024\n",
      "Loss: 0.3924476905302568\n",
      "Loss: 0.34661735848947006\n",
      "Loss: 0.3207901491631161\n",
      "Loss: 0.2937542607296597\n",
      "Loss: 0.2796425008231943\n",
      "Loss: 0.25493392765522005\n",
      "______\n",
      "Iteration t=3\n",
      "all:  cs/acc_i=81.66 cs/acc_c=82.29 os/recall_knw=69.70 os/recall_unk=93.00 total/acc_i=74.13 total/acc_c=67.74 total/h_score=77.53\n",
      "selected:  cs/acc_i=79.47 cs/acc_c=81.09 os/recall_knw=60.44 os/recall_unk=97.84 total/acc_i=72.62 total/acc_c=62.16 total/h_score=74.67\n",
      "Loss: 2.094037783924247\n",
      "Loss: 0.7081936584510344\n",
      "Loss: 0.481745050381549\n",
      "Loss: 0.41340369682541417\n",
      "Loss: 0.3520752674167099\n",
      "Loss: 0.3314761786219181\n",
      "Loss: 0.3103462639184752\n",
      "Loss: 0.28294957890031264\n",
      "Loss: 0.2518154749601977\n",
      "Loss: 0.22676985082936654\n",
      "______\n",
      "Iteration t=4\n",
      "all:  cs/acc_i=82.09 cs/acc_c=82.88 os/recall_knw=69.10 os/recall_unk=93.32 total/acc_i=73.97 total/acc_c=67.44 total/h_score=77.42\n",
      "selected:  cs/acc_i=80.98 cs/acc_c=82.18 os/recall_knw=64.32 os/recall_unk=95.22 total/acc_i=72.91 total/acc_c=64.52 total/h_score=75.82\n",
      "Loss: 2.0723886226270065\n",
      "Loss: 0.7005995770688891\n",
      "Loss: 0.4713509194429952\n",
      "Loss: 0.39291644543901133\n",
      "Loss: 0.3498478203077521\n",
      "Loss: 0.31477932769669953\n",
      "Loss: 0.28581319351007445\n",
      "Loss: 0.2618230634519566\n",
      "Loss: 0.2383197504080365\n",
      "Loss: 0.22347881464232314\n",
      "______\n",
      "Iteration t=5\n",
      "all:  cs/acc_i=81.72 cs/acc_c=82.52 os/recall_knw=68.93 os/recall_unk=93.52 total/acc_i=73.93 total/acc_c=67.31 total/h_score=77.39\n",
      "selected:  cs/acc_i=81.36 cs/acc_c=82.32 os/recall_knw=67.07 os/recall_unk=94.18 total/acc_i=73.54 total/acc_c=66.28 total/h_score=76.84\n",
      "Loss: 2.020818473245853\n",
      "Loss: 0.6545776225721989\n",
      "Loss: 0.4672208113166002\n",
      "Loss: 0.39029935768877083\n",
      "Loss: 0.32720385620800346\n",
      "Loss: 0.3094067982612894\n",
      "Loss: 0.2689644121445524\n",
      "Loss: 0.2695742421664106\n",
      "Loss: 0.23692529041988727\n",
      "Loss: 0.2100687162974515\n",
      "______\n",
      "Iteration t=6\n",
      "all:  cs/acc_i=81.83 cs/acc_c=82.52 os/recall_knw=68.81 os/recall_unk=93.58 total/acc_i=73.95 total/acc_c=67.31 total/h_score=77.41\n",
      "selected:  cs/acc_i=81.72 cs/acc_c=82.52 os/recall_knw=68.21 os/recall_unk=93.94 total/acc_i=73.86 total/acc_c=67.07 total/h_score=77.34\n",
      "Loss: 2.0153130507921873\n",
      "Loss: 0.6435332572724246\n",
      "Loss: 0.45779786320238175\n",
      "Loss: 0.3706703252052959\n",
      "Loss: 0.34046902698523634\n",
      "Loss: 0.2857606622944527\n",
      "Loss: 0.2890646182990904\n",
      "Loss: 0.2605624028564065\n",
      "Loss: 0.23372770898940065\n",
      "Loss: 0.2190756270119661\n",
      "______\n",
      "Iteration t=7\n",
      "all:  cs/acc_i=81.98 cs/acc_c=82.60 os/recall_knw=68.78 os/recall_unk=93.58 total/acc_i=73.93 total/acc_c=67.27 total/h_score=77.38\n",
      "selected:  cs/acc_i=81.96 cs/acc_c=82.59 os/recall_knw=68.75 os/recall_unk=93.64 total/acc_i=73.93 total/acc_c=67.25 total/h_score=77.38\n",
      "Loss: 1.9929673932258438\n",
      "Loss: 0.6518069565671045\n",
      "Loss: 0.4530824288585276\n",
      "Loss: 0.373043131832994\n",
      "Loss: 0.33313811457944364\n",
      "Loss: 0.30455309562619376\n",
      "Loss: 0.2819399937589026\n",
      "Loss: 0.2521122401263916\n",
      "Loss: 0.2252491497721687\n",
      "Loss: 0.21816543054491658\n",
      "______\n",
      "Iteration t=8\n",
      "all:  cs/acc_i=82.12 cs/acc_c=82.93 os/recall_knw=68.78 os/recall_unk=93.58 total/acc_i=73.93 total/acc_c=67.27 total/h_score=77.38\n",
      "selected:  cs/acc_i=82.12 cs/acc_c=82.93 os/recall_knw=68.78 os/recall_unk=93.58 total/acc_i=73.93 total/acc_c=67.27 total/h_score=77.38\n",
      "Loss: 1.9999240065145794\n",
      "Loss: 0.6530372118050197\n",
      "Loss: 0.4450931191069525\n",
      "Loss: 0.37354188735754984\n",
      "Loss: 0.3408300848033443\n",
      "Loss: 0.29670702342717153\n",
      "Loss: 0.2809070866531546\n",
      "Loss: 0.25938650747796277\n",
      "Loss: 0.2276839406094836\n",
      "Loss: 0.21581727965682182\n",
      "______\n",
      "Iteration t=9\n",
      "all:  cs/acc_i=82.35 cs/acc_c=83.04 os/recall_knw=68.78 os/recall_unk=93.58 total/acc_i=73.93 total/acc_c=67.27 total/h_score=77.38\n",
      "selected:  cs/acc_i=82.35 cs/acc_c=83.04 os/recall_knw=68.78 os/recall_unk=93.58 total/acc_i=73.93 total/acc_c=67.27 total/h_score=77.38\n",
      "tensor(0)\n",
      "all:  cs/acc_i=82.35 cs/acc_c=83.04 os/recall_knw=68.78 os/recall_unk=93.58 total/acc_i=73.93 total/acc_c=67.27 total/h_score=77.38\n",
      "real -> painting lr= 0.001 seed= 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19]\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20]\n",
      "Loss: 1.6998560120055146\n",
      "Loss: 0.3083541560259279\n",
      "Loss: 0.17869068620504866\n",
      "Loss: 0.1356609110627623\n",
      "Loss: 0.11387435545683673\n",
      "Loss: 0.09665934126404896\n",
      "Loss: 0.08742652124338977\n",
      "Loss: 0.07384159058853505\n",
      "Loss: 0.06657851652251227\n",
      "Loss: 0.06502841519629074\n",
      "tensor(True) tensor(True)\n",
      "______\n",
      "Iteration t=1\n",
      "all:  cs/acc_i=73.10 cs/acc_c=72.74 os/recall_knw=94.71 os/recall_unk=19.79 total/acc_i=54.93 total/acc_c=68.90 total/h_score=30.99\n",
      "selected:  cs/acc_i=77.83 cs/acc_c=77.26 os/recall_knw=75.33 os/recall_unk=94.64 total/acc_i=78.86 total/acc_c=71.64 total/h_score=80.80\n",
      "Loss: 1.6531615615622397\n",
      "Loss: 0.2765743202227025\n",
      "Loss: 0.16345254536375312\n",
      "Loss: 0.13515676713428615\n",
      "Loss: 0.11575669549588412\n",
      "Loss: 0.09141530717888767\n",
      "Loss: 0.07988599447699184\n",
      "Loss: 0.07249143752812243\n",
      "Loss: 0.06157340239904867\n",
      "Loss: 0.0521334178911442\n",
      "______\n",
      "Iteration t=2\n",
      "all:  cs/acc_i=72.92 cs/acc_c=72.45 os/recall_knw=61.91 os/recall_unk=77.74 total/acc_i=63.70 total/acc_c=57.70 total/h_score=65.57\n",
      "selected:  cs/acc_i=63.88 cs/acc_c=64.11 os/recall_knw=44.28 os/recall_unk=92.95 total/acc_i=59.91 total/acc_c=43.87 total/h_score=57.30\n",
      "Loss: 1.598158555959954\n",
      "Loss: 0.25351539434974685\n",
      "Loss: 0.15514930519549286\n",
      "Loss: 0.12453224063467454\n",
      "Loss: 0.1027608403333408\n",
      "Loss: 0.08641022803700145\n",
      "Loss: 0.0752437196802074\n",
      "Loss: 0.06599906011183253\n",
      "Loss: 0.05303494581706165\n",
      "Loss: 0.04929905161672436\n",
      "______\n",
      "Iteration t=3\n",
      "all:  cs/acc_i=72.20 cs/acc_c=71.69 os/recall_knw=58.74 os/recall_unk=80.73 total/acc_i=63.15 total/acc_c=55.81 total/h_score=65.12\n",
      "selected:  cs/acc_i=66.53 cs/acc_c=66.60 os/recall_knw=48.74 os/recall_unk=87.11 total/acc_i=59.85 total/acc_c=47.76 total/h_score=60.03\n",
      "Loss: 1.5874702342067446\n",
      "Loss: 0.26093103733445916\n",
      "Loss: 0.15142463234918457\n",
      "Loss: 0.12098048370863711\n",
      "Loss: 0.09932609409492996\n",
      "Loss: 0.08510772939638368\n",
      "Loss: 0.07412534622076367\n",
      "Loss: 0.060025277322690404\n",
      "Loss: 0.05737536838145128\n",
      "Loss: 0.047773814952400115\n",
      "______\n",
      "Iteration t=4\n",
      "all:  cs/acc_i=73.35 cs/acc_c=72.74 os/recall_knw=57.91 os/recall_unk=81.03 total/acc_i=62.78 total/acc_c=55.11 total/h_score=64.68\n",
      "selected:  cs/acc_i=70.13 cs/acc_c=70.15 os/recall_knw=52.19 os/recall_unk=83.65 total/acc_i=60.44 total/acc_c=50.76 total/h_score=61.89\n",
      "Loss: 1.5662258219952023\n",
      "Loss: 0.24624580577765098\n",
      "Loss: 0.15375293484842145\n",
      "Loss: 0.12422174828480825\n",
      "Loss: 0.0918971278819167\n",
      "Loss: 0.08629769864414075\n",
      "Loss: 0.06809141317918356\n",
      "Loss: 0.06057545285822834\n",
      "Loss: 0.05451890001952773\n",
      "Loss: 0.04339243913480398\n",
      "______\n",
      "Iteration t=5\n",
      "all:  cs/acc_i=73.13 cs/acc_c=72.65 os/recall_knw=57.91 os/recall_unk=81.11 total/acc_i=62.81 total/acc_c=55.12 total/h_score=64.70\n",
      "selected:  cs/acc_i=71.38 cs/acc_c=71.30 os/recall_knw=54.81 os/recall_unk=81.72 total/acc_i=61.31 total/acc_c=52.89 total/h_score=63.15\n",
      "Loss: 1.5449495348391782\n",
      "Loss: 0.25385288069070866\n",
      "Loss: 0.15606066246950592\n",
      "Loss: 0.10949329141599252\n",
      "Loss: 0.09178244319972749\n",
      "Loss: 0.0828212537897684\n",
      "Loss: 0.0691305374824147\n",
      "Loss: 0.0581513971741986\n",
      "Loss: 0.04917627905775118\n",
      "Loss: 0.04918928787153286\n",
      "______\n",
      "Iteration t=6\n",
      "all:  cs/acc_i=73.85 cs/acc_c=73.54 os/recall_knw=57.91 os/recall_unk=81.11 total/acc_i=62.81 total/acc_c=55.12 total/h_score=64.70\n",
      "selected:  cs/acc_i=73.34 cs/acc_c=73.22 os/recall_knw=56.87 os/recall_unk=81.41 total/acc_i=62.36 total/acc_c=54.53 total/h_score=64.34\n",
      "Loss: 1.5378920742049205\n",
      "Loss: 0.2556208366127203\n",
      "Loss: 0.15120809441000954\n",
      "Loss: 0.11430631890608764\n",
      "Loss: 0.09711140263267369\n",
      "Loss: 0.07783046618043077\n",
      "Loss: 0.06621213490904718\n",
      "Loss: 0.06024176852868956\n",
      "Loss: 0.04979689550530216\n",
      "Loss: 0.045503493947197736\n",
      "______\n",
      "Iteration t=7\n",
      "all:  cs/acc_i=74.31 cs/acc_c=74.07 os/recall_knw=57.91 os/recall_unk=81.11 total/acc_i=62.81 total/acc_c=55.12 total/h_score=64.70\n",
      "selected:  cs/acc_i=74.23 cs/acc_c=73.98 os/recall_knw=57.66 os/recall_unk=81.35 total/acc_i=62.76 total/acc_c=54.98 total/h_score=64.67\n",
      "Loss: 1.5425330425907926\n",
      "Loss: 0.24390629095436758\n",
      "Loss: 0.15182180290784292\n",
      "Loss: 0.11879487763736953\n",
      "Loss: 0.09081886256199462\n",
      "Loss: 0.0806111401164031\n",
      "Loss: 0.06937911455850129\n",
      "Loss: 0.059589960977061575\n",
      "Loss: 0.04913776340770729\n",
      "Loss: 0.04334103146335741\n",
      "______\n",
      "Iteration t=8\n",
      "all:  cs/acc_i=74.88 cs/acc_c=74.57 os/recall_knw=57.91 os/recall_unk=81.11 total/acc_i=62.81 total/acc_c=55.12 total/h_score=64.70\n",
      "selected:  cs/acc_i=74.88 cs/acc_c=74.57 os/recall_knw=57.91 os/recall_unk=81.11 total/acc_i=62.81 total/acc_c=55.12 total/h_score=64.70\n",
      "Loss: 1.5408318282784643\n",
      "Loss: 0.2507789036510764\n",
      "Loss: 0.15246154129807207\n",
      "Loss: 0.11139648346784146\n",
      "Loss: 0.09494260897155146\n",
      "Loss: 0.08225963598721334\n",
      "Loss: 0.0702354455945661\n",
      "Loss: 0.06012199952997066\n",
      "Loss: 0.05138962336287305\n",
      "Loss: 0.04808362511779509\n",
      "______\n",
      "Iteration t=9\n",
      "all:  cs/acc_i=73.95 cs/acc_c=73.58 os/recall_knw=57.91 os/recall_unk=81.11 total/acc_i=62.81 total/acc_c=55.12 total/h_score=64.70\n",
      "selected:  cs/acc_i=73.95 cs/acc_c=73.58 os/recall_knw=57.91 os/recall_unk=81.11 total/acc_i=62.81 total/acc_c=55.12 total/h_score=64.70\n",
      "tensor(0)\n",
      "all:  cs/acc_i=73.95 cs/acc_c=73.58 os/recall_knw=57.91 os/recall_unk=81.11 total/acc_i=62.81 total/acc_c=55.12 total/h_score=64.70\n",
      "real -> painting lr= 0.001 seed= 1\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19]\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20]\n",
      "Loss: 1.7120454871002884\n",
      "Loss: 0.2991120621466177\n",
      "Loss: 0.1803029521557104\n",
      "Loss: 0.13741067691535427\n",
      "Loss: 0.11747193832393628\n",
      "Loss: 0.10243488685302796\n",
      "Loss: 0.08427771838783164\n",
      "Loss: 0.07525826318315275\n",
      "Loss: 0.06555002074317341\n",
      "Loss: 0.06163685457253906\n",
      "tensor(True) tensor(True)\n",
      "______\n",
      "Iteration t=1\n",
      "all:  cs/acc_i=72.85 cs/acc_c=72.53 os/recall_knw=94.61 os/recall_unk=19.57 total/acc_i=54.74 total/acc_c=68.72 total/h_score=30.70\n",
      "selected:  cs/acc_i=77.56 cs/acc_c=76.98 os/recall_knw=75.08 os/recall_unk=94.58 total/acc_i=78.82 total/acc_c=71.62 total/h_score=80.77\n",
      "Loss: 1.6452447763341336\n",
      "Loss: 0.27698460864645935\n",
      "Loss: 0.16710843281831844\n",
      "Loss: 0.12804393887097026\n",
      "Loss: 0.1093601286354149\n",
      "Loss: 0.09723434482695409\n",
      "Loss: 0.07921763127126896\n",
      "Loss: 0.06724655199467428\n",
      "Loss: 0.06212012647319745\n",
      "Loss: 0.058289536482088865\n",
      "______\n",
      "Iteration t=2\n",
      "all:  cs/acc_i=72.78 cs/acc_c=72.34 os/recall_knw=70.49 os/recall_unk=68.19 total/acc_i=63.94 total/acc_c=61.88 total/h_score=64.71\n",
      "selected:  cs/acc_i=64.55 cs/acc_c=64.89 os/recall_knw=50.54 os/recall_unk=91.67 total/acc_i=63.28 total/acc_c=49.39 total/h_score=62.38\n",
      "Loss: 1.6051672351710937\n",
      "Loss: 0.2621347941458225\n",
      "Loss: 0.1649977803997257\n",
      "Loss: 0.12914172803763957\n",
      "Loss: 0.09972699252505074\n",
      "Loss: 0.08527365340303411\n",
      "Loss: 0.07452169907662798\n",
      "Loss: 0.061852669152979024\n",
      "Loss: 0.06344116766224889\n",
      "Loss: 0.04853004425394294\n",
      "______\n",
      "Iteration t=3\n",
      "all:  cs/acc_i=72.24 cs/acc_c=71.75 os/recall_knw=61.20 os/recall_unk=75.73 total/acc_i=61.99 total/acc_c=56.10 total/h_score=63.80\n",
      "selected:  cs/acc_i=66.80 cs/acc_c=66.70 os/recall_knw=50.82 os/recall_unk=83.87 total/acc_i=59.06 total/acc_c=47.97 total/h_score=59.56\n",
      "Loss: 1.5742507214573296\n",
      "Loss: 0.2589535229013894\n",
      "Loss: 0.1524048729757355\n",
      "Loss: 0.12325767942291516\n",
      "Loss: 0.09563413511866449\n",
      "Loss: 0.0829771692713786\n",
      "Loss: 0.07196268060943112\n",
      "Loss: 0.0659343219555343\n",
      "Loss: 0.05399553254590666\n",
      "Loss: 0.046700753348969476\n",
      "______\n",
      "Iteration t=4\n",
      "all:  cs/acc_i=72.78 cs/acc_c=72.21 os/recall_knw=60.34 os/recall_unk=76.40 total/acc_i=61.77 total/acc_c=55.49 total/h_score=63.58\n",
      "selected:  cs/acc_i=69.39 cs/acc_c=69.34 os/recall_knw=54.51 os/recall_unk=79.61 total/acc_i=59.38 total/acc_c=50.88 total/h_score=61.00\n",
      "Loss: 1.5612113744103018\n",
      "Loss: 0.24810665558992662\n",
      "Loss: 0.15224246076021827\n",
      "Loss: 0.11653360444794401\n",
      "Loss: 0.09064408393777969\n",
      "Loss: 0.0779430080757288\n",
      "Loss: 0.07540554583841455\n",
      "Loss: 0.06189665171882741\n",
      "Loss: 0.050042508682107086\n",
      "Loss: 0.0471725529137163\n",
      "______\n",
      "Iteration t=5\n",
      "all:  cs/acc_i=73.53 cs/acc_c=73.03 os/recall_knw=59.88 os/recall_unk=76.55 total/acc_i=61.55 total/acc_c=55.14 total/h_score=63.38\n",
      "selected:  cs/acc_i=71.77 cs/acc_c=71.73 os/recall_knw=56.87 os/recall_unk=77.36 total/acc_i=60.02 total/acc_c=52.94 total/h_score=61.99\n",
      "Loss: 1.54871055126515\n",
      "Loss: 0.2472756859168857\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.15562063537294435\n",
      "Loss: 0.11368351067322477\n",
      "Loss: 0.08857008795779228\n",
      "Loss: 0.0753238981219176\n",
      "Loss: 0.0718725300406687\n",
      "Loss: 0.05865499778709067\n",
      "Loss: 0.050482214093512834\n",
      "Loss: 0.043734933982402774\n",
      "______\n",
      "Iteration t=6\n",
      "all:  cs/acc_i=73.63 cs/acc_c=73.08 os/recall_knw=59.84 os/recall_unk=76.55 total/acc_i=61.53 total/acc_c=55.10 total/h_score=63.34\n",
      "selected:  cs/acc_i=72.99 cs/acc_c=72.56 os/recall_knw=58.75 os/recall_unk=76.72 total/acc_i=60.92 total/acc_c=54.31 total/h_score=62.82\n",
      "Loss: 1.5405712354215328\n",
      "Loss: 0.25709959711989944\n",
      "Loss: 0.15153315151737867\n",
      "Loss: 0.11842055395596994\n",
      "Loss: 0.08597580462975322\n",
      "Loss: 0.07760951547655014\n",
      "Loss: 0.0652831872169561\n",
      "Loss: 0.05246927472323461\n",
      "Loss: 0.046204190814209914\n",
      "Loss: 0.044912664223502506\n",
      "______\n",
      "Iteration t=7\n",
      "all:  cs/acc_i=74.03 cs/acc_c=73.52 os/recall_knw=59.84 os/recall_unk=76.55 total/acc_i=61.53 total/acc_c=55.10 total/h_score=63.34\n",
      "selected:  cs/acc_i=73.85 cs/acc_c=73.35 os/recall_knw=59.57 os/recall_unk=76.61 total/acc_i=61.36 total/acc_c=54.86 total/h_score=63.19\n",
      "Loss: 1.5242657411354157\n",
      "Loss: 0.24803099156065217\n",
      "Loss: 0.15410226902577417\n",
      "Loss: 0.10719091995511873\n",
      "Loss: 0.09447249783897128\n",
      "Loss: 0.0770403069853483\n",
      "Loss: 0.06404766276348932\n",
      "Loss: 0.05807994372753212\n",
      "Loss: 0.04937959640491604\n",
      "Loss: 0.04502668876597912\n",
      "______\n",
      "Iteration t=8\n",
      "all:  cs/acc_i=73.85 cs/acc_c=73.25 os/recall_knw=59.84 os/recall_unk=76.55 total/acc_i=61.53 total/acc_c=55.10 total/h_score=63.34\n",
      "selected:  cs/acc_i=73.85 cs/acc_c=73.25 os/recall_knw=59.84 os/recall_unk=76.55 total/acc_i=61.53 total/acc_c=55.10 total/h_score=63.34\n",
      "Loss: 1.5358724133898043\n",
      "Loss: 0.24203010536630415\n",
      "Loss: 0.1462454203785904\n",
      "Loss: 0.11335462917780988\n",
      "Loss: 0.0953981643292963\n",
      "Loss: 0.07639924633309206\n",
      "Loss: 0.06870279719818373\n",
      "Loss: 0.05882173045925376\n",
      "Loss: 0.04734890619617445\n",
      "Loss: 0.04751330374393003\n",
      "______\n",
      "Iteration t=9\n",
      "all:  cs/acc_i=73.70 cs/acc_c=73.23 os/recall_knw=59.84 os/recall_unk=76.55 total/acc_i=61.53 total/acc_c=55.10 total/h_score=63.34\n",
      "selected:  cs/acc_i=73.70 cs/acc_c=73.23 os/recall_knw=59.84 os/recall_unk=76.55 total/acc_i=61.53 total/acc_c=55.10 total/h_score=63.34\n",
      "tensor(0)\n",
      "all:  cs/acc_i=73.70 cs/acc_c=73.23 os/recall_knw=59.84 os/recall_unk=76.55 total/acc_i=61.53 total/acc_c=55.10 total/h_score=63.34\n",
      "real -> painting lr= 0.001 seed= 2\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19]\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20]\n",
      "Loss: 1.7170122198736553\n",
      "Loss: 0.2919457328664528\n",
      "Loss: 0.1767769901147801\n",
      "Loss: 0.14273207692782786\n",
      "Loss: 0.11551152534746952\n",
      "Loss: 0.10148355314490112\n",
      "Loss: 0.084314020521268\n",
      "Loss: 0.07513201174586771\n",
      "Loss: 0.07104958239882897\n",
      "Loss: 0.056843557724447685\n",
      "tensor(True) tensor(True)\n",
      "______\n",
      "Iteration t=1\n",
      "all:  cs/acc_i=72.88 cs/acc_c=72.37 os/recall_knw=94.36 os/recall_unk=19.04 total/acc_i=54.62 total/acc_c=68.61 total/h_score=30.04\n",
      "selected:  cs/acc_i=75.70 cs/acc_c=74.45 os/recall_knw=74.06 os/recall_unk=94.44 total/acc_i=77.47 total/acc_c=69.22 total/h_score=79.04\n",
      "Loss: 1.6383497723223972\n",
      "Loss: 0.27621127390788375\n",
      "Loss: 0.17290816776043066\n",
      "Loss: 0.12941617843769262\n",
      "Loss: 0.11399757389573414\n",
      "Loss: 0.09204761635089305\n",
      "Loss: 0.08007490452653243\n",
      "Loss: 0.0728675448464264\n",
      "Loss: 0.060219036198101164\n",
      "Loss: 0.05252442593212051\n",
      "______\n",
      "Iteration t=2\n",
      "all:  cs/acc_i=73.17 cs/acc_c=72.62 os/recall_knw=62.77 os/recall_unk=76.55 total/acc_i=63.51 total/acc_c=57.94 total/h_score=65.35\n",
      "selected:  cs/acc_i=64.45 cs/acc_c=64.69 os/recall_knw=44.96 os/recall_unk=93.10 total/acc_i=60.12 total/acc_c=44.54 total/h_score=58.00\n",
      "Loss: 1.6043267592787742\n",
      "Loss: 0.26531867479138516\n",
      "Loss: 0.15535843936069046\n",
      "Loss: 0.12333845655050348\n",
      "Loss: 0.09334122787558419\n",
      "Loss: 0.08381559381617562\n",
      "Loss: 0.07286708528340301\n",
      "Loss: 0.06333000856616042\n",
      "Loss: 0.059463125311509324\n",
      "Loss: 0.05184524455107749\n",
      "______\n",
      "Iteration t=3\n",
      "all:  cs/acc_i=72.28 cs/acc_c=71.67 os/recall_knw=59.84 os/recall_unk=79.16 total/acc_i=62.95 total/acc_c=56.13 total/h_score=64.89\n",
      "selected:  cs/acc_i=66.38 cs/acc_c=66.26 os/recall_knw=49.62 os/recall_unk=86.67 total/acc_i=59.73 total/acc_c=47.97 total/h_score=60.13\n",
      "Loss: 1.5892219454304786\n",
      "Loss: 0.26204817247526596\n",
      "Loss: 0.15367283842969484\n",
      "Loss: 0.11876999854277341\n",
      "Loss: 0.09874383640074917\n",
      "Loss: 0.08080791652022179\n",
      "Loss: 0.06962260694914309\n",
      "Loss: 0.06107860809176141\n",
      "Loss: 0.05489100556173216\n",
      "Loss: 0.04746007371197675\n",
      "______\n",
      "Iteration t=4\n",
      "all:  cs/acc_i=72.63 cs/acc_c=72.01 os/recall_knw=59.20 os/recall_unk=79.69 total/acc_i=62.78 total/acc_c=55.71 total/h_score=64.73\n",
      "selected:  cs/acc_i=69.02 cs/acc_c=68.95 os/recall_knw=53.20 os/recall_unk=82.91 total/acc_i=60.34 total/acc_c=51.05 total/h_score=61.95\n",
      "Loss: 1.5696391181444391\n",
      "Loss: 0.25400123527289103\n",
      "Loss: 0.15235600033178304\n",
      "Loss: 0.11072249583962236\n",
      "Loss: 0.09080025636588424\n",
      "Loss: 0.08184530000490316\n",
      "Loss: 0.06612815257307132\n",
      "Loss: 0.060368558041709874\n",
      "Loss: 0.05339002978344627\n",
      "Loss: 0.044376174028843515\n",
      "______\n",
      "Iteration t=5\n",
      "all:  cs/acc_i=72.99 cs/acc_c=72.41 os/recall_knw=59.02 os/recall_unk=79.76 total/acc_i=62.69 total/acc_c=55.48 total/h_score=64.59\n",
      "selected:  cs/acc_i=71.04 cs/acc_c=70.99 os/recall_knw=55.59 os/recall_unk=80.60 total/acc_i=61.05 total/acc_c=53.13 total/h_score=63.04\n",
      "Loss: 1.5511902550255858\n",
      "Loss: 0.24710092639325412\n",
      "Loss: 0.15422253514854953\n",
      "Loss: 0.11746336328848214\n",
      "Loss: 0.09053235534056611\n",
      "Loss: 0.07831530876017616\n",
      "Loss: 0.06361312220886267\n",
      "Loss: 0.05896964245015285\n",
      "Loss: 0.0504304606372818\n",
      "Loss: 0.0449011036716811\n",
      "______\n",
      "Iteration t=6\n",
      "all:  cs/acc_i=74.13 cs/acc_c=73.58 os/recall_knw=58.81 os/recall_unk=79.84 total/acc_i=62.59 total/acc_c=55.37 total/h_score=64.53\n",
      "selected:  cs/acc_i=73.33 cs/acc_c=73.01 os/recall_knw=57.30 os/recall_unk=79.96 total/acc_i=61.80 total/acc_c=54.41 total/h_score=63.84\n",
      "Loss: 1.5287953618832903\n",
      "Loss: 0.2503298258145704\n",
      "Loss: 0.15094147815935963\n",
      "Loss: 0.11354953702033052\n",
      "Loss: 0.09362331768700285\n",
      "Loss: 0.08014937060753531\n",
      "Loss: 0.06946444594169683\n",
      "Loss: 0.06160228006141868\n",
      "Loss: 0.05048124594664525\n",
      "Loss: 0.04538317119927935\n",
      "______\n",
      "Iteration t=7\n",
      "all:  cs/acc_i=73.31 cs/acc_c=72.73 os/recall_knw=58.70 os/recall_unk=79.84 total/acc_i=62.54 total/acc_c=55.31 total/h_score=64.48\n",
      "selected:  cs/acc_i=73.20 cs/acc_c=72.60 os/recall_knw=58.52 os/recall_unk=79.96 total/acc_i=62.46 total/acc_c=55.16 total/h_score=64.41\n",
      "Loss: 1.5239559115590275\n",
      "Loss: 0.24648285334980166\n",
      "Loss: 0.1520813475262273\n",
      "Loss: 0.11711858035744847\n",
      "Loss: 0.09193114095518516\n",
      "Loss: 0.07613565837712706\n",
      "Loss: 0.06915249363204615\n",
      "Loss: 0.056678148382972623\n",
      "Loss: 0.05582714187157516\n",
      "Loss: 0.044633797582591304\n",
      "______\n",
      "Iteration t=8\n",
      "all:  cs/acc_i=74.06 cs/acc_c=73.70 os/recall_knw=58.70 os/recall_unk=79.99 total/acc_i=62.59 total/acc_c=55.32 total/h_score=64.53\n",
      "selected:  cs/acc_i=74.06 cs/acc_c=73.70 os/recall_knw=58.70 os/recall_unk=79.99 total/acc_i=62.59 total/acc_c=55.32 total/h_score=64.53\n",
      "Loss: 1.536722464622513\n",
      "Loss: 0.24672718593132786\n",
      "Loss: 0.16184186516706192\n",
      "Loss: 0.11609663784684679\n",
      "Loss: 0.09211663059348045\n",
      "Loss: 0.07630902689547753\n",
      "Loss: 0.06605952403400184\n",
      "Loss: 0.05679434255352921\n",
      "Loss: 0.050234144167582984\n",
      "Loss: 0.044001299697740096\n",
      "______\n",
      "Iteration t=9\n",
      "all:  cs/acc_i=73.67 cs/acc_c=72.96 os/recall_knw=58.70 os/recall_unk=79.99 total/acc_i=62.59 total/acc_c=55.32 total/h_score=64.53\n",
      "selected:  cs/acc_i=73.67 cs/acc_c=72.96 os/recall_knw=58.70 os/recall_unk=79.99 total/acc_i=62.59 total/acc_c=55.32 total/h_score=64.53\n",
      "tensor(0)\n",
      "all:  cs/acc_i=73.67 cs/acc_c=72.96 os/recall_knw=58.70 os/recall_unk=79.99 total/acc_i=62.59 total/acc_c=55.32 total/h_score=64.53\n",
      "real -> painting lr= 0.001 seed= 3\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19]\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20]\n",
      "Loss: 1.710093737702661\n",
      "Loss: 0.30071225577899496\n",
      "Loss: 0.18359331333848058\n",
      "Loss: 0.14383263238540991\n",
      "Loss: 0.11394933137407832\n",
      "Loss: 0.09329450560188658\n",
      "Loss: 0.0849940731456665\n",
      "Loss: 0.07551121567690391\n",
      "Loss: 0.06542844379206945\n",
      "Loss: 0.06139700178811596\n",
      "tensor(True) tensor(True)\n",
      "______\n",
      "Iteration t=1\n",
      "all:  cs/acc_i=72.70 cs/acc_c=72.24 os/recall_knw=94.18 os/recall_unk=18.67 total/acc_i=54.30 total/acc_c=68.40 total/h_score=29.56\n",
      "selected:  cs/acc_i=76.34 cs/acc_c=75.52 os/recall_knw=73.58 os/recall_unk=94.70 total/acc_i=77.53 total/acc_c=70.79 total/h_score=80.23\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 1.6409387585758433\n",
      "Loss: 0.27239088700410047\n",
      "Loss: 0.1734020679023551\n",
      "Loss: 0.12626764239983324\n",
      "Loss: 0.10677508225070279\n",
      "Loss: 0.09582656495375959\n",
      "Loss: 0.0839525128249079\n",
      "Loss: 0.06663801614623631\n",
      "Loss: 0.06138055320640603\n",
      "Loss: 0.055051068085434335\n",
      "______\n",
      "Iteration t=2\n",
      "all:  cs/acc_i=73.28 cs/acc_c=72.90 os/recall_knw=65.59 os/recall_unk=71.84 total/acc_i=63.17 total/acc_c=59.43 total/h_score=64.67\n",
      "selected:  cs/acc_i=64.76 cs/acc_c=64.98 os/recall_knw=46.65 os/recall_unk=91.71 total/acc_i=60.69 total/acc_c=45.94 total/h_score=59.15\n",
      "Loss: 1.610034996446441\n",
      "Loss: 0.2596712278092609\n",
      "Loss: 0.1577700862661004\n",
      "Loss: 0.12134490806664176\n",
      "Loss: 0.10050911232555175\n",
      "Loss: 0.08634448071722599\n",
      "Loss: 0.07499367260812398\n",
      "Loss: 0.06330340195118504\n",
      "Loss: 0.057291942872517904\n",
      "Loss: 0.05131561321767924\n",
      "______\n",
      "Iteration t=3\n",
      "all:  cs/acc_i=72.13 cs/acc_c=71.38 os/recall_knw=59.66 os/recall_unk=77.97 total/acc_i=62.37 total/acc_c=55.71 total/h_score=64.22\n",
      "selected:  cs/acc_i=66.18 cs/acc_c=66.02 os/recall_knw=49.62 os/recall_unk=85.09 total/acc_i=58.97 total/acc_c=47.48 total/h_score=59.38\n",
      "Loss: 1.6014568858187308\n",
      "Loss: 0.2544330960266631\n",
      "Loss: 0.15365674306469207\n",
      "Loss: 0.11898470736659048\n",
      "Loss: 0.0997238310704812\n",
      "Loss: 0.08436365389603782\n",
      "Loss: 0.07398090938791442\n",
      "Loss: 0.06014144223114603\n",
      "Loss: 0.055126071954542895\n",
      "Loss: 0.047657080432558854\n",
      "______\n",
      "Iteration t=4\n",
      "all:  cs/acc_i=72.95 cs/acc_c=72.48 os/recall_knw=59.45 os/recall_unk=78.12 total/acc_i=62.30 total/acc_c=55.55 total/h_score=64.15\n",
      "selected:  cs/acc_i=69.29 cs/acc_c=69.38 os/recall_knw=53.16 os/recall_unk=81.09 total/acc_i=59.66 total/acc_c=50.75 total/h_score=61.27\n",
      "Loss: 1.5673367381095886\n",
      "Loss: 0.25266230573312154\n",
      "Loss: 0.15382129893038932\n",
      "Loss: 0.11507395013108393\n",
      "Loss: 0.0950908248175278\n",
      "Loss: 0.0829056754330832\n",
      "Loss: 0.07270269673369555\n",
      "Loss: 0.05809313122930218\n",
      "Loss: 0.05429314699122542\n",
      "Loss: 0.04916787310049436\n",
      "______\n",
      "Iteration t=5\n",
      "all:  cs/acc_i=72.85 cs/acc_c=72.43 os/recall_knw=58.63 os/recall_unk=78.49 total/acc_i=61.94 total/acc_c=55.02 total/h_score=63.87\n",
      "selected:  cs/acc_i=70.82 cs/acc_c=70.85 os/recall_knw=55.31 os/recall_unk=79.26 total/acc_i=60.22 total/acc_c=52.57 total/h_score=62.24\n",
      "Loss: 1.5482115200669555\n",
      "Loss: 0.24767140373792296\n",
      "Loss: 0.14666508112593993\n",
      "Loss: 0.11744960941947423\n",
      "Loss: 0.09705227580443435\n",
      "Loss: 0.08420711891357224\n",
      "Loss: 0.06509021679988479\n",
      "Loss: 0.0561130469035521\n",
      "Loss: 0.047948567771447494\n",
      "Loss: 0.044742810901940114\n",
      "______\n",
      "Iteration t=6\n",
      "all:  cs/acc_i=73.74 cs/acc_c=73.25 os/recall_knw=58.63 os/recall_unk=78.49 total/acc_i=61.94 total/acc_c=55.02 total/h_score=63.87\n",
      "selected:  cs/acc_i=73.11 cs/acc_c=72.68 os/recall_knw=57.46 os/recall_unk=78.73 total/acc_i=61.35 total/acc_c=54.17 total/h_score=63.31\n",
      "Loss: 1.5544356787753946\n",
      "Loss: 0.2503574051487898\n",
      "Loss: 0.1492232147220593\n",
      "Loss: 0.1162796111772377\n",
      "Loss: 0.09486417227543305\n",
      "Loss: 0.07447273215167931\n",
      "Loss: 0.0682987298634721\n",
      "Loss: 0.05794581683948232\n",
      "Loss: 0.05166409537890235\n",
      "Loss: 0.04660787208126933\n",
      "______\n",
      "Iteration t=7\n",
      "all:  cs/acc_i=73.67 cs/acc_c=73.23 os/recall_knw=58.59 os/recall_unk=78.57 total/acc_i=61.94 total/acc_c=54.97 total/h_score=63.86\n",
      "selected:  cs/acc_i=73.53 cs/acc_c=73.08 os/recall_knw=58.31 os/recall_unk=78.74 total/acc_i=61.83 total/acc_c=54.79 total/h_score=63.78\n",
      "Loss: 1.556928317461695\n",
      "Loss: 0.24422246934670322\n",
      "Loss: 0.14926333915231363\n",
      "Loss: 0.11629861141642872\n",
      "Loss: 0.09167401764461534\n",
      "Loss: 0.07856848955184542\n",
      "Loss: 0.06947867036734348\n",
      "Loss: 0.05999979902701477\n",
      "Loss: 0.05497633789871842\n",
      "Loss: 0.04194148851500829\n",
      "______\n",
      "Iteration t=8\n",
      "all:  cs/acc_i=75.03 cs/acc_c=74.46 os/recall_knw=58.59 os/recall_unk=78.57 total/acc_i=61.94 total/acc_c=54.97 total/h_score=63.86\n",
      "selected:  cs/acc_i=75.03 cs/acc_c=74.46 os/recall_knw=58.59 os/recall_unk=78.57 total/acc_i=61.94 total/acc_c=54.97 total/h_score=63.86\n",
      "Loss: 1.5375314802333029\n",
      "Loss: 0.25614396755827085\n",
      "Loss: 0.15121945741804785\n",
      "Loss: 0.11487428530689199\n",
      "Loss: 0.0934859180817948\n",
      "Loss: 0.07965676130656645\n",
      "Loss: 0.06467919045120397\n",
      "Loss: 0.05625106122550577\n",
      "Loss: 0.05314143254507002\n",
      "Loss: 0.04838697107777381\n",
      "______\n",
      "Iteration t=9\n",
      "all:  cs/acc_i=74.49 cs/acc_c=74.07 os/recall_knw=58.59 os/recall_unk=78.57 total/acc_i=61.94 total/acc_c=54.97 total/h_score=63.86\n",
      "selected:  cs/acc_i=74.49 cs/acc_c=74.07 os/recall_knw=58.59 os/recall_unk=78.57 total/acc_i=61.94 total/acc_c=54.97 total/h_score=63.86\n",
      "tensor(0)\n",
      "all:  cs/acc_i=74.49 cs/acc_c=74.07 os/recall_knw=58.59 os/recall_unk=78.57 total/acc_i=61.94 total/acc_c=54.97 total/h_score=63.86\n",
      "real -> painting lr= 0.001 seed= 4\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19]\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20]\n",
      "Loss: 1.7240010171266231\n",
      "Loss: 0.2996205268038431\n",
      "Loss: 0.18541902976284264\n",
      "Loss: 0.13747803042148662\n",
      "Loss: 0.12223161537787156\n",
      "Loss: 0.0982427502955367\n",
      "Loss: 0.08846242379373197\n",
      "Loss: 0.07478976803397538\n",
      "Loss: 0.06180219820002843\n",
      "Loss: 0.05856834826961016\n",
      "tensor(True) tensor(True)\n",
      "______\n",
      "Iteration t=1\n",
      "all:  cs/acc_i=72.99 cs/acc_c=72.56 os/recall_knw=94.61 os/recall_unk=19.57 total/acc_i=54.64 total/acc_c=68.52 total/h_score=30.68\n",
      "selected:  cs/acc_i=79.47 cs/acc_c=78.53 os/recall_knw=75.00 os/recall_unk=94.58 total/acc_i=79.23 total/acc_c=71.82 total/h_score=80.90\n",
      "Loss: 1.643218269743071\n",
      "Loss: 0.2792880378572122\n",
      "Loss: 0.1670767271239882\n",
      "Loss: 0.13204170492666265\n",
      "Loss: 0.10997894508021375\n",
      "Loss: 0.0905964223687977\n",
      "Loss: 0.0761899374271143\n",
      "Loss: 0.0702215663508792\n",
      "Loss: 0.06010453216303026\n",
      "Loss: 0.05530962328129431\n",
      "______\n",
      "Iteration t=2\n",
      "all:  cs/acc_i=72.38 cs/acc_c=71.98 os/recall_knw=66.95 os/recall_unk=71.70 total/acc_i=63.24 total/acc_c=59.66 total/h_score=64.77\n",
      "selected:  cs/acc_i=64.47 cs/acc_c=64.79 os/recall_knw=47.50 os/recall_unk=91.25 total/acc_i=61.37 total/acc_c=46.98 total/h_score=60.07\n",
      "Loss: 1.589243812333135\n",
      "Loss: 0.26793424612020744\n",
      "Loss: 0.160758508435067\n",
      "Loss: 0.11727891623261659\n",
      "Loss: 0.09220184271141668\n",
      "Loss: 0.08951830988311592\n",
      "Loss: 0.07410808554028764\n",
      "Loss: 0.06725764981169692\n",
      "Loss: 0.05579170977066764\n",
      "Loss: 0.05220805007265881\n",
      "______\n",
      "Iteration t=3\n",
      "all:  cs/acc_i=72.13 cs/acc_c=71.68 os/recall_knw=60.77 os/recall_unk=77.15 total/acc_i=62.45 total/acc_c=56.19 total/h_score=64.31\n",
      "selected:  cs/acc_i=66.64 cs/acc_c=66.69 os/recall_knw=50.83 os/recall_unk=85.51 total/acc_i=59.66 total/acc_c=48.22 total/h_score=60.12\n",
      "Loss: 1.5840692972256378\n",
      "Loss: 0.25695508798923006\n",
      "Loss: 0.15624284860678017\n",
      "Loss: 0.11992285317815417\n",
      "Loss: 0.09741853518062271\n",
      "Loss: 0.07939389228968965\n",
      "Loss: 0.06872056492482609\n",
      "Loss: 0.05843376641860232\n",
      "Loss: 0.05770387944953241\n",
      "Loss: 0.04742075160571734\n",
      "______\n",
      "Iteration t=4\n",
      "all:  cs/acc_i=72.28 cs/acc_c=71.65 os/recall_knw=59.34 os/recall_unk=77.74 total/acc_i=61.79 total/acc_c=54.98 total/h_score=63.62\n",
      "selected:  cs/acc_i=68.79 cs/acc_c=68.80 os/recall_knw=53.51 os/recall_unk=80.82 total/acc_i=59.37 total/acc_c=50.38 total/h_score=60.90\n",
      "Loss: 1.5679635596772035\n",
      "Loss: 0.25970778836765224\n",
      "Loss: 0.15153181489246587\n",
      "Loss: 0.1131495606723345\n",
      "Loss: 0.09367997551000573\n",
      "Loss: 0.0757944098014074\n",
      "Loss: 0.06574179709423333\n",
      "Loss: 0.0617960161025015\n",
      "Loss: 0.05872535871522915\n",
      "Loss: 0.045043065519550715\n",
      "______\n",
      "Iteration t=5\n",
      "all:  cs/acc_i=72.42 cs/acc_c=71.77 os/recall_knw=59.24 os/recall_unk=77.74 total/acc_i=61.72 total/acc_c=54.85 total/h_score=63.52\n",
      "selected:  cs/acc_i=70.83 cs/acc_c=70.65 os/recall_knw=56.32 os/recall_unk=78.45 total/acc_i=60.35 total/acc_c=52.87 total/h_score=62.25\n",
      "Loss: 1.5638908019157056\n",
      "Loss: 0.25035423446507726\n",
      "Loss: 0.1533419891143513\n",
      "Loss: 0.11632153315500157\n",
      "Loss: 0.09354009909830133\n",
      "Loss: 0.07559488620100126\n",
      "Loss: 0.06699094725670955\n",
      "Loss: 0.05777780944608722\n",
      "Loss: 0.05115403409518016\n",
      "Loss: 0.042493839273636376\n",
      "______\n",
      "Iteration t=6\n",
      "all:  cs/acc_i=73.67 cs/acc_c=73.13 os/recall_knw=59.09 os/recall_unk=77.89 total/acc_i=61.70 total/acc_c=54.77 total/h_score=63.51\n",
      "selected:  cs/acc_i=73.02 cs/acc_c=72.62 os/recall_knw=57.86 os/recall_unk=78.19 total/acc_i=61.10 total/acc_c=53.98 total/h_score=63.01\n",
      "Loss: 1.5299335416901079\n",
      "Loss: 0.247059915325829\n",
      "Loss: 0.1505772896656176\n",
      "Loss: 0.11157828857137905\n",
      "Loss: 0.09350201342164016\n",
      "Loss: 0.07542772145896423\n",
      "Loss: 0.06889070168914914\n",
      "Loss: 0.05970930664731962\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.055384967120889285\n",
      "Loss: 0.04770332695108644\n",
      "______\n",
      "Iteration t=7\n",
      "all:  cs/acc_i=74.49 cs/acc_c=74.01 os/recall_knw=59.09 os/recall_unk=77.97 total/acc_i=61.72 total/acc_c=54.77 total/h_score=63.54\n",
      "selected:  cs/acc_i=74.48 cs/acc_c=74.02 os/recall_knw=58.90 os/recall_unk=78.14 total/acc_i=61.72 total/acc_c=54.74 total/h_score=63.56\n",
      "Loss: 1.53412173800571\n",
      "Loss: 0.24665779641438876\n",
      "Loss: 0.1526128826562756\n",
      "Loss: 0.11222758456083234\n",
      "Loss: 0.0895931978449626\n",
      "Loss: 0.07730420858358904\n",
      "Loss: 0.06456203054278709\n",
      "Loss: 0.060932789265768984\n",
      "Loss: 0.0501466024434194\n",
      "Loss: 0.0446525988712286\n",
      "______\n",
      "Iteration t=8\n",
      "all:  cs/acc_i=73.63 cs/acc_c=73.14 os/recall_knw=59.09 os/recall_unk=77.97 total/acc_i=61.72 total/acc_c=54.77 total/h_score=63.54\n",
      "selected:  cs/acc_i=73.63 cs/acc_c=73.14 os/recall_knw=59.09 os/recall_unk=77.97 total/acc_i=61.72 total/acc_c=54.77 total/h_score=63.54\n",
      "Loss: 1.5401497126747203\n",
      "Loss: 0.25351280454666386\n",
      "Loss: 0.15154029373379965\n",
      "Loss: 0.11488392368279478\n",
      "Loss: 0.09420782080801424\n",
      "Loss: 0.07919530481130126\n",
      "Loss: 0.06521228263505123\n",
      "Loss: 0.05654851871828038\n",
      "Loss: 0.05056211362362549\n",
      "Loss: 0.04395619643131091\n",
      "______\n",
      "Iteration t=9\n",
      "all:  cs/acc_i=73.88 cs/acc_c=73.33 os/recall_knw=59.09 os/recall_unk=77.97 total/acc_i=61.72 total/acc_c=54.77 total/h_score=63.54\n",
      "selected:  cs/acc_i=73.88 cs/acc_c=73.33 os/recall_knw=59.09 os/recall_unk=77.97 total/acc_i=61.72 total/acc_c=54.77 total/h_score=63.54\n",
      "tensor(0)\n",
      "all:  cs/acc_i=73.88 cs/acc_c=73.33 os/recall_knw=59.09 os/recall_unk=77.97 total/acc_i=61.72 total/acc_c=54.77 total/h_score=63.54\n",
      "real -> painting lr= 0.001 seed= 0\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19]\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20]\n",
      "Loss: 1.6973589165226057\n",
      "Loss: 0.30852574768844526\n",
      "Loss: 0.17902127913292198\n",
      "Loss: 0.1358824581674441\n",
      "Loss: 0.11404558022317875\n",
      "Loss: 0.09717314847268858\n",
      "Loss: 0.08767150004972311\n",
      "Loss: 0.07405568020930364\n",
      "Loss: 0.06682081703677582\n",
      "Loss: 0.06501211066748289\n",
      "tensor(True) tensor(True)\n",
      "______\n",
      "Iteration t=1\n",
      "all:  cs/acc_i=72.92 cs/acc_c=72.62 os/recall_knw=94.71 os/recall_unk=19.79 total/acc_i=55.00 total/acc_c=69.04 total/h_score=31.00\n",
      "selected:  cs/acc_i=76.83 cs/acc_c=75.75 os/recall_knw=75.33 os/recall_unk=94.31 total/acc_i=79.00 total/acc_c=71.81 total/h_score=80.81\n",
      "Loss: 1.6534036684072821\n",
      "Loss: 0.2840788888122224\n",
      "Loss: 0.1710781487150609\n",
      "Loss: 0.1294438701545808\n",
      "Loss: 0.11167386606438486\n",
      "Loss: 0.09200527967365196\n",
      "Loss: 0.08248855006178281\n",
      "Loss: 0.06810528082498835\n",
      "Loss: 0.058567820731807566\n",
      "Loss: 0.05324399701828148\n",
      "______\n",
      "Iteration t=2\n",
      "all:  cs/acc_i=72.74 cs/acc_c=72.42 os/recall_knw=64.92 os/recall_unk=75.06 total/acc_i=63.90 total/acc_c=59.23 total/h_score=65.71\n",
      "selected:  cs/acc_i=63.81 cs/acc_c=63.98 os/recall_knw=46.40 os/recall_unk=92.80 total/acc_i=60.96 total/acc_c=45.42 total/h_score=58.81\n",
      "Loss: 1.6065792237134542\n",
      "Loss: 0.2691701620378915\n",
      "Loss: 0.15656168018193806\n",
      "Loss: 0.12456400712732883\n",
      "Loss: 0.10240988811368451\n",
      "Loss: 0.08251105014864793\n",
      "Loss: 0.07170797544120647\n",
      "Loss: 0.06576172243050464\n",
      "Loss: 0.05721907320925418\n",
      "Loss: 0.04993504149127094\n",
      "______\n",
      "Iteration t=3\n",
      "all:  cs/acc_i=72.70 cs/acc_c=72.01 os/recall_knw=60.16 os/recall_unk=79.09 total/acc_i=62.98 total/acc_c=56.00 total/h_score=64.77\n",
      "selected:  cs/acc_i=66.93 cs/acc_c=66.86 os/recall_knw=50.38 os/recall_unk=85.40 total/acc_i=59.51 total/acc_c=47.82 total/h_score=59.74\n",
      "Loss: 1.5820777538994497\n",
      "Loss: 0.25335714168084617\n",
      "Loss: 0.1550743619022383\n",
      "Loss: 0.11973783310862597\n",
      "Loss: 0.0975587478262076\n",
      "Loss: 0.07830753357848153\n",
      "Loss: 0.06800209233651086\n",
      "Loss: 0.06007943468284793\n",
      "Loss: 0.056414812185473485\n",
      "Loss: 0.04911872203890446\n",
      "______\n",
      "Iteration t=4\n",
      "all:  cs/acc_i=72.78 cs/acc_c=72.06 os/recall_knw=59.20 os/recall_unk=79.46 total/acc_i=62.49 total/acc_c=55.20 total/h_score=64.29\n",
      "selected:  cs/acc_i=69.45 cs/acc_c=69.41 os/recall_knw=53.54 os/recall_unk=81.85 total/acc_i=60.03 total/acc_c=50.82 total/h_score=61.51\n",
      "Loss: 1.5648670045865907\n",
      "Loss: 0.2486832697254916\n",
      "Loss: 0.155696048716911\n",
      "Loss: 0.11773527621602019\n",
      "Loss: 0.09471146733396583\n",
      "Loss: 0.0765511304864453\n",
      "Loss: 0.07336774450054186\n",
      "Loss: 0.06392340681826075\n",
      "Loss: 0.04949579471075494\n",
      "Loss: 0.04506143999751657\n",
      "______\n",
      "Iteration t=5\n",
      "all:  cs/acc_i=72.78 cs/acc_c=72.20 os/recall_knw=58.99 os/recall_unk=79.54 total/acc_i=62.40 total/acc_c=55.06 total/h_score=64.21\n",
      "selected:  cs/acc_i=71.07 cs/acc_c=71.00 os/recall_knw=56.07 os/recall_unk=80.20 total/acc_i=60.95 total/acc_c=53.03 total/h_score=62.85\n",
      "Loss: 1.546154562414509\n",
      "Loss: 0.24962636084385115\n",
      "Loss: 0.15526513357276786\n",
      "Loss: 0.11542011286093765\n",
      "Loss: 0.0920839534485585\n",
      "Loss: 0.076621055256014\n",
      "Loss: 0.06573093723735376\n",
      "Loss: 0.061740605454024385\n",
      "Loss: 0.046758519651444806\n",
      "Loss: 0.04291970150239051\n",
      "______\n",
      "Iteration t=6\n",
      "all:  cs/acc_i=74.10 cs/acc_c=73.47 os/recall_knw=58.91 os/recall_unk=79.61 total/acc_i=62.37 total/acc_c=54.99 total/h_score=64.18\n",
      "selected:  cs/acc_i=73.55 cs/acc_c=73.08 os/recall_knw=57.81 os/recall_unk=79.79 total/acc_i=61.84 total/acc_c=54.32 total/h_score=63.72\n",
      "Loss: 1.5420532178103439\n",
      "Loss: 0.2552980660463413\n",
      "Loss: 0.15246873810321981\n",
      "Loss: 0.11094234252555503\n",
      "Loss: 0.09114559509268985\n",
      "Loss: 0.07481604049532475\n",
      "Loss: 0.06551934845195351\n",
      "Loss: 0.057297277329918656\n",
      "Loss: 0.05289488868045855\n",
      "Loss: 0.044439754157635035\n",
      "______\n",
      "Iteration t=7\n",
      "all:  cs/acc_i=74.24 cs/acc_c=73.81 os/recall_knw=58.88 os/recall_unk=79.61 total/acc_i=62.35 total/acc_c=54.95 total/h_score=64.15\n",
      "selected:  cs/acc_i=74.11 cs/acc_c=73.68 os/recall_knw=58.61 os/recall_unk=79.67 total/acc_i=62.22 total/acc_c=54.78 total/h_score=64.04\n",
      "Loss: 1.5311056157810026\n",
      "Loss: 0.24658948731309963\n",
      "Loss: 0.1529411502945616\n",
      "Loss: 0.11894608643960278\n",
      "Loss: 0.0910288856673554\n",
      "Loss: 0.07751811075343115\n",
      "Loss: 0.06743551442284147\n",
      "Loss: 0.053250246674997226\n",
      "Loss: 0.05040844438052824\n",
      "Loss: 0.04626015864307628\n",
      "______\n",
      "Iteration t=8\n",
      "all:  cs/acc_i=73.88 cs/acc_c=73.48 os/recall_knw=58.88 os/recall_unk=79.61 total/acc_i=62.35 total/acc_c=54.95 total/h_score=64.15\n",
      "selected:  cs/acc_i=73.87 cs/acc_c=73.47 os/recall_knw=58.86 os/recall_unk=79.61 total/acc_i=62.34 total/acc_c=54.94 total/h_score=64.14\n",
      "Loss: 1.5518629229614997\n",
      "Loss: 0.25322409448115973\n",
      "Loss: 0.1499058512664548\n",
      "Loss: 0.11316561874132754\n",
      "Loss: 0.09639619724483624\n",
      "Loss: 0.07883728775158123\n",
      "Loss: 0.06659332355434161\n",
      "Loss: 0.06307379410770343\n",
      "Loss: 0.04832390510047864\n",
      "Loss: 0.04560734057419926\n",
      "______\n",
      "Iteration t=9\n",
      "all:  cs/acc_i=73.28 cs/acc_c=72.87 os/recall_knw=58.88 os/recall_unk=79.61 total/acc_i=62.35 total/acc_c=54.95 total/h_score=64.15\n",
      "selected:  cs/acc_i=73.28 cs/acc_c=72.87 os/recall_knw=58.88 os/recall_unk=79.61 total/acc_i=62.35 total/acc_c=54.95 total/h_score=64.15\n",
      "tensor(0)\n",
      "all:  cs/acc_i=73.28 cs/acc_c=72.87 os/recall_knw=58.88 os/recall_unk=79.61 total/acc_i=62.35 total/acc_c=54.95 total/h_score=64.15\n",
      "real -> painting lr= 0.001 seed= 1\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19]\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20]\n",
      "Loss: 1.7121760672695001\n",
      "Loss: 0.29935120546836946\n",
      "Loss: 0.18062123172344502\n",
      "Loss: 0.13754606563178673\n",
      "Loss: 0.11769091032169927\n",
      "Loss: 0.10251932736138822\n",
      "Loss: 0.08462000214509738\n",
      "Loss: 0.07561913859683098\n",
      "Loss: 0.065744979645446\n",
      "Loss: 0.06174400420949294\n",
      "tensor(True) tensor(True)\n",
      "______\n",
      "Iteration t=1\n",
      "all:  cs/acc_i=72.56 cs/acc_c=72.23 os/recall_knw=94.50 os/recall_unk=19.34 total/acc_i=54.49 total/acc_c=68.47 total/h_score=30.40\n",
      "selected:  cs/acc_i=76.52 cs/acc_c=75.73 os/recall_knw=74.71 os/recall_unk=94.18 total/acc_i=78.05 total/acc_c=70.87 total/h_score=80.11\n",
      "Loss: 1.6412683652222522\n",
      "Loss: 0.2756874798082867\n",
      "Loss: 0.160709661111647\n",
      "Loss: 0.12393557832810594\n",
      "Loss: 0.11186005380804553\n",
      "Loss: 0.0943695091945262\n",
      "Loss: 0.08118707205717413\n",
      "Loss: 0.06966932511037113\n",
      "Loss: 0.06416138761642566\n",
      "Loss: 0.05608971591216106\n",
      "______\n",
      "Iteration t=2\n",
      "all:  cs/acc_i=72.74 cs/acc_c=72.25 os/recall_knw=67.42 os/recall_unk=71.84 total/acc_i=63.82 total/acc_c=60.33 total/h_score=65.24\n",
      "selected:  cs/acc_i=64.64 cs/acc_c=64.80 os/recall_knw=48.06 os/recall_unk=92.06 total/acc_i=62.12 total/acc_c=47.68 total/h_score=60.86\n",
      "Loss: 1.6052254377919084\n",
      "Loss: 0.26916958495755405\n",
      "Loss: 0.16220605916836683\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.12066738865173915\n",
      "Loss: 0.09902106240556083\n",
      "Loss: 0.0844275349367629\n",
      "Loss: 0.07542826647952418\n",
      "Loss: 0.06678764989380451\n",
      "Loss: 0.0593883351306431\n",
      "Loss: 0.04798643687151044\n",
      "______\n",
      "Iteration t=3\n",
      "all:  cs/acc_i=72.70 cs/acc_c=72.09 os/recall_knw=60.16 os/recall_unk=77.74 total/acc_i=62.49 total/acc_c=55.97 total/h_score=64.34\n",
      "selected:  cs/acc_i=67.07 cs/acc_c=66.96 os/recall_knw=50.04 os/recall_unk=85.68 total/acc_i=59.41 total/acc_c=47.79 total/h_score=59.77\n",
      "Loss: 1.578629710565605\n",
      "Loss: 0.25309858910548383\n",
      "Loss: 0.15672192444488872\n",
      "Loss: 0.12392001455793014\n",
      "Loss: 0.09690889158150834\n",
      "Loss: 0.08397120404510926\n",
      "Loss: 0.06831416767886561\n",
      "Loss: 0.06538068587650303\n",
      "Loss: 0.05391636080482704\n",
      "Loss: 0.04528786083603771\n",
      "______\n",
      "Iteration t=4\n",
      "all:  cs/acc_i=73.24 cs/acc_c=72.60 os/recall_knw=59.41 os/recall_unk=78.19 total/acc_i=62.25 total/acc_c=55.39 total/h_score=64.06\n",
      "selected:  cs/acc_i=70.05 cs/acc_c=69.91 os/recall_knw=53.71 os/recall_unk=80.72 total/acc_i=59.85 total/acc_c=51.02 total/h_score=61.39\n",
      "Loss: 1.5697176417542829\n",
      "Loss: 0.2571014299264385\n",
      "Loss: 0.15191210274481112\n",
      "Loss: 0.12193739927477307\n",
      "Loss: 0.09098718566690675\n",
      "Loss: 0.0761995871991126\n",
      "Loss: 0.068682732369699\n",
      "Loss: 0.05948213912003363\n",
      "Loss: 0.04951414894959372\n",
      "Loss: 0.047471820377460165\n",
      "______\n",
      "Iteration t=5\n",
      "all:  cs/acc_i=73.60 cs/acc_c=73.07 os/recall_knw=59.20 os/recall_unk=78.34 total/acc_i=62.20 total/acc_c=55.28 total/h_score=64.02\n",
      "selected:  cs/acc_i=71.79 cs/acc_c=71.68 os/recall_knw=56.04 os/recall_unk=78.69 total/acc_i=60.52 total/acc_c=53.00 total/h_score=62.42\n",
      "Loss: 1.5642566179575985\n",
      "Loss: 0.25449997047855427\n",
      "Loss: 0.15260709005675904\n",
      "Loss: 0.12051323849758873\n",
      "Loss: 0.08950298203742259\n",
      "Loss: 0.08132404710280977\n",
      "Loss: 0.07056490328316002\n",
      "Loss: 0.059554806957659245\n",
      "Loss: 0.05498851257159489\n",
      "Loss: 0.045552937496989354\n",
      "______\n",
      "Iteration t=6\n",
      "all:  cs/acc_i=73.35 cs/acc_c=73.03 os/recall_knw=59.16 os/recall_unk=78.34 total/acc_i=62.18 total/acc_c=55.25 total/h_score=64.00\n",
      "selected:  cs/acc_i=72.58 cs/acc_c=72.42 os/recall_knw=57.87 os/recall_unk=78.46 total/acc_i=61.46 total/acc_c=54.37 total/h_score=63.38\n",
      "Loss: 1.5364683486904878\n",
      "Loss: 0.2510216426922054\n",
      "Loss: 0.1496818860523342\n",
      "Loss: 0.11737275017844387\n",
      "Loss: 0.09156511124314332\n",
      "Loss: 0.07965374281655159\n",
      "Loss: 0.06450859495870225\n",
      "Loss: 0.05857126530497095\n",
      "Loss: 0.04972385558827217\n",
      "Loss: 0.043817387623106684\n",
      "______\n",
      "Iteration t=7\n",
      "all:  cs/acc_i=74.38 cs/acc_c=73.87 os/recall_knw=59.02 os/recall_unk=78.34 total/acc_i=62.08 total/acc_c=55.15 total/h_score=63.92\n",
      "selected:  cs/acc_i=74.36 cs/acc_c=73.84 os/recall_knw=58.92 os/recall_unk=78.40 total/acc_i=62.06 total/acc_c=55.11 total/h_score=63.91\n",
      "Loss: 1.5443979901091387\n",
      "Loss: 0.24875190074966158\n",
      "Loss: 0.15502833931516574\n",
      "Loss: 0.10803451082639155\n",
      "Loss: 0.09322034614786545\n",
      "Loss: 0.07660748337781037\n",
      "Loss: 0.06486719714913276\n",
      "Loss: 0.05957176359946169\n",
      "Loss: 0.0509592494745839\n",
      "Loss: 0.04626287438128124\n",
      "______\n",
      "Iteration t=8\n",
      "all:  cs/acc_i=74.13 cs/acc_c=73.65 os/recall_knw=59.02 os/recall_unk=78.34 total/acc_i=62.08 total/acc_c=55.15 total/h_score=63.92\n",
      "selected:  cs/acc_i=74.12 cs/acc_c=73.64 os/recall_knw=59.01 os/recall_unk=78.40 total/acc_i=62.09 total/acc_c=55.14 total/h_score=63.94\n",
      "Loss: 1.5439894586320846\n",
      "Loss: 0.2475375309586525\n",
      "Loss: 0.15092738433891245\n",
      "Loss: 0.11289156357988074\n",
      "Loss: 0.09272477191231984\n",
      "Loss: 0.07996226729880217\n",
      "Loss: 0.06533923156444303\n",
      "Loss: 0.059288860626658925\n",
      "Loss: 0.04936055785736009\n",
      "Loss: 0.04508519084355544\n",
      "______\n",
      "Iteration t=9\n",
      "all:  cs/acc_i=74.28 cs/acc_c=73.84 os/recall_knw=59.02 os/recall_unk=78.34 total/acc_i=62.08 total/acc_c=55.15 total/h_score=63.92\n",
      "selected:  cs/acc_i=74.28 cs/acc_c=73.84 os/recall_knw=59.02 os/recall_unk=78.34 total/acc_i=62.08 total/acc_c=55.15 total/h_score=63.92\n",
      "tensor(0)\n",
      "all:  cs/acc_i=74.28 cs/acc_c=73.84 os/recall_knw=59.02 os/recall_unk=78.34 total/acc_i=62.08 total/acc_c=55.15 total/h_score=63.92\n",
      "real -> painting lr= 0.001 seed= 2\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19]\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20]\n",
      "Loss: 1.7176129526647341\n",
      "Loss: 0.29131600878821307\n",
      "Loss: 0.17623158906050435\n",
      "Loss: 0.14207280172675943\n",
      "Loss: 0.11498209674486297\n",
      "Loss: 0.10123623959971682\n",
      "Loss: 0.08406693994447924\n",
      "Loss: 0.07497325703992817\n",
      "Loss: 0.07050232211624982\n",
      "Loss: 0.05671689407510677\n",
      "tensor(True) tensor(True)\n",
      "______\n",
      "Iteration t=1\n",
      "all:  cs/acc_i=72.95 cs/acc_c=72.41 os/recall_knw=94.14 os/recall_unk=18.60 total/acc_i=54.42 total/acc_c=68.55 total/h_score=29.48\n",
      "selected:  cs/acc_i=75.69 cs/acc_c=74.75 os/recall_knw=73.42 os/recall_unk=93.96 total/acc_i=76.76 total/acc_c=69.57 total/h_score=79.14\n",
      "Loss: 1.6386878613862523\n",
      "Loss: 0.27189815163246694\n",
      "Loss: 0.17036843834662\n",
      "Loss: 0.1308882969997229\n",
      "Loss: 0.10760718166108238\n",
      "Loss: 0.09268982004248566\n",
      "Loss: 0.07616253203763826\n",
      "Loss: 0.0653919239108525\n",
      "Loss: 0.06136893760270091\n",
      "Loss: 0.05338130611997738\n",
      "______\n",
      "Iteration t=2\n",
      "all:  cs/acc_i=72.74 cs/acc_c=72.38 os/recall_knw=62.77 os/recall_unk=76.03 total/acc_i=63.27 total/acc_c=57.91 total/h_score=65.15\n",
      "selected:  cs/acc_i=63.92 cs/acc_c=64.14 os/recall_knw=44.63 os/recall_unk=92.13 total/acc_i=59.76 total/acc_c=44.25 total/h_score=57.56\n",
      "Loss: 1.5986107765313458\n",
      "Loss: 0.25675058086567065\n",
      "Loss: 0.15522057340644738\n",
      "Loss: 0.12854918130289983\n",
      "Loss: 0.09972640474546043\n",
      "Loss: 0.0807204112465329\n",
      "Loss: 0.07013256147996906\n",
      "Loss: 0.06759842182098723\n",
      "Loss: 0.05764250278418117\n",
      "Loss: 0.051142575389102975\n",
      "______\n",
      "Iteration t=3\n",
      "all:  cs/acc_i=72.92 cs/acc_c=72.42 os/recall_knw=58.77 os/recall_unk=79.69 total/acc_i=62.52 total/acc_c=55.35 total/h_score=64.47\n",
      "selected:  cs/acc_i=67.43 cs/acc_c=67.42 os/recall_knw=49.21 os/recall_unk=85.98 total/acc_i=59.15 total/acc_c=47.45 total/h_score=59.53\n",
      "Loss: 1.583324142076351\n",
      "Loss: 0.2531585106228152\n",
      "Loss: 0.14980636713256862\n",
      "Loss: 0.11603812481199743\n",
      "Loss: 0.09413766873167281\n",
      "Loss: 0.07823820028220571\n",
      "Loss: 0.06601988302644586\n",
      "Loss: 0.06714905974749699\n",
      "Loss: 0.05156595367099825\n",
      "Loss: 0.04853299539403571\n",
      "______\n",
      "Iteration t=4\n",
      "all:  cs/acc_i=72.67 cs/acc_c=72.22 os/recall_knw=58.06 os/recall_unk=80.06 total/acc_i=62.16 total/acc_c=54.68 total/h_score=64.08\n",
      "selected:  cs/acc_i=69.00 cs/acc_c=69.00 os/recall_knw=51.87 os/recall_unk=82.46 total/acc_i=59.40 total/acc_c=49.72 total/h_score=60.75\n",
      "Loss: 1.5686301993591159\n",
      "Loss: 0.25091389794547797\n",
      "Loss: 0.1513181438815244\n",
      "Loss: 0.1176278268210798\n",
      "Loss: 0.0921832880098893\n",
      "Loss: 0.0837585089868715\n",
      "Loss: 0.06691871035074055\n",
      "Loss: 0.06035202025376031\n",
      "Loss: 0.053486332030675515\n",
      "Loss: 0.04939324825393379\n",
      "______\n",
      "Iteration t=5\n",
      "all:  cs/acc_i=72.60 cs/acc_c=72.11 os/recall_knw=57.98 os/recall_unk=80.06 total/acc_i=62.11 total/acc_c=54.59 total/h_score=64.01\n",
      "selected:  cs/acc_i=70.79 cs/acc_c=70.66 os/recall_knw=54.80 os/recall_unk=80.72 total/acc_i=60.56 total/acc_c=52.27 total/h_score=62.40\n",
      "Loss: 1.5489438973203464\n",
      "Loss: 0.25261962066844595\n",
      "Loss: 0.14936552219256594\n",
      "Loss: 0.11609595206535452\n",
      "Loss: 0.09326325661942854\n",
      "Loss: 0.08037532486052222\n",
      "Loss: 0.0654301855452154\n",
      "Loss: 0.05798630865551736\n",
      "Loss: 0.05117729062132619\n",
      "Loss: 0.045711564187953184\n",
      "______\n",
      "Iteration t=6\n",
      "all:  cs/acc_i=73.92 cs/acc_c=73.44 os/recall_knw=57.88 os/recall_unk=80.13 total/acc_i=62.06 total/acc_c=54.51 total/h_score=63.97\n",
      "selected:  cs/acc_i=73.36 cs/acc_c=72.97 os/recall_knw=56.73 os/recall_unk=80.25 total/acc_i=61.50 total/acc_c=53.73 total/h_score=63.41\n",
      "Loss: 1.533980061300099\n",
      "Loss: 0.2482773453483115\n",
      "Loss: 0.1507190980989\n",
      "Loss: 0.1125218073467967\n",
      "Loss: 0.08893948556025229\n",
      "Loss: 0.07973841182462385\n",
      "Loss: 0.06686227877166263\n",
      "Loss: 0.058879028957048635\n",
      "Loss: 0.051082082627386706\n",
      "Loss: 0.043712938408134505\n",
      "______\n",
      "Iteration t=7\n",
      "all:  cs/acc_i=73.38 cs/acc_c=72.79 os/recall_knw=57.84 os/recall_unk=80.13 total/acc_i=62.03 total/acc_c=54.47 total/h_score=63.94\n",
      "selected:  cs/acc_i=73.25 cs/acc_c=72.65 os/recall_knw=57.52 os/recall_unk=80.25 total/acc_i=61.92 total/acc_c=54.26 total/h_score=63.81\n",
      "Loss: 1.557935955724742\n",
      "Loss: 0.2543548714763265\n",
      "Loss: 0.1478290361299263\n",
      "Loss: 0.11383911337814519\n",
      "Loss: 0.09480497131482533\n",
      "Loss: 0.07945414036411419\n",
      "Loss: 0.06811094006932364\n",
      "Loss: 0.05638467441098437\n",
      "Loss: 0.05340362084161258\n",
      "Loss: 0.04406695343367251\n",
      "______\n",
      "Iteration t=8\n",
      "all:  cs/acc_i=74.13 cs/acc_c=73.65 os/recall_knw=57.84 os/recall_unk=80.13 total/acc_i=62.03 total/acc_c=54.47 total/h_score=63.94\n",
      "selected:  cs/acc_i=74.13 cs/acc_c=73.65 os/recall_knw=57.84 os/recall_unk=80.13 total/acc_i=62.03 total/acc_c=54.47 total/h_score=63.94\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 1.5286549811830392\n",
      "Loss: 0.24171089125243392\n",
      "Loss: 0.154060352583592\n",
      "Loss: 0.11708447835534005\n",
      "Loss: 0.09392207368604234\n",
      "Loss: 0.0789003610384424\n",
      "Loss: 0.07051959074656101\n",
      "Loss: 0.05922559676062618\n",
      "Loss: 0.05023331921673506\n",
      "Loss: 0.047132365692507575\n",
      "______\n",
      "Iteration t=9\n",
      "all:  cs/acc_i=74.06 cs/acc_c=73.56 os/recall_knw=57.84 os/recall_unk=80.13 total/acc_i=62.03 total/acc_c=54.47 total/h_score=63.94\n",
      "selected:  cs/acc_i=74.06 cs/acc_c=73.56 os/recall_knw=57.84 os/recall_unk=80.13 total/acc_i=62.03 total/acc_c=54.47 total/h_score=63.94\n",
      "tensor(0)\n",
      "all:  cs/acc_i=74.06 cs/acc_c=73.56 os/recall_knw=57.84 os/recall_unk=80.13 total/acc_i=62.03 total/acc_c=54.47 total/h_score=63.94\n",
      "real -> painting lr= 0.001 seed= 3\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19]\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20]\n",
      "Loss: 1.7086327956612086\n",
      "Loss: 0.3007956814392203\n",
      "Loss: 0.1837192547546514\n",
      "Loss: 0.14399216728961736\n",
      "Loss: 0.1138830967157648\n",
      "Loss: 0.09333374484523028\n",
      "Loss: 0.08480602578586417\n",
      "Loss: 0.07579530049953909\n",
      "Loss: 0.06575515861637962\n",
      "Loss: 0.06135963610825623\n",
      "tensor(True) tensor(True)\n",
      "______\n",
      "Iteration t=1\n",
      "all:  cs/acc_i=72.38 cs/acc_c=71.98 os/recall_knw=94.07 os/recall_unk=18.45 total/acc_i=54.13 total/acc_c=68.28 total/h_score=29.27\n",
      "selected:  cs/acc_i=74.47 cs/acc_c=73.39 os/recall_knw=73.18 os/recall_unk=94.27 total/acc_i=76.62 total/acc_c=69.21 total/h_score=78.98\n",
      "Loss: 1.644973275120273\n",
      "Loss: 0.2716446549180278\n",
      "Loss: 0.16873975087848544\n",
      "Loss: 0.13619669388545438\n",
      "Loss: 0.10391580777677016\n",
      "Loss: 0.09262124457013754\n",
      "Loss: 0.08385550077330389\n",
      "Loss: 0.06997662008185786\n",
      "Loss: 0.0618512242021142\n",
      "Loss: 0.052712457068121644\n",
      "______\n",
      "Iteration t=2\n",
      "all:  cs/acc_i=72.78 cs/acc_c=72.38 os/recall_knw=65.17 os/recall_unk=72.67 total/acc_i=63.05 total/acc_c=58.94 total/h_score=64.66\n",
      "selected:  cs/acc_i=64.01 cs/acc_c=64.24 os/recall_knw=46.10 os/recall_unk=91.19 total/acc_i=60.15 total/acc_c=45.29 total/h_score=58.44\n",
      "Loss: 1.6002026106066563\n",
      "Loss: 0.2600226837812978\n",
      "Loss: 0.1635119664208854\n",
      "Loss: 0.13064947811996236\n",
      "Loss: 0.10222565483247094\n",
      "Loss: 0.08771629131070394\n",
      "Loss: 0.079703377090011\n",
      "Loss: 0.061319412006174814\n",
      "Loss: 0.05496873345075394\n",
      "Loss: 0.0535706466762349\n",
      "______\n",
      "Iteration t=3\n",
      "all:  cs/acc_i=72.49 cs/acc_c=72.01 os/recall_knw=59.13 os/recall_unk=78.04 total/acc_i=61.99 total/acc_c=55.20 total/h_score=63.87\n",
      "selected:  cs/acc_i=66.64 cs/acc_c=66.69 os/recall_knw=48.77 os/recall_unk=84.82 total/acc_i=58.41 total/acc_c=46.82 total/h_score=58.73\n",
      "Loss: 1.5847926241719825\n",
      "Loss: 0.2579324915049932\n",
      "Loss: 0.15564265218895046\n",
      "Loss: 0.11674345772119074\n",
      "Loss: 0.09742792214179395\n",
      "Loss: 0.0804499415282765\n",
      "Loss: 0.07235542233725559\n",
      "Loss: 0.06165279985101697\n",
      "Loss: 0.05347266009387871\n",
      "Loss: 0.04955102360549985\n",
      "______\n",
      "Iteration t=4\n",
      "all:  cs/acc_i=72.31 cs/acc_c=71.79 os/recall_knw=57.95 os/recall_unk=78.72 total/acc_i=61.50 total/acc_c=54.24 total/h_score=63.36\n",
      "selected:  cs/acc_i=68.90 cs/acc_c=69.04 os/recall_knw=52.21 os/recall_unk=81.77 total/acc_i=59.12 total/acc_c=49.85 total/h_score=60.69\n",
      "Loss: 1.5586325318700425\n",
      "Loss: 0.25761118399441074\n",
      "Loss: 0.14882651799485544\n",
      "Loss: 0.11043974481689067\n",
      "Loss: 0.09480754991936235\n",
      "Loss: 0.08241170942316398\n",
      "Loss: 0.07252389752347552\n",
      "Loss: 0.05907632532584011\n",
      "Loss: 0.053736428276851024\n",
      "Loss: 0.04849851526213618\n",
      "______\n",
      "Iteration t=5\n",
      "all:  cs/acc_i=73.45 cs/acc_c=72.96 os/recall_knw=57.88 os/recall_unk=78.79 total/acc_i=61.48 total/acc_c=54.18 total/h_score=63.34\n",
      "selected:  cs/acc_i=71.72 cs/acc_c=71.69 os/recall_knw=54.76 os/recall_unk=79.26 total/acc_i=59.87 total/acc_c=52.00 total/h_score=61.80\n",
      "Loss: 1.5494767259601707\n",
      "Loss: 0.251439289803934\n",
      "Loss: 0.14821599766223148\n",
      "Loss: 0.1177975451164357\n",
      "Loss: 0.0937524224493325\n",
      "Loss: 0.0784329012622238\n",
      "Loss: 0.06597083325978818\n",
      "Loss: 0.05778367084497074\n",
      "Loss: 0.04955755129065058\n",
      "Loss: 0.04292858980409289\n",
      "______\n",
      "Iteration t=6\n",
      "all:  cs/acc_i=73.67 cs/acc_c=73.26 os/recall_knw=57.88 os/recall_unk=78.79 total/acc_i=61.48 total/acc_c=54.18 total/h_score=63.34\n",
      "selected:  cs/acc_i=73.00 cs/acc_c=72.77 os/recall_knw=56.57 os/recall_unk=78.97 total/acc_i=60.82 total/acc_c=53.34 total/h_score=62.75\n",
      "Loss: 1.5540915356706018\n",
      "Loss: 0.25082090407933877\n",
      "Loss: 0.15214961181070819\n",
      "Loss: 0.11699895422561499\n",
      "Loss: 0.09522565089307887\n",
      "Loss: 0.07877141461991098\n",
      "Loss: 0.06330440829017038\n",
      "Loss: 0.05931472100137793\n",
      "Loss: 0.05213419723061278\n",
      "Loss: 0.043281890708148356\n",
      "______\n",
      "Iteration t=7\n",
      "all:  cs/acc_i=73.81 cs/acc_c=73.60 os/recall_knw=57.84 os/recall_unk=78.79 total/acc_i=61.45 total/acc_c=54.15 total/h_score=63.31\n",
      "selected:  cs/acc_i=73.70 cs/acc_c=73.49 os/recall_knw=57.54 os/recall_unk=78.91 total/acc_i=61.35 total/acc_c=53.98 total/h_score=63.22\n",
      "Loss: 1.5595590566058417\n",
      "Loss: 0.2602549111017504\n",
      "Loss: 0.14747533125148432\n",
      "Loss: 0.11041844377696917\n",
      "Loss: 0.09653738344944007\n",
      "Loss: 0.07647838297778288\n",
      "Loss: 0.06812836827735441\n",
      "Loss: 0.053809128509129625\n",
      "Loss: 0.04909651831069307\n",
      "Loss: 0.04570346264848234\n",
      "______\n",
      "Iteration t=8\n",
      "all:  cs/acc_i=73.35 cs/acc_c=72.76 os/recall_knw=57.84 os/recall_unk=78.79 total/acc_i=61.45 total/acc_c=54.15 total/h_score=63.31\n",
      "selected:  cs/acc_i=73.35 cs/acc_c=72.76 os/recall_knw=57.84 os/recall_unk=78.85 total/acc_i=61.47 total/acc_c=54.15 total/h_score=63.33\n",
      "Loss: 1.5474722562131855\n",
      "Loss: 0.2520812547230978\n",
      "Loss: 0.14820735822268574\n",
      "Loss: 0.11269999547256533\n",
      "Loss: 0.10215286055524554\n",
      "Loss: 0.07858194700866496\n",
      "Loss: 0.06764407745986735\n",
      "Loss: 0.059019932566044944\n",
      "Loss: 0.04711577852226472\n",
      "Loss: 0.04651492344707532\n",
      "______\n",
      "Iteration t=9\n",
      "all:  cs/acc_i=73.38 cs/acc_c=72.85 os/recall_knw=57.84 os/recall_unk=78.79 total/acc_i=61.45 total/acc_c=54.15 total/h_score=63.31\n",
      "selected:  cs/acc_i=73.38 cs/acc_c=72.85 os/recall_knw=57.84 os/recall_unk=78.79 total/acc_i=61.45 total/acc_c=54.15 total/h_score=63.31\n",
      "tensor(0)\n",
      "all:  cs/acc_i=73.38 cs/acc_c=72.85 os/recall_knw=57.84 os/recall_unk=78.79 total/acc_i=61.45 total/acc_c=54.15 total/h_score=63.31\n",
      "real -> painting lr= 0.001 seed= 4\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19]\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20]\n",
      "Loss: 1.7222436953970857\n",
      "Loss: 0.2996408206761075\n",
      "Loss: 0.1857904796922801\n",
      "Loss: 0.13789613440129725\n",
      "Loss: 0.12226444753815219\n",
      "Loss: 0.09823991047440042\n",
      "Loss: 0.08901297765816907\n",
      "Loss: 0.07495998146036383\n",
      "Loss: 0.06204666807376136\n",
      "Loss: 0.05855374514137266\n",
      "tensor(True) tensor(True)\n",
      "______\n",
      "Iteration t=1\n",
      "all:  cs/acc_i=72.85 cs/acc_c=72.46 os/recall_knw=94.43 os/recall_unk=19.19 total/acc_i=54.35 total/acc_c=68.31 total/h_score=30.20\n",
      "selected:  cs/acc_i=79.18 cs/acc_c=78.57 os/recall_knw=74.43 os/recall_unk=94.49 total/acc_i=78.57 total/acc_c=71.37 total/h_score=80.56\n",
      "Loss: 1.637166104616563\n",
      "Loss: 0.27997639999250695\n",
      "Loss: 0.1696952276183235\n",
      "Loss: 0.12804377897202604\n",
      "Loss: 0.10934450122544918\n",
      "Loss: 0.08996491813803652\n",
      "Loss: 0.07916436444088085\n",
      "Loss: 0.06888095152341515\n",
      "Loss: 0.05928778587097725\n",
      "Loss: 0.05820096294578462\n",
      "______\n",
      "Iteration t=2\n",
      "all:  cs/acc_i=72.63 cs/acc_c=72.27 os/recall_knw=64.06 os/recall_unk=74.31 total/acc_i=63.29 total/acc_c=58.47 total/h_score=64.95\n",
      "selected:  cs/acc_i=63.53 cs/acc_c=64.14 os/recall_knw=45.65 os/recall_unk=92.39 total/acc_i=60.18 total/acc_c=44.86 total/h_score=58.21\n",
      "Loss: 1.5926478668170816\n",
      "Loss: 0.2646191539900268\n",
      "Loss: 0.15703268799492542\n",
      "Loss: 0.11784979809513864\n",
      "Loss: 0.09956978994476444\n",
      "Loss: 0.08719113726059304\n",
      "Loss: 0.07356756105128785\n",
      "Loss: 0.06545159985612639\n",
      "Loss: 0.053544420679099855\n",
      "Loss: 0.050405632748323326\n",
      "______\n",
      "Iteration t=3\n",
      "all:  cs/acc_i=73.31 cs/acc_c=72.84 os/recall_knw=59.66 os/recall_unk=78.57 total/acc_i=62.64 total/acc_c=55.93 total/h_score=64.56\n",
      "selected:  cs/acc_i=67.99 cs/acc_c=68.07 os/recall_knw=50.22 os/recall_unk=86.66 total/acc_i=59.79 total/acc_c=48.10 total/h_score=60.25\n",
      "Loss: 1.579855483363975\n",
      "Loss: 0.26127584551630373\n",
      "Loss: 0.15732999063435604\n",
      "Loss: 0.12220002969049594\n",
      "Loss: 0.09764909220658327\n",
      "Loss: 0.08146199429227802\n",
      "Loss: 0.0709149348761209\n",
      "Loss: 0.06347139744850044\n",
      "Loss: 0.05455100275205702\n",
      "Loss: 0.04606864126055205\n",
      "______\n",
      "Iteration t=4\n",
      "all:  cs/acc_i=72.63 cs/acc_c=72.15 os/recall_knw=58.84 os/recall_unk=79.01 total/acc_i=62.30 total/acc_c=55.27 total/h_score=64.21\n",
      "selected:  cs/acc_i=69.09 cs/acc_c=69.14 os/recall_knw=52.96 os/recall_unk=81.26 total/acc_i=59.64 total/acc_c=50.47 total/h_score=61.08\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 1.5703431645143664\n",
      "Loss: 0.25606395569850476\n",
      "Loss: 0.15499606268340332\n",
      "Loss: 0.11464357003310181\n",
      "Loss: 0.10058159669108875\n",
      "Loss: 0.07776108028725164\n",
      "Loss: 0.07184775433150278\n",
      "Loss: 0.06535680487253871\n",
      "Loss: 0.05015597052413005\n",
      "Loss: 0.0433644554409144\n",
      "______\n",
      "Iteration t=5\n",
      "all:  cs/acc_i=73.24 cs/acc_c=72.65 os/recall_knw=58.81 os/recall_unk=79.16 total/acc_i=62.32 total/acc_c=55.23 total/h_score=64.23\n",
      "selected:  cs/acc_i=71.58 cs/acc_c=71.39 os/recall_knw=55.84 os/recall_unk=79.94 total/acc_i=60.91 total/acc_c=53.07 total/h_score=62.81\n",
      "Loss: 1.5542554211126616\n",
      "Loss: 0.2482018351861059\n",
      "Loss: 0.1553082625598532\n",
      "Loss: 0.11987143133141814\n",
      "Loss: 0.09038857313077131\n",
      "Loss: 0.07573674685283474\n",
      "Loss: 0.06766126777160249\n",
      "Loss: 0.061956417854007795\n",
      "Loss: 0.04642713575253952\n",
      "Loss: 0.047424054521850424\n",
      "______\n",
      "Iteration t=6\n",
      "all:  cs/acc_i=72.92 cs/acc_c=72.48 os/recall_knw=58.70 os/recall_unk=79.16 total/acc_i=62.25 total/acc_c=55.11 total/h_score=64.14\n",
      "selected:  cs/acc_i=72.30 cs/acc_c=71.98 os/recall_knw=57.53 os/recall_unk=79.46 total/acc_i=61.71 total/acc_c=54.32 total/h_score=63.63\n",
      "Loss: 1.5321343379615122\n",
      "Loss: 0.24646814758094346\n",
      "Loss: 0.15424696061770282\n",
      "Loss: 0.12096978897143024\n",
      "Loss: 0.08995048063087875\n",
      "Loss: 0.07693147895287289\n",
      "Loss: 0.06911327049065492\n",
      "Loss: 0.06128368248562341\n",
      "Loss: 0.05417505076892048\n",
      "Loss: 0.0416042370883228\n",
      "______\n",
      "Iteration t=7\n",
      "all:  cs/acc_i=74.38 cs/acc_c=73.90 os/recall_knw=58.66 os/recall_unk=79.16 total/acc_i=62.25 total/acc_c=55.11 total/h_score=64.14\n",
      "selected:  cs/acc_i=74.31 cs/acc_c=73.81 os/recall_knw=58.49 os/recall_unk=79.22 total/acc_i=62.18 total/acc_c=55.00 total/h_score=64.07\n",
      "Loss: 1.5399395587309352\n",
      "Loss: 0.24557609811947353\n",
      "Loss: 0.14770097757446154\n",
      "Loss: 0.11380822042811592\n",
      "Loss: 0.09720584481070947\n",
      "Loss: 0.07909594670269447\n",
      "Loss: 0.06418599553325909\n",
      "Loss: 0.05636361719239654\n",
      "Loss: 0.04977619407116122\n",
      "Loss: 0.042552017021266555\n",
      "______\n",
      "Iteration t=8\n",
      "all:  cs/acc_i=73.70 cs/acc_c=73.18 os/recall_knw=58.66 os/recall_unk=79.16 total/acc_i=62.25 total/acc_c=55.11 total/h_score=64.14\n",
      "selected:  cs/acc_i=73.70 cs/acc_c=73.18 os/recall_knw=58.66 os/recall_unk=79.16 total/acc_i=62.25 total/acc_c=55.11 total/h_score=64.14\n",
      "Loss: 1.5409354372326576\n",
      "Loss: 0.25401462927822155\n",
      "Loss: 0.15662533676407409\n",
      "Loss: 0.1093112292907871\n",
      "Loss: 0.0939494097038019\n",
      "Loss: 0.07604569783609993\n",
      "Loss: 0.06735215864001179\n",
      "Loss: 0.057906608722320785\n",
      "Loss: 0.05127313386930047\n",
      "Loss: 0.04444168734544953\n",
      "______\n",
      "Iteration t=9\n",
      "all:  cs/acc_i=74.03 cs/acc_c=73.43 os/recall_knw=58.66 os/recall_unk=79.16 total/acc_i=62.25 total/acc_c=55.11 total/h_score=64.14\n",
      "selected:  cs/acc_i=74.03 cs/acc_c=73.43 os/recall_knw=58.66 os/recall_unk=79.16 total/acc_i=62.25 total/acc_c=55.11 total/h_score=64.14\n",
      "tensor(0)\n",
      "all:  cs/acc_i=74.03 cs/acc_c=73.43 os/recall_knw=58.66 os/recall_unk=79.16 total/acc_i=62.25 total/acc_c=55.11 total/h_score=64.14\n",
      "real -> painting lr= 0.001 seed= 0\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19]\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20]\n",
      "Loss: 1.6995061741381212\n",
      "Loss: 0.30845579227067266\n",
      "Loss: 0.17895103489135622\n",
      "Loss: 0.13586159559547709\n",
      "Loss: 0.1140105275413279\n",
      "Loss: 0.09685234816211884\n",
      "Loss: 0.0874586020150129\n",
      "Loss: 0.07419997050615561\n",
      "Loss: 0.0667474666307905\n",
      "Loss: 0.0649970709117896\n",
      "tensor(True) tensor(True)\n",
      "______\n",
      "Iteration t=1\n",
      "all:  cs/acc_i=73.17 cs/acc_c=72.82 os/recall_knw=94.64 os/recall_unk=19.64 total/acc_i=55.03 total/acc_c=69.12 total/h_score=30.83\n",
      "selected:  cs/acc_i=77.56 cs/acc_c=77.27 os/recall_knw=75.25 os/recall_unk=94.95 total/acc_i=79.16 total/acc_c=72.25 total/h_score=81.32\n",
      "Loss: 1.6528992886923572\n",
      "Loss: 0.2781020361084514\n",
      "Loss: 0.1657080316996099\n",
      "Loss: 0.13452275830715255\n",
      "Loss: 0.10818719051126963\n",
      "Loss: 0.09480780782178044\n",
      "Loss: 0.08132512560771332\n",
      "Loss: 0.06730548049140424\n",
      "Loss: 0.058425153575643346\n",
      "Loss: 0.051964896363263346\n",
      "______\n",
      "Iteration t=2\n",
      "all:  cs/acc_i=72.88 cs/acc_c=72.54 os/recall_knw=64.59 os/recall_unk=74.09 total/acc_i=63.32 total/acc_c=58.80 total/h_score=65.09\n",
      "selected:  cs/acc_i=64.53 cs/acc_c=64.51 os/recall_knw=46.17 os/recall_unk=92.71 total/acc_i=60.74 total/acc_c=45.12 total/h_score=58.51\n",
      "Loss: 1.6070550335680738\n",
      "Loss: 0.26699208768413346\n",
      "Loss: 0.15391239968183287\n",
      "Loss: 0.11628082714536611\n",
      "Loss: 0.1056808438124683\n",
      "Loss: 0.08107188109527616\n",
      "Loss: 0.07127041842185837\n",
      "Loss: 0.06531837165410466\n",
      "Loss: 0.0583669623154599\n",
      "Loss: 0.05390854656066307\n",
      "______\n",
      "Iteration t=3\n",
      "all:  cs/acc_i=72.60 cs/acc_c=72.03 os/recall_knw=58.34 os/recall_unk=79.31 total/acc_i=62.20 total/acc_c=55.01 total/h_score=64.11\n",
      "selected:  cs/acc_i=66.98 cs/acc_c=66.96 os/recall_knw=48.45 os/recall_unk=86.20 total/acc_i=58.87 total/acc_c=46.69 total/h_score=58.88\n",
      "Loss: 1.6047577672025077\n",
      "Loss: 0.25782943634778005\n",
      "Loss: 0.15883187060257647\n",
      "Loss: 0.12023405546582493\n",
      "Loss: 0.09165069273542985\n",
      "Loss: 0.0828162853067417\n",
      "Loss: 0.06843064595186324\n",
      "Loss: 0.06407785011943631\n",
      "Loss: 0.05298748105217801\n",
      "Loss: 0.0477047484053665\n",
      "______\n",
      "Iteration t=4\n",
      "all:  cs/acc_i=72.92 cs/acc_c=72.40 os/recall_knw=57.63 os/recall_unk=80.13 total/acc_i=62.11 total/acc_c=54.55 total/h_score=64.00\n",
      "selected:  cs/acc_i=69.47 cs/acc_c=69.38 os/recall_knw=51.59 os/recall_unk=82.10 total/acc_i=59.38 total/acc_c=49.73 total/h_score=60.67\n",
      "Loss: 1.561709524033456\n",
      "Loss: 0.25455700869375436\n",
      "Loss: 0.15313529377210075\n",
      "Loss: 0.11472157942516177\n",
      "Loss: 0.0974001044696249\n",
      "Loss: 0.08287880307729434\n",
      "Loss: 0.06935314752562127\n",
      "Loss: 0.058479303230698006\n",
      "Loss: 0.04967652796182324\n",
      "Loss: 0.0427515620909444\n",
      "______\n",
      "Iteration t=5\n",
      "all:  cs/acc_i=72.78 cs/acc_c=72.25 os/recall_knw=57.52 os/recall_unk=80.13 total/acc_i=62.06 total/acc_c=54.46 total/h_score=63.93\n",
      "selected:  cs/acc_i=71.11 cs/acc_c=70.88 os/recall_knw=54.50 os/recall_unk=80.50 total/acc_i=60.54 total/acc_c=52.24 total/h_score=62.31\n",
      "Loss: 1.5492944370259296\n",
      "Loss: 0.2540245092177129\n",
      "Loss: 0.15535937649310455\n",
      "Loss: 0.11782679363194812\n",
      "Loss: 0.0926249856794519\n",
      "Loss: 0.075850597209205\n",
      "Loss: 0.06921449987407119\n",
      "Loss: 0.05806424179508422\n",
      "Loss: 0.04984720649740116\n",
      "Loss: 0.04872985696867825\n",
      "______\n",
      "Iteration t=6\n",
      "all:  cs/acc_i=73.78 cs/acc_c=73.40 os/recall_knw=57.52 os/recall_unk=80.13 total/acc_i=62.06 total/acc_c=54.46 total/h_score=63.93\n",
      "selected:  cs/acc_i=73.22 cs/acc_c=72.94 os/recall_knw=56.49 os/recall_unk=80.25 total/acc_i=61.52 total/acc_c=53.77 total/h_score=63.43\n",
      "Loss: 1.5477057906758527\n",
      "Loss: 0.25760233807175054\n",
      "Loss: 0.1560330149039383\n",
      "Loss: 0.12042464216179012\n",
      "Loss: 0.09456827126332032\n",
      "Loss: 0.0819559999205091\n",
      "Loss: 0.06758737577246907\n",
      "Loss: 0.05308252124181625\n",
      "Loss: 0.05190108813163217\n",
      "Loss: 0.038934621349376954\n",
      "______\n",
      "Iteration t=7\n",
      "all:  cs/acc_i=74.06 cs/acc_c=73.82 os/recall_knw=57.52 os/recall_unk=80.13 total/acc_i=62.06 total/acc_c=54.46 total/h_score=63.93\n",
      "selected:  cs/acc_i=74.01 cs/acc_c=73.74 os/recall_knw=57.43 os/recall_unk=80.25 total/acc_i=62.03 total/acc_c=54.38 total/h_score=63.90\n",
      "Loss: 1.5376399777284482\n",
      "Loss: 0.25349138755866185\n",
      "Loss: 0.15402500548458034\n",
      "Loss: 0.11562092798360722\n",
      "Loss: 0.09343480147789851\n",
      "Loss: 0.08150554083661254\n",
      "Loss: 0.06784418036878553\n",
      "Loss: 0.06141246817021714\n",
      "Loss: 0.04790648376962882\n",
      "Loss: 0.04630544593953338\n",
      "______\n",
      "Iteration t=8\n",
      "all:  cs/acc_i=74.35 cs/acc_c=73.92 os/recall_knw=57.52 os/recall_unk=80.13 total/acc_i=62.06 total/acc_c=54.46 total/h_score=63.93\n",
      "selected:  cs/acc_i=74.35 cs/acc_c=73.92 os/recall_knw=57.52 os/recall_unk=80.13 total/acc_i=62.06 total/acc_c=54.46 total/h_score=63.93\n",
      "Loss: 1.5565080616925213\n",
      "Loss: 0.2466069631681249\n",
      "Loss: 0.15216295606381183\n",
      "Loss: 0.11396054946691603\n",
      "Loss: 0.09315341259227009\n",
      "Loss: 0.08158616724398893\n",
      "Loss: 0.07194402017882345\n",
      "Loss: 0.058447171304676984\n",
      "Loss: 0.04894515867407962\n",
      "Loss: 0.04792823044432176\n",
      "______\n",
      "Iteration t=9\n",
      "all:  cs/acc_i=74.06 cs/acc_c=73.62 os/recall_knw=57.52 os/recall_unk=80.13 total/acc_i=62.06 total/acc_c=54.46 total/h_score=63.93\n",
      "selected:  cs/acc_i=74.06 cs/acc_c=73.62 os/recall_knw=57.52 os/recall_unk=80.13 total/acc_i=62.06 total/acc_c=54.46 total/h_score=63.93\n",
      "tensor(0)\n",
      "all:  cs/acc_i=74.06 cs/acc_c=73.62 os/recall_knw=57.52 os/recall_unk=80.13 total/acc_i=62.06 total/acc_c=54.46 total/h_score=63.93\n",
      "real -> painting lr= 0.001 seed= 1\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19]\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 1.711325420060725\n",
      "Loss: 0.29977138486609967\n",
      "Loss: 0.1806576890793069\n",
      "Loss: 0.13767595802376892\n",
      "Loss: 0.11761751489779669\n",
      "Loss: 0.10246697372466422\n",
      "Loss: 0.08439298811701046\n",
      "Loss: 0.07531783136934449\n",
      "Loss: 0.06549370919213514\n",
      "Loss: 0.061403089044226325\n",
      "tensor(True) tensor(True)\n",
      "______\n",
      "Iteration t=1\n",
      "all:  cs/acc_i=72.85 cs/acc_c=72.57 os/recall_knw=94.71 os/recall_unk=19.79 total/acc_i=54.69 total/acc_c=68.58 total/h_score=30.96\n",
      "selected:  cs/acc_i=79.08 cs/acc_c=78.88 os/recall_knw=75.62 os/recall_unk=94.98 total/acc_i=79.46 total/acc_c=72.56 total/h_score=81.55\n",
      "Loss: 1.6415334669358892\n",
      "Loss: 0.26911296494350845\n",
      "Loss: 0.16327837392962052\n",
      "Loss: 0.13605266265239727\n",
      "Loss: 0.10649931122280337\n",
      "Loss: 0.09231942843508684\n",
      "Loss: 0.079308990767637\n",
      "Loss: 0.06757630063277995\n",
      "Loss: 0.06162315821475092\n",
      "Loss: 0.05449428995342731\n",
      "______\n",
      "Iteration t=2\n",
      "all:  cs/acc_i=73.13 cs/acc_c=72.66 os/recall_knw=59.52 os/recall_unk=79.84 total/acc_i=63.03 total/acc_c=56.26 total/h_score=65.19\n",
      "selected:  cs/acc_i=64.83 cs/acc_c=64.83 os/recall_knw=42.57 os/recall_unk=92.39 total/acc_i=58.79 total/acc_c=42.62 total/h_score=55.96\n",
      "Loss: 1.6142648689887102\n",
      "Loss: 0.26103767717585846\n",
      "Loss: 0.16644626139279675\n",
      "Loss: 0.12703727946945412\n",
      "Loss: 0.10427487570354167\n",
      "Loss: 0.08330495132763377\n",
      "Loss: 0.07494709421195747\n",
      "Loss: 0.06871400220757898\n",
      "Loss: 0.05500232070985743\n",
      "Loss: 0.04858598222079522\n",
      "______\n",
      "Iteration t=3\n",
      "all:  cs/acc_i=71.92 cs/acc_c=71.31 os/recall_knw=56.41 os/recall_unk=82.37 total/acc_i=62.32 total/acc_c=54.07 total/h_score=64.24\n",
      "selected:  cs/acc_i=66.33 cs/acc_c=66.22 os/recall_knw=46.51 os/recall_unk=87.61 total/acc_i=58.73 total/acc_c=45.91 total/h_score=58.43\n",
      "Loss: 1.5919835056821392\n",
      "Loss: 0.2595576165953817\n",
      "Loss: 0.15792756075610576\n",
      "Loss: 0.12260524291320994\n",
      "Loss: 0.0932142858348125\n",
      "Loss: 0.08334943892989297\n",
      "Loss: 0.07088903053250047\n",
      "Loss: 0.06518162680485615\n",
      "Loss: 0.054060299958857604\n",
      "Loss: 0.04650984262983531\n",
      "______\n",
      "Iteration t=4\n",
      "all:  cs/acc_i=73.13 cs/acc_c=72.60 os/recall_knw=55.84 os/recall_unk=82.52 total/acc_i=62.01 total/acc_c=53.49 total/h_score=63.83\n",
      "selected:  cs/acc_i=70.06 cs/acc_c=70.01 os/recall_knw=50.20 os/recall_unk=84.03 total/acc_i=59.47 total/acc_c=49.10 total/h_score=60.58\n",
      "Loss: 1.5572721329556793\n",
      "Loss: 0.2572884585510115\n",
      "Loss: 0.15356361318682255\n",
      "Loss: 0.12699236123658278\n",
      "Loss: 0.08812012353583294\n",
      "Loss: 0.08062624877334393\n",
      "Loss: 0.06967034238698457\n",
      "Loss: 0.061927399463711584\n",
      "Loss: 0.05548609345525253\n",
      "Loss: 0.047095836686747834\n",
      "______\n",
      "Iteration t=5\n",
      "all:  cs/acc_i=73.42 cs/acc_c=72.97 os/recall_knw=55.59 os/recall_unk=82.52 total/acc_i=61.87 total/acc_c=53.29 total/h_score=63.67\n",
      "selected:  cs/acc_i=72.02 cs/acc_c=71.86 os/recall_knw=52.93 os/recall_unk=82.83 total/acc_i=60.55 total/acc_c=51.41 total/h_score=62.23\n",
      "Loss: 1.5660214957611336\n",
      "Loss: 0.2555502718468891\n",
      "Loss: 0.15989302438349354\n",
      "Loss: 0.11432678776777745\n",
      "Loss: 0.09390322646661275\n",
      "Loss: 0.08076486558504196\n",
      "Loss: 0.07222165240268145\n",
      "Loss: 0.06217403867853116\n",
      "Loss: 0.05679023783918964\n",
      "Loss: 0.04775181040489398\n",
      "______\n",
      "Iteration t=6\n",
      "all:  cs/acc_i=73.63 cs/acc_c=73.18 os/recall_knw=55.59 os/recall_unk=82.52 total/acc_i=61.87 total/acc_c=53.29 total/h_score=63.67\n",
      "selected:  cs/acc_i=73.14 cs/acc_c=72.75 os/recall_knw=54.52 os/recall_unk=82.71 total/acc_i=61.39 total/acc_c=52.56 total/h_score=63.13\n",
      "Loss: 1.5486684250913254\n",
      "Loss: 0.24791599708060696\n",
      "Loss: 0.15321917879867228\n",
      "Loss: 0.11916148135157889\n",
      "Loss: 0.09194677345556755\n",
      "Loss: 0.0802840581495468\n",
      "Loss: 0.06849695336813592\n",
      "Loss: 0.06150024180134682\n",
      "Loss: 0.05266774252363264\n",
      "Loss: 0.04192678978704937\n",
      "______\n",
      "Iteration t=7\n",
      "all:  cs/acc_i=74.10 cs/acc_c=73.80 os/recall_knw=55.59 os/recall_unk=82.52 total/acc_i=61.87 total/acc_c=53.29 total/h_score=63.67\n",
      "selected:  cs/acc_i=74.08 cs/acc_c=73.78 os/recall_knw=55.56 os/recall_unk=82.59 total/acc_i=61.86 total/acc_c=53.26 total/h_score=63.67\n",
      "Loss: 1.5608034467664662\n",
      "Loss: 0.24612157424399247\n",
      "Loss: 0.14993658839986337\n",
      "Loss: 0.11962033973179494\n",
      "Loss: 0.10067565950034668\n",
      "Loss: 0.08070256948922773\n",
      "Loss: 0.06709072381329065\n",
      "Loss: 0.06148514314808398\n",
      "Loss: 0.05200397375811206\n",
      "Loss: 0.044910019908191726\n",
      "______\n",
      "Iteration t=8\n",
      "all:  cs/acc_i=74.31 cs/acc_c=73.77 os/recall_knw=55.59 os/recall_unk=82.52 total/acc_i=61.87 total/acc_c=53.29 total/h_score=63.67\n",
      "selected:  cs/acc_i=74.31 cs/acc_c=73.77 os/recall_knw=55.59 os/recall_unk=82.52 total/acc_i=61.87 total/acc_c=53.29 total/h_score=63.67\n",
      "Loss: 1.5505139029480781\n",
      "Loss: 0.2528456453162903\n",
      "Loss: 0.1529847873471251\n",
      "Loss: 0.11407174588731751\n",
      "Loss: 0.09751798302361524\n",
      "Loss: 0.0761313466888114\n",
      "Loss: 0.06877840337615045\n",
      "Loss: 0.05967385639317273\n",
      "Loss: 0.051237317797542634\n",
      "Loss: 0.044777673262498804\n",
      "______\n",
      "Iteration t=9\n",
      "all:  cs/acc_i=74.10 cs/acc_c=73.69 os/recall_knw=55.59 os/recall_unk=82.52 total/acc_i=61.87 total/acc_c=53.29 total/h_score=63.67\n",
      "selected:  cs/acc_i=74.10 cs/acc_c=73.69 os/recall_knw=55.59 os/recall_unk=82.52 total/acc_i=61.87 total/acc_c=53.29 total/h_score=63.67\n",
      "tensor(0)\n",
      "all:  cs/acc_i=74.10 cs/acc_c=73.69 os/recall_knw=55.59 os/recall_unk=82.52 total/acc_i=61.87 total/acc_c=53.29 total/h_score=63.67\n",
      "real -> painting lr= 0.001 seed= 2\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19]\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20]\n",
      "Loss: 1.7145605825151278\n",
      "Loss: 0.29080590193677947\n",
      "Loss: 0.1764292472979455\n",
      "Loss: 0.14223308413861457\n",
      "Loss: 0.11548422379688722\n",
      "Loss: 0.10150244623015356\n",
      "Loss: 0.08432249803922567\n",
      "Loss: 0.07533241530964181\n",
      "Loss: 0.07131327588674148\n",
      "Loss: 0.05738811454229608\n",
      "tensor(True) tensor(True)\n",
      "______\n",
      "Iteration t=1\n",
      "all:  cs/acc_i=72.81 cs/acc_c=72.28 os/recall_knw=94.32 os/recall_unk=18.97 total/acc_i=54.49 total/acc_c=68.45 total/h_score=29.93\n",
      "selected:  cs/acc_i=75.94 cs/acc_c=75.02 os/recall_knw=73.98 os/recall_unk=94.78 total/acc_i=77.47 total/acc_c=69.54 total/h_score=79.37\n",
      "Loss: 1.634387300332631\n",
      "Loss: 0.2761659714753277\n",
      "Loss: 0.17149466500714697\n",
      "Loss: 0.1270921154839038\n",
      "Loss: 0.11271449814384883\n",
      "Loss: 0.09503109565867465\n",
      "Loss: 0.07976493617359755\n",
      "Loss: 0.07282880872653717\n",
      "Loss: 0.05925113109277527\n",
      "Loss: 0.051597139411005966\n",
      "______\n",
      "Iteration t=2\n",
      "all:  cs/acc_i=72.99 cs/acc_c=72.43 os/recall_knw=63.17 os/recall_unk=75.65 total/acc_i=63.32 total/acc_c=58.11 total/h_score=65.16\n",
      "selected:  cs/acc_i=64.24 cs/acc_c=64.40 os/recall_knw=45.13 os/recall_unk=92.60 total/acc_i=60.01 total/acc_c=44.58 total/h_score=57.96\n",
      "Loss: 1.597080759002882\n",
      "Loss: 0.2569712410407031\n",
      "Loss: 0.15577678749995197\n",
      "Loss: 0.12227748729945982\n",
      "Loss: 0.10257651371443097\n",
      "Loss: 0.0807851039681255\n",
      "Loss: 0.07239048195427612\n",
      "Loss: 0.06544531264944989\n",
      "Loss: 0.05820476520970902\n",
      "Loss: 0.05412465772413484\n",
      "______\n",
      "Iteration t=3\n",
      "all:  cs/acc_i=72.45 cs/acc_c=71.89 os/recall_knw=59.06 os/recall_unk=79.16 total/acc_i=62.59 total/acc_c=55.68 total/h_score=64.56\n",
      "selected:  cs/acc_i=66.61 cs/acc_c=66.63 os/recall_knw=49.11 os/recall_unk=85.83 total/acc_i=59.13 total/acc_c=47.43 total/h_score=59.48\n",
      "Loss: 1.583641011405874\n",
      "Loss: 0.25626300878164776\n",
      "Loss: 0.154982896463314\n",
      "Loss: 0.11866645251753663\n",
      "Loss: 0.09892665439595778\n",
      "Loss: 0.07706673925960081\n",
      "Loss: 0.07021081949082705\n",
      "Loss: 0.06472417356000625\n",
      "Loss: 0.0541681122828137\n",
      "Loss: 0.052763831387128035\n",
      "______\n",
      "Iteration t=4\n",
      "all:  cs/acc_i=72.60 cs/acc_c=72.08 os/recall_knw=58.56 os/recall_unk=79.76 total/acc_i=62.47 total/acc_c=55.26 total/h_score=64.42\n",
      "selected:  cs/acc_i=68.91 cs/acc_c=68.81 os/recall_knw=52.48 os/recall_unk=82.73 total/acc_i=59.89 total/acc_c=50.40 total/h_score=61.38\n",
      "Loss: 1.5724584283775458\n",
      "Loss: 0.2475736202599283\n",
      "Loss: 0.1494966026229066\n",
      "Loss: 0.1157840985503027\n",
      "Loss: 0.09117720919718456\n",
      "Loss: 0.08440836001572578\n",
      "Loss: 0.06598659227316023\n",
      "Loss: 0.058703936410120915\n",
      "Loss: 0.05259319711554608\n",
      "Loss: 0.046806339653828\n",
      "______\n",
      "Iteration t=5\n",
      "all:  cs/acc_i=73.38 cs/acc_c=72.85 os/recall_knw=57.98 os/recall_unk=79.99 total/acc_i=62.18 total/acc_c=54.82 total/h_score=64.16\n",
      "selected:  cs/acc_i=71.75 cs/acc_c=71.60 os/recall_knw=55.17 os/recall_unk=80.53 total/acc_i=60.74 total/acc_c=52.78 total/h_score=62.74\n",
      "Loss: 1.5576902896902718\n",
      "Loss: 0.24681878190201062\n",
      "Loss: 0.14865009204719912\n",
      "Loss: 0.11335901087047634\n",
      "Loss: 0.09553790058950884\n",
      "Loss: 0.07812460348045883\n",
      "Loss: 0.06703075758759751\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.05432975698252219\n",
      "Loss: 0.05689756858551486\n",
      "Loss: 0.04763323129960694\n",
      "______\n",
      "Iteration t=6\n",
      "all:  cs/acc_i=73.78 cs/acc_c=73.32 os/recall_knw=57.91 os/recall_unk=79.99 total/acc_i=62.13 total/acc_c=54.73 total/h_score=64.09\n",
      "selected:  cs/acc_i=73.13 cs/acc_c=72.81 os/recall_knw=56.71 os/recall_unk=80.10 total/acc_i=61.51 total/acc_c=53.90 total/h_score=63.49\n",
      "Loss: 1.5384271003143943\n",
      "Loss: 0.24974637479602319\n",
      "Loss: 0.14820726078165614\n",
      "Loss: 0.11318187271092978\n",
      "Loss: 0.09552263417888594\n",
      "Loss: 0.07675392827418957\n",
      "Loss: 0.06522249736134773\n",
      "Loss: 0.05965570777809025\n",
      "Loss: 0.05446698397155041\n",
      "Loss: 0.04694759787083097\n",
      "______\n",
      "Iteration t=7\n",
      "all:  cs/acc_i=74.67 cs/acc_c=74.11 os/recall_knw=57.91 os/recall_unk=79.99 total/acc_i=62.13 total/acc_c=54.73 total/h_score=64.09\n",
      "selected:  cs/acc_i=74.60 cs/acc_c=73.99 os/recall_knw=57.73 os/recall_unk=80.04 total/acc_i=62.06 total/acc_c=54.59 total/h_score=64.00\n",
      "Loss: 1.5416124435695442\n",
      "Loss: 0.2525051262531732\n",
      "Loss: 0.1484963083388032\n",
      "Loss: 0.11860319353841446\n",
      "Loss: 0.09090624980225756\n",
      "Loss: 0.07661664093013953\n",
      "Loss: 0.07131810273748596\n",
      "Loss: 0.05534428458321034\n",
      "Loss: 0.05135660122677281\n",
      "Loss: 0.045187650776367536\n",
      "______\n",
      "Iteration t=8\n",
      "all:  cs/acc_i=74.31 cs/acc_c=73.75 os/recall_knw=57.91 os/recall_unk=79.99 total/acc_i=62.13 total/acc_c=54.73 total/h_score=64.09\n",
      "selected:  cs/acc_i=74.31 cs/acc_c=73.75 os/recall_knw=57.91 os/recall_unk=79.99 total/acc_i=62.13 total/acc_c=54.73 total/h_score=64.09\n",
      "Loss: 1.5482948963303824\n",
      "Loss: 0.24381587132811547\n",
      "Loss: 0.15239700446459087\n",
      "Loss: 0.11197075860423816\n",
      "Loss: 0.09034170175625665\n",
      "Loss: 0.08150752216225138\n",
      "Loss: 0.06693088133265641\n",
      "Loss: 0.06002158894537117\n",
      "Loss: 0.046853043915502525\n",
      "Loss: 0.0473183093963795\n",
      "______\n",
      "Iteration t=9\n",
      "all:  cs/acc_i=74.63 cs/acc_c=74.14 os/recall_knw=57.91 os/recall_unk=79.99 total/acc_i=62.13 total/acc_c=54.73 total/h_score=64.09\n",
      "selected:  cs/acc_i=74.63 cs/acc_c=74.14 os/recall_knw=57.91 os/recall_unk=79.99 total/acc_i=62.13 total/acc_c=54.73 total/h_score=64.09\n",
      "tensor(0)\n",
      "all:  cs/acc_i=74.63 cs/acc_c=74.14 os/recall_knw=57.91 os/recall_unk=79.99 total/acc_i=62.13 total/acc_c=54.73 total/h_score=64.09\n",
      "real -> painting lr= 0.001 seed= 3\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19]\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20]\n",
      "Loss: 1.7074574351885694\n",
      "Loss: 0.3007581471630231\n",
      "Loss: 0.1838528896259725\n",
      "Loss: 0.144022940619103\n",
      "Loss: 0.11384180087260783\n",
      "Loss: 0.09318549700165198\n",
      "Loss: 0.08481088690639405\n",
      "Loss: 0.07546034448112322\n",
      "Loss: 0.06558675213097041\n",
      "Loss: 0.06122440410406595\n",
      "tensor(True) tensor(True)\n",
      "______\n",
      "Iteration t=1\n",
      "all:  cs/acc_i=72.56 cs/acc_c=72.05 os/recall_knw=94.03 os/recall_unk=18.37 total/acc_i=54.18 total/acc_c=68.29 total/h_score=29.17\n",
      "selected:  cs/acc_i=75.24 cs/acc_c=74.18 os/recall_knw=73.15 os/recall_unk=94.62 total/acc_i=76.98 total/acc_c=69.84 total/h_score=79.54\n",
      "Loss: 1.6356884756245496\n",
      "Loss: 0.26885337869356746\n",
      "Loss: 0.16657619116587874\n",
      "Loss: 0.12907518241325952\n",
      "Loss: 0.10620148049416078\n",
      "Loss: 0.08985784972955022\n",
      "Loss: 0.08258104697441214\n",
      "Loss: 0.0696050633442091\n",
      "Loss: 0.05872309215201145\n",
      "Loss: 0.05468888261192621\n",
      "______\n",
      "Iteration t=2\n",
      "all:  cs/acc_i=72.78 cs/acc_c=72.42 os/recall_knw=64.42 os/recall_unk=74.98 total/acc_i=63.51 total/acc_c=58.76 total/h_score=65.38\n",
      "selected:  cs/acc_i=64.83 cs/acc_c=65.32 os/recall_knw=46.10 os/recall_unk=93.14 total/acc_i=61.14 total/acc_c=46.19 total/h_score=59.62\n",
      "Loss: 1.6158951468327467\n",
      "Loss: 0.2632637106758707\n",
      "Loss: 0.16540340119424987\n",
      "Loss: 0.1266902653281303\n",
      "Loss: 0.10350728167001816\n",
      "Loss: 0.08412273314452785\n",
      "Loss: 0.0792468322934035\n",
      "Loss: 0.06202557736952954\n",
      "Loss: 0.05483072102412253\n",
      "Loss: 0.051686156893094234\n",
      "______\n",
      "Iteration t=3\n",
      "all:  cs/acc_i=73.31 cs/acc_c=72.81 os/recall_knw=59.99 os/recall_unk=78.34 total/acc_i=62.74 total/acc_c=56.29 total/h_score=64.76\n",
      "selected:  cs/acc_i=67.83 cs/acc_c=67.87 os/recall_knw=49.96 os/recall_unk=85.98 total/acc_i=59.63 total/acc_c=48.28 total/h_score=60.27\n",
      "Loss: 1.586172537076847\n",
      "Loss: 0.2619007173766438\n",
      "Loss: 0.15401336193572931\n",
      "Loss: 0.11686296113355463\n",
      "Loss: 0.09464374087628859\n",
      "Loss: 0.0823363522518734\n",
      "Loss: 0.06999331594781785\n",
      "Loss: 0.06481814854499748\n",
      "Loss: 0.057922570072008336\n",
      "Loss: 0.050839084128257515\n",
      "______\n",
      "Iteration t=4\n",
      "all:  cs/acc_i=72.74 cs/acc_c=72.07 os/recall_knw=59.41 os/recall_unk=78.72 total/acc_i=62.54 total/acc_c=55.82 total/h_score=64.53\n",
      "selected:  cs/acc_i=69.37 cs/acc_c=69.05 os/recall_knw=53.48 os/recall_unk=81.52 total/acc_i=60.13 total/acc_c=51.17 total/h_score=61.71\n",
      "Loss: 1.5594652919384098\n",
      "Loss: 0.2494280946370951\n",
      "Loss: 0.15096627821767064\n",
      "Loss: 0.11460983898480291\n",
      "Loss: 0.09808365903109893\n",
      "Loss: 0.08381839058411238\n",
      "Loss: 0.07026586346042896\n",
      "Loss: 0.06011215050530965\n",
      "Loss: 0.0529922928478216\n",
      "Loss: 0.04593475550882684\n",
      "______\n",
      "Iteration t=5\n",
      "all:  cs/acc_i=73.13 cs/acc_c=72.44 os/recall_knw=58.81 os/recall_unk=78.94 total/acc_i=62.25 total/acc_c=55.20 total/h_score=64.14\n",
      "selected:  cs/acc_i=71.32 cs/acc_c=70.90 os/recall_knw=55.67 os/recall_unk=80.02 total/acc_i=60.79 total/acc_c=52.83 total/h_score=62.64\n",
      "Loss: 1.5535827016585493\n",
      "Loss: 0.24699547089738388\n",
      "Loss: 0.15484268998038278\n",
      "Loss: 0.11582208909349491\n",
      "Loss: 0.09374958317318599\n",
      "Loss: 0.08127121811043726\n",
      "Loss: 0.06781228732776969\n",
      "Loss: 0.05999189812103159\n",
      "Loss: 0.05194726116980796\n",
      "Loss: 0.044570047935241296\n",
      "______\n",
      "Iteration t=6\n",
      "all:  cs/acc_i=73.49 cs/acc_c=72.95 os/recall_knw=58.70 os/recall_unk=79.01 total/acc_i=62.20 total/acc_c=55.10 total/h_score=64.09\n",
      "selected:  cs/acc_i=72.82 cs/acc_c=72.41 os/recall_knw=57.48 os/recall_unk=79.31 total/acc_i=61.61 total/acc_c=54.28 total/h_score=63.56\n",
      "Loss: 1.5454499965437705\n",
      "Loss: 0.25722323735635777\n",
      "Loss: 0.14444165879754517\n",
      "Loss: 0.11318321804690167\n",
      "Loss: 0.0927620936982677\n",
      "Loss: 0.07467115224720178\n",
      "Loss: 0.0698049729740434\n",
      "Loss: 0.0612953466926083\n",
      "Loss: 0.05370020825128124\n",
      "Loss: 0.044718317315865785\n",
      "______\n",
      "Iteration t=7\n",
      "all:  cs/acc_i=74.13 cs/acc_c=73.65 os/recall_knw=58.70 os/recall_unk=79.01 total/acc_i=62.20 total/acc_c=55.10 total/h_score=64.09\n",
      "selected:  cs/acc_i=74.08 cs/acc_c=73.59 os/recall_knw=58.51 os/recall_unk=79.25 total/acc_i=62.19 total/acc_c=55.02 total/h_score=64.10\n",
      "Loss: 1.5506390796678085\n",
      "Loss: 0.2456626163097726\n",
      "Loss: 0.14617341043894502\n",
      "Loss: 0.11468992140294727\n",
      "Loss: 0.09246052975322037\n",
      "Loss: 0.07804282764198806\n",
      "Loss: 0.07238646148455473\n",
      "Loss: 0.05710656098353694\n",
      "Loss: 0.0512683630551932\n",
      "Loss: 0.046708275693923114\n",
      "______\n",
      "Iteration t=8\n",
      "all:  cs/acc_i=74.06 cs/acc_c=73.54 os/recall_knw=58.70 os/recall_unk=79.01 total/acc_i=62.20 total/acc_c=55.10 total/h_score=64.09\n",
      "selected:  cs/acc_i=74.06 cs/acc_c=73.54 os/recall_knw=58.70 os/recall_unk=79.01 total/acc_i=62.20 total/acc_c=55.10 total/h_score=64.09\n",
      "Loss: 1.525845052659351\n",
      "Loss: 0.25039530344648825\n",
      "Loss: 0.15128006609884717\n",
      "Loss: 0.11419804009666662\n",
      "Loss: 0.0933122205023335\n",
      "Loss: 0.07994154056740016\n",
      "Loss: 0.07086320604496407\n",
      "Loss: 0.05855206185901623\n",
      "Loss: 0.05083009958859643\n",
      "Loss: 0.046109157988131345\n",
      "______\n",
      "Iteration t=9\n",
      "all:  cs/acc_i=74.24 cs/acc_c=73.59 os/recall_knw=58.70 os/recall_unk=79.01 total/acc_i=62.20 total/acc_c=55.10 total/h_score=64.09\n",
      "selected:  cs/acc_i=74.24 cs/acc_c=73.59 os/recall_knw=58.70 os/recall_unk=79.01 total/acc_i=62.20 total/acc_c=55.10 total/h_score=64.09\n",
      "tensor(0)\n",
      "all:  cs/acc_i=74.24 cs/acc_c=73.59 os/recall_knw=58.70 os/recall_unk=79.01 total/acc_i=62.20 total/acc_c=55.10 total/h_score=64.09\n",
      "real -> painting lr= 0.001 seed= 4\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19]\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20]\n",
      "Loss: 1.7215526144220898\n",
      "Loss: 0.29936873500753447\n",
      "Loss: 0.18549743849316977\n",
      "Loss: 0.13766510109641736\n",
      "Loss: 0.12219030670282638\n",
      "Loss: 0.09814368129686911\n",
      "Loss: 0.08874077559823104\n",
      "Loss: 0.07489778368413401\n",
      "Loss: 0.06203073727856375\n",
      "Loss: 0.05904834947572764\n",
      "tensor(True) tensor(True)\n",
      "______\n",
      "Iteration t=1\n",
      "all:  cs/acc_i=72.67 cs/acc_c=72.24 os/recall_knw=94.61 os/recall_unk=19.57 total/acc_i=54.62 total/acc_c=68.49 total/h_score=30.67\n",
      "selected:  cs/acc_i=77.78 cs/acc_c=77.29 os/recall_knw=74.96 os/recall_unk=94.58 total/acc_i=78.98 total/acc_c=71.83 total/h_score=80.91\n",
      "Loss: 1.6438765380462985\n",
      "Loss: 0.2795950745923753\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.1722523837001777\n",
      "Loss: 0.13089358812895108\n",
      "Loss: 0.1090459487760908\n",
      "Loss: 0.09132992638349305\n",
      "Loss: 0.07877523519892954\n",
      "Loss: 0.06839927769854573\n",
      "Loss: 0.06225667073337098\n",
      "Loss: 0.05123323246413853\n",
      "______\n",
      "Iteration t=2\n",
      "all:  cs/acc_i=73.10 cs/acc_c=72.69 os/recall_knw=64.34 os/recall_unk=75.73 total/acc_i=63.94 total/acc_c=58.94 total/h_score=65.75\n",
      "selected:  cs/acc_i=64.84 cs/acc_c=65.23 os/recall_knw=45.85 os/recall_unk=92.43 total/acc_i=61.05 total/acc_c=45.85 total/h_score=59.17\n",
      "Loss: 1.6013039767742157\n",
      "Loss: 0.264765628679272\n",
      "Loss: 0.16258219061967205\n",
      "Loss: 0.1230412251316011\n",
      "Loss: 0.09930038704975125\n",
      "Loss: 0.0860146944411099\n",
      "Loss: 0.07028187365161584\n",
      "Loss: 0.06378363127176485\n",
      "Loss: 0.056899222565869635\n",
      "Loss: 0.05024536881349324\n",
      "______\n",
      "Iteration t=3\n",
      "all:  cs/acc_i=73.03 cs/acc_c=72.46 os/recall_knw=60.27 os/recall_unk=78.94 total/acc_i=63.15 total/acc_c=56.49 total/h_score=65.09\n",
      "selected:  cs/acc_i=67.68 cs/acc_c=67.57 os/recall_knw=50.16 os/recall_unk=86.78 total/acc_i=60.28 total/acc_c=48.64 total/h_score=60.75\n",
      "Loss: 1.5721515997013136\n",
      "Loss: 0.2597800412154266\n",
      "Loss: 0.15438492340898072\n",
      "Loss: 0.12306026798113119\n",
      "Loss: 0.09837676610988684\n",
      "Loss: 0.08550997080541405\n",
      "Loss: 0.070319775769227\n",
      "Loss: 0.06341806350095447\n",
      "Loss: 0.053609323361490525\n",
      "Loss: 0.048173540822386826\n",
      "______\n",
      "Iteration t=4\n",
      "all:  cs/acc_i=72.74 cs/acc_c=72.25 os/recall_knw=59.45 os/recall_unk=79.91 total/acc_i=62.98 total/acc_c=55.86 total/h_score=64.91\n",
      "selected:  cs/acc_i=69.34 cs/acc_c=69.33 os/recall_knw=53.60 os/recall_unk=82.56 total/acc_i=60.56 total/acc_c=51.36 total/h_score=62.12\n",
      "Loss: 1.5617724554120331\n",
      "Loss: 0.2524404009612158\n",
      "Loss: 0.15734638574644716\n",
      "Loss: 0.1212548585297296\n",
      "Loss: 0.09510963892662758\n",
      "Loss: 0.081970696458152\n",
      "Loss: 0.07133405257799873\n",
      "Loss: 0.059208836144453804\n",
      "Loss: 0.05307062951624809\n",
      "Loss: 0.0421369556191022\n",
      "______\n",
      "Iteration t=5\n",
      "all:  cs/acc_i=73.42 cs/acc_c=72.95 os/recall_knw=59.34 os/recall_unk=80.06 total/acc_i=62.98 total/acc_c=55.80 total/h_score=64.92\n",
      "selected:  cs/acc_i=71.53 cs/acc_c=71.41 os/recall_knw=56.04 os/recall_unk=80.48 total/acc_i=61.29 total/acc_c=53.44 total/h_score=63.24\n",
      "Loss: 1.5602110592469778\n",
      "Loss: 0.24672771051321943\n",
      "Loss: 0.15554099446800473\n",
      "Loss: 0.11981620302500381\n",
      "Loss: 0.08937614673927222\n",
      "Loss: 0.08010123182623965\n",
      "Loss: 0.06957465854077918\n",
      "Loss: 0.06205511127203091\n",
      "Loss: 0.05120787633302277\n",
      "Loss: 0.0441759252984536\n",
      "______\n",
      "Iteration t=6\n",
      "all:  cs/acc_i=73.95 cs/acc_c=73.49 os/recall_knw=59.20 os/recall_unk=80.06 total/acc_i=62.88 total/acc_c=55.65 total/h_score=64.81\n",
      "selected:  cs/acc_i=73.31 cs/acc_c=72.94 os/recall_knw=58.01 os/recall_unk=80.30 total/acc_i=62.29 total/acc_c=54.83 total/h_score=64.26\n",
      "Loss: 1.5406377918836547\n",
      "Loss: 0.24286644611012967\n",
      "Loss: 0.15495992990003693\n",
      "Loss: 0.11533704350089155\n",
      "Loss: 0.09595379053784135\n",
      "Loss: 0.07411362366564067\n",
      "Loss: 0.06665823187143984\n",
      "Loss: 0.058123629658828745\n",
      "Loss: 0.05331891980829843\n",
      "Loss: 0.046508048968339155\n",
      "______\n",
      "Iteration t=7\n",
      "all:  cs/acc_i=74.67 cs/acc_c=74.28 os/recall_knw=59.16 os/recall_unk=80.06 total/acc_i=62.86 total/acc_c=55.63 total/h_score=64.79\n",
      "selected:  cs/acc_i=74.60 cs/acc_c=74.18 os/recall_knw=58.93 os/recall_unk=80.18 total/acc_i=62.79 total/acc_c=55.49 total/h_score=64.72\n",
      "Loss: 1.5419094213899576\n",
      "Loss: 0.24708911326696287\n",
      "Loss: 0.15118692923246851\n",
      "Loss: 0.1137462945760421\n",
      "Loss: 0.09054400419158676\n",
      "Loss: 0.07706075264115861\n",
      "Loss: 0.06379440878681096\n",
      "Loss: 0.058620396707799394\n",
      "Loss: 0.051958697340313116\n",
      "Loss: 0.04719787097167013\n",
      "______\n",
      "Iteration t=8\n",
      "all:  cs/acc_i=74.31 cs/acc_c=73.77 os/recall_knw=59.16 os/recall_unk=80.06 total/acc_i=62.86 total/acc_c=55.63 total/h_score=64.79\n",
      "selected:  cs/acc_i=74.31 cs/acc_c=73.77 os/recall_knw=59.16 os/recall_unk=80.06 total/acc_i=62.86 total/acc_c=55.63 total/h_score=64.79\n",
      "Loss: 1.5298896096948023\n",
      "Loss: 0.24991165916874725\n",
      "Loss: 0.1546813044496222\n",
      "Loss: 0.11454949095704646\n",
      "Loss: 0.09041281971789274\n",
      "Loss: 0.08071356671021353\n",
      "Loss: 0.06775075983697915\n",
      "Loss: 0.057962563855327526\n",
      "Loss: 0.04905581609923342\n",
      "Loss: 0.044597667695909254\n",
      "______\n",
      "Iteration t=9\n",
      "all:  cs/acc_i=74.21 cs/acc_c=73.68 os/recall_knw=59.16 os/recall_unk=80.06 total/acc_i=62.86 total/acc_c=55.63 total/h_score=64.79\n",
      "selected:  cs/acc_i=74.21 cs/acc_c=73.68 os/recall_knw=59.16 os/recall_unk=80.06 total/acc_i=62.86 total/acc_c=55.63 total/h_score=64.79\n",
      "tensor(0)\n",
      "all:  cs/acc_i=74.21 cs/acc_c=73.68 os/recall_knw=59.16 os/recall_unk=80.06 total/acc_i=62.86 total/acc_c=55.63 total/h_score=64.79\n",
      "real -> painting lr= 0.001 seed= 0\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19]\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20]\n",
      "Loss: 1.7001185109569328\n",
      "Loss: 0.3090085916197185\n",
      "Loss: 0.17911771350686956\n",
      "Loss: 0.13600392419233967\n",
      "Loss: 0.1141660870037901\n",
      "Loss: 0.09714031769591608\n",
      "Loss: 0.08767253619549838\n",
      "Loss: 0.07426654167961437\n",
      "Loss: 0.06690442898697026\n",
      "Loss: 0.06555421274886063\n",
      "tensor(True) tensor(True)\n",
      "______\n",
      "Iteration t=1\n",
      "all:  cs/acc_i=73.06 cs/acc_c=72.69 os/recall_knw=94.75 os/recall_unk=19.87 total/acc_i=55.07 total/acc_c=69.07 total/h_score=31.09\n",
      "selected:  cs/acc_i=76.91 cs/acc_c=76.33 os/recall_knw=75.58 os/recall_unk=95.00 total/acc_i=79.02 total/acc_c=71.60 total/h_score=80.89\n",
      "Loss: 1.6520642711341016\n",
      "Loss: 0.2820849457035767\n",
      "Loss: 0.16413408311575287\n",
      "Loss: 0.13279922665353933\n",
      "Loss: 0.1136258823448575\n",
      "Loss: 0.09150619254921752\n",
      "Loss: 0.08095336056948622\n",
      "Loss: 0.0744482064891058\n",
      "Loss: 0.06079505581517298\n",
      "Loss: 0.05391116622418302\n",
      "______\n",
      "Iteration t=2\n",
      "all:  cs/acc_i=73.60 cs/acc_c=73.13 os/recall_knw=66.10 os/recall_unk=74.09 total/acc_i=64.50 total/acc_c=60.24 total/h_score=66.02\n",
      "selected:  cs/acc_i=64.74 cs/acc_c=64.99 os/recall_knw=47.22 os/recall_unk=92.54 total/acc_i=61.78 total/acc_c=46.65 total/h_score=59.97\n",
      "Loss: 1.6069150205044185\n",
      "Loss: 0.26743620329481715\n",
      "Loss: 0.15370190761545124\n",
      "Loss: 0.12044360035044306\n",
      "Loss: 0.0986118182676899\n",
      "Loss: 0.08562348406104481\n",
      "Loss: 0.07390615303302184\n",
      "Loss: 0.06535329770515946\n",
      "Loss: 0.05661174898611053\n",
      "Loss: 0.05066229686250581\n",
      "______\n",
      "Iteration t=3\n",
      "all:  cs/acc_i=72.70 cs/acc_c=72.27 os/recall_knw=60.74 os/recall_unk=78.19 total/acc_i=63.24 total/acc_c=56.98 total/h_score=65.21\n",
      "selected:  cs/acc_i=66.95 cs/acc_c=66.99 os/recall_knw=50.38 os/recall_unk=85.96 total/acc_i=60.15 total/acc_c=48.93 total/h_score=60.84\n",
      "Loss: 1.598433763383121\n",
      "Loss: 0.2525884756165692\n",
      "Loss: 0.15434333052687835\n",
      "Loss: 0.11545109649870725\n",
      "Loss: 0.09613708738885035\n",
      "Loss: 0.08570706090913752\n",
      "Loss: 0.06865030759680178\n",
      "Loss: 0.05921616781028014\n",
      "Loss: 0.0596623666076377\n",
      "Loss: 0.04577589022099144\n",
      "______\n",
      "Iteration t=4\n",
      "all:  cs/acc_i=73.13 cs/acc_c=72.58 os/recall_knw=59.84 os/recall_unk=78.94 total/acc_i=62.98 total/acc_c=56.22 total/h_score=64.89\n",
      "selected:  cs/acc_i=69.61 cs/acc_c=69.49 os/recall_knw=53.84 os/recall_unk=82.26 total/acc_i=60.59 total/acc_c=51.60 total/h_score=62.24\n",
      "Loss: 1.563515518286102\n",
      "Loss: 0.25350411810126144\n",
      "Loss: 0.1475964252652813\n",
      "Loss: 0.11593509446777674\n",
      "Loss: 0.09954091581233199\n",
      "Loss: 0.083467370267532\n",
      "Loss: 0.06911165545847589\n",
      "Loss: 0.0632695732664182\n",
      "Loss: 0.04998113992844493\n",
      "Loss: 0.04440009081055226\n",
      "______\n",
      "Iteration t=5\n",
      "all:  cs/acc_i=73.38 cs/acc_c=72.96 os/recall_knw=59.49 os/recall_unk=79.09 total/acc_i=62.78 total/acc_c=55.88 total/h_score=64.69\n",
      "selected:  cs/acc_i=71.40 cs/acc_c=71.44 os/recall_knw=56.11 os/recall_unk=79.68 total/acc_i=61.05 total/acc_c=53.45 total/h_score=63.03\n",
      "Loss: 1.5542633115428768\n",
      "Loss: 0.24111800816369383\n",
      "Loss: 0.14855521023783783\n",
      "Loss: 0.11849817724975005\n",
      "Loss: 0.08781849542658214\n",
      "Loss: 0.08066570014144256\n",
      "Loss: 0.06995831080265853\n",
      "Loss: 0.06048049220738754\n",
      "Loss: 0.05335804834668461\n",
      "Loss: 0.05001574436917085\n",
      "______\n",
      "Iteration t=6\n",
      "all:  cs/acc_i=73.81 cs/acc_c=73.30 os/recall_knw=59.49 os/recall_unk=79.09 total/acc_i=62.78 total/acc_c=55.88 total/h_score=64.69\n",
      "selected:  cs/acc_i=73.11 cs/acc_c=72.70 os/recall_knw=58.28 os/recall_unk=79.33 total/acc_i=62.15 total/acc_c=55.02 total/h_score=64.12\n",
      "Loss: 1.5496536232430114\n",
      "Loss: 0.2506839571101717\n",
      "Loss: 0.15480558004300932\n",
      "Loss: 0.1163645991424558\n",
      "Loss: 0.0896962369188949\n",
      "Loss: 0.0764182068086999\n",
      "Loss: 0.06621208228044677\n",
      "Loss: 0.06238085691133125\n",
      "Loss: 0.04969749974748145\n",
      "Loss: 0.04661626425233536\n",
      "______\n",
      "Iteration t=7\n",
      "all:  cs/acc_i=74.42 cs/acc_c=74.18 os/recall_knw=59.41 os/recall_unk=79.16 total/acc_i=62.76 total/acc_c=55.84 total/h_score=64.68\n",
      "selected:  cs/acc_i=74.33 cs/acc_c=74.11 os/recall_knw=59.21 os/recall_unk=79.28 total/acc_i=62.69 total/acc_c=55.74 total/h_score=64.64\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 1.531302124261856\n",
      "Loss: 0.24932353237689023\n",
      "Loss: 0.15472082144548147\n",
      "Loss: 0.11497948115636315\n",
      "Loss: 0.09096764025562054\n",
      "Loss: 0.07711377978887198\n",
      "Loss: 0.06833309555963445\n",
      "Loss: 0.06016026370382976\n",
      "Loss: 0.054944380556767924\n",
      "Loss: 0.045251576465898447\n",
      "______\n",
      "Iteration t=8\n",
      "all:  cs/acc_i=74.53 cs/acc_c=74.15 os/recall_knw=59.41 os/recall_unk=79.16 total/acc_i=62.76 total/acc_c=55.84 total/h_score=64.68\n",
      "selected:  cs/acc_i=74.53 cs/acc_c=74.15 os/recall_knw=59.41 os/recall_unk=79.16 total/acc_i=62.76 total/acc_c=55.84 total/h_score=64.68\n",
      "Loss: 1.5319437457508938\n",
      "Loss: 0.25021382681624865\n",
      "Loss: 0.1466832593463922\n",
      "Loss: 0.11231748863894453\n",
      "Loss: 0.1010567389719028\n",
      "Loss: 0.0755830991197057\n",
      "Loss: 0.0662880915827969\n",
      "Loss: 0.06270029698748902\n",
      "Loss: 0.051057039542869734\n",
      "Loss: 0.04622783974784436\n",
      "______\n",
      "Iteration t=9\n",
      "all:  cs/acc_i=74.31 cs/acc_c=73.92 os/recall_knw=59.41 os/recall_unk=79.16 total/acc_i=62.76 total/acc_c=55.84 total/h_score=64.68\n",
      "selected:  cs/acc_i=74.31 cs/acc_c=73.92 os/recall_knw=59.41 os/recall_unk=79.16 total/acc_i=62.76 total/acc_c=55.84 total/h_score=64.68\n",
      "tensor(0)\n",
      "all:  cs/acc_i=74.31 cs/acc_c=73.92 os/recall_knw=59.41 os/recall_unk=79.16 total/acc_i=62.76 total/acc_c=55.84 total/h_score=64.68\n",
      "real -> painting lr= 0.001 seed= 1\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19]\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20]\n",
      "Loss: 1.7110666348044896\n",
      "Loss: 0.2988099839622185\n",
      "Loss: 0.18048757021210585\n",
      "Loss: 0.1376070054996627\n",
      "Loss: 0.11751353195973244\n",
      "Loss: 0.10249318484324735\n",
      "Loss: 0.08434400313992017\n",
      "Loss: 0.07530649152578385\n",
      "Loss: 0.06556544659458628\n",
      "Loss: 0.0613630020532793\n",
      "tensor(True) tensor(True)\n",
      "______\n",
      "Iteration t=1\n",
      "all:  cs/acc_i=72.78 cs/acc_c=72.47 os/recall_knw=94.86 os/recall_unk=20.09 total/acc_i=54.98 total/acc_c=68.87 total/h_score=31.35\n",
      "selected:  cs/acc_i=77.96 cs/acc_c=77.31 os/recall_knw=75.96 os/recall_unk=94.72 total/acc_i=79.84 total/acc_c=72.82 total/h_score=81.63\n",
      "Loss: 1.639605035719696\n",
      "Loss: 0.27174584268152346\n",
      "Loss: 0.17044075619589333\n",
      "Loss: 0.1303508663521451\n",
      "Loss: 0.1081542560053658\n",
      "Loss: 0.09219638454053619\n",
      "Loss: 0.08407784601890601\n",
      "Loss: 0.06623852472363806\n",
      "Loss: 0.06357525105650988\n",
      "Loss: 0.05492403289014645\n",
      "______\n",
      "Iteration t=2\n",
      "all:  cs/acc_i=72.99 cs/acc_c=72.46 os/recall_knw=61.34 os/recall_unk=79.39 total/acc_i=63.82 total/acc_c=57.29 total/h_score=65.80\n",
      "selected:  cs/acc_i=64.20 cs/acc_c=64.17 os/recall_knw=43.94 os/recall_unk=93.00 total/acc_i=59.78 total/acc_c=43.70 total/h_score=57.13\n",
      "Loss: 1.6108660727739335\n",
      "Loss: 0.2592888618216795\n",
      "Loss: 0.15798121756490538\n",
      "Loss: 0.1279410013846834\n",
      "Loss: 0.09837405551772783\n",
      "Loss: 0.08838196583913968\n",
      "Loss: 0.07578840171370436\n",
      "Loss: 0.0658462627503254\n",
      "Loss: 0.05751271667095887\n",
      "Loss: 0.0505668932085802\n",
      "______\n",
      "Iteration t=3\n",
      "all:  cs/acc_i=71.92 cs/acc_c=71.15 os/recall_knw=58.31 os/recall_unk=80.88 total/acc_i=62.78 total/acc_c=55.14 total/h_score=64.66\n",
      "selected:  cs/acc_i=66.06 cs/acc_c=65.85 os/recall_knw=48.02 os/recall_unk=87.83 total/acc_i=59.46 total/acc_c=46.89 total/h_score=59.37\n",
      "Loss: 1.5957088116076068\n",
      "Loss: 0.2549463027506469\n",
      "Loss: 0.15946943518895132\n",
      "Loss: 0.11798800284678068\n",
      "Loss: 0.09388890393334508\n",
      "Loss: 0.08125170579121413\n",
      "Loss: 0.07191771208268609\n",
      "Loss: 0.06424643591921617\n",
      "Loss: 0.0576898188031356\n",
      "Loss: 0.0481590232278159\n",
      "______\n",
      "Iteration t=4\n",
      "all:  cs/acc_i=72.38 cs/acc_c=71.69 os/recall_knw=58.02 os/recall_unk=81.11 total/acc_i=62.69 total/acc_c=54.90 total/h_score=64.53\n",
      "selected:  cs/acc_i=68.68 cs/acc_c=68.48 os/recall_knw=51.77 os/recall_unk=83.73 total/acc_i=60.03 total/acc_c=50.02 total/h_score=61.29\n",
      "Loss: 1.5736478829250282\n",
      "Loss: 0.26330165827975555\n",
      "Loss: 0.15452100076720493\n",
      "Loss: 0.11924492084898618\n",
      "Loss: 0.09776962517711128\n",
      "Loss: 0.08528841844517268\n",
      "Loss: 0.06691636444468584\n",
      "Loss: 0.059833521078176355\n",
      "Loss: 0.053347859865560586\n",
      "Loss: 0.049909174343158884\n",
      "______\n",
      "Iteration t=5\n",
      "all:  cs/acc_i=73.17 cs/acc_c=72.60 os/recall_knw=57.81 os/recall_unk=81.25 total/acc_i=62.59 total/acc_c=54.71 total/h_score=64.43\n",
      "selected:  cs/acc_i=71.59 cs/acc_c=71.40 os/recall_knw=54.84 os/recall_unk=81.62 total/acc_i=61.14 total/acc_c=52.70 total/h_score=62.97\n",
      "Loss: 1.5513794799591158\n",
      "Loss: 0.256055047121513\n",
      "Loss: 0.15571365595007172\n",
      "Loss: 0.11358929793657428\n",
      "Loss: 0.09305612349519404\n",
      "Loss: 0.0795885489250605\n",
      "Loss: 0.07459296168283569\n",
      "Loss: 0.05886370712343685\n",
      "Loss: 0.051951961138971395\n",
      "Loss: 0.045542113099804986\n",
      "______\n",
      "Iteration t=6\n",
      "all:  cs/acc_i=74.06 cs/acc_c=73.69 os/recall_knw=57.66 os/recall_unk=81.33 total/acc_i=62.52 total/acc_c=54.55 total/h_score=64.33\n",
      "selected:  cs/acc_i=73.37 cs/acc_c=73.16 os/recall_knw=56.35 os/recall_unk=81.51 total/acc_i=61.86 total/acc_c=53.69 total/h_score=63.71\n",
      "Loss: 1.5528274111104596\n",
      "Loss: 0.24794104649642182\n",
      "Loss: 0.14805500608252245\n",
      "Loss: 0.12466331125726816\n",
      "Loss: 0.09765254943162122\n",
      "Loss: 0.07951789704082934\n",
      "Loss: 0.0639208118794156\n",
      "Loss: 0.05811979547295242\n",
      "Loss: 0.05080602597191483\n",
      "Loss: 0.04145776849539509\n",
      "______\n",
      "Iteration t=7\n",
      "all:  cs/acc_i=74.35 cs/acc_c=73.99 os/recall_knw=57.66 os/recall_unk=81.33 total/acc_i=62.52 total/acc_c=54.55 total/h_score=64.33\n",
      "selected:  cs/acc_i=74.28 cs/acc_c=73.94 os/recall_knw=57.50 os/recall_unk=81.39 total/acc_i=62.46 total/acc_c=54.46 total/h_score=64.28\n",
      "Loss: 1.5347756810466124\n",
      "Loss: 0.25160017241105476\n",
      "Loss: 0.1479679389899662\n",
      "Loss: 0.1125053691205778\n",
      "Loss: 0.0915816464691062\n",
      "Loss: 0.0780799351052096\n",
      "Loss: 0.06585923766687028\n",
      "Loss: 0.056904510859283934\n",
      "Loss: 0.048649407939627\n",
      "Loss: 0.046535143472234086\n",
      "______\n",
      "Iteration t=8\n",
      "all:  cs/acc_i=74.13 cs/acc_c=73.74 os/recall_knw=57.66 os/recall_unk=81.33 total/acc_i=62.52 total/acc_c=54.55 total/h_score=64.33\n",
      "selected:  cs/acc_i=74.13 cs/acc_c=73.74 os/recall_knw=57.66 os/recall_unk=81.33 total/acc_i=62.52 total/acc_c=54.55 total/h_score=64.33\n",
      "Loss: 1.5540062787571574\n",
      "Loss: 0.2590616123604419\n",
      "Loss: 0.14693456759479473\n",
      "Loss: 0.12390360899451303\n",
      "Loss: 0.09855557341623274\n",
      "Loss: 0.07359263390242084\n",
      "Loss: 0.06645467301305676\n",
      "Loss: 0.05836021527647972\n",
      "Loss: 0.051161746611833814\n",
      "Loss: 0.04916843938891117\n",
      "______\n",
      "Iteration t=9\n",
      "all:  cs/acc_i=73.49 cs/acc_c=72.92 os/recall_knw=57.66 os/recall_unk=81.33 total/acc_i=62.52 total/acc_c=54.55 total/h_score=64.33\n",
      "selected:  cs/acc_i=73.49 cs/acc_c=72.92 os/recall_knw=57.66 os/recall_unk=81.33 total/acc_i=62.52 total/acc_c=54.55 total/h_score=64.33\n",
      "tensor(0)\n",
      "all:  cs/acc_i=73.49 cs/acc_c=72.92 os/recall_knw=57.66 os/recall_unk=81.33 total/acc_i=62.52 total/acc_c=54.55 total/h_score=64.33\n",
      "real -> painting lr= 0.001 seed= 2\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19]\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20]\n",
      "Loss: 1.7177976113040347\n",
      "Loss: 0.29163310303086254\n",
      "Loss: 0.17619787420107239\n",
      "Loss: 0.1419964282027778\n",
      "Loss: 0.11522341927459577\n",
      "Loss: 0.1012734580108255\n",
      "Loss: 0.08405763359734388\n",
      "Loss: 0.07519452461308031\n",
      "Loss: 0.07071651086223182\n",
      "Loss: 0.056922570834463386\n",
      "tensor(True) tensor(True)\n",
      "______\n",
      "Iteration t=1\n",
      "all:  cs/acc_i=73.17 cs/acc_c=72.62 os/recall_knw=94.43 os/recall_unk=19.19 total/acc_i=54.71 total/acc_c=68.68 total/h_score=30.23\n",
      "selected:  cs/acc_i=77.21 cs/acc_c=76.46 os/recall_knw=74.43 os/recall_unk=94.83 total/acc_i=77.98 total/acc_c=70.22 total/h_score=79.87\n",
      "Loss: 1.6388822808587478\n",
      "Loss: 0.2729381631282758\n",
      "Loss: 0.17028952256256452\n",
      "Loss: 0.12875197286734735\n",
      "Loss: 0.1067265541824095\n",
      "Loss: 0.09552487567070003\n",
      "Loss: 0.07489509311036144\n",
      "Loss: 0.06564931578482816\n",
      "Loss: 0.05840260513481096\n",
      "Loss: 0.05334855381619368\n",
      "______\n",
      "Iteration t=2\n",
      "all:  cs/acc_i=73.17 cs/acc_c=72.87 os/recall_knw=69.20 os/recall_unk=70.05 total/acc_i=63.75 total/acc_c=61.08 total/h_score=65.00\n",
      "selected:  cs/acc_i=65.81 cs/acc_c=65.82 os/recall_knw=49.71 os/recall_unk=92.50 total/acc_i=62.98 total/acc_c=48.46 total/h_score=61.68\n",
      "Loss: 1.5908838281298385\n",
      "Loss: 0.26273161120274485\n",
      "Loss: 0.16409087904235897\n",
      "Loss: 0.12585756033385062\n",
      "Loss: 0.09821870286455926\n",
      "Loss: 0.0800625010551063\n",
      "Loss: 0.07289164733442971\n",
      "Loss: 0.06331751187852419\n",
      "Loss: 0.056491410574766206\n",
      "Loss: 0.04920598137575914\n",
      "______\n",
      "Iteration t=3\n",
      "all:  cs/acc_i=72.56 cs/acc_c=72.06 os/recall_knw=61.59 os/recall_unk=76.70 total/acc_i=62.74 total/acc_c=56.72 total/h_score=64.55\n",
      "selected:  cs/acc_i=66.67 cs/acc_c=66.57 os/recall_knw=51.31 os/recall_unk=84.74 total/acc_i=59.56 total/acc_c=48.17 total/h_score=59.92\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 1.584989989599721\n",
      "Loss: 0.2599572504934093\n",
      "Loss: 0.14990419234064492\n",
      "Loss: 0.11287478285323066\n",
      "Loss: 0.09648902344369245\n",
      "Loss: 0.07693952254009094\n",
      "Loss: 0.07004939977460625\n",
      "Loss: 0.06486360407738671\n",
      "Loss: 0.05475983477927829\n",
      "Loss: 0.04774232354975538\n",
      "______\n",
      "Iteration t=4\n",
      "all:  cs/acc_i=71.85 cs/acc_c=71.21 os/recall_knw=60.34 os/recall_unk=77.45 total/acc_i=62.32 total/acc_c=55.79 total/h_score=64.12\n",
      "selected:  cs/acc_i=67.97 cs/acc_c=67.78 os/recall_knw=53.94 os/recall_unk=81.14 total/acc_i=59.82 total/acc_c=50.67 total/h_score=61.21\n",
      "Loss: 1.5590697365052852\n",
      "Loss: 0.24993407958729352\n",
      "Loss: 0.15226026180830673\n",
      "Loss: 0.12077861863466026\n",
      "Loss: 0.08847964087807285\n",
      "Loss: 0.08374534955528412\n",
      "Loss: 0.06626812609633778\n",
      "Loss: 0.06195117443966002\n",
      "Loss: 0.05769953880041402\n",
      "Loss: 0.0487762439216443\n",
      "______\n",
      "Iteration t=5\n",
      "all:  cs/acc_i=72.67 cs/acc_c=72.06 os/recall_knw=60.13 os/recall_unk=77.52 total/acc_i=62.23 total/acc_c=55.66 total/h_score=64.05\n",
      "selected:  cs/acc_i=70.64 cs/acc_c=70.42 os/recall_knw=56.83 os/recall_unk=78.58 total/acc_i=60.60 total/acc_c=53.20 total/h_score=62.54\n",
      "Loss: 1.5369671504598497\n",
      "Loss: 0.2528353534801736\n",
      "Loss: 0.15705553740466552\n",
      "Loss: 0.1097225835648635\n",
      "Loss: 0.0971137753845564\n",
      "Loss: 0.07473906444110831\n",
      "Loss: 0.0699296846840775\n",
      "Loss: 0.05645169092016549\n",
      "Loss: 0.05007328731491347\n",
      "Loss: 0.043337477591840416\n",
      "______\n",
      "Iteration t=6\n",
      "all:  cs/acc_i=73.88 cs/acc_c=73.30 os/recall_knw=60.09 os/recall_unk=77.60 total/acc_i=62.23 total/acc_c=55.64 total/h_score=64.06\n",
      "selected:  cs/acc_i=73.21 cs/acc_c=72.76 os/recall_knw=58.84 os/recall_unk=77.83 total/acc_i=61.60 total/acc_c=54.79 total/h_score=63.51\n",
      "Loss: 1.5421674207255647\n",
      "Loss: 0.25681940895077343\n",
      "Loss: 0.14983898221036873\n",
      "Loss: 0.11643204016208246\n",
      "Loss: 0.08958971043796958\n",
      "Loss: 0.07697201650086287\n",
      "Loss: 0.06517983421783995\n",
      "Loss: 0.058746177372774364\n",
      "Loss: 0.05091564720118972\n",
      "Loss: 0.041994768288615786\n",
      "______\n",
      "Iteration t=7\n",
      "all:  cs/acc_i=73.67 cs/acc_c=73.02 os/recall_knw=60.09 os/recall_unk=77.60 total/acc_i=62.23 total/acc_c=55.64 total/h_score=64.06\n",
      "selected:  cs/acc_i=73.55 cs/acc_c=72.88 os/recall_knw=59.81 os/recall_unk=77.71 total/acc_i=62.12 total/acc_c=55.45 total/h_score=63.95\n",
      "Loss: 1.5533661066043762\n",
      "Loss: 0.250932130091373\n",
      "Loss: 0.154557733075513\n",
      "Loss: 0.11053397919061364\n",
      "Loss: 0.09048700657978614\n",
      "Loss: 0.0768677461016122\n",
      "Loss: 0.06847338007152161\n",
      "Loss: 0.058339274284349735\n",
      "Loss: 0.05132923811118329\n",
      "Loss: 0.043382603118711865\n",
      "______\n",
      "Iteration t=8\n",
      "all:  cs/acc_i=73.95 cs/acc_c=73.30 os/recall_knw=60.09 os/recall_unk=77.60 total/acc_i=62.23 total/acc_c=55.64 total/h_score=64.06\n",
      "selected:  cs/acc_i=73.95 cs/acc_c=73.30 os/recall_knw=60.09 os/recall_unk=77.60 total/acc_i=62.23 total/acc_c=55.64 total/h_score=64.06\n",
      "Loss: 1.5257416944002018\n",
      "Loss: 0.24862312736244369\n",
      "Loss: 0.15148742153401668\n",
      "Loss: 0.11004210782834097\n",
      "Loss: 0.08884308421509915\n",
      "Loss: 0.07849825500203521\n",
      "Loss: 0.06790557309695527\n",
      "Loss: 0.06041276103369991\n",
      "Loss: 0.052169128861677794\n",
      "Loss: 0.04626767222966809\n",
      "______\n",
      "Iteration t=9\n",
      "all:  cs/acc_i=74.35 cs/acc_c=73.96 os/recall_knw=60.09 os/recall_unk=77.60 total/acc_i=62.23 total/acc_c=55.64 total/h_score=64.06\n",
      "selected:  cs/acc_i=74.35 cs/acc_c=73.96 os/recall_knw=60.09 os/recall_unk=77.60 total/acc_i=62.23 total/acc_c=55.64 total/h_score=64.06\n",
      "tensor(0)\n",
      "all:  cs/acc_i=74.35 cs/acc_c=73.96 os/recall_knw=60.09 os/recall_unk=77.60 total/acc_i=62.23 total/acc_c=55.64 total/h_score=64.06\n",
      "real -> painting lr= 0.001 seed= 3\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19]\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20]\n",
      "Loss: 1.7122035214372002\n",
      "Loss: 0.30203299859233224\n",
      "Loss: 0.18351674650068067\n",
      "Loss: 0.14342135701244668\n",
      "Loss: 0.11351941398665356\n",
      "Loss: 0.09262168803327145\n",
      "Loss: 0.08445140665361113\n",
      "Loss: 0.07501068126134743\n",
      "Loss: 0.06499844951213747\n",
      "Loss: 0.06049277489388008\n",
      "tensor(True) tensor(True)\n",
      "______\n",
      "Iteration t=1\n",
      "all:  cs/acc_i=72.78 cs/acc_c=72.27 os/recall_knw=94.53 os/recall_unk=19.42 total/acc_i=54.69 total/acc_c=68.61 total/h_score=30.50\n",
      "selected:  cs/acc_i=76.97 cs/acc_c=75.92 os/recall_knw=74.84 os/recall_unk=95.24 total/acc_i=78.77 total/acc_c=71.53 total/h_score=80.92\n",
      "Loss: 1.6419978102474857\n",
      "Loss: 0.2676862888266704\n",
      "Loss: 0.17848519383261174\n",
      "Loss: 0.12967830872380295\n",
      "Loss: 0.106602785943156\n",
      "Loss: 0.09660047716518258\n",
      "Loss: 0.0832895361932646\n",
      "Loss: 0.0656788007190531\n",
      "Loss: 0.058631323835743945\n",
      "Loss: 0.053373804397343946\n",
      "______\n",
      "Iteration t=2\n",
      "all:  cs/acc_i=72.67 cs/acc_c=72.33 os/recall_knw=71.03 os/recall_unk=65.27 total/acc_i=62.83 total/acc_c=61.65 total/h_score=63.31\n",
      "selected:  cs/acc_i=64.95 cs/acc_c=64.85 os/recall_knw=51.00 os/recall_unk=91.14 total/acc_i=62.78 total/acc_c=48.94 total/h_score=61.87\n",
      "Loss: 1.5996548472958452\n",
      "Loss: 0.2616795718560324\n",
      "Loss: 0.15789517721928217\n",
      "Loss: 0.12204218838802156\n",
      "Loss: 0.09917764877078726\n",
      "Loss: 0.08403627469533068\n",
      "Loss: 0.07101265963660006\n",
      "Loss: 0.06488399361945031\n",
      "Loss: 0.05829452106674366\n",
      "Loss: 0.04986112356281785\n",
      "______\n",
      "Iteration t=3\n",
      "all:  cs/acc_i=72.95 cs/acc_c=72.41 os/recall_knw=60.88 os/recall_unk=76.47 total/acc_i=62.06 total/acc_c=55.85 total/h_score=63.86\n",
      "selected:  cs/acc_i=67.82 cs/acc_c=67.85 os/recall_knw=50.98 os/recall_unk=83.80 total/acc_i=59.06 total/acc_c=48.14 total/h_score=59.69\n",
      "Loss: 1.5949980039941014\n",
      "Loss: 0.25139766621268844\n",
      "Loss: 0.16212678923886323\n",
      "Loss: 0.11428739138411902\n",
      "Loss: 0.10466758910798739\n",
      "Loss: 0.08284250883749625\n",
      "Loss: 0.07253441648958805\n",
      "Loss: 0.05988067244351037\n",
      "Loss: 0.05172259634671991\n",
      "Loss: 0.048818126782542756\n",
      "______\n",
      "Iteration t=4\n",
      "all:  cs/acc_i=72.06 cs/acc_c=71.43 os/recall_knw=59.56 os/recall_unk=77.15 total/acc_i=61.58 total/acc_c=54.81 total/h_score=63.32\n",
      "selected:  cs/acc_i=68.54 cs/acc_c=68.36 os/recall_knw=53.57 os/recall_unk=80.33 total/acc_i=59.13 total/acc_c=50.08 total/h_score=60.53\n",
      "Loss: 1.5683503116998407\n",
      "Loss: 0.25313627032770053\n",
      "Loss: 0.15176662851849365\n",
      "Loss: 0.11880006060625116\n",
      "Loss: 0.09578415904866738\n",
      "Loss: 0.07746753929079407\n",
      "Loss: 0.06877578029590141\n",
      "Loss: 0.06117811263797598\n",
      "Loss: 0.0529558555313593\n",
      "Loss: 0.044832141095927605\n",
      "______\n",
      "Iteration t=5\n",
      "all:  cs/acc_i=73.03 cs/acc_c=72.47 os/recall_knw=59.45 os/recall_unk=77.15 total/acc_i=61.53 total/acc_c=54.74 total/h_score=63.27\n",
      "selected:  cs/acc_i=71.35 cs/acc_c=71.13 os/recall_knw=56.65 os/recall_unk=77.79 total/acc_i=60.06 total/acc_c=52.64 total/h_score=61.88\n",
      "Loss: 1.5547850683372093\n",
      "Loss: 0.25183111228231514\n",
      "Loss: 0.15148860525228183\n",
      "Loss: 0.11795175480795897\n",
      "Loss: 0.09454708632934403\n",
      "Loss: 0.07888576182935195\n",
      "Loss: 0.06651814092884516\n",
      "Loss: 0.05633989662916605\n",
      "Loss: 0.04950717279981893\n",
      "Loss: 0.039753116252997066\n",
      "______\n",
      "Iteration t=6\n",
      "all:  cs/acc_i=73.06 cs/acc_c=72.65 os/recall_knw=59.41 os/recall_unk=77.15 total/acc_i=61.50 total/acc_c=54.69 total/h_score=63.23\n",
      "selected:  cs/acc_i=72.30 cs/acc_c=72.02 os/recall_knw=58.16 os/recall_unk=77.44 total/acc_i=60.83 total/acc_c=53.80 total/h_score=62.66\n",
      "Loss: 1.5458029511007103\n",
      "Loss: 0.24715245879582456\n",
      "Loss: 0.1517705444347214\n",
      "Loss: 0.11520241136486466\n",
      "Loss: 0.09571453111397253\n",
      "Loss: 0.07843269482254982\n",
      "Loss: 0.06405058990585039\n",
      "Loss: 0.060244563062096364\n",
      "Loss: 0.05075666079253613\n",
      "Loss: 0.04483050940577193\n",
      "______\n",
      "Iteration t=7\n",
      "all:  cs/acc_i=73.53 cs/acc_c=73.10 os/recall_knw=59.38 os/recall_unk=77.15 total/acc_i=61.48 total/acc_c=54.65 total/h_score=63.20\n",
      "selected:  cs/acc_i=73.44 cs/acc_c=73.02 os/recall_knw=59.19 os/recall_unk=77.32 total/acc_i=61.43 total/acc_c=54.54 total/h_score=63.17\n",
      "Loss: 1.537394392874933\n",
      "Loss: 0.23973199777225013\n",
      "Loss: 0.14925858942210996\n",
      "Loss: 0.11085748691011661\n",
      "Loss: 0.09175847405918262\n",
      "Loss: 0.07893456112573384\n",
      "Loss: 0.06905289150534137\n",
      "Loss: 0.058566687858953914\n",
      "Loss: 0.04979230889109194\n",
      "Loss: 0.04533585008566759\n",
      "______\n",
      "Iteration t=8\n",
      "all:  cs/acc_i=73.13 cs/acc_c=72.48 os/recall_knw=59.38 os/recall_unk=77.15 total/acc_i=61.48 total/acc_c=54.65 total/h_score=63.20\n",
      "selected:  cs/acc_i=73.13 cs/acc_c=72.48 os/recall_knw=59.38 os/recall_unk=77.15 total/acc_i=61.48 total/acc_c=54.65 total/h_score=63.20\n",
      "Loss: 1.5395716824256702\n",
      "Loss: 0.24664829361774326\n",
      "Loss: 0.15140829065529973\n",
      "Loss: 0.10833637187152542\n",
      "Loss: 0.09097615796723091\n",
      "Loss: 0.07626192216404362\n",
      "Loss: 0.07171166549254479\n",
      "Loss: 0.05435868322127686\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.04911093676248041\n",
      "Loss: 0.049054241956438836\n",
      "______\n",
      "Iteration t=9\n",
      "all:  cs/acc_i=72.92 cs/acc_c=72.37 os/recall_knw=59.38 os/recall_unk=77.15 total/acc_i=61.48 total/acc_c=54.65 total/h_score=63.20\n",
      "selected:  cs/acc_i=72.92 cs/acc_c=72.37 os/recall_knw=59.38 os/recall_unk=77.15 total/acc_i=61.48 total/acc_c=54.65 total/h_score=63.20\n",
      "tensor(0)\n",
      "all:  cs/acc_i=72.92 cs/acc_c=72.37 os/recall_knw=59.38 os/recall_unk=77.15 total/acc_i=61.48 total/acc_c=54.65 total/h_score=63.20\n",
      "real -> painting lr= 0.001 seed= 4\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19]\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20]\n",
      "Loss: 1.7231364823230977\n",
      "Loss: 0.2994767332814897\n",
      "Loss: 0.18545191897935806\n",
      "Loss: 0.13774963788736097\n",
      "Loss: 0.12238745529120758\n",
      "Loss: 0.09837119253142662\n",
      "Loss: 0.0887179736862516\n",
      "Loss: 0.07498254406436607\n",
      "Loss: 0.062040521811178834\n",
      "Loss: 0.05891492508480571\n",
      "tensor(True) tensor(True)\n",
      "______\n",
      "Iteration t=1\n",
      "all:  cs/acc_i=72.95 cs/acc_c=72.50 os/recall_knw=94.71 os/recall_unk=19.79 total/acc_i=54.71 total/acc_c=68.49 total/h_score=30.95\n",
      "selected:  cs/acc_i=79.03 cs/acc_c=78.27 os/recall_knw=75.37 os/recall_unk=94.31 total/acc_i=79.02 total/acc_c=71.85 total/h_score=80.83\n",
      "Loss: 1.6496020764843817\n",
      "Loss: 0.27916950846742267\n",
      "Loss: 0.16824963806551294\n",
      "Loss: 0.12712236973199925\n",
      "Loss: 0.10981436147200276\n",
      "Loss: 0.09236487517836132\n",
      "Loss: 0.07912666597289313\n",
      "Loss: 0.0675375332364504\n",
      "Loss: 0.05947649997281928\n",
      "Loss: 0.05547450168595358\n",
      "______\n",
      "Iteration t=2\n",
      "all:  cs/acc_i=72.85 cs/acc_c=72.51 os/recall_knw=68.35 os/recall_unk=70.50 total/acc_i=63.65 total/acc_c=60.64 total/h_score=64.91\n",
      "selected:  cs/acc_i=64.84 cs/acc_c=65.05 os/recall_knw=48.85 os/recall_unk=91.92 total/acc_i=62.27 total/acc_c=47.68 total/h_score=60.84\n",
      "Loss: 1.607452085263589\n",
      "Loss: 0.2608150668223115\n",
      "Loss: 0.16181238226811676\n",
      "Loss: 0.12077325762194746\n",
      "Loss: 0.10099239317316781\n",
      "Loss: 0.08790197745239471\n",
      "Loss: 0.07212423520053134\n",
      "Loss: 0.06325032264952932\n",
      "Loss: 0.05247845600687844\n",
      "Loss: 0.049750888924223975\n",
      "______\n",
      "Iteration t=3\n",
      "all:  cs/acc_i=72.74 cs/acc_c=72.32 os/recall_knw=60.38 os/recall_unk=78.57 total/acc_i=62.78 total/acc_c=56.17 total/h_score=64.74\n",
      "selected:  cs/acc_i=67.30 cs/acc_c=67.37 os/recall_knw=50.80 os/recall_unk=85.81 total/acc_i=59.74 total/acc_c=48.26 total/h_score=60.22\n",
      "Loss: 1.569214115173302\n",
      "Loss: 0.254684398225932\n",
      "Loss: 0.1682133816013282\n",
      "Loss: 0.11650838537819007\n",
      "Loss: 0.1030276609023779\n",
      "Loss: 0.07870530324924568\n",
      "Loss: 0.06838811276380015\n",
      "Loss: 0.06216500967804512\n",
      "Loss: 0.05715371025607138\n",
      "Loss: 0.046627531099974556\n",
      "______\n",
      "Iteration t=4\n",
      "all:  cs/acc_i=72.35 cs/acc_c=71.68 os/recall_knw=59.77 os/recall_unk=79.16 total/acc_i=62.64 total/acc_c=55.65 total/h_score=64.54\n",
      "selected:  cs/acc_i=68.94 cs/acc_c=68.81 os/recall_knw=53.93 os/recall_unk=82.55 total/acc_i=60.41 total/acc_c=51.03 total/h_score=61.86\n",
      "Loss: 1.562623179183033\n",
      "Loss: 0.247824587903315\n",
      "Loss: 0.15196114335427044\n",
      "Loss: 0.11864531590943134\n",
      "Loss: 0.08845503702448437\n",
      "Loss: 0.08004566063860581\n",
      "Loss: 0.06627260928345756\n",
      "Loss: 0.05825504818723685\n",
      "Loss: 0.05212702428854608\n",
      "Loss: 0.04570976487545084\n",
      "______\n",
      "Iteration t=5\n",
      "all:  cs/acc_i=72.99 cs/acc_c=72.52 os/recall_knw=59.63 os/recall_unk=79.24 total/acc_i=62.61 total/acc_c=55.62 total/h_score=64.54\n",
      "selected:  cs/acc_i=71.32 cs/acc_c=71.27 os/recall_knw=56.74 os/recall_unk=80.02 total/acc_i=61.22 total/acc_c=53.58 total/h_score=63.22\n",
      "Loss: 1.5440752693945592\n",
      "Loss: 0.2520530071883091\n",
      "Loss: 0.1544965744893896\n",
      "Loss: 0.11497373332885283\n",
      "Loss: 0.09659020650032603\n",
      "Loss: 0.07848926099485469\n",
      "Loss: 0.06932594286038699\n",
      "Loss: 0.06206098996367448\n",
      "Loss: 0.051580666556135024\n",
      "Loss: 0.041717468367131236\n",
      "______\n",
      "Iteration t=6\n",
      "all:  cs/acc_i=72.70 cs/acc_c=72.24 os/recall_knw=59.52 os/recall_unk=79.24 total/acc_i=62.57 total/acc_c=55.55 total/h_score=64.49\n",
      "selected:  cs/acc_i=71.98 cs/acc_c=71.65 os/recall_knw=58.28 os/recall_unk=79.48 total/acc_i=61.94 total/acc_c=54.70 total/h_score=63.92\n",
      "Loss: 1.538597664737766\n",
      "Loss: 0.25161044263258214\n",
      "Loss: 0.14735134488077667\n",
      "Loss: 0.11833372991279696\n",
      "Loss: 0.09408839972220301\n",
      "Loss: 0.07859908516309287\n",
      "Loss: 0.06811930460042666\n",
      "Loss: 0.0572749049804075\n",
      "Loss: 0.05055440357522812\n",
      "Loss: 0.04596511705344427\n",
      "______\n",
      "Iteration t=7\n",
      "all:  cs/acc_i=74.24 cs/acc_c=73.89 os/recall_knw=59.52 os/recall_unk=79.31 total/acc_i=62.59 total/acc_c=55.56 total/h_score=64.51\n",
      "selected:  cs/acc_i=74.12 cs/acc_c=73.79 os/recall_knw=59.27 os/recall_unk=79.37 total/acc_i=62.48 total/acc_c=55.40 total/h_score=64.42\n",
      "Loss: 1.5374776903349112\n",
      "Loss: 0.24633856620790182\n",
      "Loss: 0.15412408236986544\n",
      "Loss: 0.1147497447503786\n",
      "Loss: 0.09612933144154093\n",
      "Loss: 0.07598176580725735\n",
      "Loss: 0.06525706260457555\n",
      "Loss: 0.05772327428126351\n",
      "Loss: 0.05154406412371567\n",
      "Loss: 0.04692198897051723\n",
      "______\n",
      "Iteration t=8\n",
      "all:  cs/acc_i=73.88 cs/acc_c=73.45 os/recall_knw=59.45 os/recall_unk=79.31 total/acc_i=62.54 total/acc_c=55.52 total/h_score=64.49\n",
      "selected:  cs/acc_i=73.87 cs/acc_c=73.44 os/recall_knw=59.44 os/recall_unk=79.31 total/acc_i=62.53 total/acc_c=55.50 total/h_score=64.47\n",
      "Loss: 1.5297758563231396\n",
      "Loss: 0.2435293790573875\n",
      "Loss: 0.15252758169506667\n",
      "Loss: 0.11176361537648626\n",
      "Loss: 0.09423855209462745\n",
      "Loss: 0.07895271118319723\n",
      "Loss: 0.06555616370557497\n",
      "Loss: 0.0574762776984723\n",
      "Loss: 0.05009445975038914\n",
      "Loss: 0.0446459483899807\n",
      "______\n",
      "Iteration t=9\n",
      "all:  cs/acc_i=73.85 cs/acc_c=73.42 os/recall_knw=59.45 os/recall_unk=79.31 total/acc_i=62.54 total/acc_c=55.52 total/h_score=64.49\n",
      "selected:  cs/acc_i=73.85 cs/acc_c=73.42 os/recall_knw=59.45 os/recall_unk=79.31 total/acc_i=62.54 total/acc_c=55.52 total/h_score=64.49\n",
      "tensor(0)\n",
      "all:  cs/acc_i=73.85 cs/acc_c=73.42 os/recall_knw=59.45 os/recall_unk=79.31 total/acc_i=62.54 total/acc_c=55.52 total/h_score=64.49\n",
      "real -> painting lr= 0.001 seed= 0\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19]\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20]\n",
      "Loss: 1.6992985233424944\n",
      "Loss: 0.30842709881508085\n",
      "Loss: 0.17892565899244076\n",
      "Loss: 0.1360312275995779\n",
      "Loss: 0.11413707632655308\n",
      "Loss: 0.09698180240426224\n",
      "Loss: 0.08773666332472846\n",
      "Loss: 0.07405490412562486\n",
      "Loss: 0.06668616558793465\n",
      "Loss: 0.06504328222159249\n",
      "tensor(True) tensor(True)\n",
      "______\n",
      "Iteration t=1\n",
      "all:  cs/acc_i=72.95 cs/acc_c=72.60 os/recall_knw=84.82 os/recall_unk=45.48 total/acc_i=60.92 total/acc_c=66.93 total/h_score=54.51\n",
      "selected:  cs/acc_i=64.20 cs/acc_c=64.48 os/recall_knw=51.70 os/recall_unk=97.75 total/acc_i=69.46 total/acc_c=52.29 total/h_score=66.17\n",
      "Loss: 1.6489603917108724\n",
      "Loss: 0.28036969532173106\n",
      "Loss: 0.1651268223631967\n",
      "Loss: 0.13578730762759053\n",
      "Loss: 0.11163946339414894\n",
      "Loss: 0.09163568019181308\n",
      "Loss: 0.07807297914066107\n",
      "Loss: 0.07165794479060758\n",
      "Loss: 0.059413255346607574\n",
      "Loss: 0.05243372984881873\n",
      "______\n",
      "Iteration t=2\n",
      "all:  cs/acc_i=73.42 cs/acc_c=72.94 os/recall_knw=59.16 os/recall_unk=80.96 total/acc_i=63.27 total/acc_c=55.85 total/h_score=65.21\n",
      "selected:  cs/acc_i=65.24 cs/acc_c=65.51 os/recall_knw=42.59 os/recall_unk=93.13 total/acc_i=59.02 total/acc_c=42.73 total/h_score=56.17\n",
      "Loss: 1.617524491162861\n",
      "Loss: 0.25684766086804517\n",
      "Loss: 0.14984108465449775\n",
      "Loss: 0.1256341532968423\n",
      "Loss: 0.09933106243500815\n",
      "Loss: 0.07765298950184575\n",
      "Loss: 0.07719894230831414\n",
      "Loss: 0.06622355841511093\n",
      "Loss: 0.056889497714034995\n",
      "Loss: 0.05456346070585663\n",
      "______\n",
      "Iteration t=3\n",
      "all:  cs/acc_i=72.70 cs/acc_c=72.25 os/recall_knw=56.48 os/recall_unk=82.52 total/acc_i=62.47 total/acc_c=54.03 total/h_score=64.25\n",
      "selected:  cs/acc_i=67.52 cs/acc_c=67.69 os/recall_knw=47.04 os/recall_unk=88.33 total/acc_i=59.22 total/acc_c=46.55 total/h_score=59.15\n",
      "Loss: 1.5988072673536644\n",
      "Loss: 0.2593774331525438\n",
      "Loss: 0.15443621778641867\n",
      "Loss: 0.11958090463295622\n",
      "Loss: 0.09548990419374667\n",
      "Loss: 0.08467866394556739\n",
      "Loss: 0.06757256341564408\n",
      "Loss: 0.059817396090325915\n",
      "Loss: 0.05717520206035208\n",
      "Loss: 0.04607048604028956\n",
      "______\n",
      "Iteration t=4\n",
      "all:  cs/acc_i=72.85 cs/acc_c=72.46 os/recall_knw=56.13 os/recall_unk=82.60 total/acc_i=62.28 total/acc_c=53.69 total/h_score=64.00\n",
      "selected:  cs/acc_i=69.66 cs/acc_c=69.73 os/recall_knw=50.32 os/recall_unk=84.88 total/acc_i=59.87 total/acc_c=49.34 total/h_score=60.96\n",
      "Loss: 1.5684763759039761\n",
      "Loss: 0.2541711056667767\n",
      "Loss: 0.15281507715561918\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.11969065915249037\n",
      "Loss: 0.09904468379224117\n",
      "Loss: 0.08143996294284386\n",
      "Loss: 0.06880549662824971\n",
      "Loss: 0.06299545965615262\n",
      "Loss: 0.05232258579887324\n",
      "Loss: 0.04567603806486312\n",
      "______\n",
      "Iteration t=5\n",
      "all:  cs/acc_i=73.10 cs/acc_c=72.67 os/recall_knw=55.84 os/recall_unk=82.82 total/acc_i=62.18 total/acc_c=53.50 total/h_score=63.91\n",
      "selected:  cs/acc_i=71.55 cs/acc_c=71.46 os/recall_knw=53.06 os/recall_unk=83.13 total/acc_i=60.78 total/acc_c=51.57 total/h_score=62.44\n",
      "Loss: 1.547057426148686\n",
      "Loss: 0.2544713169336319\n",
      "Loss: 0.14882680121809244\n",
      "Loss: 0.11933291146984498\n",
      "Loss: 0.09143323382203215\n",
      "Loss: 0.08175847880048318\n",
      "Loss: 0.06940321323914628\n",
      "Loss: 0.05804098532174956\n",
      "Loss: 0.05128594393872795\n",
      "Loss: 0.05006603524442608\n",
      "______\n",
      "Iteration t=6\n",
      "all:  cs/acc_i=73.85 cs/acc_c=73.39 os/recall_knw=55.84 os/recall_unk=82.82 total/acc_i=62.18 total/acc_c=53.50 total/h_score=63.91\n",
      "selected:  cs/acc_i=73.40 cs/acc_c=73.01 os/recall_knw=54.96 os/recall_unk=83.01 total/acc_i=61.76 total/acc_c=52.91 total/h_score=63.49\n",
      "Loss: 1.5368888665960259\n",
      "Loss: 0.24506906479188842\n",
      "Loss: 0.15572354739455327\n",
      "Loss: 0.11826386727800925\n",
      "Loss: 0.09277781808417138\n",
      "Loss: 0.07438006455665581\n",
      "Loss: 0.07193528921726121\n",
      "Loss: 0.057806092274872815\n",
      "Loss: 0.05286749626050563\n",
      "Loss: 0.04487161542263443\n",
      "______\n",
      "Iteration t=7\n",
      "all:  cs/acc_i=74.24 cs/acc_c=73.85 os/recall_knw=55.84 os/recall_unk=82.82 total/acc_i=62.18 total/acc_c=53.50 total/h_score=63.91\n",
      "selected:  cs/acc_i=74.19 cs/acc_c=73.79 os/recall_knw=55.70 os/recall_unk=82.95 total/acc_i=62.15 total/acc_c=53.41 total/h_score=63.88\n",
      "Loss: 1.527076477575692\n",
      "Loss: 0.24472148419035553\n",
      "Loss: 0.14741399878133546\n",
      "Loss: 0.11336678224653818\n",
      "Loss: 0.09255781146375416\n",
      "Loss: 0.0821884918465642\n",
      "Loss: 0.07430110110492733\n",
      "Loss: 0.057272401632619284\n",
      "Loss: 0.050686061287765725\n",
      "Loss: 0.04723371520932835\n",
      "______\n",
      "Iteration t=8\n",
      "all:  cs/acc_i=73.81 cs/acc_c=73.35 os/recall_knw=55.84 os/recall_unk=82.82 total/acc_i=62.18 total/acc_c=53.50 total/h_score=63.91\n",
      "selected:  cs/acc_i=73.81 cs/acc_c=73.35 os/recall_knw=55.84 os/recall_unk=82.82 total/acc_i=62.18 total/acc_c=53.50 total/h_score=63.91\n",
      "Loss: 1.5565670205721738\n",
      "Loss: 0.2421683640363918\n",
      "Loss: 0.15676145643320655\n",
      "Loss: 0.11689554019361653\n",
      "Loss: 0.09119993428209903\n",
      "Loss: 0.07715584465736468\n",
      "Loss: 0.06954926308574363\n",
      "Loss: 0.06033884328967645\n",
      "Loss: 0.0541316277039179\n",
      "Loss: 0.048371095675975084\n",
      "______\n",
      "Iteration t=9\n",
      "all:  cs/acc_i=74.03 cs/acc_c=73.66 os/recall_knw=55.84 os/recall_unk=82.82 total/acc_i=62.18 total/acc_c=53.50 total/h_score=63.91\n",
      "selected:  cs/acc_i=74.03 cs/acc_c=73.66 os/recall_knw=55.84 os/recall_unk=82.82 total/acc_i=62.18 total/acc_c=53.50 total/h_score=63.91\n",
      "tensor(0)\n",
      "all:  cs/acc_i=74.03 cs/acc_c=73.66 os/recall_knw=55.84 os/recall_unk=82.82 total/acc_i=62.18 total/acc_c=53.50 total/h_score=63.91\n",
      "real -> painting lr= 0.001 seed= 1\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19]\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20]\n",
      "Loss: 1.7106601743452803\n",
      "Loss: 0.29883846887342413\n",
      "Loss: 0.18008370077015887\n",
      "Loss: 0.1371976129195602\n",
      "Loss: 0.11744009682734967\n",
      "Loss: 0.10235147049404993\n",
      "Loss: 0.08413467647274207\n",
      "Loss: 0.07513344024796147\n",
      "Loss: 0.06543225163617845\n",
      "Loss: 0.061370536333123685\n",
      "tensor(True) tensor(True)\n",
      "______\n",
      "Iteration t=1\n",
      "all:  cs/acc_i=72.74 cs/acc_c=72.30 os/recall_knw=83.89 os/recall_unk=43.54 total/acc_i=59.98 total/acc_c=66.36 total/h_score=52.93\n",
      "selected:  cs/acc_i=63.09 cs/acc_c=62.39 os/recall_knw=50.17 os/recall_unk=97.49 total/acc_i=67.66 total/acc_c=50.12 total/h_score=64.10\n",
      "Loss: 1.6374534326462657\n",
      "Loss: 0.27569427748033604\n",
      "Loss: 0.16783911930797107\n",
      "Loss: 0.12623806461189058\n",
      "Loss: 0.11151632599166932\n",
      "Loss: 0.09338660717604716\n",
      "Loss: 0.07991060095216417\n",
      "Loss: 0.06738143196140925\n",
      "Loss: 0.06381588208951924\n",
      "Loss: 0.05597275995043752\n",
      "______\n",
      "Iteration t=2\n",
      "all:  cs/acc_i=72.53 cs/acc_c=72.01 os/recall_knw=62.59 os/recall_unk=76.70 total/acc_i=63.36 total/acc_c=57.82 total/h_score=65.32\n",
      "selected:  cs/acc_i=63.45 cs/acc_c=63.48 os/recall_knw=44.46 os/recall_unk=91.86 total/acc_i=59.54 total/acc_c=43.92 total/h_score=57.20\n",
      "Loss: 1.6110262542086489\n",
      "Loss: 0.2628738562412122\n",
      "Loss: 0.15610033423256348\n",
      "Loss: 0.12957767689710153\n",
      "Loss: 0.10146296202643391\n",
      "Loss: 0.08547825660446988\n",
      "Loss: 0.07844088303938727\n",
      "Loss: 0.06358180914128966\n",
      "Loss: 0.05745850862825618\n",
      "Loss: 0.05422211259822635\n",
      "______\n",
      "Iteration t=3\n",
      "all:  cs/acc_i=72.63 cs/acc_c=72.00 os/recall_knw=56.73 os/recall_unk=81.33 total/acc_i=61.84 total/acc_c=53.69 total/h_score=63.67\n",
      "selected:  cs/acc_i=67.47 cs/acc_c=67.26 os/recall_knw=47.05 os/recall_unk=87.05 total/acc_i=58.48 total/acc_c=45.81 total/h_score=58.23\n",
      "Loss: 1.5875171943221773\n",
      "Loss: 0.2612126271852425\n",
      "Loss: 0.15556731076112815\n",
      "Loss: 0.12055721682629415\n",
      "Loss: 0.09793118919911128\n",
      "Loss: 0.08857465788855085\n",
      "Loss: 0.0699548354345773\n",
      "Loss: 0.06526614079850593\n",
      "Loss: 0.05622127630348717\n",
      "Loss: 0.04712330942308264\n",
      "______\n",
      "Iteration t=4\n",
      "all:  cs/acc_i=72.49 cs/acc_c=72.01 os/recall_knw=56.70 os/recall_unk=81.33 total/acc_i=61.82 total/acc_c=53.65 total/h_score=63.64\n",
      "selected:  cs/acc_i=69.28 cs/acc_c=69.41 os/recall_knw=50.95 os/recall_unk=83.77 total/acc_i=59.43 total/acc_c=49.39 total/h_score=60.76\n",
      "Loss: 1.564208813909055\n",
      "Loss: 0.2557689622879362\n",
      "Loss: 0.1600244470952856\n",
      "Loss: 0.11394993181363876\n",
      "Loss: 0.09882033951267474\n",
      "Loss: 0.08071770024660672\n",
      "Loss: 0.06670229684911064\n",
      "Loss: 0.061995326890284065\n",
      "Loss: 0.054517712168844226\n",
      "Loss: 0.04686645234228015\n",
      "______\n",
      "Iteration t=5\n",
      "all:  cs/acc_i=73.38 cs/acc_c=72.92 os/recall_knw=56.59 os/recall_unk=81.33 total/acc_i=61.77 total/acc_c=53.59 total/h_score=63.59\n",
      "selected:  cs/acc_i=71.85 cs/acc_c=71.77 os/recall_knw=53.66 os/recall_unk=82.00 total/acc_i=60.41 total/acc_c=51.64 total/h_score=62.22\n",
      "Loss: 1.5594205669545602\n",
      "Loss: 0.2500195444430694\n",
      "Loss: 0.15110625836680086\n",
      "Loss: 0.11512130411654793\n",
      "Loss: 0.09192984105798495\n",
      "Loss: 0.08036895626360556\n",
      "Loss: 0.06716673655727924\n",
      "Loss: 0.06185322139699515\n",
      "Loss: 0.05448803305946619\n",
      "Loss: 0.04563772747903734\n",
      "______\n",
      "Iteration t=6\n",
      "all:  cs/acc_i=73.95 cs/acc_c=73.37 os/recall_knw=56.59 os/recall_unk=81.33 total/acc_i=61.77 total/acc_c=53.59 total/h_score=63.59\n",
      "selected:  cs/acc_i=73.50 cs/acc_c=72.93 os/recall_knw=55.71 os/recall_unk=81.57 total/acc_i=61.35 total/acc_c=52.94 total/h_score=63.15\n",
      "Loss: 1.555432916865037\n",
      "Loss: 0.25901714722532015\n",
      "Loss: 0.14496422609776177\n",
      "Loss: 0.12124103735574097\n",
      "Loss: 0.09494698579912898\n",
      "Loss: 0.07787589357572047\n",
      "Loss: 0.06986805079606354\n",
      "Loss: 0.06142589620794157\n",
      "Loss: 0.04885765668563037\n",
      "Loss: 0.04339072885491685\n",
      "______\n",
      "Iteration t=7\n",
      "all:  cs/acc_i=73.31 cs/acc_c=72.94 os/recall_knw=56.59 os/recall_unk=81.40 total/acc_i=61.79 total/acc_c=53.59 total/h_score=63.61\n",
      "selected:  cs/acc_i=73.19 cs/acc_c=72.83 os/recall_knw=56.34 os/recall_unk=81.53 total/acc_i=61.70 total/acc_c=53.44 total/h_score=63.53\n",
      "Loss: 1.5513677252456546\n",
      "Loss: 0.24467019303499357\n",
      "Loss: 0.15572485668361996\n",
      "Loss: 0.11010069609113524\n",
      "Loss: 0.0912971869515984\n",
      "Loss: 0.078775134730993\n",
      "Loss: 0.06706840487996764\n",
      "Loss: 0.05877789821280875\n",
      "Loss: 0.050882858620910985\n",
      "Loss: 0.03970692049694227\n",
      "______\n",
      "Iteration t=8\n",
      "all:  cs/acc_i=73.99 cs/acc_c=73.34 os/recall_knw=56.59 os/recall_unk=81.40 total/acc_i=61.79 total/acc_c=53.59 total/h_score=63.61\n",
      "selected:  cs/acc_i=73.99 cs/acc_c=73.34 os/recall_knw=56.59 os/recall_unk=81.40 total/acc_i=61.79 total/acc_c=53.59 total/h_score=63.61\n",
      "Loss: 1.5476525398376195\n",
      "Loss: 0.24958487412811298\n",
      "Loss: 0.1470242742418676\n",
      "Loss: 0.11419955755928127\n",
      "Loss: 0.09132258496095386\n",
      "Loss: 0.08174352323808505\n",
      "Loss: 0.0679201341294886\n",
      "Loss: 0.06066845427899945\n",
      "Loss: 0.051616291544632986\n",
      "Loss: 0.04537697589093232\n",
      "______\n",
      "Iteration t=9\n",
      "all:  cs/acc_i=74.49 cs/acc_c=73.91 os/recall_knw=56.59 os/recall_unk=81.40 total/acc_i=61.79 total/acc_c=53.59 total/h_score=63.61\n",
      "selected:  cs/acc_i=74.49 cs/acc_c=73.91 os/recall_knw=56.59 os/recall_unk=81.40 total/acc_i=61.79 total/acc_c=53.59 total/h_score=63.61\n",
      "tensor(0)\n",
      "all:  cs/acc_i=74.49 cs/acc_c=73.91 os/recall_knw=56.59 os/recall_unk=81.40 total/acc_i=61.79 total/acc_c=53.59 total/h_score=63.61\n",
      "real -> painting lr= 0.001 seed= 2\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19]\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 1.7185494595018613\n",
      "Loss: 0.2919353703785556\n",
      "Loss: 0.17640633406746425\n",
      "Loss: 0.1422160631974027\n",
      "Loss: 0.11494560615785444\n",
      "Loss: 0.10147793209509642\n",
      "Loss: 0.08400268936859162\n",
      "Loss: 0.0751526798990067\n",
      "Loss: 0.07053891695149458\n",
      "Loss: 0.05680444204005925\n",
      "tensor(True) tensor(True)\n",
      "______\n",
      "Iteration t=1\n",
      "all:  cs/acc_i=72.88 cs/acc_c=72.39 os/recall_knw=84.07 os/recall_unk=43.91 total/acc_i=60.03 total/acc_c=66.03 total/h_score=53.10\n",
      "selected:  cs/acc_i=63.74 cs/acc_c=64.43 os/recall_knw=50.39 os/recall_unk=97.35 total/acc_i=67.66 total/acc_c=50.56 total/h_score=64.50\n",
      "Loss: 1.6378280318404999\n",
      "Loss: 0.2725583078351123\n",
      "Loss: 0.17206085565288556\n",
      "Loss: 0.12783015695360542\n",
      "Loss: 0.10428475706546676\n",
      "Loss: 0.09747173406320847\n",
      "Loss: 0.08029148556246347\n",
      "Loss: 0.07266500150567733\n",
      "Loss: 0.06175546339095964\n",
      "Loss: 0.05519746402721349\n",
      "______\n",
      "Iteration t=2\n",
      "all:  cs/acc_i=72.81 cs/acc_c=72.32 os/recall_knw=61.31 os/recall_unk=78.57 total/acc_i=63.36 total/acc_c=56.93 total/h_score=65.29\n",
      "selected:  cs/acc_i=64.22 cs/acc_c=64.50 os/recall_knw=44.00 os/recall_unk=93.10 total/acc_i=59.60 total/acc_c=43.66 total/h_score=57.11\n",
      "Loss: 1.5949912730385276\n",
      "Loss: 0.2667321824852158\n",
      "Loss: 0.16751286809277885\n",
      "Loss: 0.12297319175456377\n",
      "Loss: 0.10150375901721417\n",
      "Loss: 0.08212016612044809\n",
      "Loss: 0.07154715873629731\n",
      "Loss: 0.06329960300148849\n",
      "Loss: 0.05712847860036966\n",
      "Loss: 0.049699654926628097\n",
      "______\n",
      "Iteration t=3\n",
      "all:  cs/acc_i=72.06 cs/acc_c=71.51 os/recall_knw=58.70 os/recall_unk=81.33 total/acc_i=62.93 total/acc_c=55.29 total/h_score=64.89\n",
      "selected:  cs/acc_i=66.46 cs/acc_c=66.57 os/recall_knw=49.05 os/recall_unk=87.19 total/acc_i=59.55 total/acc_c=47.38 total/h_score=59.70\n",
      "Loss: 1.5903489649125992\n",
      "Loss: 0.251927648418904\n",
      "Loss: 0.15856903528746885\n",
      "Loss: 0.12318974110348273\n",
      "Loss: 0.09456745110866097\n",
      "Loss: 0.08278109718039844\n",
      "Loss: 0.07317265543816054\n",
      "Loss: 0.06306951612027155\n",
      "Loss: 0.054742539174154274\n",
      "Loss: 0.04596483859066398\n",
      "______\n",
      "Iteration t=4\n",
      "all:  cs/acc_i=72.63 cs/acc_c=72.28 os/recall_knw=57.81 os/recall_unk=81.63 total/acc_i=62.52 total/acc_c=54.55 total/h_score=64.41\n",
      "selected:  cs/acc_i=69.36 cs/acc_c=69.59 os/recall_knw=52.26 os/recall_unk=83.50 total/acc_i=60.01 total/acc_c=50.17 total/h_score=61.36\n",
      "Loss: 1.5777058857779263\n",
      "Loss: 0.2522906088088145\n",
      "Loss: 0.15737859255962033\n",
      "Loss: 0.11254976592000636\n",
      "Loss: 0.09217097048580064\n",
      "Loss: 0.08441134038324047\n",
      "Loss: 0.07164826144479923\n",
      "Loss: 0.056590253778592836\n",
      "Loss: 0.055582226145435024\n",
      "Loss: 0.04690427282290512\n",
      "______\n",
      "Iteration t=5\n",
      "all:  cs/acc_i=73.10 cs/acc_c=72.58 os/recall_knw=57.70 os/recall_unk=81.63 total/acc_i=62.45 total/acc_c=54.42 total/h_score=64.31\n",
      "selected:  cs/acc_i=71.49 cs/acc_c=71.32 os/recall_knw=54.88 os/recall_unk=82.12 total/acc_i=61.04 total/acc_c=52.38 total/h_score=62.84\n",
      "Loss: 1.5578466978456293\n",
      "Loss: 0.2513397286369742\n",
      "Loss: 0.14731206056139953\n",
      "Loss: 0.10874166665854608\n",
      "Loss: 0.09445783927663137\n",
      "Loss: 0.07981626131152222\n",
      "Loss: 0.06675501701237818\n",
      "Loss: 0.06174800368179414\n",
      "Loss: 0.054553598391306635\n",
      "Loss: 0.04608853619512437\n",
      "______\n",
      "Iteration t=6\n",
      "all:  cs/acc_i=73.49 cs/acc_c=72.89 os/recall_knw=57.70 os/recall_unk=81.70 total/acc_i=62.47 total/acc_c=54.42 total/h_score=64.33\n",
      "selected:  cs/acc_i=72.84 cs/acc_c=72.34 os/recall_knw=56.55 os/recall_unk=81.89 total/acc_i=61.88 total/acc_c=53.57 total/h_score=63.73\n",
      "Loss: 1.5532099510408552\n",
      "Loss: 0.24808542170544087\n",
      "Loss: 0.1485448616280218\n",
      "Loss: 0.11657075434720159\n",
      "Loss: 0.09533109855952315\n",
      "Loss: 0.07595522239124174\n",
      "Loss: 0.07082009948764696\n",
      "Loss: 0.058888917722883925\n",
      "Loss: 0.052537720470894785\n",
      "Loss: 0.04368867627497285\n",
      "______\n",
      "Iteration t=7\n",
      "all:  cs/acc_i=73.67 cs/acc_c=73.04 os/recall_knw=57.70 os/recall_unk=81.70 total/acc_i=62.47 total/acc_c=54.42 total/h_score=64.33\n",
      "selected:  cs/acc_i=73.63 cs/acc_c=73.00 os/recall_knw=57.52 os/recall_unk=81.82 total/acc_i=62.44 total/acc_c=54.33 total/h_score=64.30\n",
      "Loss: 1.551217150235887\n",
      "Loss: 0.24847519143325528\n",
      "Loss: 0.14894375535167328\n",
      "Loss: 0.11056493019791154\n",
      "Loss: 0.09427246729007904\n",
      "Loss: 0.07429259641191904\n",
      "Loss: 0.06532846862541103\n",
      "Loss: 0.059000672026711505\n",
      "Loss: 0.052864060019771376\n",
      "Loss: 0.04288944252829766\n",
      "______\n",
      "Iteration t=8\n",
      "all:  cs/acc_i=73.95 cs/acc_c=73.50 os/recall_knw=57.66 os/recall_unk=81.70 total/acc_i=62.45 total/acc_c=54.37 total/h_score=64.30\n",
      "selected:  cs/acc_i=73.95 cs/acc_c=73.50 os/recall_knw=57.66 os/recall_unk=81.70 total/acc_i=62.45 total/acc_c=54.37 total/h_score=64.30\n",
      "Loss: 1.557463796965798\n",
      "Loss: 0.24997226489066754\n",
      "Loss: 0.15071669988697622\n",
      "Loss: 0.11103476330557167\n",
      "Loss: 0.0895195751726062\n",
      "Loss: 0.08003349087849704\n",
      "Loss: 0.06349654660274989\n",
      "Loss: 0.06095608694448582\n",
      "Loss: 0.05147697180345513\n",
      "Loss: 0.04437008299006699\n",
      "______\n",
      "Iteration t=9\n",
      "all:  cs/acc_i=74.21 cs/acc_c=73.80 os/recall_knw=57.66 os/recall_unk=81.70 total/acc_i=62.45 total/acc_c=54.37 total/h_score=64.30\n",
      "selected:  cs/acc_i=74.21 cs/acc_c=73.80 os/recall_knw=57.66 os/recall_unk=81.70 total/acc_i=62.45 total/acc_c=54.37 total/h_score=64.30\n",
      "tensor(0)\n",
      "all:  cs/acc_i=74.21 cs/acc_c=73.80 os/recall_knw=57.66 os/recall_unk=81.70 total/acc_i=62.45 total/acc_c=54.37 total/h_score=64.30\n",
      "real -> painting lr= 0.001 seed= 3\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19]\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20]\n",
      "Loss: 1.7114688794329236\n",
      "Loss: 0.3020216359538281\n",
      "Loss: 0.1836922446750943\n",
      "Loss: 0.14357966220551366\n",
      "Loss: 0.11358109739432382\n",
      "Loss: 0.09283082822032297\n",
      "Loss: 0.08449289443456474\n",
      "Loss: 0.07496416094110997\n",
      "Loss: 0.0649503880282235\n",
      "Loss: 0.06068022643183014\n",
      "tensor(True) tensor(True)\n",
      "______\n",
      "Iteration t=1\n",
      "all:  cs/acc_i=72.99 cs/acc_c=72.53 os/recall_knw=83.82 os/recall_unk=43.39 total/acc_i=59.86 total/acc_c=66.10 total/h_score=52.74\n",
      "selected:  cs/acc_i=63.87 cs/acc_c=64.18 os/recall_knw=49.94 os/recall_unk=97.48 total/acc_i=67.42 total/acc_c=50.45 total/h_score=64.41\n",
      "Loss: 1.6408612860218148\n",
      "Loss: 0.2693958078379646\n",
      "Loss: 0.1668365219139431\n",
      "Loss: 0.13506348515100822\n",
      "Loss: 0.10784163711409718\n",
      "Loss: 0.09333006781097387\n",
      "Loss: 0.08477609819429784\n",
      "Loss: 0.0698942096955343\n",
      "Loss: 0.058885105916990275\n",
      "Loss: 0.05389277625149059\n",
      "______\n",
      "Iteration t=2\n",
      "all:  cs/acc_i=72.49 cs/acc_c=72.23 os/recall_knw=61.74 os/recall_unk=76.47 total/acc_i=62.83 total/acc_c=57.29 total/h_score=64.87\n",
      "selected:  cs/acc_i=64.10 cs/acc_c=64.21 os/recall_knw=43.87 os/recall_unk=91.92 total/acc_i=59.36 total/acc_c=43.74 total/h_score=57.02\n",
      "Loss: 1.6133693035034573\n",
      "Loss: 0.2588777565780808\n",
      "Loss: 0.1631894943797413\n",
      "Loss: 0.11697479048196008\n",
      "Loss: 0.10620424388633931\n",
      "Loss: 0.07998014908585259\n",
      "Loss: 0.07920106469023534\n",
      "Loss: 0.06620784783119554\n",
      "Loss: 0.05827920787611648\n",
      "Loss: 0.04698146469548673\n",
      "______\n",
      "Iteration t=3\n",
      "all:  cs/acc_i=72.53 cs/acc_c=72.03 os/recall_knw=59.06 os/recall_unk=78.86 total/acc_i=62.45 total/acc_c=55.77 total/h_score=64.54\n",
      "selected:  cs/acc_i=66.89 cs/acc_c=66.76 os/recall_knw=48.66 os/recall_unk=85.85 total/acc_i=59.13 total/acc_c=47.38 total/h_score=59.44\n",
      "Loss: 1.5986882265976496\n",
      "Loss: 0.25575441684041705\n",
      "Loss: 0.15139430513871568\n",
      "Loss: 0.11510084755186524\n",
      "Loss: 0.09665488639846444\n",
      "Loss: 0.07608570558950305\n",
      "Loss: 0.07372851433498519\n",
      "Loss: 0.059715576775904215\n",
      "Loss: 0.061112046050173896\n",
      "Loss: 0.05037098739695336\n",
      "______\n",
      "Iteration t=4\n",
      "all:  cs/acc_i=73.03 cs/acc_c=72.43 os/recall_knw=58.13 os/recall_unk=79.16 total/acc_i=62.03 total/acc_c=55.04 total/h_score=64.08\n",
      "selected:  cs/acc_i=69.71 cs/acc_c=69.48 os/recall_knw=52.09 os/recall_unk=81.79 total/acc_i=59.54 total/acc_c=50.28 total/h_score=61.05\n",
      "Loss: 1.5591515838766896\n",
      "Loss: 0.24741642843078634\n",
      "Loss: 0.15414430317599015\n",
      "Loss: 0.11427513842455335\n",
      "Loss: 0.09249026225567614\n",
      "Loss: 0.0836500180065736\n",
      "Loss: 0.07525374375507443\n",
      "Loss: 0.06265250522924286\n",
      "Loss: 0.05657257136040726\n",
      "Loss: 0.045665978861181844\n",
      "______\n",
      "Iteration t=5\n",
      "all:  cs/acc_i=73.20 cs/acc_c=72.77 os/recall_knw=58.06 os/recall_unk=79.16 total/acc_i=61.99 total/acc_c=54.95 total/h_score=64.02\n",
      "selected:  cs/acc_i=71.40 cs/acc_c=71.27 os/recall_knw=54.81 os/recall_unk=79.94 total/acc_i=60.42 total/acc_c=52.53 total/h_score=62.39\n",
      "Loss: 1.5603973966214684\n",
      "Loss: 0.2518071843270253\n",
      "Loss: 0.15325804984012803\n",
      "Loss: 0.1187923457882889\n",
      "Loss: 0.09579372783652046\n",
      "Loss: 0.082193442359362\n",
      "Loss: 0.07567880989901804\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.0598323167631771\n",
      "Loss: 0.048571006527968814\n",
      "Loss: 0.04513801258904245\n",
      "______\n",
      "Iteration t=6\n",
      "all:  cs/acc_i=73.38 cs/acc_c=72.99 os/recall_knw=57.95 os/recall_unk=79.31 total/acc_i=61.99 total/acc_c=54.88 total/h_score=64.01\n",
      "selected:  cs/acc_i=72.71 cs/acc_c=72.49 os/recall_knw=56.78 os/recall_unk=79.49 total/acc_i=61.37 total/acc_c=54.09 total/h_score=63.47\n",
      "Loss: 1.5524510626235735\n",
      "Loss: 0.2500647685247595\n",
      "Loss: 0.15167701469086434\n",
      "Loss: 0.11479314242783205\n",
      "Loss: 0.09507697425863665\n",
      "Loss: 0.07478485586572155\n",
      "Loss: 0.07145391226209619\n",
      "Loss: 0.056750621086077604\n",
      "Loss: 0.05390195955734943\n",
      "Loss: 0.048092283345202144\n",
      "______\n",
      "Iteration t=7\n",
      "all:  cs/acc_i=73.99 cs/acc_c=73.65 os/recall_knw=57.95 os/recall_unk=79.31 total/acc_i=61.99 total/acc_c=54.88 total/h_score=64.01\n",
      "selected:  cs/acc_i=73.91 cs/acc_c=73.56 os/recall_knw=57.75 os/recall_unk=79.37 total/acc_i=61.91 total/acc_c=54.76 total/h_score=63.94\n",
      "Loss: 1.5556586667492582\n",
      "Loss: 0.2532476664898363\n",
      "Loss: 0.1540316535663363\n",
      "Loss: 0.11701458327572893\n",
      "Loss: 0.0929416750482208\n",
      "Loss: 0.07846622218856135\n",
      "Loss: 0.0673536225360491\n",
      "Loss: 0.06068298888480844\n",
      "Loss: 0.05218233058757677\n",
      "Loss: 0.047937267671364386\n",
      "______\n",
      "Iteration t=8\n",
      "all:  cs/acc_i=74.38 cs/acc_c=73.99 os/recall_knw=57.95 os/recall_unk=79.31 total/acc_i=61.99 total/acc_c=54.88 total/h_score=64.01\n",
      "selected:  cs/acc_i=74.37 cs/acc_c=73.98 os/recall_knw=57.93 os/recall_unk=79.37 total/acc_i=61.99 total/acc_c=54.88 total/h_score=64.02\n",
      "Loss: 1.5352280474997855\n",
      "Loss: 0.24878409292448211\n",
      "Loss: 0.14965912936305678\n",
      "Loss: 0.11308165204686088\n",
      "Loss: 0.0898252192179899\n",
      "Loss: 0.07823379356917497\n",
      "Loss: 0.06414409012130991\n",
      "Loss: 0.06552510723232519\n",
      "Loss: 0.05540717811940389\n",
      "Loss: 0.04714778914065981\n",
      "______\n",
      "Iteration t=9\n",
      "all:  cs/acc_i=75.28 cs/acc_c=74.80 os/recall_knw=57.95 os/recall_unk=79.31 total/acc_i=61.99 total/acc_c=54.88 total/h_score=64.01\n",
      "selected:  cs/acc_i=75.28 cs/acc_c=74.80 os/recall_knw=57.95 os/recall_unk=79.31 total/acc_i=61.99 total/acc_c=54.88 total/h_score=64.01\n",
      "tensor(0)\n",
      "all:  cs/acc_i=75.28 cs/acc_c=74.80 os/recall_knw=57.95 os/recall_unk=79.31 total/acc_i=61.99 total/acc_c=54.88 total/h_score=64.01\n",
      "real -> painting lr= 0.001 seed= 4\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19]\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20]\n",
      "Loss: 1.723645734058699\n",
      "Loss: 0.29955781054745917\n",
      "Loss: 0.1855250736129533\n",
      "Loss: 0.13755678196237017\n",
      "Loss: 0.12198647466814595\n",
      "Loss: 0.09785405209833019\n",
      "Loss: 0.0883078441065751\n",
      "Loss: 0.07438910909601969\n",
      "Loss: 0.06180447731855838\n",
      "Loss: 0.05816417566120289\n",
      "tensor(True) tensor(True)\n",
      "______\n",
      "Iteration t=1\n",
      "all:  cs/acc_i=73.10 cs/acc_c=72.62 os/recall_knw=83.99 os/recall_unk=43.76 total/acc_i=60.00 total/acc_c=66.35 total/h_score=53.09\n",
      "selected:  cs/acc_i=64.89 cs/acc_c=64.67 os/recall_knw=50.39 os/recall_unk=97.67 total/acc_i=68.06 total/acc_c=51.63 total/h_score=65.55\n",
      "Loss: 1.6467666859092889\n",
      "Loss: 0.2764651701082847\n",
      "Loss: 0.1725821978315437\n",
      "Loss: 0.12628755292232416\n",
      "Loss: 0.11298918417237837\n",
      "Loss: 0.0915835596552473\n",
      "Loss: 0.07566435416114796\n",
      "Loss: 0.06756425995173995\n",
      "Loss: 0.05868439120097669\n",
      "Loss: 0.05535209001801862\n",
      "______\n",
      "Iteration t=2\n",
      "all:  cs/acc_i=73.03 cs/acc_c=72.59 os/recall_knw=61.09 os/recall_unk=77.97 total/acc_i=63.22 total/acc_c=56.92 total/h_score=65.09\n",
      "selected:  cs/acc_i=64.49 cs/acc_c=64.74 os/recall_knw=43.95 os/recall_unk=93.46 total/acc_i=59.64 total/acc_c=43.54 total/h_score=57.04\n",
      "Loss: 1.5949478769127061\n",
      "Loss: 0.2661527519497801\n",
      "Loss: 0.15330211294486243\n",
      "Loss: 0.1182550410137457\n",
      "Loss: 0.0996189245926764\n",
      "Loss: 0.08907499612747308\n",
      "Loss: 0.06932598314494552\n",
      "Loss: 0.06396689137361725\n",
      "Loss: 0.05925737425260355\n",
      "Loss: 0.04808940969181576\n",
      "______\n",
      "Iteration t=3\n",
      "all:  cs/acc_i=72.45 cs/acc_c=71.89 os/recall_knw=58.66 os/recall_unk=80.28 total/acc_i=62.69 total/acc_c=55.30 total/h_score=64.61\n",
      "selected:  cs/acc_i=66.99 cs/acc_c=67.09 os/recall_knw=48.94 os/recall_unk=87.12 total/acc_i=59.54 total/acc_c=47.53 total/h_score=59.82\n",
      "Loss: 1.5821678891480817\n",
      "Loss: 0.26496006548404694\n",
      "Loss: 0.15442284371205034\n",
      "Loss: 0.11805745739585315\n",
      "Loss: 0.10283411432991595\n",
      "Loss: 0.08137353110071431\n",
      "Loss: 0.07369818787576042\n",
      "Loss: 0.06176869012946077\n",
      "Loss: 0.053868071952877176\n",
      "Loss: 0.0466779120216024\n",
      "______\n",
      "Iteration t=4\n",
      "all:  cs/acc_i=72.63 cs/acc_c=72.05 os/recall_knw=58.09 os/recall_unk=81.11 total/acc_i=62.61 total/acc_c=54.89 total/h_score=64.53\n",
      "selected:  cs/acc_i=69.09 cs/acc_c=69.00 os/recall_knw=52.04 os/recall_unk=83.47 total/acc_i=59.99 total/acc_c=50.12 total/h_score=61.32\n",
      "Loss: 1.5718985713560487\n",
      "Loss: 0.2545758546668225\n",
      "Loss: 0.15347747650392896\n",
      "Loss: 0.11835337106226917\n",
      "Loss: 0.09218392465211576\n",
      "Loss: 0.08036144400879158\n",
      "Loss: 0.06792662491860628\n",
      "Loss: 0.06500268902098916\n",
      "Loss: 0.05357304998860804\n",
      "Loss: 0.04267070767490516\n",
      "______\n",
      "Iteration t=5\n",
      "all:  cs/acc_i=73.20 cs/acc_c=72.52 os/recall_knw=57.98 os/recall_unk=81.11 total/acc_i=62.54 total/acc_c=54.79 total/h_score=64.45\n",
      "selected:  cs/acc_i=71.55 cs/acc_c=71.21 os/recall_knw=55.10 os/recall_unk=81.84 total/acc_i=61.15 total/acc_c=52.71 total/h_score=63.03\n",
      "Loss: 1.5560186230219328\n",
      "Loss: 0.2620096275439629\n",
      "Loss: 0.1545403202801206\n",
      "Loss: 0.12135845817277556\n",
      "Loss: 0.09586384028431724\n",
      "Loss: 0.08112043537874962\n",
      "Loss: 0.0665388193664622\n",
      "Loss: 0.06133852771273558\n",
      "Loss: 0.056020982682469536\n",
      "Loss: 0.04572449871121425\n",
      "______\n",
      "Iteration t=6\n",
      "all:  cs/acc_i=73.92 cs/acc_c=73.46 os/recall_knw=57.98 os/recall_unk=81.18 total/acc_i=62.57 total/acc_c=54.79 total/h_score=64.47\n",
      "selected:  cs/acc_i=73.33 cs/acc_c=72.96 os/recall_knw=56.80 os/recall_unk=81.42 total/acc_i=62.02 total/acc_c=54.04 total/h_score=63.97\n",
      "Loss: 1.5558896426933664\n",
      "Loss: 0.25015602380605745\n",
      "Loss: 0.15442140745024427\n",
      "Loss: 0.11380634804532866\n",
      "Loss: 0.09536745952954896\n",
      "Loss: 0.07976791935741942\n",
      "Loss: 0.06808163542351216\n",
      "Loss: 0.060868912517303746\n",
      "Loss: 0.05154244425612672\n",
      "Loss: 0.044520144277868906\n",
      "______\n",
      "Iteration t=7\n",
      "all:  cs/acc_i=74.10 cs/acc_c=73.63 os/recall_knw=57.95 os/recall_unk=81.18 total/acc_i=62.54 total/acc_c=54.77 total/h_score=64.46\n",
      "selected:  cs/acc_i=74.03 cs/acc_c=73.55 os/recall_knw=57.78 os/recall_unk=81.36 total/acc_i=62.51 total/acc_c=54.66 total/h_score=64.43\n",
      "Loss: 1.547188291139396\n",
      "Loss: 0.2420588227589602\n",
      "Loss: 0.15621097186494487\n",
      "Loss: 0.11125658787938396\n",
      "Loss: 0.09429339961802491\n",
      "Loss: 0.07505132235727982\n",
      "Loss: 0.06939154952956328\n",
      "Loss: 0.05471773547824563\n",
      "Loss: 0.0507195156034799\n",
      "Loss: 0.04364692912245205\n",
      "______\n",
      "Iteration t=8\n",
      "all:  cs/acc_i=73.99 cs/acc_c=73.42 os/recall_knw=57.95 os/recall_unk=81.18 total/acc_i=62.54 total/acc_c=54.77 total/h_score=64.46\n",
      "selected:  cs/acc_i=73.98 cs/acc_c=73.41 os/recall_knw=57.93 os/recall_unk=81.24 total/acc_i=62.55 total/acc_c=54.76 total/h_score=64.47\n",
      "Loss: 1.5422102544758771\n",
      "Loss: 0.24107429086155183\n",
      "Loss: 0.1496607494011924\n",
      "Loss: 0.11639074567151633\n",
      "Loss: 0.0958291914439886\n",
      "Loss: 0.08069494252495871\n",
      "Loss: 0.06690149640010015\n",
      "Loss: 0.06221784503400527\n",
      "Loss: 0.05195888354304574\n",
      "Loss: 0.04533343701371671\n",
      "______\n",
      "Iteration t=9\n",
      "all:  cs/acc_i=74.06 cs/acc_c=73.56 os/recall_knw=57.95 os/recall_unk=81.18 total/acc_i=62.54 total/acc_c=54.77 total/h_score=64.46\n",
      "selected:  cs/acc_i=74.06 cs/acc_c=73.56 os/recall_knw=57.95 os/recall_unk=81.18 total/acc_i=62.54 total/acc_c=54.77 total/h_score=64.46\n",
      "tensor(0)\n",
      "all:  cs/acc_i=74.06 cs/acc_c=73.56 os/recall_knw=57.95 os/recall_unk=81.18 total/acc_i=62.54 total/acc_c=54.77 total/h_score=64.46\n",
      "real -> painting lr= 0.001 seed= 0\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19]\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20]\n",
      "Loss: 1.6994058215733125\n",
      "Loss: 0.3086929098250782\n",
      "Loss: 0.17924185048106014\n",
      "Loss: 0.13596228680235015\n",
      "Loss: 0.11414009953438757\n",
      "Loss: 0.0969470894065988\n",
      "Loss: 0.08805759227160856\n",
      "Loss: 0.07412655216752524\n",
      "Loss: 0.06660311277716202\n",
      "Loss: 0.06496522582616729\n",
      "tensor(True) tensor(True)\n",
      "______\n",
      "Iteration t=1\n",
      "all:  cs/acc_i=73.03 cs/acc_c=72.63 os/recall_knw=84.67 os/recall_unk=45.18 total/acc_i=60.80 total/acc_c=66.85 total/h_score=54.27\n",
      "selected:  cs/acc_i=63.68 cs/acc_c=64.22 os/recall_knw=51.31 os/recall_unk=97.74 total/acc_i=68.87 total/acc_c=51.78 total/h_score=65.70\n",
      "Loss: 1.6574873067667149\n",
      "Loss: 0.27983349781094885\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.16416143615690112\n",
      "Loss: 0.13449140215875363\n",
      "Loss: 0.10973104503737088\n",
      "Loss: 0.0880768864838395\n",
      "Loss: 0.08079507704852777\n",
      "Loss: 0.07354782370741884\n",
      "Loss: 0.0621041095532774\n",
      "Loss: 0.04881546187051715\n",
      "______\n",
      "Iteration t=2\n",
      "all:  cs/acc_i=73.45 cs/acc_c=72.89 os/recall_knw=61.91 os/recall_unk=78.86 total/acc_i=64.14 total/acc_c=57.86 total/h_score=66.05\n",
      "selected:  cs/acc_i=64.70 cs/acc_c=64.80 os/recall_knw=44.33 os/recall_unk=93.12 total/acc_i=60.25 total/acc_c=44.36 total/h_score=57.81\n",
      "Loss: 1.6134726160589385\n",
      "Loss: 0.2559034080518519\n",
      "Loss: 0.15646199003848082\n",
      "Loss: 0.12404411822173964\n",
      "Loss: 0.10490077206152765\n",
      "Loss: 0.08700052448000539\n",
      "Loss: 0.07427631257074502\n",
      "Loss: 0.06605947295970777\n",
      "Loss: 0.05579358563717345\n",
      "Loss: 0.0524573301533511\n",
      "______\n",
      "Iteration t=3\n",
      "all:  cs/acc_i=72.81 cs/acc_c=72.22 os/recall_knw=58.24 os/recall_unk=80.88 total/acc_i=62.93 total/acc_c=55.43 total/h_score=64.88\n",
      "selected:  cs/acc_i=67.18 cs/acc_c=67.04 os/recall_knw=48.30 os/recall_unk=87.27 total/acc_i=59.54 total/acc_c=47.34 total/h_score=59.68\n",
      "Loss: 1.6003762059552329\n",
      "Loss: 0.2594504152025495\n",
      "Loss: 0.16307317659791026\n",
      "Loss: 0.11708270223545177\n",
      "Loss: 0.10044062414871795\n",
      "Loss: 0.07985092540936811\n",
      "Loss: 0.07392782805088376\n",
      "Loss: 0.06344118568247982\n",
      "Loss: 0.054187698891120295\n",
      "Loss: 0.05071316221795444\n",
      "______\n",
      "Iteration t=4\n",
      "all:  cs/acc_i=73.42 cs/acc_c=72.81 os/recall_knw=57.95 os/recall_unk=81.40 total/acc_i=62.90 total/acc_c=55.16 total/h_score=64.82\n",
      "selected:  cs/acc_i=70.21 cs/acc_c=70.17 os/recall_knw=52.37 os/recall_unk=84.10 total/acc_i=60.61 total/acc_c=50.93 total/h_score=62.14\n",
      "Loss: 1.5648118118084342\n",
      "Loss: 0.248813123676364\n",
      "Loss: 0.15007231720624356\n",
      "Loss: 0.11548026581424907\n",
      "Loss: 0.09824628990622206\n",
      "Loss: 0.0807184385351691\n",
      "Loss: 0.0729428451318377\n",
      "Loss: 0.05821128712587225\n",
      "Loss: 0.05303542907076612\n",
      "Loss: 0.04590177027555443\n",
      "______\n",
      "Iteration t=5\n",
      "all:  cs/acc_i=73.45 cs/acc_c=73.02 os/recall_knw=57.66 os/recall_unk=81.63 total/acc_i=62.78 total/acc_c=54.90 total/h_score=64.69\n",
      "selected:  cs/acc_i=71.59 cs/acc_c=71.55 os/recall_knw=54.51 os/recall_unk=82.12 total/acc_i=61.15 total/acc_c=52.66 total/h_score=63.06\n",
      "Loss: 1.5452198526172927\n",
      "Loss: 0.2522948434468636\n",
      "Loss: 0.15053109734347372\n",
      "Loss: 0.11895717255329873\n",
      "Loss: 0.09444288380659563\n",
      "Loss: 0.08159551327822334\n",
      "Loss: 0.06558105139031022\n",
      "Loss: 0.05619579190696197\n",
      "Loss: 0.05053121165292897\n",
      "Loss: 0.04670876449201071\n",
      "______\n",
      "Iteration t=6\n",
      "all:  cs/acc_i=73.67 cs/acc_c=73.28 os/recall_knw=57.56 os/recall_unk=81.70 total/acc_i=62.74 total/acc_c=54.80 total/h_score=64.62\n",
      "selected:  cs/acc_i=73.01 cs/acc_c=72.69 os/recall_knw=56.37 os/recall_unk=81.89 total/acc_i=62.13 total/acc_c=53.98 total/h_score=64.04\n",
      "Loss: 1.5413387451087421\n",
      "Loss: 0.25215178582949277\n",
      "Loss: 0.15826830011094623\n",
      "Loss: 0.12044871082321337\n",
      "Loss: 0.0969336328759018\n",
      "Loss: 0.07806617543304324\n",
      "Loss: 0.06938529696838286\n",
      "Loss: 0.05991827314770311\n",
      "Loss: 0.051645592390496174\n",
      "Loss: 0.04458039911966314\n",
      "______\n",
      "Iteration t=7\n",
      "all:  cs/acc_i=74.31 cs/acc_c=73.96 os/recall_knw=57.45 os/recall_unk=81.70 total/acc_i=62.66 total/acc_c=54.69 total/h_score=64.54\n",
      "selected:  cs/acc_i=74.12 cs/acc_c=73.83 os/recall_knw=57.07 os/recall_unk=81.82 total/acc_i=62.49 total/acc_c=54.51 total/h_score=64.43\n",
      "Loss: 1.5414961790261061\n",
      "Loss: 0.2472884429456747\n",
      "Loss: 0.15602827390007998\n",
      "Loss: 0.11628543279315952\n",
      "Loss: 0.09217882010852918\n",
      "Loss: 0.07935354991755246\n",
      "Loss: 0.06933045287935427\n",
      "Loss: 0.05956435280107974\n",
      "Loss: 0.05178733477014643\n",
      "Loss: 0.04566766947075097\n",
      "______\n",
      "Iteration t=8\n",
      "all:  cs/acc_i=74.67 cs/acc_c=74.25 os/recall_knw=57.45 os/recall_unk=81.70 total/acc_i=62.66 total/acc_c=54.69 total/h_score=64.54\n",
      "selected:  cs/acc_i=74.67 cs/acc_c=74.25 os/recall_knw=57.45 os/recall_unk=81.70 total/acc_i=62.66 total/acc_c=54.69 total/h_score=64.54\n",
      "Loss: 1.5565279285274547\n",
      "Loss: 0.25404394084845133\n",
      "Loss: 0.15855619803495039\n",
      "Loss: 0.1107180880327131\n",
      "Loss: 0.09465437813038587\n",
      "Loss: 0.07552503528916416\n",
      "Loss: 0.06556021118458351\n",
      "Loss: 0.06235596175535221\n",
      "Loss: 0.04970760416267263\n",
      "Loss: 0.04751274802186968\n",
      "______\n",
      "Iteration t=9\n",
      "all:  cs/acc_i=74.46 cs/acc_c=73.99 os/recall_knw=57.45 os/recall_unk=81.70 total/acc_i=62.66 total/acc_c=54.69 total/h_score=64.54\n",
      "selected:  cs/acc_i=74.46 cs/acc_c=73.99 os/recall_knw=57.45 os/recall_unk=81.70 total/acc_i=62.66 total/acc_c=54.69 total/h_score=64.54\n",
      "tensor(0)\n",
      "all:  cs/acc_i=74.46 cs/acc_c=73.99 os/recall_knw=57.45 os/recall_unk=81.70 total/acc_i=62.66 total/acc_c=54.69 total/h_score=64.54\n",
      "real -> painting lr= 0.001 seed= 1\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19]\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20]\n",
      "Loss: 1.712220582164752\n",
      "Loss: 0.29890927746652407\n",
      "Loss: 0.18049257655906523\n",
      "Loss: 0.13740488701167597\n",
      "Loss: 0.11753162196043795\n",
      "Loss: 0.10276483049933646\n",
      "Loss: 0.08452420009725346\n",
      "Loss: 0.07558651126013811\n",
      "Loss: 0.06603537056927489\n",
      "Loss: 0.06180236269076058\n",
      "tensor(True) tensor(True)\n",
      "______\n",
      "Iteration t=1\n",
      "all:  cs/acc_i=72.88 cs/acc_c=72.59 os/recall_knw=83.49 os/recall_unk=42.72 total/acc_i=59.64 total/acc_c=66.24 total/h_score=52.30\n",
      "selected:  cs/acc_i=62.88 cs/acc_c=63.36 os/recall_knw=49.56 os/recall_unk=97.44 total/acc_i=66.80 total/acc_c=49.93 total/h_score=63.92\n",
      "Loss: 1.6354793998544201\n",
      "Loss: 0.27447944267030144\n",
      "Loss: 0.16316708752119835\n",
      "Loss: 0.12827335291205008\n",
      "Loss: 0.11301760647468771\n",
      "Loss: 0.09492404921197452\n",
      "Loss: 0.07992049212641786\n",
      "Loss: 0.06913955546515577\n",
      "Loss: 0.06073929970809744\n",
      "Loss: 0.05605430769922635\n",
      "______\n",
      "Iteration t=2\n",
      "all:  cs/acc_i=72.78 cs/acc_c=72.34 os/recall_knw=60.81 os/recall_unk=79.46 total/acc_i=63.56 total/acc_c=56.91 total/h_score=65.55\n",
      "selected:  cs/acc_i=63.75 cs/acc_c=64.01 os/recall_knw=43.51 os/recall_unk=92.76 total/acc_i=59.27 total/acc_c=43.29 total/h_score=56.69\n",
      "Loss: 1.6065445403842364\n",
      "Loss: 0.264589940646992\n",
      "Loss: 0.15780999779920368\n",
      "Loss: 0.12711204690310884\n",
      "Loss: 0.10140649355838403\n",
      "Loss: 0.08669228454887429\n",
      "Loss: 0.0717308299300973\n",
      "Loss: 0.06520722181371906\n",
      "Loss: 0.05653401234337841\n",
      "Loss: 0.04879486503846505\n",
      "______\n",
      "Iteration t=3\n",
      "all:  cs/acc_i=71.74 cs/acc_c=71.10 os/recall_knw=56.63 os/recall_unk=82.30 total/acc_i=62.25 total/acc_c=53.88 total/h_score=64.07\n",
      "selected:  cs/acc_i=66.00 cs/acc_c=65.90 os/recall_knw=46.87 os/recall_unk=88.51 total/acc_i=58.81 total/acc_c=45.81 total/h_score=58.49\n",
      "Loss: 1.5946741105833846\n",
      "Loss: 0.25891855616325293\n",
      "Loss: 0.15474800073827236\n",
      "Loss: 0.11880138991427285\n",
      "Loss: 0.098204789870021\n",
      "Loss: 0.08138801564694646\n",
      "Loss: 0.07054672595433742\n",
      "Loss: 0.06480838464743813\n",
      "Loss: 0.056913294538556675\n",
      "Loss: 0.045885452326189693\n",
      "______\n",
      "Iteration t=4\n",
      "all:  cs/acc_i=73.13 cs/acc_c=72.60 os/recall_knw=56.09 os/recall_unk=82.60 total/acc_i=62.03 total/acc_c=53.42 total/h_score=63.79\n",
      "selected:  cs/acc_i=69.94 cs/acc_c=69.99 os/recall_knw=50.40 os/recall_unk=84.30 total/acc_i=59.45 total/acc_c=49.01 total/h_score=60.56\n",
      "Loss: 1.5664435409280766\n",
      "Loss: 0.25858030583010333\n",
      "Loss: 0.1571515999442222\n",
      "Loss: 0.11936625780887297\n",
      "Loss: 0.09050914172750979\n",
      "Loss: 0.0855743654779255\n",
      "Loss: 0.06837565700343552\n",
      "Loss: 0.06172290348372206\n",
      "Loss: 0.05194393747730092\n",
      "Loss: 0.04813029298282304\n",
      "______\n",
      "Iteration t=5\n",
      "all:  cs/acc_i=73.31 cs/acc_c=72.83 os/recall_knw=55.59 os/recall_unk=82.82 total/acc_i=61.79 total/acc_c=52.99 total/h_score=63.51\n",
      "selected:  cs/acc_i=71.73 cs/acc_c=71.62 os/recall_knw=52.77 os/recall_unk=83.26 total/acc_i=60.37 total/acc_c=50.97 total/h_score=61.98\n",
      "Loss: 1.5605969977180714\n",
      "Loss: 0.2541212924650336\n",
      "Loss: 0.1525307903092076\n",
      "Loss: 0.11532438545903176\n",
      "Loss: 0.0911992288238454\n",
      "Loss: 0.08089184426441995\n",
      "Loss: 0.06977130001710104\n",
      "Loss: 0.06219912025886601\n",
      "Loss: 0.05491206688945726\n",
      "Loss: 0.04683245401481203\n",
      "______\n",
      "Iteration t=6\n",
      "all:  cs/acc_i=72.99 cs/acc_c=72.43 os/recall_knw=55.59 os/recall_unk=82.82 total/acc_i=61.79 total/acc_c=52.99 total/h_score=63.51\n",
      "selected:  cs/acc_i=72.36 cs/acc_c=71.93 os/recall_knw=54.44 os/recall_unk=82.95 total/acc_i=61.21 total/acc_c=52.18 total/h_score=62.89\n",
      "Loss: 1.5392936633466041\n",
      "Loss: 0.25487368141543376\n",
      "Loss: 0.15305179047257933\n",
      "Loss: 0.11776424177399236\n",
      "Loss: 0.09804403573427707\n",
      "Loss: 0.07865349682277605\n",
      "Loss: 0.06695930860451843\n",
      "Loss: 0.06008199973236004\n",
      "Loss: 0.04889369648370943\n",
      "Loss: 0.04374521315250903\n",
      "______\n",
      "Iteration t=7\n",
      "all:  cs/acc_i=73.42 cs/acc_c=72.91 os/recall_knw=55.59 os/recall_unk=82.82 total/acc_i=61.79 total/acc_c=52.99 total/h_score=63.51\n",
      "selected:  cs/acc_i=73.34 cs/acc_c=72.83 os/recall_knw=55.46 os/recall_unk=82.82 total/acc_i=61.72 total/acc_c=52.89 total/h_score=63.42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 1.538448695428365\n",
      "Loss: 0.24839202299389268\n",
      "Loss: 0.14821444450793864\n",
      "Loss: 0.11490631397884613\n",
      "Loss: 0.08847001441361063\n",
      "Loss: 0.07747986495662329\n",
      "Loss: 0.06844175417021892\n",
      "Loss: 0.06321235928857034\n",
      "Loss: 0.05235299279682379\n",
      "Loss: 0.04349388967189501\n",
      "______\n",
      "Iteration t=8\n",
      "all:  cs/acc_i=73.88 cs/acc_c=73.35 os/recall_knw=55.59 os/recall_unk=82.82 total/acc_i=61.79 total/acc_c=52.99 total/h_score=63.51\n",
      "selected:  cs/acc_i=73.88 cs/acc_c=73.35 os/recall_knw=55.59 os/recall_unk=82.82 total/acc_i=61.79 total/acc_c=52.99 total/h_score=63.51\n",
      "Loss: 1.539462870164528\n",
      "Loss: 0.2510949622342307\n",
      "Loss: 0.15229799204102493\n",
      "Loss: 0.11718240390945357\n",
      "Loss: 0.09130115865930225\n",
      "Loss: 0.07954031450049673\n",
      "Loss: 0.06644184112026069\n",
      "Loss: 0.064768305425824\n",
      "Loss: 0.04870154070464909\n",
      "Loss: 0.04307382063856424\n",
      "______\n",
      "Iteration t=9\n",
      "all:  cs/acc_i=73.45 cs/acc_c=72.91 os/recall_knw=55.59 os/recall_unk=82.82 total/acc_i=61.79 total/acc_c=52.99 total/h_score=63.51\n",
      "selected:  cs/acc_i=73.45 cs/acc_c=72.91 os/recall_knw=55.59 os/recall_unk=82.82 total/acc_i=61.79 total/acc_c=52.99 total/h_score=63.51\n",
      "tensor(0)\n",
      "all:  cs/acc_i=73.45 cs/acc_c=72.91 os/recall_knw=55.59 os/recall_unk=82.82 total/acc_i=61.79 total/acc_c=52.99 total/h_score=63.51\n",
      "real -> painting lr= 0.001 seed= 2\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19]\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20]\n",
      "Loss: 1.7184803083395268\n",
      "Loss: 0.2909261249604716\n",
      "Loss: 0.17660973151588746\n",
      "Loss: 0.14233156479296194\n",
      "Loss: 0.1156158871721129\n",
      "Loss: 0.10173038090504347\n",
      "Loss: 0.08458197306110928\n",
      "Loss: 0.07563056830628222\n",
      "Loss: 0.07125194884770793\n",
      "Loss: 0.0576846599167099\n",
      "tensor(True) tensor(True)\n",
      "______\n",
      "Iteration t=1\n",
      "all:  cs/acc_i=72.92 cs/acc_c=72.40 os/recall_knw=83.82 os/recall_unk=43.39 total/acc_i=59.74 total/acc_c=65.88 total/h_score=52.67\n",
      "selected:  cs/acc_i=63.87 cs/acc_c=64.50 os/recall_knw=49.94 os/recall_unk=97.48 total/acc_i=67.22 total/acc_c=50.24 total/h_score=64.22\n",
      "Loss: 1.6398811117271703\n",
      "Loss: 0.27044672162437733\n",
      "Loss: 0.16841388881160804\n",
      "Loss: 0.13134330255122273\n",
      "Loss: 0.10530810170104167\n",
      "Loss: 0.09575761073808889\n",
      "Loss: 0.07794025365228942\n",
      "Loss: 0.06651655034350654\n",
      "Loss: 0.05848493154497783\n",
      "Loss: 0.05459056358693019\n",
      "______\n",
      "Iteration t=2\n",
      "all:  cs/acc_i=72.85 cs/acc_c=72.48 os/recall_knw=61.27 os/recall_unk=77.07 total/acc_i=62.86 total/acc_c=56.95 total/h_score=64.83\n",
      "selected:  cs/acc_i=64.39 cs/acc_c=64.65 os/recall_knw=43.89 os/recall_unk=92.64 total/acc_i=59.29 total/acc_c=43.61 total/h_score=57.00\n",
      "Loss: 1.6103013419053134\n",
      "Loss: 0.2611055227325243\n",
      "Loss: 0.15991107013405245\n",
      "Loss: 0.12499555750914357\n",
      "Loss: 0.10129354861291016\n",
      "Loss: 0.08187533939421615\n",
      "Loss: 0.07324141626355841\n",
      "Loss: 0.06344793945249608\n",
      "Loss: 0.059944093860137986\n",
      "Loss: 0.053527770700919276\n",
      "______\n",
      "Iteration t=3\n",
      "all:  cs/acc_i=72.81 cs/acc_c=72.46 os/recall_knw=58.24 os/recall_unk=79.99 total/acc_i=62.47 total/acc_c=55.15 total/h_score=64.41\n",
      "selected:  cs/acc_i=67.27 cs/acc_c=67.71 os/recall_knw=48.71 os/recall_unk=87.07 total/acc_i=59.28 total/acc_c=47.41 total/h_score=59.70\n",
      "Loss: 1.5869421486416433\n",
      "Loss: 0.25495869473174765\n",
      "Loss: 0.14932944013225047\n",
      "Loss: 0.11261541919087582\n",
      "Loss: 0.0971046814222706\n",
      "Loss: 0.08257328489784714\n",
      "Loss: 0.07234150398140535\n",
      "Loss: 0.06502446372186675\n",
      "Loss: 0.05578620862374958\n",
      "Loss: 0.052553720203124814\n",
      "______\n",
      "Iteration t=4\n",
      "all:  cs/acc_i=73.10 cs/acc_c=72.63 os/recall_knw=57.70 os/recall_unk=80.66 total/acc_i=62.35 total/acc_c=54.65 total/h_score=64.22\n",
      "selected:  cs/acc_i=69.87 cs/acc_c=69.99 os/recall_knw=52.18 os/recall_unk=83.53 total/acc_i=60.07 total/acc_c=50.38 total/h_score=61.54\n",
      "Loss: 1.5737907034891279\n",
      "Loss: 0.25376103337666844\n",
      "Loss: 0.14749066395341684\n",
      "Loss: 0.11447812188364691\n",
      "Loss: 0.08911467719869948\n",
      "Loss: 0.08554574374796292\n",
      "Loss: 0.0680364369240449\n",
      "Loss: 0.06161851782804386\n",
      "Loss: 0.05523851636131216\n",
      "Loss: 0.049120772523316425\n",
      "______\n",
      "Iteration t=5\n",
      "all:  cs/acc_i=73.10 cs/acc_c=72.56 os/recall_knw=57.66 os/recall_unk=80.66 total/acc_i=62.32 total/acc_c=54.60 total/h_score=64.19\n",
      "selected:  cs/acc_i=71.34 cs/acc_c=71.27 os/recall_knw=54.65 os/recall_unk=81.02 total/acc_i=60.75 total/acc_c=52.51 total/h_score=62.66\n",
      "Loss: 1.5581414844062957\n",
      "Loss: 0.24786213383201386\n",
      "Loss: 0.1496916635391804\n",
      "Loss: 0.11480090099356167\n",
      "Loss: 0.09808425643547837\n",
      "Loss: 0.08418101607310166\n",
      "Loss: 0.06791938819850867\n",
      "Loss: 0.06177170190878294\n",
      "Loss: 0.051957862613502645\n",
      "Loss: 0.04608050030099668\n",
      "______\n",
      "Iteration t=6\n",
      "all:  cs/acc_i=74.56 cs/acc_c=74.15 os/recall_knw=57.66 os/recall_unk=80.66 total/acc_i=62.32 total/acc_c=54.60 total/h_score=64.19\n",
      "selected:  cs/acc_i=74.00 cs/acc_c=73.68 os/recall_knw=56.67 os/recall_unk=80.90 total/acc_i=61.82 total/acc_c=53.90 total/h_score=63.71\n",
      "Loss: 1.5627134311944246\n",
      "Loss: 0.2565643016005988\n",
      "Loss: 0.15548964124172926\n",
      "Loss: 0.11313217032052901\n",
      "Loss: 0.08908924849137016\n",
      "Loss: 0.08220115071795274\n",
      "Loss: 0.07295836473855635\n",
      "Loss: 0.05850322295800257\n",
      "Loss: 0.051802857366451266\n",
      "Loss: 0.042879522152994155\n",
      "______\n",
      "Iteration t=7\n",
      "all:  cs/acc_i=73.63 cs/acc_c=73.04 os/recall_knw=57.66 os/recall_unk=80.66 total/acc_i=62.32 total/acc_c=54.60 total/h_score=64.19\n",
      "selected:  cs/acc_i=73.46 cs/acc_c=72.88 os/recall_knw=57.33 os/recall_unk=80.78 total/acc_i=62.18 total/acc_c=54.39 total/h_score=64.06\n",
      "Loss: 1.5465489723656558\n",
      "Loss: 0.246184589114131\n",
      "Loss: 0.15286273634449898\n",
      "Loss: 0.11120605550019884\n",
      "Loss: 0.09192284297066813\n",
      "Loss: 0.08169193375290329\n",
      "Loss: 0.06537669199849491\n",
      "Loss: 0.06481142977800292\n",
      "Loss: 0.05226548577262578\n",
      "Loss: 0.0494003194853724\n",
      "______\n",
      "Iteration t=8\n",
      "all:  cs/acc_i=73.74 cs/acc_c=73.22 os/recall_knw=57.66 os/recall_unk=80.66 total/acc_i=62.32 total/acc_c=54.60 total/h_score=64.19\n",
      "selected:  cs/acc_i=73.74 cs/acc_c=73.22 os/recall_knw=57.66 os/recall_unk=80.66 total/acc_i=62.32 total/acc_c=54.60 total/h_score=64.19\n",
      "Loss: 1.5456313668070614\n",
      "Loss: 0.24093874217690647\n",
      "Loss: 0.1522875173973876\n",
      "Loss: 0.11262386281143974\n",
      "Loss: 0.08749517180982071\n",
      "Loss: 0.07497293024223198\n",
      "Loss: 0.06409251843201551\n",
      "Loss: 0.059717251244630364\n",
      "Loss: 0.05196110714428328\n",
      "Loss: 0.04446901289834263\n",
      "______\n",
      "Iteration t=9\n",
      "all:  cs/acc_i=73.88 cs/acc_c=73.42 os/recall_knw=57.66 os/recall_unk=80.66 total/acc_i=62.32 total/acc_c=54.60 total/h_score=64.19\n",
      "selected:  cs/acc_i=73.88 cs/acc_c=73.42 os/recall_knw=57.66 os/recall_unk=80.66 total/acc_i=62.32 total/acc_c=54.60 total/h_score=64.19\n",
      "tensor(0)\n",
      "all:  cs/acc_i=73.88 cs/acc_c=73.42 os/recall_knw=57.66 os/recall_unk=80.66 total/acc_i=62.32 total/acc_c=54.60 total/h_score=64.19\n",
      "real -> painting lr= 0.001 seed= 3\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19]\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20]\n",
      "Loss: 1.7087104736417054\n",
      "Loss: 0.30065601333448744\n",
      "Loss: 0.18377658204921188\n",
      "Loss: 0.14384806763464614\n",
      "Loss: 0.1138147102291561\n",
      "Loss: 0.09323412957047247\n",
      "Loss: 0.08485268282635179\n",
      "Loss: 0.07563731206694792\n",
      "Loss: 0.06548683376910938\n",
      "Loss: 0.06110767207117422\n",
      "tensor(True) tensor(True)\n",
      "______\n",
      "Iteration t=1\n",
      "all:  cs/acc_i=72.56 cs/acc_c=72.14 os/recall_knw=83.53 os/recall_unk=42.79 total/acc_i=59.40 total/acc_c=65.76 total/h_score=52.20\n",
      "selected:  cs/acc_i=63.13 cs/acc_c=64.04 os/recall_knw=49.56 os/recall_unk=97.61 total/acc_i=66.89 total/acc_c=50.46 total/h_score=64.45\n",
      "Loss: 1.6327981385716632\n",
      "Loss: 0.2731669583569275\n",
      "Loss: 0.16813915563415896\n",
      "Loss: 0.13423596475090535\n",
      "Loss: 0.10898874158131107\n",
      "Loss: 0.09335348605852506\n",
      "Loss: 0.08175520956704815\n",
      "Loss: 0.07007357362726349\n",
      "Loss: 0.06454973898119538\n",
      "Loss: 0.051102448221970284\n",
      "______\n",
      "Iteration t=2\n",
      "all:  cs/acc_i=72.92 cs/acc_c=72.52 os/recall_knw=60.52 os/recall_unk=76.70 total/acc_i=62.40 total/acc_c=56.56 total/h_score=64.44\n",
      "selected:  cs/acc_i=64.97 cs/acc_c=64.97 os/recall_knw=43.33 os/recall_unk=92.61 total/acc_i=59.10 total/acc_c=43.50 total/h_score=56.88\n",
      "Loss: 1.6163005238070207\n",
      "Loss: 0.2584652926115429\n",
      "Loss: 0.16431035943438901\n",
      "Loss: 0.12237291633534958\n",
      "Loss: 0.10083370574421305\n",
      "Loss: 0.08432249601464718\n",
      "Loss: 0.08468241804443738\n",
      "Loss: 0.06534123894320253\n",
      "Loss: 0.05515608198612052\n",
      "Loss: 0.050001142599948624\n",
      "______\n",
      "Iteration t=3\n",
      "all:  cs/acc_i=72.70 cs/acc_c=72.10 os/recall_knw=57.63 os/recall_unk=79.84 total/acc_i=62.25 total/acc_c=55.00 total/h_score=64.25\n",
      "selected:  cs/acc_i=67.14 cs/acc_c=67.00 os/recall_knw=47.82 os/recall_unk=85.38 total/acc_i=58.64 total/acc_c=46.84 total/h_score=58.87\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 1.6051242711537244\n",
      "Loss: 0.2599886198583831\n",
      "Loss: 0.1511354374134133\n",
      "Loss: 0.11939226420452961\n",
      "Loss: 0.09740870347527782\n",
      "Loss: 0.0842202829616277\n",
      "Loss: 0.07176558455542537\n",
      "Loss: 0.06522316773000181\n",
      "Loss: 0.05376619703409678\n",
      "Loss: 0.04904887224666965\n",
      "______\n",
      "Iteration t=4\n",
      "all:  cs/acc_i=71.99 cs/acc_c=71.49 os/recall_knw=57.45 os/recall_unk=79.99 total/acc_i=62.18 total/acc_c=54.83 total/h_score=64.17\n",
      "selected:  cs/acc_i=68.36 cs/acc_c=68.51 os/recall_knw=51.62 os/recall_unk=82.32 total/acc_i=59.55 total/acc_c=50.24 total/h_score=61.15\n",
      "Loss: 1.5720103910848415\n",
      "Loss: 0.24489342908286515\n",
      "Loss: 0.14750617991238\n",
      "Loss: 0.117589208198576\n",
      "Loss: 0.09418132184229416\n",
      "Loss: 0.08031122905576821\n",
      "Loss: 0.07639631477195\n",
      "Loss: 0.061497855376108815\n",
      "Loss: 0.05711429956819154\n",
      "Loss: 0.047686597501453244\n",
      "______\n",
      "Iteration t=5\n",
      "all:  cs/acc_i=73.45 cs/acc_c=72.96 os/recall_knw=57.31 os/recall_unk=80.06 total/acc_i=62.13 total/acc_c=54.70 total/h_score=64.09\n",
      "selected:  cs/acc_i=71.67 cs/acc_c=71.45 os/recall_knw=54.25 os/recall_unk=80.60 total/acc_i=60.55 total/acc_c=52.38 total/h_score=62.44\n",
      "Loss: 1.5463083603165366\n",
      "Loss: 0.2526864227081954\n",
      "Loss: 0.1485770988655238\n",
      "Loss: 0.1135512924350326\n",
      "Loss: 0.09706380814262576\n",
      "Loss: 0.07950561088522685\n",
      "Loss: 0.06588906988555426\n",
      "Loss: 0.0613352153103891\n",
      "Loss: 0.048718298809761924\n",
      "Loss: 0.045060637839633676\n",
      "______\n",
      "Iteration t=6\n",
      "all:  cs/acc_i=73.42 cs/acc_c=73.04 os/recall_knw=57.27 os/recall_unk=80.13 total/acc_i=62.13 total/acc_c=54.66 total/h_score=64.08\n",
      "selected:  cs/acc_i=72.69 cs/acc_c=72.45 os/recall_knw=56.05 os/recall_unk=80.37 total/acc_i=61.49 total/acc_c=53.78 total/h_score=63.48\n",
      "Loss: 1.5680924007613262\n",
      "Loss: 0.25131612144187293\n",
      "Loss: 0.14730145183343654\n",
      "Loss: 0.11551393505327952\n",
      "Loss: 0.09414280980967533\n",
      "Loss: 0.07959366523044067\n",
      "Loss: 0.06522911535296842\n",
      "Loss: 0.05729508746227589\n",
      "Loss: 0.05536526939019622\n",
      "Loss: 0.04612412299372114\n",
      "______\n",
      "Iteration t=7\n",
      "all:  cs/acc_i=73.35 cs/acc_c=72.97 os/recall_knw=57.27 os/recall_unk=80.13 total/acc_i=62.13 total/acc_c=54.66 total/h_score=64.08\n",
      "selected:  cs/acc_i=73.23 cs/acc_c=72.85 os/recall_knw=57.02 os/recall_unk=80.31 total/acc_i=62.05 total/acc_c=54.51 total/h_score=64.02\n",
      "Loss: 1.5509717728548902\n",
      "Loss: 0.24868932267433905\n",
      "Loss: 0.14895106670080727\n",
      "Loss: 0.12085007270419501\n",
      "Loss: 0.08886503979694957\n",
      "Loss: 0.08478463881808083\n",
      "Loss: 0.07147769353965797\n",
      "Loss: 0.05962899181648564\n",
      "Loss: 0.0504080005599625\n",
      "Loss: 0.045533453503643795\n",
      "______\n",
      "Iteration t=8\n",
      "all:  cs/acc_i=73.63 cs/acc_c=73.03 os/recall_knw=57.27 os/recall_unk=80.13 total/acc_i=62.13 total/acc_c=54.66 total/h_score=64.08\n",
      "selected:  cs/acc_i=73.63 cs/acc_c=73.03 os/recall_knw=57.27 os/recall_unk=80.13 total/acc_i=62.13 total/acc_c=54.66 total/h_score=64.08\n",
      "Loss: 1.5397065083320076\n",
      "Loss: 0.2455049594914591\n",
      "Loss: 0.1522102104751645\n",
      "Loss: 0.11230521103417551\n",
      "Loss: 0.09273824723991188\n",
      "Loss: 0.0834878216094866\n",
      "Loss: 0.07073325001559144\n",
      "Loss: 0.05733801249439853\n",
      "Loss: 0.052119958747455196\n",
      "Loss: 0.047212520472680194\n",
      "______\n",
      "Iteration t=9\n",
      "all:  cs/acc_i=74.24 cs/acc_c=73.69 os/recall_knw=57.27 os/recall_unk=80.13 total/acc_i=62.13 total/acc_c=54.66 total/h_score=64.08\n",
      "selected:  cs/acc_i=74.24 cs/acc_c=73.69 os/recall_knw=57.27 os/recall_unk=80.13 total/acc_i=62.13 total/acc_c=54.66 total/h_score=64.08\n",
      "tensor(0)\n",
      "all:  cs/acc_i=74.24 cs/acc_c=73.69 os/recall_knw=57.27 os/recall_unk=80.13 total/acc_i=62.13 total/acc_c=54.66 total/h_score=64.08\n",
      "real -> painting lr= 0.001 seed= 4\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19]\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20]\n",
      "Loss: 1.721550238860765\n",
      "Loss: 0.2990329762219999\n",
      "Loss: 0.18549567292716918\n",
      "Loss: 0.13778996783221842\n",
      "Loss: 0.12223601472411316\n",
      "Loss: 0.09822701228560934\n",
      "Loss: 0.08888254789306133\n",
      "Loss: 0.0748836285931768\n",
      "Loss: 0.06224005626382791\n",
      "Loss: 0.05881958087259406\n",
      "tensor(True) tensor(True)\n",
      "______\n",
      "Iteration t=1\n",
      "all:  cs/acc_i=72.88 cs/acc_c=72.46 os/recall_knw=83.57 os/recall_unk=42.87 total/acc_i=59.52 total/acc_c=66.08 total/h_score=52.36\n",
      "selected:  cs/acc_i=64.22 cs/acc_c=64.51 os/recall_knw=49.67 os/recall_unk=97.29 total/acc_i=67.15 total/acc_c=51.43 total/h_score=65.30\n",
      "Loss: 1.6332866765238756\n",
      "Loss: 0.28065919454432336\n",
      "Loss: 0.16797858682901032\n",
      "Loss: 0.12860233174705524\n",
      "Loss: 0.11694137344388233\n",
      "Loss: 0.09112363145972367\n",
      "Loss: 0.07531486983993804\n",
      "Loss: 0.06998201449004579\n",
      "Loss: 0.0586912768201594\n",
      "Loss: 0.05480397132188196\n",
      "______\n",
      "Iteration t=2\n",
      "all:  cs/acc_i=72.99 cs/acc_c=72.46 os/recall_knw=59.45 os/recall_unk=79.24 total/acc_i=62.86 total/acc_c=55.91 total/h_score=64.75\n",
      "selected:  cs/acc_i=64.45 cs/acc_c=64.54 os/recall_knw=42.85 os/recall_unk=93.23 total/acc_i=58.83 total/acc_c=42.48 total/h_score=55.93\n",
      "Loss: 1.590774101457175\n",
      "Loss: 0.2659500588827273\n",
      "Loss: 0.15589884231962703\n",
      "Loss: 0.12424036240314736\n",
      "Loss: 0.09872103303616099\n",
      "Loss: 0.08552774426472538\n",
      "Loss: 0.07062309938072063\n",
      "Loss: 0.06598579719498315\n",
      "Loss: 0.053815323129460656\n",
      "Loss: 0.05237108443808906\n",
      "______\n",
      "Iteration t=3\n",
      "all:  cs/acc_i=72.53 cs/acc_c=71.91 os/recall_knw=58.13 os/recall_unk=80.73 total/acc_i=62.61 total/acc_c=54.97 total/h_score=64.48\n",
      "selected:  cs/acc_i=66.81 cs/acc_c=66.70 os/recall_knw=48.21 os/recall_unk=87.60 total/acc_i=59.28 total/acc_c=46.79 total/h_score=59.24\n",
      "Loss: 1.5755322131940297\n",
      "Loss: 0.2514421953580209\n",
      "Loss: 0.16265007153685604\n",
      "Loss: 0.12094956162784781\n",
      "Loss: 0.10680982688441873\n",
      "Loss: 0.07811161496410413\n",
      "Loss: 0.07252511504372315\n",
      "Loss: 0.06030569938277559\n",
      "Loss: 0.05313908272090235\n",
      "Loss: 0.05162691556848586\n",
      "______\n",
      "Iteration t=4\n",
      "all:  cs/acc_i=72.38 cs/acc_c=71.96 os/recall_knw=57.20 os/recall_unk=81.18 total/acc_i=62.25 total/acc_c=54.39 total/h_score=64.17\n",
      "selected:  cs/acc_i=68.77 cs/acc_c=68.87 os/recall_knw=51.16 os/recall_unk=83.49 total/acc_i=59.57 total/acc_c=49.55 total/h_score=60.84\n",
      "Loss: 1.567917530484894\n",
      "Loss: 0.2520201718252079\n",
      "Loss: 0.1501939501248154\n",
      "Loss: 0.12019296461084977\n",
      "Loss: 0.09554863465475101\n",
      "Loss: 0.07721879597915028\n",
      "Loss: 0.0713779526796578\n",
      "Loss: 0.06237395139572834\n",
      "Loss: 0.05402671673572531\n",
      "Loss: 0.046704245471664255\n",
      "______\n",
      "Iteration t=5\n",
      "all:  cs/acc_i=72.70 cs/acc_c=72.20 os/recall_knw=56.84 os/recall_unk=81.18 total/acc_i=62.01 total/acc_c=54.10 total/h_score=63.94\n",
      "selected:  cs/acc_i=71.04 cs/acc_c=70.89 os/recall_knw=53.96 os/recall_unk=81.79 total/acc_i=60.59 total/acc_c=52.00 total/h_score=62.45\n",
      "Loss: 1.5544814059392809\n",
      "Loss: 0.2503397651940338\n",
      "Loss: 0.1568234907283599\n",
      "Loss: 0.12147674737267258\n",
      "Loss: 0.0921823120504084\n",
      "Loss: 0.07937045811775549\n",
      "Loss: 0.06847282019046137\n",
      "Loss: 0.0575910293787061\n",
      "Loss: 0.0528013552859754\n",
      "Loss: 0.046621368962568396\n",
      "______\n",
      "Iteration t=6\n",
      "all:  cs/acc_i=73.99 cs/acc_c=73.31 os/recall_knw=56.81 os/recall_unk=81.18 total/acc_i=61.99 total/acc_c=54.06 total/h_score=63.92\n",
      "selected:  cs/acc_i=73.47 cs/acc_c=72.90 os/recall_knw=55.94 os/recall_unk=81.30 total/acc_i=61.50 total/acc_c=53.44 total/h_score=63.47\n",
      "Loss: 1.54774209515925\n",
      "Loss: 0.24625950727906148\n",
      "Loss: 0.15333134430265233\n",
      "Loss: 0.11366345609566171\n",
      "Loss: 0.09174157927010705\n",
      "Loss: 0.07650017162927043\n",
      "Loss: 0.06828384857741501\n",
      "Loss: 0.05759471635098191\n",
      "Loss: 0.0569661210122333\n",
      "Loss: 0.04454191242996857\n",
      "______\n",
      "Iteration t=7\n",
      "all:  cs/acc_i=73.60 cs/acc_c=73.12 os/recall_knw=56.81 os/recall_unk=81.18 total/acc_i=61.99 total/acc_c=54.06 total/h_score=63.92\n",
      "selected:  cs/acc_i=73.50 cs/acc_c=73.02 os/recall_knw=56.65 os/recall_unk=81.30 total/acc_i=61.92 total/acc_c=53.93 total/h_score=63.85\n",
      "Loss: 1.5532510044134182\n",
      "Loss: 0.2448690278435369\n",
      "Loss: 0.15380475397788637\n",
      "Loss: 0.11595355862569388\n",
      "Loss: 0.09291808691847583\n",
      "Loss: 0.0832889748018478\n",
      "Loss: 0.06404485060382918\n",
      "Loss: 0.058582991404008404\n",
      "Loss: 0.05222161344768803\n",
      "Loss: 0.04692895934947402\n",
      "______\n",
      "Iteration t=8\n",
      "all:  cs/acc_i=73.95 cs/acc_c=73.38 os/recall_knw=56.81 os/recall_unk=81.18 total/acc_i=61.99 total/acc_c=54.06 total/h_score=63.92\n",
      "selected:  cs/acc_i=73.95 cs/acc_c=73.38 os/recall_knw=56.81 os/recall_unk=81.18 total/acc_i=61.99 total/acc_c=54.06 total/h_score=63.92\n",
      "Loss: 1.5500015143941088\n",
      "Loss: 0.24156865017200874\n",
      "Loss: 0.15485724691695313\n",
      "Loss: 0.11510727637596327\n",
      "Loss: 0.09465523528031056\n",
      "Loss: 0.0756219734152562\n",
      "Loss: 0.07126327442903789\n",
      "Loss: 0.05710870108559606\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.04880536406308534\n",
      "Loss: 0.04598995678878937\n",
      "______\n",
      "Iteration t=9\n",
      "all:  cs/acc_i=73.81 cs/acc_c=73.37 os/recall_knw=56.81 os/recall_unk=81.18 total/acc_i=61.99 total/acc_c=54.06 total/h_score=63.92\n",
      "selected:  cs/acc_i=73.81 cs/acc_c=73.37 os/recall_knw=56.81 os/recall_unk=81.18 total/acc_i=61.99 total/acc_c=54.06 total/h_score=63.92\n",
      "tensor(0)\n",
      "all:  cs/acc_i=73.81 cs/acc_c=73.37 os/recall_knw=56.81 os/recall_unk=81.18 total/acc_i=61.99 total/acc_c=54.06 total/h_score=63.92\n",
      "real -> painting lr= 0.001 seed= 0\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19]\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20]\n",
      "Loss: 1.7007055508745446\n",
      "Loss: 0.30896711529163684\n",
      "Loss: 0.17921951707224945\n",
      "Loss: 0.1360175392539555\n",
      "Loss: 0.11418814510646069\n",
      "Loss: 0.09714484313005803\n",
      "Loss: 0.08787918194433693\n",
      "Loss: 0.07447923066384994\n",
      "Loss: 0.06668398948236581\n",
      "Loss: 0.0651393478801414\n",
      "tensor(True) tensor(True)\n",
      "______\n",
      "Iteration t=1\n",
      "all:  cs/acc_i=72.81 cs/acc_c=72.51 os/recall_knw=84.49 os/recall_unk=44.81 total/acc_i=60.75 total/acc_c=66.91 total/h_score=54.03\n",
      "selected:  cs/acc_i=62.30 cs/acc_c=62.96 os/recall_knw=51.02 os/recall_unk=97.56 total/acc_i=68.49 total/acc_c=51.09 total/h_score=65.03\n",
      "Loss: 1.6513705643042464\n",
      "Loss: 0.27757712554163727\n",
      "Loss: 0.16573206776970187\n",
      "Loss: 0.13620415168808647\n",
      "Loss: 0.11083165445347871\n",
      "Loss: 0.08938397903372448\n",
      "Loss: 0.07944560042822425\n",
      "Loss: 0.07511922173156328\n",
      "Loss: 0.06113925602064222\n",
      "Loss: 0.04995147046344526\n",
      "______\n",
      "Iteration t=2\n",
      "all:  cs/acc_i=73.35 cs/acc_c=72.83 os/recall_knw=61.91 os/recall_unk=77.15 total/acc_i=63.39 total/acc_c=57.51 total/h_score=65.25\n",
      "selected:  cs/acc_i=64.77 cs/acc_c=64.83 os/recall_knw=44.28 os/recall_unk=92.90 total/acc_i=59.80 total/acc_c=44.05 total/h_score=57.48\n",
      "Loss: 1.592846408749328\n",
      "Loss: 0.2538481136564823\n",
      "Loss: 0.1595029073055176\n",
      "Loss: 0.12656696682028912\n",
      "Loss: 0.10292698234620998\n",
      "Loss: 0.08567630228696062\n",
      "Loss: 0.07286320238730268\n",
      "Loss: 0.06335750452160616\n",
      "Loss: 0.05666816177955993\n",
      "Loss: 0.05326703362824286\n",
      "______\n",
      "Iteration t=3\n",
      "all:  cs/acc_i=72.38 cs/acc_c=71.66 os/recall_knw=57.27 os/recall_unk=81.55 total/acc_i=62.57 total/acc_c=54.53 total/h_score=64.38\n",
      "selected:  cs/acc_i=66.90 cs/acc_c=66.68 os/recall_knw=47.08 os/recall_unk=88.42 total/acc_i=59.37 total/acc_c=46.55 total/h_score=59.16\n",
      "Loss: 1.5923249540492934\n",
      "Loss: 0.2515278456673923\n",
      "Loss: 0.15270533019351243\n",
      "Loss: 0.12389030199722097\n",
      "Loss: 0.10455836844563826\n",
      "Loss: 0.08384448682147487\n",
      "Loss: 0.07166019615511754\n",
      "Loss: 0.0596855193400558\n",
      "Loss: 0.05294366109780006\n",
      "Loss: 0.04940352611107629\n",
      "______\n",
      "Iteration t=4\n",
      "all:  cs/acc_i=73.13 cs/acc_c=72.46 os/recall_knw=56.91 os/recall_unk=81.85 total/acc_i=62.42 total/acc_c=54.23 total/h_score=64.23\n",
      "selected:  cs/acc_i=70.01 cs/acc_c=69.87 os/recall_knw=51.00 os/recall_unk=84.50 total/acc_i=60.11 total/acc_c=49.88 total/h_score=61.34\n",
      "Loss: 1.5618093368135582\n",
      "Loss: 0.26349436005457444\n",
      "Loss: 0.15188791090492107\n",
      "Loss: 0.1177152350899719\n",
      "Loss: 0.0933307857834408\n",
      "Loss: 0.07931776358341637\n",
      "Loss: 0.0707340404151284\n",
      "Loss: 0.05974693249334537\n",
      "Loss: 0.051000917934309116\n",
      "Loss: 0.049058022123633645\n",
      "______\n",
      "Iteration t=5\n",
      "all:  cs/acc_i=73.06 cs/acc_c=72.58 os/recall_knw=56.81 os/recall_unk=81.85 total/acc_i=62.35 total/acc_c=54.10 total/h_score=64.13\n",
      "selected:  cs/acc_i=71.37 cs/acc_c=71.29 os/recall_knw=53.66 os/recall_unk=82.59 total/acc_i=60.90 total/acc_c=51.98 total/h_score=62.64\n",
      "Loss: 1.5434560993923008\n",
      "Loss: 0.26227203052676185\n",
      "Loss: 0.14907023680103088\n",
      "Loss: 0.11955096750926658\n",
      "Loss: 0.09480115168506681\n",
      "Loss: 0.08124558991644511\n",
      "Loss: 0.07270713125417287\n",
      "Loss: 0.06103240295688915\n",
      "Loss: 0.053392235428295534\n",
      "Loss: 0.04793764013303083\n",
      "______\n",
      "Iteration t=6\n",
      "all:  cs/acc_i=73.53 cs/acc_c=73.16 os/recall_knw=56.81 os/recall_unk=81.85 total/acc_i=62.35 total/acc_c=54.10 total/h_score=64.13\n",
      "selected:  cs/acc_i=72.99 cs/acc_c=72.76 os/recall_knw=55.70 os/recall_unk=82.16 total/acc_i=61.88 total/acc_c=53.46 total/h_score=63.71\n",
      "Loss: 1.5364561690007403\n",
      "Loss: 0.25033442725941457\n",
      "Loss: 0.15090927438393154\n",
      "Loss: 0.12028221676604507\n",
      "Loss: 0.09531918621260693\n",
      "Loss: 0.08346372952079147\n",
      "Loss: 0.06496052894120415\n",
      "Loss: 0.06157351180954322\n",
      "Loss: 0.04957831313304318\n",
      "Loss: 0.044078391846880075\n",
      "______\n",
      "Iteration t=7\n",
      "all:  cs/acc_i=74.03 cs/acc_c=73.59 os/recall_knw=56.81 os/recall_unk=81.85 total/acc_i=62.35 total/acc_c=54.10 total/h_score=64.13\n",
      "selected:  cs/acc_i=73.99 cs/acc_c=73.55 os/recall_knw=56.62 os/recall_unk=82.04 total/acc_i=62.33 total/acc_c=54.03 total/h_score=64.12\n",
      "Loss: 1.5410038565649935\n",
      "Loss: 0.24673777482593837\n",
      "Loss: 0.14654499065616858\n",
      "Loss: 0.11937584971842032\n",
      "Loss: 0.0944422052479754\n",
      "Loss: 0.07961993116338778\n",
      "Loss: 0.0742531331697651\n",
      "Loss: 0.0632072795744297\n",
      "Loss: 0.048955744386109036\n",
      "Loss: 0.04482163582186964\n",
      "______\n",
      "Iteration t=8\n",
      "all:  cs/acc_i=73.53 cs/acc_c=73.17 os/recall_knw=56.81 os/recall_unk=81.85 total/acc_i=62.35 total/acc_c=54.10 total/h_score=64.13\n",
      "selected:  cs/acc_i=73.53 cs/acc_c=73.17 os/recall_knw=56.81 os/recall_unk=81.85 total/acc_i=62.35 total/acc_c=54.10 total/h_score=64.13\n",
      "Loss: 1.547723742444878\n",
      "Loss: 0.24446276842576006\n",
      "Loss: 0.1482917828404385\n",
      "Loss: 0.11552470840979367\n",
      "Loss: 0.09180134183565236\n",
      "Loss: 0.08223322472464212\n",
      "Loss: 0.06978219494213471\n",
      "Loss: 0.06028737713020983\n",
      "Loss: 0.048143181942261595\n",
      "Loss: 0.04458536157629999\n",
      "______\n",
      "Iteration t=9\n",
      "all:  cs/acc_i=74.28 cs/acc_c=73.81 os/recall_knw=56.81 os/recall_unk=81.85 total/acc_i=62.35 total/acc_c=54.10 total/h_score=64.13\n",
      "selected:  cs/acc_i=74.28 cs/acc_c=73.81 os/recall_knw=56.81 os/recall_unk=81.85 total/acc_i=62.35 total/acc_c=54.10 total/h_score=64.13\n",
      "tensor(0)\n",
      "all:  cs/acc_i=74.28 cs/acc_c=73.81 os/recall_knw=56.81 os/recall_unk=81.85 total/acc_i=62.35 total/acc_c=54.10 total/h_score=64.13\n",
      "real -> painting lr= 0.001 seed= 1\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19]\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20]\n",
      "Loss: 1.710695373954497\n",
      "Loss: 0.29905237444344057\n",
      "Loss: 0.18083294073772585\n",
      "Loss: 0.1377975818704083\n",
      "Loss: 0.11778092918576151\n",
      "Loss: 0.10281115546942332\n",
      "Loss: 0.08493051762390175\n",
      "Loss: 0.07564167007040293\n",
      "Loss: 0.06561554279447895\n",
      "Loss: 0.06175826581260878\n",
      "tensor(True) tensor(True)\n",
      "______\n",
      "Iteration t=1\n",
      "all:  cs/acc_i=72.53 cs/acc_c=72.23 os/recall_knw=83.67 os/recall_unk=43.09 total/acc_i=59.74 total/acc_c=66.28 total/h_score=52.58\n",
      "selected:  cs/acc_i=62.39 cs/acc_c=62.36 os/recall_knw=49.89 os/recall_unk=97.47 total/acc_i=67.22 total/acc_c=50.10 total/h_score=64.08\n",
      "Loss: 1.639857950843185\n",
      "Loss: 0.26808830334639255\n",
      "Loss: 0.16727866376950148\n",
      "Loss: 0.13195625237229228\n",
      "Loss: 0.1085600285488038\n",
      "Loss: 0.09575299159952216\n",
      "Loss: 0.08331290118687677\n",
      "Loss: 0.06714101230862773\n",
      "Loss: 0.06280447600375107\n",
      "Loss: 0.05539071468487839\n",
      "______\n",
      "Iteration t=2\n",
      "all:  cs/acc_i=72.88 cs/acc_c=72.46 os/recall_knw=61.91 os/recall_unk=77.89 total/acc_i=63.44 total/acc_c=57.41 total/h_score=65.42\n",
      "selected:  cs/acc_i=64.10 cs/acc_c=64.38 os/recall_knw=44.13 os/recall_unk=92.38 total/acc_i=59.53 total/acc_c=43.75 total/h_score=57.10\n",
      "Loss: 1.601773797545363\n",
      "Loss: 0.26209798164884834\n",
      "Loss: 0.16246631705366513\n",
      "Loss: 0.1235058720333173\n",
      "Loss: 0.10090190792346702\n",
      "Loss: 0.0834499070639996\n",
      "Loss: 0.07340299112941412\n",
      "Loss: 0.06190320116139072\n",
      "Loss: 0.05827527513234493\n",
      "Loss: 0.050087999016977844\n",
      "______\n",
      "Iteration t=3\n",
      "all:  cs/acc_i=73.06 cs/acc_c=72.42 os/recall_knw=58.84 os/recall_unk=79.84 total/acc_i=62.49 total/acc_c=55.23 total/h_score=64.43\n",
      "selected:  cs/acc_i=67.81 cs/acc_c=67.55 os/recall_knw=48.57 os/recall_unk=87.48 total/acc_i=59.50 total/acc_c=47.28 total/h_score=59.66\n",
      "Loss: 1.5817287684338432\n",
      "Loss: 0.25265536921364923\n",
      "Loss: 0.15987282236771924\n",
      "Loss: 0.11213294938472765\n",
      "Loss: 0.1017269200139812\n",
      "Loss: 0.08696061063690909\n",
      "Loss: 0.06951328688966377\n",
      "Loss: 0.06404340289400093\n",
      "Loss: 0.05701796854047903\n",
      "Loss: 0.04798224815367056\n",
      "______\n",
      "Iteration t=4\n",
      "all:  cs/acc_i=72.99 cs/acc_c=72.56 os/recall_knw=58.70 os/recall_unk=80.13 total/acc_i=62.52 total/acc_c=55.17 total/h_score=64.46\n",
      "selected:  cs/acc_i=69.62 cs/acc_c=69.54 os/recall_knw=52.60 os/recall_unk=82.86 total/acc_i=60.04 total/acc_c=50.49 total/h_score=61.48\n",
      "Loss: 1.5629220645687434\n",
      "Loss: 0.25177786451394996\n",
      "Loss: 0.15734669541180465\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.11938601698435052\n",
      "Loss: 0.09223735055433555\n",
      "Loss: 0.07961580080016616\n",
      "Loss: 0.07148201677716706\n",
      "Loss: 0.060421991691399134\n",
      "Loss: 0.05501743511286403\n",
      "Loss: 0.050169223407673644\n",
      "______\n",
      "Iteration t=5\n",
      "all:  cs/acc_i=73.24 cs/acc_c=72.78 os/recall_knw=58.31 os/recall_unk=80.13 total/acc_i=62.30 total/acc_c=54.79 total/h_score=64.18\n",
      "selected:  cs/acc_i=71.38 cs/acc_c=71.24 os/recall_knw=54.92 os/recall_unk=80.86 total/acc_i=60.67 total/acc_c=52.34 total/h_score=62.48\n",
      "Loss: 1.568267168502834\n",
      "Loss: 0.2547040695206521\n",
      "Loss: 0.15804486186564298\n",
      "Loss: 0.11406297922729625\n",
      "Loss: 0.09632848956450286\n",
      "Loss: 0.08169261181403782\n",
      "Loss: 0.06485976736489735\n",
      "Loss: 0.06278466331431277\n",
      "Loss: 0.048992798788108693\n",
      "Loss: 0.045645162160444196\n",
      "______\n",
      "Iteration t=6\n",
      "all:  cs/acc_i=73.42 cs/acc_c=73.11 os/recall_knw=58.16 os/recall_unk=80.36 total/acc_i=62.28 total/acc_c=54.67 total/h_score=64.15\n",
      "selected:  cs/acc_i=72.73 cs/acc_c=72.59 os/recall_knw=56.85 os/recall_unk=80.42 total/acc_i=61.60 total/acc_c=53.86 total/h_score=63.55\n",
      "Loss: 1.5416454755822602\n",
      "Loss: 0.25540589363030763\n",
      "Loss: 0.14992111937507338\n",
      "Loss: 0.1215322834272545\n",
      "Loss: 0.09453962429973256\n",
      "Loss: 0.0767865362374679\n",
      "Loss: 0.0674115750273062\n",
      "Loss: 0.06219390327611979\n",
      "Loss: 0.052997069062573995\n",
      "Loss: 0.04197840063083593\n",
      "______\n",
      "Iteration t=7\n",
      "all:  cs/acc_i=73.92 cs/acc_c=73.30 os/recall_knw=58.13 os/recall_unk=80.36 total/acc_i=62.25 total/acc_c=54.65 total/h_score=64.14\n",
      "selected:  cs/acc_i=73.84 cs/acc_c=73.19 os/recall_knw=57.89 os/recall_unk=80.42 total/acc_i=62.17 total/acc_c=54.50 total/h_score=64.04\n",
      "Loss: 1.5392649973566468\n",
      "Loss: 0.24541144407278784\n",
      "Loss: 0.14831959768072575\n",
      "Loss: 0.10949171665753867\n",
      "Loss: 0.0931020362705395\n",
      "Loss: 0.08076394409746737\n",
      "Loss: 0.07070831671306813\n",
      "Loss: 0.05809991735763646\n",
      "Loss: 0.049650493519053464\n",
      "Loss: 0.04446341016776608\n",
      "______\n",
      "Iteration t=8\n",
      "all:  cs/acc_i=74.24 cs/acc_c=73.73 os/recall_knw=58.13 os/recall_unk=80.36 total/acc_i=62.25 total/acc_c=54.65 total/h_score=64.14\n",
      "selected:  cs/acc_i=74.24 cs/acc_c=73.73 os/recall_knw=58.13 os/recall_unk=80.36 total/acc_i=62.25 total/acc_c=54.65 total/h_score=64.14\n",
      "Loss: 1.5446967188973684\n",
      "Loss: 0.2535504393581603\n",
      "Loss: 0.15069612483619838\n",
      "Loss: 0.10603892294488645\n",
      "Loss: 0.09178566978489225\n",
      "Loss: 0.07740724934265017\n",
      "Loss: 0.06846122038047257\n",
      "Loss: 0.05649651092653339\n",
      "Loss: 0.051105389588613166\n",
      "Loss: 0.046004249656421914\n",
      "______\n",
      "Iteration t=9\n",
      "all:  cs/acc_i=74.31 cs/acc_c=73.77 os/recall_knw=58.13 os/recall_unk=80.36 total/acc_i=62.25 total/acc_c=54.65 total/h_score=64.14\n",
      "selected:  cs/acc_i=74.31 cs/acc_c=73.77 os/recall_knw=58.13 os/recall_unk=80.36 total/acc_i=62.25 total/acc_c=54.65 total/h_score=64.14\n",
      "tensor(0)\n",
      "all:  cs/acc_i=74.31 cs/acc_c=73.77 os/recall_knw=58.13 os/recall_unk=80.36 total/acc_i=62.25 total/acc_c=54.65 total/h_score=64.14\n",
      "real -> painting lr= 0.001 seed= 2\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19]\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20]\n",
      "Loss: 1.7166242824681701\n",
      "Loss: 0.2913136986051342\n",
      "Loss: 0.17660747188176373\n",
      "Loss: 0.14258416460593415\n",
      "Loss: 0.11547048823830111\n",
      "Loss: 0.10168323279253635\n",
      "Loss: 0.08459290266156771\n",
      "Loss: 0.07568140457447176\n",
      "Loss: 0.0714685870828616\n",
      "Loss: 0.05751498839653238\n",
      "tensor(True) tensor(True)\n",
      "______\n",
      "Iteration t=1\n",
      "all:  cs/acc_i=72.85 cs/acc_c=72.34 os/recall_knw=83.78 os/recall_unk=43.32 total/acc_i=59.79 total/acc_c=65.99 total/h_score=52.65\n",
      "selected:  cs/acc_i=63.09 cs/acc_c=63.98 os/recall_knw=49.83 os/recall_unk=97.32 total/acc_i=67.02 total/acc_c=50.31 total/h_score=64.25\n",
      "Loss: 1.6371728426839676\n",
      "Loss: 0.27804935015052373\n",
      "Loss: 0.16767371094505662\n",
      "Loss: 0.12739954610566603\n",
      "Loss: 0.11209359782193702\n",
      "Loss: 0.09320907286322601\n",
      "Loss: 0.078054027237638\n",
      "Loss: 0.07296878839785839\n",
      "Loss: 0.06338324425942007\n",
      "Loss: 0.05360017991424795\n",
      "______\n",
      "Iteration t=2\n",
      "all:  cs/acc_i=72.99 cs/acc_c=72.39 os/recall_knw=59.20 os/recall_unk=79.54 total/acc_i=62.86 total/acc_c=55.79 total/h_score=64.75\n",
      "selected:  cs/acc_i=64.24 cs/acc_c=64.41 os/recall_knw=42.64 os/recall_unk=93.09 total/acc_i=58.60 total/acc_c=42.51 total/h_score=55.94\n",
      "Loss: 1.6167639444417814\n",
      "Loss: 0.2770842199378154\n",
      "Loss: 0.1597889104310204\n",
      "Loss: 0.12801392575287643\n",
      "Loss: 0.10483349189984009\n",
      "Loss: 0.08196677481755614\n",
      "Loss: 0.06931214293958071\n",
      "Loss: 0.06411431928658311\n",
      "Loss: 0.0584455143133014\n",
      "Loss: 0.05255180074326585\n",
      "______\n",
      "Iteration t=3\n",
      "all:  cs/acc_i=73.28 cs/acc_c=72.75 os/recall_knw=57.27 os/recall_unk=81.78 total/acc_i=62.52 total/acc_c=54.43 total/h_score=64.36\n",
      "selected:  cs/acc_i=68.13 cs/acc_c=68.29 os/recall_knw=47.57 os/recall_unk=87.46 total/acc_i=59.16 total/acc_c=46.79 total/h_score=59.21\n",
      "Loss: 1.580894028033529\n",
      "Loss: 0.24775251086269107\n",
      "Loss: 0.15872673504054546\n",
      "Loss: 0.11959967199180807\n",
      "Loss: 0.09821781400857227\n",
      "Loss: 0.07916348043030925\n",
      "Loss: 0.07804490052030555\n",
      "Loss: 0.06258460901012378\n",
      "Loss: 0.05487160187746797\n",
      "Loss: 0.04838182136682528\n",
      "______\n",
      "Iteration t=4\n",
      "all:  cs/acc_i=72.24 cs/acc_c=71.74 os/recall_knw=57.09 os/recall_unk=82.00 total/acc_i=62.47 total/acc_c=54.27 total/h_score=64.30\n",
      "selected:  cs/acc_i=68.69 cs/acc_c=68.81 os/recall_knw=50.98 os/recall_unk=84.46 total/acc_i=59.89 total/acc_c=49.64 total/h_score=61.13\n",
      "Loss: 1.577646617474181\n",
      "Loss: 0.26743932290191064\n",
      "Loss: 0.14815603941679\n",
      "Loss: 0.12192054923749372\n",
      "Loss: 0.09400058129613989\n",
      "Loss: 0.0764858613884223\n",
      "Loss: 0.06742521162338429\n",
      "Loss: 0.05958656887549991\n",
      "Loss: 0.05909518243383951\n",
      "Loss: 0.050686211705867075\n",
      "______\n",
      "Iteration t=5\n",
      "all:  cs/acc_i=73.63 cs/acc_c=73.21 os/recall_knw=57.06 os/recall_unk=82.08 total/acc_i=62.47 total/acc_c=54.23 total/h_score=64.29\n",
      "selected:  cs/acc_i=71.90 cs/acc_c=71.87 os/recall_knw=53.98 os/recall_unk=82.94 total/acc_i=61.01 total/acc_c=52.07 total/h_score=62.80\n",
      "Loss: 1.567855649890162\n",
      "Loss: 0.25119244254796214\n",
      "Loss: 0.15416362734501204\n",
      "Loss: 0.12157192930723257\n",
      "Loss: 0.10201895309776808\n",
      "Loss: 0.07873608425995386\n",
      "Loss: 0.06647760563051502\n",
      "Loss: 0.056384716006716226\n",
      "Loss: 0.05463203013545283\n",
      "Loss: 0.047996854414077715\n",
      "______\n",
      "Iteration t=6\n",
      "all:  cs/acc_i=73.03 cs/acc_c=72.42 os/recall_knw=56.77 os/recall_unk=82.08 total/acc_i=62.30 total/acc_c=54.00 total/h_score=64.11\n",
      "selected:  cs/acc_i=72.29 cs/acc_c=71.90 os/recall_knw=55.42 os/recall_unk=82.32 total/acc_i=61.64 total/acc_c=53.17 total/h_score=63.52\n",
      "Loss: 1.5523950455939932\n",
      "Loss: 0.2552408660111362\n",
      "Loss: 0.1546424162510323\n",
      "Loss: 0.11707503063323563\n",
      "Loss: 0.08930077750286827\n",
      "Loss: 0.08076780762727538\n",
      "Loss: 0.06844162298621584\n",
      "Loss: 0.057093991697702094\n",
      "Loss: 0.0516942803499174\n",
      "Loss: 0.046645467918468256\n",
      "______\n",
      "Iteration t=7\n",
      "all:  cs/acc_i=74.03 cs/acc_c=73.40 os/recall_knw=56.77 os/recall_unk=82.08 total/acc_i=62.30 total/acc_c=54.00 total/h_score=64.11\n",
      "selected:  cs/acc_i=73.91 cs/acc_c=73.25 os/recall_knw=56.58 os/recall_unk=82.20 total/acc_i=62.22 total/acc_c=53.84 total/h_score=64.01\n",
      "Loss: 1.532290465319934\n",
      "Loss: 0.24772159757254564\n",
      "Loss: 0.1528582835580101\n",
      "Loss: 0.11088963494504518\n",
      "Loss: 0.09028796954384155\n",
      "Loss: 0.07812242646595342\n",
      "Loss: 0.07026496966263159\n",
      "Loss: 0.06034551347535023\n",
      "Loss: 0.053401248955355106\n",
      "Loss: 0.04446133971467371\n",
      "______\n",
      "Iteration t=8\n",
      "all:  cs/acc_i=74.35 cs/acc_c=73.85 os/recall_knw=56.77 os/recall_unk=82.08 total/acc_i=62.30 total/acc_c=54.00 total/h_score=64.11\n",
      "selected:  cs/acc_i=74.35 cs/acc_c=73.85 os/recall_knw=56.77 os/recall_unk=82.08 total/acc_i=62.30 total/acc_c=54.00 total/h_score=64.11\n",
      "Loss: 1.5466295600585316\n",
      "Loss: 0.2514373555212565\n",
      "Loss: 0.14932645614886575\n",
      "Loss: 0.11828020555169685\n",
      "Loss: 0.09263855880683126\n",
      "Loss: 0.08081371933677355\n",
      "Loss: 0.06867647268961224\n",
      "Loss: 0.059390427185343986\n",
      "Loss: 0.05323792655785244\n",
      "Loss: 0.04789954207460497\n",
      "______\n",
      "Iteration t=9\n",
      "all:  cs/acc_i=73.74 cs/acc_c=73.13 os/recall_knw=56.77 os/recall_unk=82.08 total/acc_i=62.30 total/acc_c=54.00 total/h_score=64.11\n",
      "selected:  cs/acc_i=73.74 cs/acc_c=73.13 os/recall_knw=56.77 os/recall_unk=82.08 total/acc_i=62.30 total/acc_c=54.00 total/h_score=64.11\n",
      "tensor(0)\n",
      "all:  cs/acc_i=73.74 cs/acc_c=73.13 os/recall_knw=56.77 os/recall_unk=82.08 total/acc_i=62.30 total/acc_c=54.00 total/h_score=64.11\n",
      "real -> painting lr= 0.001 seed= 3\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19]\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 1.7094001912802361\n",
      "Loss: 0.3006458119803686\n",
      "Loss: 0.18377310821001935\n",
      "Loss: 0.14389199909673242\n",
      "Loss: 0.11382124425657693\n",
      "Loss: 0.09298470548961994\n",
      "Loss: 0.08445433327490973\n",
      "Loss: 0.07521509571701672\n",
      "Loss: 0.06533865842045887\n",
      "Loss: 0.060586621195760665\n",
      "tensor(True) tensor(True)\n",
      "______\n",
      "Iteration t=1\n",
      "all:  cs/acc_i=72.85 cs/acc_c=72.34 os/recall_knw=83.85 os/recall_unk=43.47 total/acc_i=59.84 total/acc_c=66.12 total/h_score=52.80\n",
      "selected:  cs/acc_i=63.84 cs/acc_c=63.88 os/recall_knw=50.17 os/recall_unk=97.82 total/acc_i=67.64 total/acc_c=50.80 total/h_score=64.80\n",
      "Loss: 1.6463655658020564\n",
      "Loss: 0.27157078564532694\n",
      "Loss: 0.16917126070410926\n",
      "Loss: 0.13396357029013656\n",
      "Loss: 0.10225001985401463\n",
      "Loss: 0.09450857106459104\n",
      "Loss: 0.0841597326876927\n",
      "Loss: 0.07265477011585894\n",
      "Loss: 0.06082126199113536\n",
      "Loss: 0.054399012410841836\n",
      "______\n",
      "Iteration t=2\n",
      "all:  cs/acc_i=73.24 cs/acc_c=73.05 os/recall_knw=58.27 os/recall_unk=80.81 total/acc_i=63.05 total/acc_c=55.78 total/h_score=65.12\n",
      "selected:  cs/acc_i=64.81 cs/acc_c=64.97 os/recall_knw=41.86 os/recall_unk=92.64 total/acc_i=58.58 total/acc_c=42.42 total/h_score=55.78\n",
      "Loss: 1.6027495083563468\n",
      "Loss: 0.2593646765631788\n",
      "Loss: 0.16116577059249668\n",
      "Loss: 0.11953781562419061\n",
      "Loss: 0.10162237501593635\n",
      "Loss: 0.08475049602223889\n",
      "Loss: 0.07337466296808356\n",
      "Loss: 0.06418795517906\n",
      "Loss: 0.054983376315794884\n",
      "Loss: 0.049057881881291156\n",
      "______\n",
      "Iteration t=3\n",
      "all:  cs/acc_i=73.17 cs/acc_c=72.68 os/recall_knw=56.59 os/recall_unk=82.08 total/acc_i=62.61 total/acc_c=54.51 total/h_score=64.51\n",
      "selected:  cs/acc_i=67.82 cs/acc_c=67.78 os/recall_knw=46.94 os/recall_unk=88.06 total/acc_i=59.24 total/acc_c=46.58 total/h_score=59.12\n",
      "Loss: 1.5965347906579943\n",
      "Loss: 0.2556701247449591\n",
      "Loss: 0.15875799214216563\n",
      "Loss: 0.11612404809255997\n",
      "Loss: 0.09784372386797452\n",
      "Loss: 0.08421791454558301\n",
      "Loss: 0.07172594196229831\n",
      "Loss: 0.06395330879420981\n",
      "Loss: 0.05710978287787185\n",
      "Loss: 0.045922002768448225\n",
      "______\n",
      "Iteration t=4\n",
      "all:  cs/acc_i=73.17 cs/acc_c=72.61 os/recall_knw=56.59 os/recall_unk=82.08 total/acc_i=62.61 total/acc_c=54.51 total/h_score=64.51\n",
      "selected:  cs/acc_i=69.89 cs/acc_c=69.78 os/recall_knw=50.77 os/recall_unk=83.70 total/acc_i=59.98 total/acc_c=50.00 total/h_score=61.26\n",
      "Loss: 1.5655285265265393\n",
      "Loss: 0.2543369570240921\n",
      "Loss: 0.15319269812595443\n",
      "Loss: 0.12113285858278014\n",
      "Loss: 0.1003692986245374\n",
      "Loss: 0.07693172606485647\n",
      "Loss: 0.07035367357406337\n",
      "Loss: 0.06009726356571483\n",
      "Loss: 0.05315035614067642\n",
      "Loss: 0.04791629784453545\n",
      "______\n",
      "Iteration t=5\n",
      "all:  cs/acc_i=73.28 cs/acc_c=72.94 os/recall_knw=56.48 os/recall_unk=82.23 total/acc_i=62.61 total/acc_c=54.45 total/h_score=64.50\n",
      "selected:  cs/acc_i=71.45 cs/acc_c=71.53 os/recall_knw=53.26 os/recall_unk=82.72 total/acc_i=61.01 total/acc_c=52.24 total/h_score=62.88\n",
      "Loss: 1.5581625857241246\n",
      "Loss: 0.25491936422513994\n",
      "Loss: 0.14968811466425494\n",
      "Loss: 0.12007056779192132\n",
      "Loss: 0.09942154620017712\n",
      "Loss: 0.08030710199806654\n",
      "Loss: 0.06655390560112441\n",
      "Loss: 0.057352110002580926\n",
      "Loss: 0.0504440573695018\n",
      "Loss: 0.04428577818586208\n",
      "______\n",
      "Iteration t=6\n",
      "all:  cs/acc_i=73.60 cs/acc_c=73.07 os/recall_knw=56.09 os/recall_unk=82.37 total/acc_i=62.40 total/acc_c=54.10 total/h_score=64.27\n",
      "selected:  cs/acc_i=73.02 cs/acc_c=72.60 os/recall_knw=54.95 os/recall_unk=82.50 total/acc_i=61.85 total/acc_c=53.37 total/h_score=63.72\n",
      "Loss: 1.559339273057572\n",
      "Loss: 0.2509804316171228\n",
      "Loss: 0.15017588590718295\n",
      "Loss: 0.11530010505285981\n",
      "Loss: 0.09427883972299017\n",
      "Loss: 0.0838892593609858\n",
      "Loss: 0.07220248353909957\n",
      "Loss: 0.05957919402838978\n",
      "Loss: 0.05510989761566871\n",
      "Loss: 0.047531550802443534\n",
      "______\n",
      "Iteration t=7\n",
      "all:  cs/acc_i=73.99 cs/acc_c=73.55 os/recall_knw=56.09 os/recall_unk=82.37 total/acc_i=62.40 total/acc_c=54.10 total/h_score=64.27\n",
      "selected:  cs/acc_i=73.92 cs/acc_c=73.42 os/recall_knw=55.85 os/recall_unk=82.50 total/acc_i=62.34 total/acc_c=53.94 total/h_score=64.18\n",
      "Loss: 1.5448506964974573\n",
      "Loss: 0.2624038435742056\n",
      "Loss: 0.14703971108964745\n",
      "Loss: 0.11211231666076574\n",
      "Loss: 0.09347130863467988\n",
      "Loss: 0.08040391792840139\n",
      "Loss: 0.07057387152133504\n",
      "Loss: 0.05688910480405963\n",
      "Loss: 0.049823513725259894\n",
      "Loss: 0.04565951480702764\n",
      "______\n",
      "Iteration t=8\n",
      "all:  cs/acc_i=74.85 cs/acc_c=74.52 os/recall_knw=56.09 os/recall_unk=82.37 total/acc_i=62.40 total/acc_c=54.10 total/h_score=64.27\n",
      "selected:  cs/acc_i=74.85 cs/acc_c=74.52 os/recall_knw=56.09 os/recall_unk=82.50 total/acc_i=62.43 total/acc_c=54.11 total/h_score=64.31\n",
      "Loss: 1.5424601265130315\n",
      "Loss: 0.24424644276418542\n",
      "Loss: 0.1528213247047783\n",
      "Loss: 0.11085265036164821\n",
      "Loss: 0.09728257023610114\n",
      "Loss: 0.07800271721145681\n",
      "Loss: 0.06777758431831522\n",
      "Loss: 0.05967822110366675\n",
      "Loss: 0.051895594054310296\n",
      "Loss: 0.04608451812566139\n",
      "______\n",
      "Iteration t=9\n",
      "all:  cs/acc_i=74.42 cs/acc_c=74.01 os/recall_knw=56.09 os/recall_unk=82.37 total/acc_i=62.40 total/acc_c=54.10 total/h_score=64.27\n",
      "selected:  cs/acc_i=74.42 cs/acc_c=74.01 os/recall_knw=56.09 os/recall_unk=82.37 total/acc_i=62.40 total/acc_c=54.10 total/h_score=64.27\n",
      "tensor(0)\n",
      "all:  cs/acc_i=74.42 cs/acc_c=74.01 os/recall_knw=56.09 os/recall_unk=82.37 total/acc_i=62.40 total/acc_c=54.10 total/h_score=64.27\n",
      "real -> painting lr= 0.001 seed= 4\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19]\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20]\n",
      "Loss: 1.7231126582890846\n",
      "Loss: 0.29964455181187755\n",
      "Loss: 0.18550479306069792\n",
      "Loss: 0.1377243300019449\n",
      "Loss: 0.12238403578615266\n",
      "Loss: 0.09817776302552492\n",
      "Loss: 0.08876807996973252\n",
      "Loss: 0.07485591487246311\n",
      "Loss: 0.06203990292037655\n",
      "Loss: 0.058547710476539\n",
      "tensor(True) tensor(True)\n",
      "______\n",
      "Iteration t=1\n",
      "all:  cs/acc_i=72.99 cs/acc_c=72.54 os/recall_knw=83.32 os/recall_unk=42.35 total/acc_i=59.30 total/acc_c=65.98 total/h_score=51.94\n",
      "selected:  cs/acc_i=64.39 cs/acc_c=64.24 os/recall_knw=49.29 os/recall_unk=97.59 total/acc_i=66.84 total/acc_c=50.86 total/h_score=64.82\n",
      "Loss: 1.6423403975422397\n",
      "Loss: 0.27816491377499936\n",
      "Loss: 0.17170100445442038\n",
      "Loss: 0.1274020371792918\n",
      "Loss: 0.11094786027629226\n",
      "Loss: 0.09258657099073467\n",
      "Loss: 0.07675929843488098\n",
      "Loss: 0.07019670818149587\n",
      "Loss: 0.058426008542622525\n",
      "Loss: 0.05430556383009634\n",
      "______\n",
      "Iteration t=2\n",
      "all:  cs/acc_i=72.99 cs/acc_c=72.68 os/recall_knw=59.84 os/recall_unk=78.86 total/acc_i=62.76 total/acc_c=56.06 total/h_score=64.75\n",
      "selected:  cs/acc_i=64.62 cs/acc_c=65.18 os/recall_knw=42.62 os/recall_unk=92.07 total/acc_i=58.60 total/acc_c=42.82 total/h_score=56.12\n",
      "Loss: 1.5870784741114168\n",
      "Loss: 0.27189589002553155\n",
      "Loss: 0.15488656081040117\n",
      "Loss: 0.11664095787221894\n",
      "Loss: 0.10019734182997661\n",
      "Loss: 0.08405908200451556\n",
      "Loss: 0.07602491517934729\n",
      "Loss: 0.06442877562743995\n",
      "Loss: 0.05445283780230538\n",
      "Loss: 0.051367807673180804\n",
      "______\n",
      "Iteration t=3\n",
      "all:  cs/acc_i=73.45 cs/acc_c=73.11 os/recall_knw=57.20 os/recall_unk=80.43 total/acc_i=62.18 total/acc_c=54.64 total/h_score=64.15\n",
      "selected:  cs/acc_i=68.17 cs/acc_c=68.24 os/recall_knw=47.48 os/recall_unk=87.14 total/acc_i=58.91 total/acc_c=46.78 total/h_score=59.15\n",
      "Loss: 1.5985152035100119\n",
      "Loss: 0.2604708521174533\n",
      "Loss: 0.1573565679628934\n",
      "Loss: 0.11892562368884682\n",
      "Loss: 0.09861916497881923\n",
      "Loss: 0.08275084126740694\n",
      "Loss: 0.06951806928297238\n",
      "Loss: 0.05912506020295301\n",
      "Loss: 0.05354907135346106\n",
      "Loss: 0.048103461584209334\n",
      "______\n",
      "Iteration t=4\n",
      "all:  cs/acc_i=72.49 cs/acc_c=71.93 os/recall_knw=56.81 os/recall_unk=80.73 total/acc_i=62.06 total/acc_c=54.35 total/h_score=64.02\n",
      "selected:  cs/acc_i=69.35 cs/acc_c=69.44 os/recall_knw=51.31 os/recall_unk=83.86 total/acc_i=59.94 total/acc_c=50.31 total/h_score=61.56\n",
      "Loss: 1.5646274117361598\n",
      "Loss: 0.25602834107202976\n",
      "Loss: 0.1566032408697515\n",
      "Loss: 0.11579075941414226\n",
      "Loss: 0.09836571272045207\n",
      "Loss: 0.08077187594339377\n",
      "Loss: 0.06582621004333307\n",
      "Loss: 0.061701710277213516\n",
      "Loss: 0.055188321634339225\n",
      "Loss: 0.04642587844595438\n",
      "______\n",
      "Iteration t=5\n",
      "all:  cs/acc_i=73.17 cs/acc_c=72.72 os/recall_knw=56.73 os/recall_unk=80.96 total/acc_i=62.08 total/acc_c=54.30 total/h_score=64.04\n",
      "selected:  cs/acc_i=71.53 cs/acc_c=71.38 os/recall_knw=53.73 os/recall_unk=81.75 total/acc_i=60.69 total/acc_c=52.18 total/h_score=62.59\n",
      "Loss: 1.5582275363531979\n",
      "Loss: 0.24597005126356422\n",
      "Loss: 0.15056728960089283\n",
      "Loss: 0.11650615912084737\n",
      "Loss: 0.09577197628224027\n",
      "Loss: 0.07943536403535073\n",
      "Loss: 0.06527406852512772\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.05988710001495875\n",
      "Loss: 0.055289709857169834\n",
      "Loss: 0.0481951402938994\n",
      "______\n",
      "Iteration t=6\n",
      "all:  cs/acc_i=74.21 cs/acc_c=73.74 os/recall_knw=56.70 os/recall_unk=81.03 total/acc_i=62.11 total/acc_c=54.30 total/h_score=64.06\n",
      "selected:  cs/acc_i=73.61 cs/acc_c=73.27 os/recall_knw=55.52 os/recall_unk=81.33 total/acc_i=61.57 total/acc_c=53.57 total/h_score=63.58\n",
      "Loss: 1.5367359816213775\n",
      "Loss: 0.2581885204818405\n",
      "Loss: 0.1517163532546879\n",
      "Loss: 0.11208998472200798\n",
      "Loss: 0.09644264567266804\n",
      "Loss: 0.07761228087363266\n",
      "Loss: 0.06855245170443029\n",
      "Loss: 0.06030439062278128\n",
      "Loss: 0.055715104440975265\n",
      "Loss: 0.04608142113598074\n",
      "______\n",
      "Iteration t=7\n",
      "all:  cs/acc_i=73.78 cs/acc_c=73.38 os/recall_knw=56.63 os/recall_unk=81.03 total/acc_i=62.06 total/acc_c=54.24 total/h_score=64.01\n",
      "selected:  cs/acc_i=73.69 cs/acc_c=73.26 os/recall_knw=56.36 os/recall_unk=81.21 total/acc_i=62.00 total/acc_c=54.07 total/h_score=63.93\n",
      "Loss: 1.5374909162764316\n",
      "Loss: 0.24660636539287542\n",
      "Loss: 0.1504897184457387\n",
      "Loss: 0.11595876978042172\n",
      "Loss: 0.09824394929961747\n",
      "Loss: 0.08270175612035571\n",
      "Loss: 0.06962515097098809\n",
      "Loss: 0.05957135814558411\n",
      "Loss: 0.05338354919513222\n",
      "Loss: 0.04618835978908464\n",
      "______\n",
      "Iteration t=8\n",
      "all:  cs/acc_i=74.17 cs/acc_c=73.87 os/recall_knw=56.63 os/recall_unk=81.03 total/acc_i=62.06 total/acc_c=54.24 total/h_score=64.01\n",
      "selected:  cs/acc_i=74.17 cs/acc_c=73.87 os/recall_knw=56.63 os/recall_unk=81.03 total/acc_i=62.06 total/acc_c=54.24 total/h_score=64.01\n",
      "Loss: 1.5349528827076035\n",
      "Loss: 0.24020745703158017\n",
      "Loss: 0.1503889907787486\n",
      "Loss: 0.12208862708210137\n",
      "Loss: 0.09694861988902981\n",
      "Loss: 0.07886910313477886\n",
      "Loss: 0.06645197725822004\n",
      "Loss: 0.05823525570479391\n",
      "Loss: 0.055810163779370994\n",
      "Loss: 0.04605158280737718\n",
      "______\n",
      "Iteration t=9\n",
      "all:  cs/acc_i=73.35 cs/acc_c=72.75 os/recall_knw=56.63 os/recall_unk=81.03 total/acc_i=62.06 total/acc_c=54.24 total/h_score=64.01\n",
      "selected:  cs/acc_i=73.35 cs/acc_c=72.75 os/recall_knw=56.63 os/recall_unk=81.03 total/acc_i=62.06 total/acc_c=54.24 total/h_score=64.01\n",
      "tensor(0)\n",
      "all:  cs/acc_i=73.35 cs/acc_c=72.75 os/recall_knw=56.63 os/recall_unk=81.03 total/acc_i=62.06 total/acc_c=54.24 total/h_score=64.01\n",
      "real -> painting lr= 0.001 seed= 0\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19]\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20]\n",
      "Loss: 1.698582589530485\n",
      "Loss: 0.3084443796581777\n",
      "Loss: 0.17911824683428193\n",
      "Loss: 0.13609007939432788\n",
      "Loss: 0.11410709489675963\n",
      "Loss: 0.09703497584142581\n",
      "Loss: 0.08782454643254782\n",
      "Loss: 0.07439012312737572\n",
      "Loss: 0.06667461754436757\n",
      "Loss: 0.0652067328629554\n",
      "tensor(True) tensor(True)\n",
      "______\n",
      "Iteration t=1\n",
      "all:  cs/acc_i=72.99 cs/acc_c=72.64 os/recall_knw=84.78 os/recall_unk=45.41 total/acc_i=61.02 total/acc_c=67.05 total/h_score=54.50\n",
      "selected:  cs/acc_i=63.03 cs/acc_c=63.46 os/recall_knw=51.54 os/recall_unk=97.44 total/acc_i=68.93 total/acc_c=51.28 total/h_score=65.19\n",
      "Loss: 1.6573436537220434\n",
      "Loss: 0.273979877036042\n",
      "Loss: 0.17085898924687523\n",
      "Loss: 0.13028673494543216\n",
      "Loss: 0.11697519446603177\n",
      "Loss: 0.08805825261604841\n",
      "Loss: 0.08240109855349124\n",
      "Loss: 0.07019459465632867\n",
      "Loss: 0.060566623422368626\n",
      "Loss: 0.05001513243787151\n",
      "______\n",
      "Iteration t=2\n",
      "all:  cs/acc_i=72.88 cs/acc_c=72.44 os/recall_knw=59.16 os/recall_unk=81.63 total/acc_i=63.34 total/acc_c=55.61 total/h_score=65.22\n",
      "selected:  cs/acc_i=64.62 cs/acc_c=64.78 os/recall_knw=42.56 os/recall_unk=93.26 total/acc_i=59.04 total/acc_c=42.55 total/h_score=56.01\n",
      "Loss: 1.6082463989362996\n",
      "Loss: 0.2634267983848558\n",
      "Loss: 0.15553557791692368\n",
      "Loss: 0.12427517641335725\n",
      "Loss: 0.09658725596416523\n",
      "Loss: 0.08167403485242497\n",
      "Loss: 0.07325014649643836\n",
      "Loss: 0.06775681792813189\n",
      "Loss: 0.05739174471921561\n",
      "Loss: 0.049584565065828534\n",
      "______\n",
      "Iteration t=3\n",
      "all:  cs/acc_i=72.74 cs/acc_c=72.22 os/recall_knw=56.48 os/recall_unk=82.52 total/acc_i=62.28 total/acc_c=53.85 total/h_score=64.11\n",
      "selected:  cs/acc_i=67.46 cs/acc_c=67.41 os/recall_knw=47.02 os/recall_unk=87.77 total/acc_i=58.80 total/acc_c=46.03 total/h_score=58.56\n",
      "Loss: 1.5913351760591778\n",
      "Loss: 0.25311006088341986\n",
      "Loss: 0.16406994680741002\n",
      "Loss: 0.12492064685427717\n",
      "Loss: 0.09683239023866398\n",
      "Loss: 0.08372493254819087\n",
      "Loss: 0.06977296994999051\n",
      "Loss: 0.0611621840697314\n",
      "Loss: 0.05197895675099322\n",
      "Loss: 0.04785195823226656\n",
      "______\n",
      "Iteration t=4\n",
      "all:  cs/acc_i=73.38 cs/acc_c=72.76 os/recall_knw=56.16 os/recall_unk=82.67 total/acc_i=62.13 total/acc_c=53.52 total/h_score=63.89\n",
      "selected:  cs/acc_i=70.54 cs/acc_c=70.34 os/recall_knw=50.82 os/recall_unk=84.63 total/acc_i=59.87 total/acc_c=49.47 total/h_score=61.02\n",
      "Loss: 1.5657874010190242\n",
      "Loss: 0.24985326720135553\n",
      "Loss: 0.15344118189682313\n",
      "Loss: 0.12259360144034821\n",
      "Loss: 0.09039883326259063\n",
      "Loss: 0.07921366629135959\n",
      "Loss: 0.0714204581219609\n",
      "Loss: 0.057332967839749005\n",
      "Loss: 0.05491435435060568\n",
      "Loss: 0.04518935089625668\n",
      "______\n",
      "Iteration t=5\n",
      "all:  cs/acc_i=74.17 cs/acc_c=73.58 os/recall_knw=56.13 os/recall_unk=82.67 total/acc_i=62.11 total/acc_c=53.48 total/h_score=63.86\n",
      "selected:  cs/acc_i=72.80 cs/acc_c=72.42 os/recall_knw=53.54 os/recall_unk=82.98 total/acc_i=60.80 total/acc_c=51.58 total/h_score=62.41\n",
      "Loss: 1.5618724402307806\n",
      "Loss: 0.2466116836860529\n",
      "Loss: 0.16116446005540658\n",
      "Loss: 0.10967908614155585\n",
      "Loss: 0.09147415741074069\n",
      "Loss: 0.08265356342719858\n",
      "Loss: 0.06776811760973742\n",
      "Loss: 0.057561238503433476\n",
      "Loss: 0.051925254674391685\n",
      "Loss: 0.04305107856377733\n",
      "______\n",
      "Iteration t=6\n",
      "all:  cs/acc_i=73.63 cs/acc_c=73.26 os/recall_knw=56.06 os/recall_unk=82.75 total/acc_i=62.08 total/acc_c=53.42 total/h_score=63.83\n",
      "selected:  cs/acc_i=72.93 cs/acc_c=72.67 os/recall_knw=54.83 os/recall_unk=82.87 total/acc_i=61.43 total/acc_c=52.56 total/h_score=63.18\n",
      "Loss: 1.5389989157245583\n",
      "Loss: 0.25391298963190756\n",
      "Loss: 0.14952106876936677\n",
      "Loss: 0.1216021274305778\n",
      "Loss: 0.09474851547753158\n",
      "Loss: 0.07988686878744462\n",
      "Loss: 0.06732239786229313\n",
      "Loss: 0.0555591077556553\n",
      "Loss: 0.05262670455156022\n",
      "Loss: 0.043721523194586574\n",
      "______\n",
      "Iteration t=7\n",
      "all:  cs/acc_i=74.56 cs/acc_c=73.98 os/recall_knw=56.06 os/recall_unk=82.75 total/acc_i=62.08 total/acc_c=53.42 total/h_score=63.83\n",
      "selected:  cs/acc_i=74.51 cs/acc_c=73.88 os/recall_knw=55.90 os/recall_unk=82.87 total/acc_i=62.05 total/acc_c=53.30 total/h_score=63.77\n",
      "Loss: 1.5520506346907863\n",
      "Loss: 0.24980337406211717\n",
      "Loss: 0.1522058141836516\n",
      "Loss: 0.11862042699547165\n",
      "Loss: 0.09360804120510086\n",
      "Loss: 0.08165478987786767\n",
      "Loss: 0.07094471095946975\n",
      "Loss: 0.05964705074581569\n",
      "Loss: 0.05010592199199673\n",
      "Loss: 0.04513989213082625\n",
      "______\n",
      "Iteration t=8\n",
      "all:  cs/acc_i=74.10 cs/acc_c=73.68 os/recall_knw=56.06 os/recall_unk=82.75 total/acc_i=62.08 total/acc_c=53.42 total/h_score=63.83\n",
      "selected:  cs/acc_i=74.10 cs/acc_c=73.68 os/recall_knw=56.06 os/recall_unk=82.75 total/acc_i=62.08 total/acc_c=53.42 total/h_score=63.83\n",
      "Loss: 1.557129314671745\n",
      "Loss: 0.24485003469100766\n",
      "Loss: 0.16140552312744735\n",
      "Loss: 0.11746157913110968\n",
      "Loss: 0.09192568318517397\n",
      "Loss: 0.07772916253168917\n",
      "Loss: 0.06935404137929023\n",
      "Loss: 0.06462435652844466\n",
      "Loss: 0.05150323703235436\n",
      "Loss: 0.04265851832733411\n",
      "______\n",
      "Iteration t=9\n",
      "all:  cs/acc_i=73.92 cs/acc_c=73.54 os/recall_knw=56.06 os/recall_unk=82.75 total/acc_i=62.08 total/acc_c=53.42 total/h_score=63.83\n",
      "selected:  cs/acc_i=73.92 cs/acc_c=73.54 os/recall_knw=56.06 os/recall_unk=82.75 total/acc_i=62.08 total/acc_c=53.42 total/h_score=63.83\n",
      "tensor(0)\n",
      "all:  cs/acc_i=73.92 cs/acc_c=73.54 os/recall_knw=56.06 os/recall_unk=82.75 total/acc_i=62.08 total/acc_c=53.42 total/h_score=63.83\n",
      "real -> painting lr= 0.001 seed= 1\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19]\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20]\n",
      "Loss: 1.7106994723967035\n",
      "Loss: 0.29944620487486817\n",
      "Loss: 0.1808012448658514\n",
      "Loss: 0.1377419289680635\n",
      "Loss: 0.11800348910823512\n",
      "Loss: 0.10275148270034809\n",
      "Loss: 0.08481155130473172\n",
      "Loss: 0.07563502943873933\n",
      "Loss: 0.06580669873459953\n",
      "Loss: 0.061822028565624805\n",
      "tensor(True) tensor(True)\n",
      "______\n",
      "Iteration t=1\n",
      "all:  cs/acc_i=72.81 cs/acc_c=72.46 os/recall_knw=83.99 os/recall_unk=43.76 total/acc_i=60.17 total/acc_c=66.61 total/h_score=53.18\n",
      "selected:  cs/acc_i=62.90 cs/acc_c=62.93 os/recall_knw=50.39 os/recall_unk=97.34 total/acc_i=67.77 total/acc_c=50.90 total/h_score=64.81\n",
      "Loss: 1.6387995621360885\n",
      "Loss: 0.26974264468334935\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.17030046130044876\n",
      "Loss: 0.13022072458971132\n",
      "Loss: 0.11222095258442537\n",
      "Loss: 0.09169068827688054\n",
      "Loss: 0.08253816654619996\n",
      "Loss: 0.0685884839158071\n",
      "Loss: 0.06251530477811405\n",
      "Loss: 0.05245328590093878\n",
      "______\n",
      "Iteration t=2\n",
      "all:  cs/acc_i=72.92 cs/acc_c=72.27 os/recall_knw=60.45 os/recall_unk=81.11 total/acc_i=63.99 total/acc_c=56.75 total/h_score=65.93\n",
      "selected:  cs/acc_i=63.95 cs/acc_c=63.99 os/recall_knw=43.55 os/recall_unk=93.46 total/acc_i=59.59 total/acc_c=43.33 total/h_score=56.82\n",
      "Loss: 1.6054633757647345\n",
      "Loss: 0.2575769556905417\n",
      "Loss: 0.16387196256066947\n",
      "Loss: 0.12337542945409523\n",
      "Loss: 0.10449261640143745\n",
      "Loss: 0.08692182930432918\n",
      "Loss: 0.07691593768403811\n",
      "Loss: 0.06631739767720266\n",
      "Loss: 0.056860014101873864\n",
      "Loss: 0.04991669376682052\n",
      "______\n",
      "Iteration t=3\n",
      "all:  cs/acc_i=72.56 cs/acc_c=71.89 os/recall_knw=56.20 os/recall_unk=83.12 total/acc_i=62.57 total/acc_c=53.88 total/h_score=64.29\n",
      "selected:  cs/acc_i=67.26 cs/acc_c=67.14 os/recall_knw=46.83 os/recall_unk=88.76 total/acc_i=59.24 total/acc_c=46.19 total/h_score=58.89\n",
      "Loss: 1.5932353787914046\n",
      "Loss: 0.2553372285235406\n",
      "Loss: 0.1565878205161467\n",
      "Loss: 0.12100650530767475\n",
      "Loss: 0.09621053501792828\n",
      "Loss: 0.08300860100065525\n",
      "Loss: 0.07355688094564401\n",
      "Loss: 0.0637592592404723\n",
      "Loss: 0.05895630414277465\n",
      "Loss: 0.04722734960796776\n",
      "______\n",
      "Iteration t=4\n",
      "all:  cs/acc_i=73.10 cs/acc_c=72.51 os/recall_knw=55.56 os/recall_unk=83.27 total/acc_i=62.23 total/acc_c=53.32 total/h_score=63.89\n",
      "selected:  cs/acc_i=70.04 cs/acc_c=70.04 os/recall_knw=50.10 os/recall_unk=85.18 total/acc_i=59.84 total/acc_c=49.14 total/h_score=60.86\n",
      "Loss: 1.5769396716875306\n",
      "Loss: 0.25683421683445407\n",
      "Loss: 0.16273001878616516\n",
      "Loss: 0.11792710017977973\n",
      "Loss: 0.09793098002483838\n",
      "Loss: 0.07879278691370417\n",
      "Loss: 0.06880410564435499\n",
      "Loss: 0.06828759417455811\n",
      "Loss: 0.05158401040485903\n",
      "Loss: 0.04931609867679562\n",
      "______\n",
      "Iteration t=5\n",
      "all:  cs/acc_i=73.06 cs/acc_c=72.53 os/recall_knw=55.41 os/recall_unk=83.42 total/acc_i=62.18 total/acc_c=53.22 total/h_score=63.85\n",
      "selected:  cs/acc_i=71.53 cs/acc_c=71.37 os/recall_knw=52.57 os/recall_unk=83.92 total/acc_i=60.83 total/acc_c=51.27 total/h_score=62.38\n",
      "Loss: 1.5513553305676109\n",
      "Loss: 0.25236940726514007\n",
      "Loss: 0.15206089850587362\n",
      "Loss: 0.1158330767851457\n",
      "Loss: 0.09380105406773429\n",
      "Loss: 0.08551573514979632\n",
      "Loss: 0.06800649075709551\n",
      "Loss: 0.060631619363899374\n",
      "Loss: 0.052388743574020305\n",
      "Loss: 0.045864393209994685\n",
      "______\n",
      "Iteration t=6\n",
      "all:  cs/acc_i=73.49 cs/acc_c=73.04 os/recall_knw=55.41 os/recall_unk=83.42 total/acc_i=62.18 total/acc_c=53.22 total/h_score=63.85\n",
      "selected:  cs/acc_i=72.99 cs/acc_c=72.66 os/recall_knw=54.45 os/recall_unk=83.48 total/acc_i=61.70 total/acc_c=52.62 total/h_score=63.37\n",
      "Loss: 1.5401844899540078\n",
      "Loss: 0.24154102083754866\n",
      "Loss: 0.1510371385882162\n",
      "Loss: 0.1168732194510633\n",
      "Loss: 0.09430955609638397\n",
      "Loss: 0.07609328725566603\n",
      "Loss: 0.06666469831683047\n",
      "Loss: 0.05951342772284191\n",
      "Loss: 0.04871937099282872\n",
      "Loss: 0.043410327836029126\n",
      "______\n",
      "Iteration t=7\n",
      "all:  cs/acc_i=73.56 cs/acc_c=73.18 os/recall_knw=55.34 os/recall_unk=83.42 total/acc_i=62.13 total/acc_c=53.19 total/h_score=63.82\n",
      "selected:  cs/acc_i=73.53 cs/acc_c=73.17 os/recall_knw=55.23 os/recall_unk=83.42 total/acc_i=62.09 total/acc_c=53.15 total/h_score=63.79\n",
      "Loss: 1.5366061738605707\n",
      "Loss: 0.24887249305274317\n",
      "Loss: 0.15047009140151282\n",
      "Loss: 0.1109598042504465\n",
      "Loss: 0.0940823617538875\n",
      "Loss: 0.07682176151114409\n",
      "Loss: 0.06530882103007307\n",
      "Loss: 0.0629450142449735\n",
      "Loss: 0.05062645945196737\n",
      "Loss: 0.047293121460825205\n",
      "______\n",
      "Iteration t=8\n",
      "all:  cs/acc_i=74.06 cs/acc_c=73.40 os/recall_knw=55.34 os/recall_unk=83.42 total/acc_i=62.13 total/acc_c=53.19 total/h_score=63.82\n",
      "selected:  cs/acc_i=74.06 cs/acc_c=73.40 os/recall_knw=55.34 os/recall_unk=83.42 total/acc_i=62.13 total/acc_c=53.19 total/h_score=63.82\n",
      "Loss: 1.5505926170147182\n",
      "Loss: 0.25232968198471384\n",
      "Loss: 0.14534582229219173\n",
      "Loss: 0.1155141771776103\n",
      "Loss: 0.09247707997199373\n",
      "Loss: 0.08078084376264018\n",
      "Loss: 0.06743404158782926\n",
      "Loss: 0.061497923358257024\n",
      "Loss: 0.055811987342465605\n",
      "Loss: 0.04109073743412444\n",
      "______\n",
      "Iteration t=9\n",
      "all:  cs/acc_i=74.56 cs/acc_c=74.05 os/recall_knw=55.34 os/recall_unk=83.42 total/acc_i=62.13 total/acc_c=53.19 total/h_score=63.82\n",
      "selected:  cs/acc_i=74.56 cs/acc_c=74.05 os/recall_knw=55.34 os/recall_unk=83.42 total/acc_i=62.13 total/acc_c=53.19 total/h_score=63.82\n",
      "tensor(0)\n",
      "all:  cs/acc_i=74.56 cs/acc_c=74.05 os/recall_knw=55.34 os/recall_unk=83.42 total/acc_i=62.13 total/acc_c=53.19 total/h_score=63.82\n",
      "real -> painting lr= 0.001 seed= 2\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19]\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20]\n",
      "Loss: 1.7155368427754982\n",
      "Loss: 0.29134993897182\n",
      "Loss: 0.17670852851446034\n",
      "Loss: 0.14249139407895195\n",
      "Loss: 0.11536380924715682\n",
      "Loss: 0.10148471582477307\n",
      "Loss: 0.0841409732674479\n",
      "Loss: 0.07503888041823144\n",
      "Loss: 0.07106305482434977\n",
      "Loss: 0.05681051171633304\n",
      "tensor(True) tensor(True)\n",
      "______\n",
      "Iteration t=1\n",
      "all:  cs/acc_i=72.92 cs/acc_c=72.40 os/recall_knw=83.85 os/recall_unk=43.47 total/acc_i=59.96 total/acc_c=66.18 total/h_score=52.82\n",
      "selected:  cs/acc_i=63.36 cs/acc_c=63.94 os/recall_knw=50.11 os/recall_unk=97.49 total/acc_i=67.47 total/acc_c=50.56 total/h_score=64.52\n",
      "Loss: 1.6313414886319564\n",
      "Loss: 0.2742334724935286\n",
      "Loss: 0.1713385222696819\n",
      "Loss: 0.12887087257498978\n",
      "Loss: 0.1089721210072377\n",
      "Loss: 0.09541312032779165\n",
      "Loss: 0.07632518141170495\n",
      "Loss: 0.06725451545618429\n",
      "Loss: 0.06364433016010955\n",
      "Loss: 0.05251090425678009\n",
      "______\n",
      "Iteration t=2\n",
      "all:  cs/acc_i=73.13 cs/acc_c=72.59 os/recall_knw=57.84 os/recall_unk=82.23 total/acc_i=62.81 total/acc_c=54.75 total/h_score=64.73\n",
      "selected:  cs/acc_i=65.10 cs/acc_c=65.17 os/recall_knw=42.07 os/recall_unk=93.78 total/acc_i=58.49 total/acc_c=41.79 total/h_score=55.28\n",
      "Loss: 1.5945404726354515\n",
      "Loss: 0.26196806492174374\n",
      "Loss: 0.16482930869850165\n",
      "Loss: 0.12989072784343186\n",
      "Loss: 0.10379782779799665\n",
      "Loss: 0.08342258761746481\n",
      "Loss: 0.06772254216210807\n",
      "Loss: 0.06443249052938294\n",
      "Loss: 0.05489552509765524\n",
      "Loss: 0.051457407394670605\n",
      "______\n",
      "Iteration t=3\n",
      "all:  cs/acc_i=72.81 cs/acc_c=72.20 os/recall_knw=56.31 os/recall_unk=83.57 total/acc_i=62.37 total/acc_c=53.55 total/h_score=64.15\n",
      "selected:  cs/acc_i=67.73 cs/acc_c=67.55 os/recall_knw=47.10 os/recall_unk=88.11 total/acc_i=58.88 total/acc_c=45.80 total/h_score=58.41\n",
      "Loss: 1.578941558769771\n",
      "Loss: 0.2553463206546647\n",
      "Loss: 0.15577369185430662\n",
      "Loss: 0.11924797966011932\n",
      "Loss: 0.09836843279855592\n",
      "Loss: 0.08271815388064299\n",
      "Loss: 0.07525086744555405\n",
      "Loss: 0.06748296105835054\n",
      "Loss: 0.05377873508259654\n",
      "Loss: 0.04762021148045148\n",
      "______\n",
      "Iteration t=4\n",
      "all:  cs/acc_i=72.70 cs/acc_c=72.20 os/recall_knw=56.13 os/recall_unk=83.64 total/acc_i=62.30 total/acc_c=53.43 total/h_score=64.07\n",
      "selected:  cs/acc_i=69.60 cs/acc_c=69.64 os/recall_knw=50.62 os/recall_unk=85.43 total/acc_i=59.87 total/acc_c=49.16 total/h_score=60.92\n",
      "Loss: 1.569122350868884\n",
      "Loss: 0.2579229899336783\n",
      "Loss: 0.14970097262307666\n",
      "Loss: 0.11885389729057637\n",
      "Loss: 0.09621171647515357\n",
      "Loss: 0.08251462600277631\n",
      "Loss: 0.06788534887679172\n",
      "Loss: 0.05760535511732352\n",
      "Loss: 0.05399495697373608\n",
      "Loss: 0.04689842383403415\n",
      "______\n",
      "Iteration t=5\n",
      "all:  cs/acc_i=72.92 cs/acc_c=72.49 os/recall_knw=56.06 os/recall_unk=83.64 total/acc_i=62.25 total/acc_c=53.35 total/h_score=64.00\n",
      "selected:  cs/acc_i=71.42 cs/acc_c=71.32 os/recall_knw=53.25 os/recall_unk=84.08 total/acc_i=60.91 total/acc_c=51.38 total/h_score=62.51\n",
      "Loss: 1.5532277259378802\n",
      "Loss: 0.2562694326248946\n",
      "Loss: 0.15497702901966828\n",
      "Loss: 0.11789994698676451\n",
      "Loss: 0.09568802327257246\n",
      "Loss: 0.07965318622962875\n",
      "Loss: 0.06942007817245649\n",
      "Loss: 0.05686951765934654\n",
      "Loss: 0.054086157496702134\n",
      "Loss: 0.04498291722220981\n",
      "______\n",
      "Iteration t=6\n",
      "all:  cs/acc_i=73.70 cs/acc_c=73.22 os/recall_knw=56.02 os/recall_unk=83.64 total/acc_i=62.23 total/acc_c=53.30 total/h_score=63.97\n",
      "selected:  cs/acc_i=73.19 cs/acc_c=72.82 os/recall_knw=55.04 os/recall_unk=83.90 total/acc_i=61.77 total/acc_c=52.64 total/h_score=63.50\n",
      "Loss: 1.5649212194632178\n",
      "Loss: 0.24953891321608465\n",
      "Loss: 0.14714349677709684\n",
      "Loss: 0.11341306182925832\n",
      "Loss: 0.08703480579520333\n",
      "Loss: 0.07660507199367228\n",
      "Loss: 0.07093279752370021\n",
      "Loss: 0.059446129468205856\n",
      "Loss: 0.05304172734844766\n",
      "Loss: 0.043738925320491805\n",
      "______\n",
      "Iteration t=7\n",
      "all:  cs/acc_i=73.74 cs/acc_c=73.18 os/recall_knw=55.98 os/recall_unk=83.64 total/acc_i=62.20 total/acc_c=53.26 total/h_score=63.93\n",
      "selected:  cs/acc_i=73.65 cs/acc_c=73.11 os/recall_knw=55.78 os/recall_unk=83.71 total/acc_i=62.12 total/acc_c=53.13 total/h_score=63.85\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 1.548320047842349\n",
      "Loss: 0.2544366900956696\n",
      "Loss: 0.15536874593261\n",
      "Loss: 0.11255287212609756\n",
      "Loss: 0.08980695156461961\n",
      "Loss: 0.07815292573666272\n",
      "Loss: 0.06295987328290532\n",
      "Loss: 0.0555088113003558\n",
      "Loss: 0.05414391910629296\n",
      "Loss: 0.04612781578430631\n",
      "______\n",
      "Iteration t=8\n",
      "all:  cs/acc_i=73.85 cs/acc_c=73.29 os/recall_knw=55.98 os/recall_unk=83.64 total/acc_i=62.20 total/acc_c=53.26 total/h_score=63.93\n",
      "selected:  cs/acc_i=73.85 cs/acc_c=73.29 os/recall_knw=55.98 os/recall_unk=83.64 total/acc_i=62.20 total/acc_c=53.26 total/h_score=63.93\n",
      "Loss: 1.5560458152268173\n",
      "Loss: 0.24827868299563835\n",
      "Loss: 0.15295721081463615\n",
      "Loss: 0.11690023171966667\n",
      "Loss: 0.0992608445490982\n",
      "Loss: 0.07844172069442532\n",
      "Loss: 0.0726278877540489\n",
      "Loss: 0.05771327627523312\n",
      "Loss: 0.0508535186689073\n",
      "Loss: 0.04847361826419079\n",
      "______\n",
      "Iteration t=9\n",
      "all:  cs/acc_i=73.99 cs/acc_c=73.51 os/recall_knw=55.98 os/recall_unk=83.64 total/acc_i=62.20 total/acc_c=53.26 total/h_score=63.93\n",
      "selected:  cs/acc_i=73.99 cs/acc_c=73.51 os/recall_knw=55.98 os/recall_unk=83.64 total/acc_i=62.20 total/acc_c=53.26 total/h_score=63.93\n",
      "tensor(0)\n",
      "all:  cs/acc_i=73.99 cs/acc_c=73.51 os/recall_knw=55.98 os/recall_unk=83.64 total/acc_i=62.20 total/acc_c=53.26 total/h_score=63.93\n",
      "real -> painting lr= 0.001 seed= 3\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19]\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20]\n",
      "Loss: 1.7076205314163992\n",
      "Loss: 0.30051108385013997\n",
      "Loss: 0.18342978344373764\n",
      "Loss: 0.1438822066441322\n",
      "Loss: 0.11366689481571844\n",
      "Loss: 0.09302774385827627\n",
      "Loss: 0.08482543709672916\n",
      "Loss: 0.0752951000634449\n",
      "Loss: 0.0651570586592462\n",
      "Loss: 0.06107290365382837\n",
      "tensor(True) tensor(True)\n",
      "______\n",
      "Iteration t=1\n",
      "all:  cs/acc_i=72.99 cs/acc_c=72.43 os/recall_knw=84.39 os/recall_unk=44.59 total/acc_i=60.42 total/acc_c=66.48 total/h_score=53.72\n",
      "selected:  cs/acc_i=64.13 cs/acc_c=64.06 os/recall_knw=51.01 os/recall_unk=97.71 total/acc_i=68.46 total/acc_c=51.30 total/h_score=65.25\n",
      "Loss: 1.6480114160139867\n",
      "Loss: 0.26984808888812006\n",
      "Loss: 0.1692852422457897\n",
      "Loss: 0.13349164652700987\n",
      "Loss: 0.10234390984809288\n",
      "Loss: 0.09350649888792927\n",
      "Loss: 0.08396660145714971\n",
      "Loss: 0.07330378054561196\n",
      "Loss: 0.061755005448793795\n",
      "Loss: 0.05512284818305377\n",
      "______\n",
      "Iteration t=2\n",
      "all:  cs/acc_i=72.63 cs/acc_c=72.43 os/recall_knw=58.95 os/recall_unk=80.06 total/acc_i=63.15 total/acc_c=56.19 total/h_score=65.20\n",
      "selected:  cs/acc_i=63.41 cs/acc_c=63.73 os/recall_knw=42.17 os/recall_unk=92.25 total/acc_i=58.43 total/acc_c=42.32 total/h_score=55.63\n",
      "Loss: 1.624912297462716\n",
      "Loss: 0.2589528295923682\n",
      "Loss: 0.16518128637553137\n",
      "Loss: 0.12048914304331822\n",
      "Loss: 0.10137639160213226\n",
      "Loss: 0.08461155975511407\n",
      "Loss: 0.07783727370859946\n",
      "Loss: 0.06297580975532423\n",
      "Loss: 0.060078131775919565\n",
      "Loss: 0.05111931518939159\n",
      "______\n",
      "Iteration t=3\n",
      "all:  cs/acc_i=72.92 cs/acc_c=72.45 os/recall_knw=57.88 os/recall_unk=81.33 total/acc_i=63.03 total/acc_c=55.51 total/h_score=65.06\n",
      "selected:  cs/acc_i=67.21 cs/acc_c=67.09 os/recall_knw=47.97 os/recall_unk=87.47 total/acc_i=59.53 total/acc_c=47.30 total/h_score=59.68\n",
      "Loss: 1.600065341080938\n",
      "Loss: 0.2606185717135668\n",
      "Loss: 0.15708245304546187\n",
      "Loss: 0.12105681452101895\n",
      "Loss: 0.0936788865498134\n",
      "Loss: 0.08247923596895167\n",
      "Loss: 0.06840719165945691\n",
      "Loss: 0.0641776483412832\n",
      "Loss: 0.05108175623563251\n",
      "Loss: 0.046534079087765086\n",
      "______\n",
      "Iteration t=4\n",
      "all:  cs/acc_i=72.92 cs/acc_c=72.42 os/recall_knw=57.73 os/recall_unk=81.55 total/acc_i=63.03 total/acc_c=55.39 total/h_score=65.04\n",
      "selected:  cs/acc_i=69.33 cs/acc_c=69.33 os/recall_knw=51.69 os/recall_unk=84.00 total/acc_i=60.42 total/acc_c=50.68 total/h_score=61.91\n",
      "Loss: 1.5688305662459685\n",
      "Loss: 0.250861395181728\n",
      "Loss: 0.16122320132116144\n",
      "Loss: 0.11858842583472322\n",
      "Loss: 0.10111094437831757\n",
      "Loss: 0.08028794813859447\n",
      "Loss: 0.07191883716523564\n",
      "Loss: 0.06134541025672223\n",
      "Loss: 0.050843721642406754\n",
      "Loss: 0.04620923832611961\n",
      "______\n",
      "Iteration t=5\n",
      "all:  cs/acc_i=73.17 cs/acc_c=72.67 os/recall_knw=57.59 os/recall_unk=81.70 total/acc_i=62.98 total/acc_c=55.24 total/h_score=64.96\n",
      "selected:  cs/acc_i=71.50 cs/acc_c=71.39 os/recall_knw=54.59 os/recall_unk=82.07 total/acc_i=61.49 total/acc_c=53.12 total/h_score=63.41\n",
      "Loss: 1.5638358440280946\n",
      "Loss: 0.24706784960077485\n",
      "Loss: 0.1574709187710745\n",
      "Loss: 0.12218090814869266\n",
      "Loss: 0.09655903291583226\n",
      "Loss: 0.08214530149428559\n",
      "Loss: 0.06826778289094855\n",
      "Loss: 0.06363423904737575\n",
      "Loss: 0.052183319197469914\n",
      "Loss: 0.042890239112494774\n",
      "______\n",
      "Iteration t=6\n",
      "all:  cs/acc_i=73.60 cs/acc_c=73.30 os/recall_knw=57.56 os/recall_unk=81.70 total/acc_i=62.95 total/acc_c=55.21 total/h_score=64.94\n",
      "selected:  cs/acc_i=72.96 cs/acc_c=72.80 os/recall_knw=56.29 os/recall_unk=81.89 total/acc_i=62.36 total/acc_c=54.41 total/h_score=64.37\n",
      "Loss: 1.554958938290187\n",
      "Loss: 0.25417885544602986\n",
      "Loss: 0.15099410517293899\n",
      "Loss: 0.1134520729830682\n",
      "Loss: 0.09596011413088262\n",
      "Loss: 0.08126597125541235\n",
      "Loss: 0.06789132652427655\n",
      "Loss: 0.061292459262036234\n",
      "Loss: 0.05355450291061886\n",
      "Loss: 0.04389128753599899\n",
      "______\n",
      "Iteration t=7\n",
      "all:  cs/acc_i=74.46 cs/acc_c=74.07 os/recall_knw=57.56 os/recall_unk=81.70 total/acc_i=62.95 total/acc_c=55.21 total/h_score=64.94\n",
      "selected:  cs/acc_i=74.43 cs/acc_c=74.04 os/recall_knw=57.34 os/recall_unk=81.76 total/acc_i=62.92 total/acc_c=55.14 total/h_score=64.90\n",
      "Loss: 1.564069712670838\n",
      "Loss: 0.24918388639927558\n",
      "Loss: 0.15157338263603246\n",
      "Loss: 0.11547628576112634\n",
      "Loss: 0.09370478721673735\n",
      "Loss: 0.08305153231386368\n",
      "Loss: 0.07066153058640881\n",
      "Loss: 0.06274320149975943\n",
      "Loss: 0.05100393540422788\n",
      "Loss: 0.0444022399666126\n",
      "______\n",
      "Iteration t=8\n",
      "all:  cs/acc_i=74.28 cs/acc_c=73.95 os/recall_knw=57.56 os/recall_unk=81.70 total/acc_i=62.95 total/acc_c=55.21 total/h_score=64.94\n",
      "selected:  cs/acc_i=74.28 cs/acc_c=73.95 os/recall_knw=57.56 os/recall_unk=81.70 total/acc_i=62.95 total/acc_c=55.21 total/h_score=64.94\n",
      "Loss: 1.5403666314151552\n",
      "Loss: 0.24841613379031985\n",
      "Loss: 0.15378549770227454\n",
      "Loss: 0.11253226039865556\n",
      "Loss: 0.09772849653602696\n",
      "Loss: 0.07958873928219161\n",
      "Loss: 0.06528896912881918\n",
      "Loss: 0.06389252254158904\n",
      "Loss: 0.05057010338875165\n",
      "Loss: 0.045601442130661106\n",
      "______\n",
      "Iteration t=9\n",
      "all:  cs/acc_i=74.35 cs/acc_c=73.90 os/recall_knw=57.56 os/recall_unk=81.70 total/acc_i=62.95 total/acc_c=55.21 total/h_score=64.94\n",
      "selected:  cs/acc_i=74.35 cs/acc_c=73.90 os/recall_knw=57.56 os/recall_unk=81.70 total/acc_i=62.95 total/acc_c=55.21 total/h_score=64.94\n",
      "tensor(0)\n",
      "all:  cs/acc_i=74.35 cs/acc_c=73.90 os/recall_knw=57.56 os/recall_unk=81.70 total/acc_i=62.95 total/acc_c=55.21 total/h_score=64.94\n",
      "real -> painting lr= 0.001 seed= 4\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19]\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20]\n",
      "Loss: 1.722161376878763\n",
      "Loss: 0.29980136957199244\n",
      "Loss: 0.18548131653877317\n",
      "Loss: 0.13764986612046454\n",
      "Loss: 0.12217925709950771\n",
      "Loss: 0.09790866656103127\n",
      "Loss: 0.08857374002863548\n",
      "Loss: 0.0745222844464938\n",
      "Loss: 0.06173251119780675\n",
      "Loss: 0.058207172779156754\n",
      "tensor(True) tensor(True)\n",
      "______\n",
      "Iteration t=1\n",
      "all:  cs/acc_i=73.03 cs/acc_c=72.69 os/recall_knw=84.07 os/recall_unk=43.91 total/acc_i=60.17 total/acc_c=66.62 total/h_score=53.29\n",
      "selected:  cs/acc_i=64.37 cs/acc_c=64.40 os/recall_knw=50.50 os/recall_unk=97.84 total/acc_i=68.31 total/acc_c=51.79 total/h_score=65.73\n",
      "Loss: 1.646648097349091\n",
      "Loss: 0.2757592242713903\n",
      "Loss: 0.170320374325512\n",
      "Loss: 0.12470839606266629\n",
      "Loss: 0.11198285277475792\n",
      "Loss: 0.09250200470120995\n",
      "Loss: 0.0771304404882977\n",
      "Loss: 0.06993475127279576\n",
      "Loss: 0.06056128696472801\n",
      "Loss: 0.054332365794678684\n",
      "______\n",
      "Iteration t=2\n",
      "all:  cs/acc_i=72.85 cs/acc_c=72.49 os/recall_knw=60.59 os/recall_unk=78.79 total/acc_i=63.53 total/acc_c=57.03 total/h_score=65.43\n",
      "selected:  cs/acc_i=63.86 cs/acc_c=64.36 os/recall_knw=43.29 os/recall_unk=92.46 total/acc_i=59.36 total/acc_c=43.29 total/h_score=56.65\n",
      "Loss: 1.5893856668296982\n",
      "Loss: 0.27037159081767587\n",
      "Loss: 0.153023725671365\n",
      "Loss: 0.12403644567684216\n",
      "Loss: 0.10011401362169314\n",
      "Loss: 0.0871749964542687\n",
      "Loss: 0.0700173515621025\n",
      "Loss: 0.06577588844606105\n",
      "Loss: 0.05515901753541959\n",
      "Loss: 0.048275296828326056\n",
      "______\n",
      "Iteration t=3\n",
      "all:  cs/acc_i=73.28 cs/acc_c=72.80 os/recall_knw=58.38 os/recall_unk=81.18 total/acc_i=63.24 total/acc_c=55.69 total/h_score=65.16\n",
      "selected:  cs/acc_i=68.03 cs/acc_c=68.17 os/recall_knw=48.84 os/recall_unk=87.80 total/acc_i=60.17 total/acc_c=48.09 total/h_score=60.46\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 1.577298336771139\n",
      "Loss: 0.25669759764545663\n",
      "Loss: 0.1616901217235459\n",
      "Loss: 0.11834771539007666\n",
      "Loss: 0.10312097446403952\n",
      "Loss: 0.07898949285931992\n",
      "Loss: 0.06995932675335567\n",
      "Loss: 0.06325474995960537\n",
      "Loss: 0.05642510816836969\n",
      "Loss: 0.04915546015849565\n",
      "______\n",
      "Iteration t=4\n",
      "all:  cs/acc_i=73.13 cs/acc_c=72.73 os/recall_knw=57.59 os/recall_unk=81.55 total/acc_i=62.86 total/acc_c=54.97 total/h_score=64.72\n",
      "selected:  cs/acc_i=69.74 cs/acc_c=69.91 os/recall_knw=51.85 os/recall_unk=83.61 total/acc_i=60.28 total/acc_c=50.50 total/h_score=61.66\n",
      "Loss: 1.5474725266575147\n",
      "Loss: 0.2521106882239354\n",
      "Loss: 0.15338549335804566\n",
      "Loss: 0.11258727983264617\n",
      "Loss: 0.0927980216688284\n",
      "Loss: 0.07887101489478233\n",
      "Loss: 0.06782869327756155\n",
      "Loss: 0.061800261325978115\n",
      "Loss: 0.052526521744914144\n",
      "Loss: 0.044913281127290185\n",
      "______\n",
      "Iteration t=5\n",
      "all:  cs/acc_i=74.06 cs/acc_c=73.59 os/recall_knw=57.20 os/recall_unk=81.70 total/acc_i=62.64 total/acc_c=54.60 total/h_score=64.47\n",
      "selected:  cs/acc_i=72.48 cs/acc_c=72.32 os/recall_knw=54.40 os/recall_unk=81.89 total/acc_i=61.14 total/acc_c=52.57 total/h_score=62.93\n",
      "Loss: 1.5548914912318395\n",
      "Loss: 0.25122213622262657\n",
      "Loss: 0.156631625460117\n",
      "Loss: 0.12003980876144135\n",
      "Loss: 0.09384752482627377\n",
      "Loss: 0.07832683404630497\n",
      "Loss: 0.06689859074655889\n",
      "Loss: 0.0627548993814008\n",
      "Loss: 0.05060644020049348\n",
      "Loss: 0.048002750585214866\n",
      "______\n",
      "Iteration t=6\n",
      "all:  cs/acc_i=74.28 cs/acc_c=73.76 os/recall_knw=57.13 os/recall_unk=81.70 total/acc_i=62.59 total/acc_c=54.51 total/h_score=64.41\n",
      "selected:  cs/acc_i=73.63 cs/acc_c=73.22 os/recall_knw=56.00 os/recall_unk=81.82 total/acc_i=61.98 total/acc_c=53.70 total/h_score=63.81\n",
      "Loss: 1.5444368237191861\n",
      "Loss: 0.2571000156649312\n",
      "Loss: 0.1474000625566788\n",
      "Loss: 0.11825042089213277\n",
      "Loss: 0.09072857428739062\n",
      "Loss: 0.07995467490511514\n",
      "Loss: 0.06804325722814461\n",
      "Loss: 0.06184003618036911\n",
      "Loss: 0.048673227917952616\n",
      "Loss: 0.04664345632454818\n",
      "______\n",
      "Iteration t=7\n",
      "all:  cs/acc_i=74.31 cs/acc_c=73.78 os/recall_knw=57.06 os/recall_unk=81.78 total/acc_i=62.57 total/acc_c=54.43 total/h_score=64.36\n",
      "selected:  cs/acc_i=74.24 cs/acc_c=73.71 os/recall_knw=56.93 os/recall_unk=81.84 total/acc_i=62.51 total/acc_c=54.35 total/h_score=64.32\n",
      "Loss: 1.5391792220104\n",
      "Loss: 0.24650711307059164\n",
      "Loss: 0.14664991685371523\n",
      "Loss: 0.11462118417915443\n",
      "Loss: 0.0952035859657411\n",
      "Loss: 0.07890457906203506\n",
      "Loss: 0.07133491724886445\n",
      "Loss: 0.05829965864541009\n",
      "Loss: 0.04901508724192947\n",
      "Loss: 0.042971563188273096\n",
      "______\n",
      "Iteration t=8\n",
      "all:  cs/acc_i=74.10 cs/acc_c=73.48 os/recall_knw=57.06 os/recall_unk=81.78 total/acc_i=62.57 total/acc_c=54.43 total/h_score=64.36\n",
      "selected:  cs/acc_i=74.09 cs/acc_c=73.47 os/recall_knw=57.04 os/recall_unk=81.78 total/acc_i=62.56 total/acc_c=54.42 total/h_score=64.35\n",
      "Loss: 1.5271953896778385\n",
      "Loss: 0.24083579471965794\n",
      "Loss: 0.15066181231280007\n",
      "Loss: 0.11496563659612402\n",
      "Loss: 0.09292735501134461\n",
      "Loss: 0.07832466024491522\n",
      "Loss: 0.06824925564214344\n",
      "Loss: 0.05919277426839723\n",
      "Loss: 0.05006200996944353\n",
      "Loss: 0.045090884717337805\n",
      "______\n",
      "Iteration t=9\n",
      "all:  cs/acc_i=74.03 cs/acc_c=73.48 os/recall_knw=57.06 os/recall_unk=81.78 total/acc_i=62.57 total/acc_c=54.43 total/h_score=64.36\n",
      "selected:  cs/acc_i=74.03 cs/acc_c=73.48 os/recall_knw=57.06 os/recall_unk=81.78 total/acc_i=62.57 total/acc_c=54.43 total/h_score=64.36\n",
      "tensor(0)\n",
      "all:  cs/acc_i=74.03 cs/acc_c=73.48 os/recall_knw=57.06 os/recall_unk=81.78 total/acc_i=62.57 total/acc_c=54.43 total/h_score=64.36\n",
      "real -> sketch lr= 0.001 seed= 0\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19]\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20]\n",
      "Loss: 1.8090909650529408\n",
      "Loss: 0.33556871993792015\n",
      "Loss: 0.18784823188445535\n",
      "Loss: 0.1447817085648877\n",
      "Loss: 0.12281728966088694\n",
      "Loss: 0.10662811093721737\n",
      "Loss: 0.09200584494717605\n",
      "Loss: 0.07972908733260164\n",
      "Loss: 0.076922916951407\n",
      "Loss: 0.06361005474644252\n",
      "tensor(True) tensor(True)\n",
      "______\n",
      "Iteration t=1\n",
      "all:  cs/acc_i=54.78 cs/acc_c=54.25 os/recall_knw=92.62 os/recall_unk=14.87 total/acc_i=40.11 total/acc_c=51.31 total/h_score=23.23\n",
      "selected:  cs/acc_i=70.46 cs/acc_c=64.46 os/recall_knw=68.92 os/recall_unk=89.02 total/acc_i=72.21 total/acc_c=60.91 total/h_score=71.33\n",
      "Loss: 1.7340563813508567\n",
      "Loss: 0.295077357327534\n",
      "Loss: 0.17565898775928102\n",
      "Loss: 0.1365799180405625\n",
      "Loss: 0.11275424669670352\n",
      "Loss: 0.09624272767075542\n",
      "Loss: 0.0862859071784858\n",
      "Loss: 0.07265443005204453\n",
      "Loss: 0.06358087498899866\n",
      "Loss: 0.058459954855616315\n",
      "______\n",
      "Iteration t=2\n",
      "all:  cs/acc_i=54.57 cs/acc_c=54.11 os/recall_knw=57.23 os/recall_unk=74.75 total/acc_i=55.52 total/acc_c=46.29 total/h_score=56.07\n",
      "selected:  cs/acc_i=49.08 cs/acc_c=48.40 os/recall_knw=41.71 os/recall_unk=91.22 total/acc_i=56.90 total/acc_c=38.30 total/h_score=51.27\n",
      "Loss: 1.6762034385435043\n",
      "Loss: 0.28009720665793264\n",
      "Loss: 0.1691111832316364\n",
      "Loss: 0.12867208856248086\n",
      "Loss: 0.10815754364875536\n",
      "Loss: 0.08622826695622456\n",
      "Loss: 0.07559063943823979\n",
      "Loss: 0.06585051102503653\n",
      "Loss: 0.056426709185865134\n",
      "Loss: 0.04894183448575918\n",
      "______\n",
      "Iteration t=3\n",
      "all:  cs/acc_i=54.09 cs/acc_c=53.54 os/recall_knw=51.21 os/recall_unk=80.18 total/acc_i=55.62 total/acc_c=43.82 total/h_score=55.13\n",
      "selected:  cs/acc_i=50.00 cs/acc_c=49.65 os/recall_knw=44.88 os/recall_unk=86.08 total/acc_i=54.61 total/acc_c=38.95 total/h_score=51.36\n",
      "Loss: 1.6707478778384557\n",
      "Loss: 0.2873955707405215\n",
      "Loss: 0.16340096035502225\n",
      "Loss: 0.1231323890213933\n",
      "Loss: 0.10502437563653676\n",
      "Loss: 0.07987076246014266\n",
      "Loss: 0.07140341661493309\n",
      "Loss: 0.06588796448293273\n",
      "Loss: 0.05866105517668423\n",
      "Loss: 0.05002612581061681\n",
      "______\n",
      "Iteration t=4\n",
      "all:  cs/acc_i=53.76 cs/acc_c=53.10 os/recall_knw=50.58 os/recall_unk=81.06 total/acc_i=55.59 total/acc_c=43.39 total/h_score=54.90\n",
      "selected:  cs/acc_i=51.45 cs/acc_c=50.87 os/recall_knw=47.02 os/recall_unk=84.86 total/acc_i=55.11 total/acc_c=40.74 total/h_score=53.00\n",
      "Loss: 1.6522001459965339\n",
      "Loss: 0.2868654084434876\n",
      "Loss: 0.15639987219411594\n",
      "Loss: 0.1251262797529881\n",
      "Loss: 0.09507181691722227\n",
      "Loss: 0.08535507165182095\n",
      "Loss: 0.07187518932641698\n",
      "Loss: 0.058010478852173454\n",
      "Loss: 0.055240405551516096\n",
      "Loss: 0.051603508456251945\n",
      "______\n",
      "Iteration t=5\n",
      "all:  cs/acc_i=54.49 cs/acc_c=53.90 os/recall_knw=50.44 os/recall_unk=81.19 total/acc_i=55.57 total/acc_c=43.31 total/h_score=54.86\n",
      "selected:  cs/acc_i=53.83 cs/acc_c=53.40 os/recall_knw=49.27 os/recall_unk=83.23 total/acc_i=55.64 total/acc_c=42.69 total/h_score=54.63\n",
      "Loss: 1.6450110821557262\n",
      "Loss: 0.27564547937872924\n",
      "Loss: 0.1620519259848312\n",
      "Loss: 0.11885616145348657\n",
      "Loss: 0.09975567537906231\n",
      "Loss: 0.08004356752854622\n",
      "Loss: 0.07015826960170704\n",
      "Loss: 0.06427395729472617\n",
      "Loss: 0.056720683011466974\n",
      "Loss: 0.046152323102267134\n",
      "______\n",
      "Iteration t=6\n",
      "all:  cs/acc_i=54.86 cs/acc_c=54.25 os/recall_knw=50.33 os/recall_unk=81.33 total/acc_i=55.55 total/acc_c=43.23 total/h_score=54.80\n",
      "selected:  cs/acc_i=54.68 cs/acc_c=54.15 os/recall_knw=50.09 os/recall_unk=81.94 total/acc_i=55.58 total/acc_c=43.12 total/h_score=54.81\n",
      "Loss: 1.6454238063958755\n",
      "Loss: 0.284846601536475\n",
      "Loss: 0.1605499119845679\n",
      "Loss: 0.11605862257665539\n",
      "Loss: 0.10625686470968985\n",
      "Loss: 0.07727647063894624\n",
      "Loss: 0.07163238831717207\n",
      "Loss: 0.061754719711873816\n",
      "Loss: 0.05600748604573085\n",
      "Loss: 0.04544526153154312\n",
      "______\n",
      "Iteration t=7\n",
      "all:  cs/acc_i=55.04 cs/acc_c=54.36 os/recall_knw=50.33 os/recall_unk=81.33 total/acc_i=55.55 total/acc_c=43.23 total/h_score=54.80\n",
      "selected:  cs/acc_i=55.04 cs/acc_c=54.36 os/recall_knw=50.33 os/recall_unk=81.33 total/acc_i=55.55 total/acc_c=43.23 total/h_score=54.80\n",
      "Loss: 1.6499022190649826\n",
      "Loss: 0.2883844026644905\n",
      "Loss: 0.158165134410991\n",
      "Loss: 0.12232255181634283\n",
      "Loss: 0.1039281398792897\n",
      "Loss: 0.07970758257097149\n",
      "Loss: 0.07094177197390068\n",
      "Loss: 0.06098874801551048\n",
      "Loss: 0.056978648821598886\n",
      "Loss: 0.044548150151968\n",
      "______\n",
      "Iteration t=8\n",
      "all:  cs/acc_i=55.62 cs/acc_c=55.13 os/recall_knw=50.33 os/recall_unk=81.33 total/acc_i=55.55 total/acc_c=43.23 total/h_score=54.80\n",
      "selected:  cs/acc_i=55.62 cs/acc_c=55.13 os/recall_knw=50.33 os/recall_unk=81.33 total/acc_i=55.55 total/acc_c=43.23 total/h_score=54.80\n",
      "Loss: 1.6552848948771695\n",
      "Loss: 0.2804809759359762\n",
      "Loss: 0.16440658456455154\n",
      "Loss: 0.11865851228091731\n",
      "Loss: 0.09647587395037513\n",
      "Loss: 0.08495362922380936\n",
      "Loss: 0.06741955556558916\n",
      "Loss: 0.05937484791642616\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.05191843869888325\n",
      "Loss: 0.04812965333652514\n",
      "______\n",
      "Iteration t=9\n",
      "all:  cs/acc_i=54.64 cs/acc_c=54.04 os/recall_knw=50.33 os/recall_unk=81.33 total/acc_i=55.55 total/acc_c=43.23 total/h_score=54.80\n",
      "selected:  cs/acc_i=54.64 cs/acc_c=54.04 os/recall_knw=50.33 os/recall_unk=81.33 total/acc_i=55.55 total/acc_c=43.23 total/h_score=54.80\n",
      "tensor(0)\n",
      "all:  cs/acc_i=54.64 cs/acc_c=54.04 os/recall_knw=50.33 os/recall_unk=81.33 total/acc_i=55.55 total/acc_c=43.23 total/h_score=54.80\n",
      "real -> sketch lr= 0.001 seed= 1\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19]\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20]\n",
      "Loss: 1.8157299073989706\n",
      "Loss: 0.3369721838428881\n",
      "Loss: 0.20044101003119955\n",
      "Loss: 0.14575634472522872\n",
      "Loss: 0.12252322137289517\n",
      "Loss: 0.10805363335325201\n",
      "Loss: 0.09154449161672401\n",
      "Loss: 0.07924953941255808\n",
      "Loss: 0.07453934905646216\n",
      "Loss: 0.05963577262168995\n",
      "tensor(True) tensor(True)\n",
      "______\n",
      "Iteration t=1\n",
      "all:  cs/acc_i=55.88 cs/acc_c=55.40 os/recall_knw=92.33 os/recall_unk=14.32 total/acc_i=40.77 total/acc_c=52.62 total/h_score=22.69\n",
      "selected:  cs/acc_i=68.40 cs/acc_c=63.55 os/recall_knw=67.79 os/recall_unk=85.77 total/acc_i=70.49 total/acc_c=61.03 total/h_score=70.47\n",
      "Loss: 1.7238358737447776\n",
      "Loss: 0.29851444405377714\n",
      "Loss: 0.18179271307245298\n",
      "Loss: 0.13537609743306767\n",
      "Loss: 0.11304400522714934\n",
      "Loss: 0.09811789482655758\n",
      "Loss: 0.08142182000163892\n",
      "Loss: 0.07075316637024484\n",
      "Loss: 0.0626124748669099\n",
      "Loss: 0.061992647151487904\n",
      "______\n",
      "Iteration t=2\n",
      "all:  cs/acc_i=56.17 cs/acc_c=55.63 os/recall_knw=58.80 os/recall_unk=72.23 total/acc_i=55.81 total/acc_c=47.77 total/h_score=56.61\n",
      "selected:  cs/acc_i=50.38 cs/acc_c=50.25 os/recall_knw=42.71 os/recall_unk=91.10 total/acc_i=57.51 total/acc_c=40.00 total/h_score=53.07\n",
      "Loss: 1.6792929417664004\n",
      "Loss: 0.28846209789476085\n",
      "Loss: 0.17300352751007003\n",
      "Loss: 0.12991817713144324\n",
      "Loss: 0.10780270612768589\n",
      "Loss: 0.08809567502128982\n",
      "Loss: 0.07686676392331719\n",
      "Loss: 0.06459343136708823\n",
      "Loss: 0.05741730804795459\n",
      "Loss: 0.05289081656824677\n",
      "______\n",
      "Iteration t=3\n",
      "all:  cs/acc_i=55.84 cs/acc_c=55.23 os/recall_knw=55.04 os/recall_unk=77.87 total/acc_i=56.68 total/acc_c=46.49 total/h_score=56.97\n",
      "selected:  cs/acc_i=51.63 cs/acc_c=51.12 os/recall_knw=47.26 os/recall_unk=86.63 total/acc_i=56.40 total/acc_c=41.37 total/h_score=53.89\n",
      "Loss: 1.649197881188348\n",
      "Loss: 0.2903430043397663\n",
      "Loss: 0.16513017620717255\n",
      "Loss: 0.12694221495351873\n",
      "Loss: 0.10116403093532517\n",
      "Loss: 0.08670539986864428\n",
      "Loss: 0.07199476963646037\n",
      "Loss: 0.05881897080399537\n",
      "Loss: 0.05505288172458121\n",
      "Loss: 0.04977459429162685\n",
      "______\n",
      "Iteration t=4\n",
      "all:  cs/acc_i=54.64 cs/acc_c=53.94 os/recall_knw=53.54 os/recall_unk=79.77 total/acc_i=56.78 total/acc_c=45.70 total/h_score=56.72\n",
      "selected:  cs/acc_i=51.87 cs/acc_c=51.32 os/recall_knw=49.44 os/recall_unk=84.65 total/acc_i=56.35 total/acc_c=42.72 total/h_score=54.90\n",
      "Loss: 1.6519835930477622\n",
      "Loss: 0.2757594539252527\n",
      "Loss: 0.16212454863875372\n",
      "Loss: 0.12209189834038904\n",
      "Loss: 0.10238265297004233\n",
      "Loss: 0.08046313337238928\n",
      "Loss: 0.07171023490787284\n",
      "Loss: 0.06420589657857488\n",
      "Loss: 0.05454660793680675\n",
      "Loss: 0.050935763892849074\n",
      "______\n",
      "Iteration t=5\n",
      "all:  cs/acc_i=55.70 cs/acc_c=54.92 os/recall_knw=53.14 os/recall_unk=80.24 total/acc_i=56.68 total/acc_c=45.34 total/h_score=56.50\n",
      "selected:  cs/acc_i=54.39 cs/acc_c=53.64 os/recall_knw=51.40 os/recall_unk=82.48 total/acc_i=56.42 total/acc_c=43.87 total/h_score=55.61\n",
      "Loss: 1.6455723013942696\n",
      "Loss: 0.287820403309387\n",
      "Loss: 0.16754661428424167\n",
      "Loss: 0.1246276326207416\n",
      "Loss: 0.09365447891983021\n",
      "Loss: 0.081898631594141\n",
      "Loss: 0.07250253056538969\n",
      "Loss: 0.05800192238301534\n",
      "Loss: 0.05118593871115153\n",
      "Loss: 0.04970914506553208\n",
      "______\n",
      "Iteration t=6\n",
      "all:  cs/acc_i=55.70 cs/acc_c=55.06 os/recall_knw=53.10 os/recall_unk=80.24 total/acc_i=56.66 total/acc_c=45.30 total/h_score=56.47\n",
      "selected:  cs/acc_i=55.33 cs/acc_c=54.67 os/recall_knw=52.60 os/recall_unk=81.29 total/acc_i=56.69 total/acc_c=44.89 total/h_score=56.31\n",
      "Loss: 1.636348528240969\n",
      "Loss: 0.27678548930558616\n",
      "Loss: 0.1583945860327807\n",
      "Loss: 0.12079625329125428\n",
      "Loss: 0.09926732712352794\n",
      "Loss: 0.0823395683870701\n",
      "Loss: 0.07281624687512121\n",
      "Loss: 0.05984617368608133\n",
      "Loss: 0.050096913254791924\n",
      "Loss: 0.04778897837863978\n",
      "______\n",
      "Iteration t=7\n",
      "all:  cs/acc_i=55.73 cs/acc_c=55.09 os/recall_knw=53.10 os/recall_unk=80.24 total/acc_i=56.64 total/acc_c=45.27 total/h_score=56.44\n",
      "selected:  cs/acc_i=55.74 cs/acc_c=55.10 os/recall_knw=53.04 os/recall_unk=80.24 total/acc_i=56.64 total/acc_c=45.26 total/h_score=56.43\n",
      "Loss: 1.6387798972983858\n",
      "Loss: 0.2767551877827787\n",
      "Loss: 0.16557722513133022\n",
      "Loss: 0.11908007717844266\n",
      "Loss: 0.09710307806841473\n",
      "Loss: 0.07696506998765824\n",
      "Loss: 0.07113850252675032\n",
      "Loss: 0.061341853267443715\n",
      "Loss: 0.0543687291693554\n",
      "Loss: 0.04512785741809144\n",
      "______\n",
      "Iteration t=8\n",
      "all:  cs/acc_i=56.28 cs/acc_c=55.52 os/recall_knw=53.10 os/recall_unk=80.24 total/acc_i=56.64 total/acc_c=45.27 total/h_score=56.44\n",
      "selected:  cs/acc_i=56.28 cs/acc_c=55.52 os/recall_knw=53.10 os/recall_unk=80.24 total/acc_i=56.64 total/acc_c=45.27 total/h_score=56.44\n",
      "Loss: 1.6464228359620963\n",
      "Loss: 0.2829062725625821\n",
      "Loss: 0.16224713435591157\n",
      "Loss: 0.11754685661463596\n",
      "Loss: 0.0951421817069623\n",
      "Loss: 0.08397912152333936\n",
      "Loss: 0.0692832458736514\n",
      "Loss: 0.06555032354376432\n",
      "Loss: 0.05547623074293804\n",
      "Loss: 0.044477074338929425\n",
      "______\n",
      "Iteration t=9\n",
      "all:  cs/acc_i=55.95 cs/acc_c=55.22 os/recall_knw=53.10 os/recall_unk=80.24 total/acc_i=56.64 total/acc_c=45.27 total/h_score=56.44\n",
      "selected:  cs/acc_i=55.95 cs/acc_c=55.22 os/recall_knw=53.10 os/recall_unk=80.24 total/acc_i=56.64 total/acc_c=45.27 total/h_score=56.44\n",
      "tensor(0)\n",
      "all:  cs/acc_i=55.95 cs/acc_c=55.22 os/recall_knw=53.10 os/recall_unk=80.24 total/acc_i=56.64 total/acc_c=45.27 total/h_score=56.44\n",
      "real -> sketch lr= 0.001 seed= 2\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19]\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20]\n",
      "Loss: 1.8038303579512016\n",
      "Loss: 0.3266786047890517\n",
      "Loss: 0.1953134671834652\n",
      "Loss: 0.14703984541347867\n",
      "Loss: 0.1211513038326943\n",
      "Loss: 0.11031531482881923\n",
      "Loss: 0.09518468763772067\n",
      "Loss: 0.0791345857468258\n",
      "Loss: 0.07426006024955271\n",
      "Loss: 0.06231038787591128\n",
      "tensor(True) tensor(True)\n",
      "______\n",
      "Iteration t=1\n",
      "all:  cs/acc_i=55.19 cs/acc_c=54.63 os/recall_knw=92.99 os/recall_unk=15.55 total/acc_i=40.89 total/acc_c=52.11 total/h_score=24.14\n",
      "selected:  cs/acc_i=70.40 cs/acc_c=63.92 os/recall_knw=70.09 os/recall_unk=89.11 total/acc_i=73.75 total/acc_c=62.37 total/h_score=72.44\n",
      "Loss: 1.7183102244460904\n",
      "Loss: 0.3026922904710109\n",
      "Loss: 0.17358634602026762\n",
      "Loss: 0.14086281330123343\n",
      "Loss: 0.11637050725796537\n",
      "Loss: 0.09744560226760302\n",
      "Loss: 0.08100198111748574\n",
      "Loss: 0.06826423459082238\n",
      "Loss: 0.06205712480634149\n",
      "Loss: 0.059583038686321595\n",
      "______\n",
      "Iteration t=2\n",
      "all:  cs/acc_i=55.51 cs/acc_c=54.89 os/recall_knw=52.37 os/recall_unk=79.23 total/acc_i=56.64 total/acc_c=45.63 total/h_score=56.53\n",
      "selected:  cs/acc_i=49.04 cs/acc_c=48.75 os/recall_knw=39.04 os/recall_unk=91.46 total/acc_i=56.05 total/acc_c=37.24 total/h_score=50.13\n",
      "Loss: 1.682653752642293\n",
      "Loss: 0.28270783448411574\n",
      "Loss: 0.16582261898344564\n",
      "Loss: 0.13188425767565928\n",
      "Loss: 0.1001876874436294\n",
      "Loss: 0.08837089326172587\n",
      "Loss: 0.0792662622286908\n",
      "Loss: 0.06648020958978562\n",
      "Loss: 0.05653493596961902\n",
      "Loss: 0.04988695926919219\n",
      "______\n",
      "Iteration t=3\n",
      "all:  cs/acc_i=54.86 cs/acc_c=54.19 os/recall_knw=49.42 os/recall_unk=82.55 total/acc_i=56.59 total/acc_c=44.07 total/h_score=55.81\n",
      "selected:  cs/acc_i=51.06 cs/acc_c=50.71 os/recall_knw=43.33 os/recall_unk=89.02 total/acc_i=55.88 total/acc_c=39.69 total/h_score=52.49\n",
      "Loss: 1.6689720555858791\n",
      "Loss: 0.27551766117132687\n",
      "Loss: 0.16980392318336093\n",
      "Loss: 0.126484047495555\n",
      "Loss: 0.10606718213303284\n",
      "Loss: 0.07984506878006102\n",
      "Loss: 0.07398141551259085\n",
      "Loss: 0.06543645642568949\n",
      "Loss: 0.057745651328795645\n",
      "Loss: 0.05165904182567314\n",
      "______\n",
      "Iteration t=4\n",
      "all:  cs/acc_i=55.22 cs/acc_c=54.45 os/recall_knw=49.20 os/recall_unk=82.82 total/acc_i=56.59 total/acc_c=43.95 total/h_score=55.75\n",
      "selected:  cs/acc_i=53.25 cs/acc_c=52.55 os/recall_knw=46.13 os/recall_unk=86.71 total/acc_i=56.30 total/acc_c=41.67 total/h_score=54.20\n",
      "Loss: 1.6794627158914084\n",
      "Loss: 0.285087392711437\n",
      "Loss: 0.16924692487436127\n",
      "Loss: 0.12179003378238391\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.0990239824542063\n",
      "Loss: 0.082441661613246\n",
      "Loss: 0.06968789568665311\n",
      "Loss: 0.06026911924673635\n",
      "Loss: 0.052353796093540704\n",
      "Loss: 0.045475708257498935\n",
      "______\n",
      "Iteration t=5\n",
      "all:  cs/acc_i=55.48 cs/acc_c=54.76 os/recall_knw=49.16 os/recall_unk=83.03 total/acc_i=56.64 total/acc_c=43.93 total/h_score=55.76\n",
      "selected:  cs/acc_i=54.52 cs/acc_c=53.80 os/recall_knw=47.77 os/recall_unk=85.11 total/acc_i=56.53 total/acc_c=42.84 total/h_score=55.09\n",
      "Loss: 1.6538809742038039\n",
      "Loss: 0.2815019716522927\n",
      "Loss: 0.16703787842474946\n",
      "Loss: 0.12180442946880418\n",
      "Loss: 0.10073585284230177\n",
      "Loss: 0.0814810884626588\n",
      "Loss: 0.08028221072555045\n",
      "Loss: 0.06335694695301695\n",
      "Loss: 0.05482018319177883\n",
      "Loss: 0.049878231238357336\n",
      "______\n",
      "Iteration t=6\n",
      "all:  cs/acc_i=56.03 cs/acc_c=55.35 os/recall_knw=49.09 os/recall_unk=83.03 total/acc_i=56.61 total/acc_c=43.89 total/h_score=55.72\n",
      "selected:  cs/acc_i=55.87 cs/acc_c=55.22 os/recall_knw=48.83 os/recall_unk=83.82 total/acc_i=56.71 total/acc_c=43.75 total/h_score=55.74\n",
      "Loss: 1.6626076532132699\n",
      "Loss: 0.28772358521819114\n",
      "Loss: 0.15418788255615667\n",
      "Loss: 0.12519194613577742\n",
      "Loss: 0.09953629463120843\n",
      "Loss: 0.08161692688749596\n",
      "Loss: 0.07228711222044447\n",
      "Loss: 0.06417616960649011\n",
      "Loss: 0.05835266783127956\n",
      "Loss: 0.04807375802369224\n",
      "______\n",
      "Iteration t=7\n",
      "all:  cs/acc_i=56.50 cs/acc_c=55.85 os/recall_knw=49.05 os/recall_unk=83.03 total/acc_i=56.59 total/acc_c=43.86 total/h_score=55.70\n",
      "selected:  cs/acc_i=56.50 cs/acc_c=55.85 os/recall_knw=49.05 os/recall_unk=83.03 total/acc_i=56.59 total/acc_c=43.86 total/h_score=55.70\n",
      "Loss: 1.645356453187538\n",
      "Loss: 0.2834473600441759\n",
      "Loss: 0.16344027289499838\n",
      "Loss: 0.1239052424150886\n",
      "Loss: 0.09894709158406564\n",
      "Loss: 0.08046183448679971\n",
      "Loss: 0.07175528391010381\n",
      "Loss: 0.0593842510867751\n",
      "Loss: 0.054377574736083095\n",
      "Loss: 0.04781122953687428\n",
      "______\n",
      "Iteration t=8\n",
      "all:  cs/acc_i=57.01 cs/acc_c=56.35 os/recall_knw=49.05 os/recall_unk=83.03 total/acc_i=56.59 total/acc_c=43.86 total/h_score=55.70\n",
      "selected:  cs/acc_i=57.01 cs/acc_c=56.35 os/recall_knw=49.05 os/recall_unk=83.03 total/acc_i=56.59 total/acc_c=43.86 total/h_score=55.70\n",
      "Loss: 1.6446073597127742\n",
      "Loss: 0.2863516708440853\n",
      "Loss: 0.16334935007899096\n",
      "Loss: 0.12002302484981942\n",
      "Loss: 0.09940860693653425\n",
      "Loss: 0.08100578074033062\n",
      "Loss: 0.0769321623427624\n",
      "Loss: 0.06397513434234442\n",
      "Loss: 0.05101165392040981\n",
      "Loss: 0.04554647000534742\n",
      "______\n",
      "Iteration t=9\n",
      "all:  cs/acc_i=56.65 cs/acc_c=56.07 os/recall_knw=49.05 os/recall_unk=83.03 total/acc_i=56.59 total/acc_c=43.86 total/h_score=55.70\n",
      "selected:  cs/acc_i=56.65 cs/acc_c=56.07 os/recall_knw=49.05 os/recall_unk=83.03 total/acc_i=56.59 total/acc_c=43.86 total/h_score=55.70\n",
      "tensor(0)\n",
      "all:  cs/acc_i=56.65 cs/acc_c=56.07 os/recall_knw=49.05 os/recall_unk=83.03 total/acc_i=56.59 total/acc_c=43.86 total/h_score=55.70\n",
      "real -> sketch lr= 0.001 seed= 3\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19]\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20]\n",
      "Loss: 1.8000920971729577\n",
      "Loss: 0.32906946632679673\n",
      "Loss: 0.1969280140971586\n",
      "Loss: 0.1568248466558728\n",
      "Loss: 0.12784675815643154\n",
      "Loss: 0.10368711125185164\n",
      "Loss: 0.08806705832799558\n",
      "Loss: 0.08088126937358299\n",
      "Loss: 0.07194888592926368\n",
      "Loss: 0.06720066905764074\n",
      "tensor(True) tensor(True)\n",
      "______\n",
      "Iteration t=1\n",
      "all:  cs/acc_i=54.49 cs/acc_c=53.96 os/recall_knw=93.13 os/recall_unk=15.82 total/acc_i=40.66 total/acc_c=51.70 total/h_score=24.42\n",
      "selected:  cs/acc_i=69.72 cs/acc_c=63.69 os/recall_knw=70.35 os/recall_unk=88.59 total/acc_i=73.80 total/acc_c=62.92 total/h_score=72.69\n",
      "Loss: 1.7269482259210702\n",
      "Loss: 0.29162050056195743\n",
      "Loss: 0.17418090898442912\n",
      "Loss: 0.13205402640537736\n",
      "Loss: 0.12511925409371788\n",
      "Loss: 0.09498950336883599\n",
      "Loss: 0.0824356100087784\n",
      "Loss: 0.07002171563972542\n",
      "Loss: 0.06649611740549272\n",
      "Loss: 0.053819584293681125\n",
      "______\n",
      "Iteration t=2\n",
      "all:  cs/acc_i=55.66 cs/acc_c=55.23 os/recall_knw=62.45 os/recall_unk=66.33 total/acc_i=54.24 total/acc_c=48.38 total/h_score=55.35\n",
      "selected:  cs/acc_i=50.97 cs/acc_c=50.16 os/recall_knw=44.85 os/recall_unk=89.96 total/acc_i=57.97 total/acc_c=41.10 total/h_score=54.08\n",
      "Loss: 1.6845950986108473\n",
      "Loss: 0.282110935966334\n",
      "Loss: 0.16546287190529607\n",
      "Loss: 0.1328974981642058\n",
      "Loss: 0.10841754730190001\n",
      "Loss: 0.09106706445586056\n",
      "Loss: 0.07414175818914608\n",
      "Loss: 0.06801699970383197\n",
      "Loss: 0.06290278920242863\n",
      "Loss: 0.052583946421321845\n",
      "______\n",
      "Iteration t=3\n",
      "all:  cs/acc_i=54.02 cs/acc_c=53.56 os/recall_knw=55.37 os/recall_unk=76.04 total/acc_i=55.47 total/acc_c=45.78 total/h_score=55.95\n",
      "selected:  cs/acc_i=49.89 cs/acc_c=49.52 os/recall_knw=48.07 os/recall_unk=84.78 total/acc_i=55.28 total/acc_c=40.89 total/h_score=53.13\n",
      "Loss: 1.65648859554196\n",
      "Loss: 0.27670535905668453\n",
      "Loss: 0.15735392399733852\n",
      "Loss: 0.12638909128778006\n",
      "Loss: 0.10370126527138286\n",
      "Loss: 0.08161015105751916\n",
      "Loss: 0.07440068289892089\n",
      "Loss: 0.06151280033992176\n",
      "Loss: 0.05477170226878562\n",
      "Loss: 0.04751251999835443\n",
      "______\n",
      "Iteration t=4\n",
      "all:  cs/acc_i=53.94 cs/acc_c=53.39 os/recall_knw=53.83 os/recall_unk=77.87 total/acc_i=55.55 total/acc_c=44.98 total/h_score=55.68\n",
      "selected:  cs/acc_i=51.69 cs/acc_c=51.14 os/recall_knw=50.39 os/recall_unk=82.52 total/acc_i=55.33 total/acc_c=42.39 total/h_score=54.22\n",
      "Loss: 1.6595553221499049\n",
      "Loss: 0.27327632199882007\n",
      "Loss: 0.1640810298097388\n",
      "Loss: 0.11927293185371815\n",
      "Loss: 0.10270853371291262\n",
      "Loss: 0.081196866779043\n",
      "Loss: 0.07004498771431561\n",
      "Loss: 0.06181469035942516\n",
      "Loss: 0.053712277339555595\n",
      "Loss: 0.051615170878926066\n",
      "______\n",
      "Iteration t=5\n",
      "all:  cs/acc_i=54.71 cs/acc_c=54.10 os/recall_knw=53.43 os/recall_unk=78.00 total/acc_i=55.43 total/acc_c=44.73 total/h_score=55.50\n",
      "selected:  cs/acc_i=53.48 cs/acc_c=52.92 os/recall_knw=51.78 os/recall_unk=80.69 total/acc_i=55.31 total/acc_c=43.41 total/h_score=54.85\n",
      "Loss: 1.654474873768996\n",
      "Loss: 0.27690465283770876\n",
      "Loss: 0.16786445887669563\n",
      "Loss: 0.1219879957561168\n",
      "Loss: 0.09205898392878203\n",
      "Loss: 0.08379998816603637\n",
      "Loss: 0.07090113728015449\n",
      "Loss: 0.06104028289744922\n",
      "Loss: 0.05060813403884734\n",
      "Loss: 0.04757290583872517\n",
      "______\n",
      "Iteration t=6\n",
      "all:  cs/acc_i=55.33 cs/acc_c=54.66 os/recall_knw=53.40 os/recall_unk=78.21 total/acc_i=55.47 total/acc_c=44.71 total/h_score=55.52\n",
      "selected:  cs/acc_i=55.09 cs/acc_c=54.39 os/recall_knw=53.07 os/recall_unk=79.12 total/acc_i=55.54 total/acc_c=44.44 total/h_score=55.47\n",
      "Loss: 1.6653529644902072\n",
      "Loss: 0.28023027672029255\n",
      "Loss: 0.16670680952939523\n",
      "Loss: 0.12146219524985818\n",
      "Loss: 0.10422421501699224\n",
      "Loss: 0.08287838491152472\n",
      "Loss: 0.06943491601399077\n",
      "Loss: 0.06322025394400776\n",
      "Loss: 0.04951546158530374\n",
      "Loss: 0.0462006641829859\n",
      "______\n",
      "Iteration t=7\n",
      "all:  cs/acc_i=55.22 cs/acc_c=54.64 os/recall_knw=53.40 os/recall_unk=78.21 total/acc_i=55.47 total/acc_c=44.71 total/h_score=55.52\n",
      "selected:  cs/acc_i=55.22 cs/acc_c=54.64 os/recall_knw=53.40 os/recall_unk=78.21 total/acc_i=55.47 total/acc_c=44.71 total/h_score=55.52\n",
      "Loss: 1.6419145594395341\n",
      "Loss: 0.2797449434930015\n",
      "Loss: 0.1614907688261675\n",
      "Loss: 0.12100556224495881\n",
      "Loss: 0.10038716144793268\n",
      "Loss: 0.08347199033457964\n",
      "Loss: 0.07285075840107831\n",
      "Loss: 0.060519431825793744\n",
      "Loss: 0.05679579337620886\n",
      "Loss: 0.047189435662446724\n",
      "______\n",
      "Iteration t=8\n",
      "all:  cs/acc_i=55.92 cs/acc_c=55.30 os/recall_knw=53.40 os/recall_unk=78.21 total/acc_i=55.47 total/acc_c=44.71 total/h_score=55.52\n",
      "selected:  cs/acc_i=55.92 cs/acc_c=55.30 os/recall_knw=53.40 os/recall_unk=78.21 total/acc_i=55.47 total/acc_c=44.71 total/h_score=55.52\n",
      "Loss: 1.642478374498231\n",
      "Loss: 0.28260032552117037\n",
      "Loss: 0.16472652663166323\n",
      "Loss: 0.12211711844983733\n",
      "Loss: 0.09836432832248863\n",
      "Loss: 0.07995090549368233\n",
      "Loss: 0.06814753579064495\n",
      "Loss: 0.06065130018812072\n",
      "Loss: 0.053717683259275784\n",
      "Loss: 0.04544196509994522\n",
      "______\n",
      "Iteration t=9\n",
      "all:  cs/acc_i=54.78 cs/acc_c=54.16 os/recall_knw=53.40 os/recall_unk=78.21 total/acc_i=55.47 total/acc_c=44.71 total/h_score=55.52\n",
      "selected:  cs/acc_i=54.78 cs/acc_c=54.16 os/recall_knw=53.40 os/recall_unk=78.21 total/acc_i=55.47 total/acc_c=44.71 total/h_score=55.52\n",
      "tensor(0)\n",
      "all:  cs/acc_i=54.78 cs/acc_c=54.16 os/recall_knw=53.40 os/recall_unk=78.21 total/acc_i=55.47 total/acc_c=44.71 total/h_score=55.52\n",
      "real -> sketch lr= 0.001 seed= 4\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19]\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 1.799475712708307\n",
      "Loss: 0.3423459087349342\n",
      "Loss: 0.19482735429767825\n",
      "Loss: 0.1446677025115893\n",
      "Loss: 0.1247906261272861\n",
      "Loss: 0.11061687534840718\n",
      "Loss: 0.09118150895149894\n",
      "Loss: 0.08259671068090774\n",
      "Loss: 0.0679845981949483\n",
      "Loss: 0.06129498597817807\n",
      "tensor(True) tensor(True)\n",
      "______\n",
      "Iteration t=1\n",
      "all:  cs/acc_i=55.51 cs/acc_c=54.84 os/recall_knw=93.21 os/recall_unk=15.95 total/acc_i=41.27 total/acc_c=52.42 total/h_score=24.66\n",
      "selected:  cs/acc_i=70.44 cs/acc_c=63.16 os/recall_knw=70.75 os/recall_unk=89.02 total/acc_i=74.00 total/acc_c=61.89 total/h_score=72.06\n",
      "Loss: 1.7409302572140823\n",
      "Loss: 0.30354603505819233\n",
      "Loss: 0.1769580815012592\n",
      "Loss: 0.13454858678065845\n",
      "Loss: 0.11206527940324836\n",
      "Loss: 0.09713923900287498\n",
      "Loss: 0.08628472851627078\n",
      "Loss: 0.0719725994921818\n",
      "Loss: 0.05805128639818773\n",
      "Loss: 0.0569705797164273\n",
      "______\n",
      "Iteration t=2\n",
      "all:  cs/acc_i=55.62 cs/acc_c=54.97 os/recall_knw=53.29 os/recall_unk=78.21 total/acc_i=56.33 total/acc_c=45.76 total/h_score=56.43\n",
      "selected:  cs/acc_i=49.36 cs/acc_c=49.07 os/recall_knw=39.58 os/recall_unk=91.43 total/acc_i=56.09 total/acc_c=37.60 total/h_score=50.53\n",
      "Loss: 1.706972794667367\n",
      "Loss: 0.2906900898102791\n",
      "Loss: 0.1707563727733589\n",
      "Loss: 0.12141342979044684\n",
      "Loss: 0.10597692238046758\n",
      "Loss: 0.08940968476536293\n",
      "Loss: 0.07902021764236833\n",
      "Loss: 0.06963075486597635\n",
      "Loss: 0.05880782544582842\n",
      "Loss: 0.051895814579761314\n",
      "______\n",
      "Iteration t=3\n",
      "all:  cs/acc_i=54.46 cs/acc_c=53.77 os/recall_knw=50.40 os/recall_unk=81.87 total/acc_i=56.52 total/acc_c=44.28 total/h_score=55.86\n",
      "selected:  cs/acc_i=50.55 cs/acc_c=49.94 os/recall_knw=44.32 os/recall_unk=87.26 total/acc_i=55.54 total/acc_c=39.62 total/h_score=52.20\n",
      "Loss: 1.667647478170693\n",
      "Loss: 0.2818009524838999\n",
      "Loss: 0.16721985028125347\n",
      "Loss: 0.12426492542144843\n",
      "Loss: 0.1061621762579307\n",
      "Loss: 0.08059852470469195\n",
      "Loss: 0.0727008820991614\n",
      "Loss: 0.06427688642579596\n",
      "Loss: 0.054397253750357775\n",
      "Loss: 0.04729391567379935\n",
      "______\n",
      "Iteration t=4\n",
      "all:  cs/acc_i=55.55 cs/acc_c=54.93 os/recall_knw=50.00 os/recall_unk=82.28 total/acc_i=56.49 total/acc_c=44.06 total/h_score=55.74\n",
      "selected:  cs/acc_i=53.67 cs/acc_c=53.16 os/recall_knw=47.14 os/recall_unk=85.59 total/acc_i=56.12 total/acc_c=41.93 total/h_score=54.28\n",
      "Loss: 1.6309398387028622\n",
      "Loss: 0.2677316908079844\n",
      "Loss: 0.15232948799545948\n",
      "Loss: 0.11662968651606487\n",
      "Loss: 0.1040401769372133\n",
      "Loss: 0.0853199355977659\n",
      "Loss: 0.07318870207438102\n",
      "Loss: 0.06208583757997706\n",
      "Loss: 0.05559832850041298\n",
      "Loss: 0.04619625272086034\n",
      "______\n",
      "Iteration t=5\n",
      "all:  cs/acc_i=55.84 cs/acc_c=55.03 os/recall_knw=49.67 os/recall_unk=82.48 total/acc_i=56.40 total/acc_c=43.82 total/h_score=55.56\n",
      "selected:  cs/acc_i=55.00 cs/acc_c=54.29 os/recall_knw=48.54 os/recall_unk=84.38 total/acc_i=56.31 total/acc_c=42.97 total/h_score=55.10\n",
      "Loss: 1.6567407172264121\n",
      "Loss: 0.27130725472120615\n",
      "Loss: 0.16177840019780687\n",
      "Loss: 0.10863296770513421\n",
      "Loss: 0.0971999339782065\n",
      "Loss: 0.08932114488490653\n",
      "Loss: 0.07007206248392056\n",
      "Loss: 0.05510570459059303\n",
      "Loss: 0.05598093522854558\n",
      "Loss: 0.05092225405856081\n",
      "______\n",
      "Iteration t=6\n",
      "all:  cs/acc_i=56.25 cs/acc_c=55.69 os/recall_knw=49.63 os/recall_unk=82.48 total/acc_i=56.38 total/acc_c=43.78 total/h_score=55.52\n",
      "selected:  cs/acc_i=56.09 cs/acc_c=55.59 os/recall_knw=49.45 os/recall_unk=82.88 total/acc_i=56.37 total/acc_c=43.67 total/h_score=55.50\n",
      "Loss: 1.6381100691697388\n",
      "Loss: 0.2774193977706382\n",
      "Loss: 0.16870639715174893\n",
      "Loss: 0.11899150921498901\n",
      "Loss: 0.09249282202027806\n",
      "Loss: 0.08200028417294344\n",
      "Loss: 0.07318676722565176\n",
      "Loss: 0.06026666702736405\n",
      "Loss: 0.04890963691638451\n",
      "Loss: 0.04632814804210224\n",
      "______\n",
      "Iteration t=7\n",
      "all:  cs/acc_i=56.87 cs/acc_c=56.11 os/recall_knw=49.63 os/recall_unk=82.48 total/acc_i=56.38 total/acc_c=43.78 total/h_score=55.52\n",
      "selected:  cs/acc_i=56.87 cs/acc_c=56.11 os/recall_knw=49.63 os/recall_unk=82.48 total/acc_i=56.38 total/acc_c=43.78 total/h_score=55.52\n",
      "Loss: 1.6575460236778432\n",
      "Loss: 0.27834426564392367\n",
      "Loss: 0.15589277097938464\n",
      "Loss: 0.1140462639896351\n",
      "Loss: 0.0954053891636994\n",
      "Loss: 0.08399679329038072\n",
      "Loss: 0.0750167996389088\n",
      "Loss: 0.060607757742215634\n",
      "Loss: 0.05819583794923663\n",
      "Loss: 0.04621745891351354\n",
      "______\n",
      "Iteration t=8\n",
      "all:  cs/acc_i=56.36 cs/acc_c=55.67 os/recall_knw=49.63 os/recall_unk=82.48 total/acc_i=56.38 total/acc_c=43.78 total/h_score=55.52\n",
      "selected:  cs/acc_i=56.36 cs/acc_c=55.67 os/recall_knw=49.63 os/recall_unk=82.48 total/acc_i=56.38 total/acc_c=43.78 total/h_score=55.52\n",
      "Loss: 1.6421247807154122\n",
      "Loss: 0.2704410238973684\n",
      "Loss: 0.1642078226854254\n",
      "Loss: 0.12186268164447067\n",
      "Loss: 0.09357564639176306\n",
      "Loss: 0.08221487884952762\n",
      "Loss: 0.07064798992869988\n",
      "Loss: 0.0612696895215469\n",
      "Loss: 0.051333545248539066\n",
      "Loss: 0.05033046439194382\n",
      "______\n",
      "Iteration t=9\n",
      "all:  cs/acc_i=55.77 cs/acc_c=55.15 os/recall_knw=49.63 os/recall_unk=82.48 total/acc_i=56.38 total/acc_c=43.78 total/h_score=55.52\n",
      "selected:  cs/acc_i=55.77 cs/acc_c=55.15 os/recall_knw=49.63 os/recall_unk=82.48 total/acc_i=56.38 total/acc_c=43.78 total/h_score=55.52\n",
      "tensor(0)\n",
      "all:  cs/acc_i=55.77 cs/acc_c=55.15 os/recall_knw=49.63 os/recall_unk=82.48 total/acc_i=56.38 total/acc_c=43.78 total/h_score=55.52\n",
      "real -> sketch lr= 0.001 seed= 0\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19]\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20]\n",
      "Loss: 1.8080772594200758\n",
      "Loss: 0.33556834197341334\n",
      "Loss: 0.18794300795608992\n",
      "Loss: 0.14506085228930587\n",
      "Loss: 0.12287870283467278\n",
      "Loss: 0.1066435390413868\n",
      "Loss: 0.0919586146628199\n",
      "Loss: 0.0794985465907568\n",
      "Loss: 0.07625297574803658\n",
      "Loss: 0.06354022019433381\n",
      "tensor(True) tensor(True)\n",
      "______\n",
      "Iteration t=1\n",
      "all:  cs/acc_i=54.60 cs/acc_c=54.08 os/recall_knw=92.44 os/recall_unk=14.53 total/acc_i=39.85 total/acc_c=51.08 total/h_score=22.80\n",
      "selected:  cs/acc_i=70.21 cs/acc_c=64.00 os/recall_knw=68.54 os/recall_unk=88.80 total/acc_i=71.75 total/acc_c=60.30 total/h_score=70.80\n",
      "Loss: 1.7314617062944013\n",
      "Loss: 0.3004199829758019\n",
      "Loss: 0.17632121012571292\n",
      "Loss: 0.13482468409740642\n",
      "Loss: 0.11090371151127525\n",
      "Loss: 0.09530439169139827\n",
      "Loss: 0.08453492058529141\n",
      "Loss: 0.07476742265469118\n",
      "Loss: 0.05931844401198465\n",
      "Loss: 0.05910602052746391\n",
      "______\n",
      "Iteration t=2\n",
      "all:  cs/acc_i=54.71 cs/acc_c=54.18 os/recall_knw=55.15 os/recall_unk=76.37 total/acc_i=55.90 total/acc_c=45.99 total/h_score=56.21\n",
      "selected:  cs/acc_i=48.86 cs/acc_c=48.34 os/recall_knw=40.53 os/recall_unk=91.39 total/acc_i=56.58 total/acc_c=38.01 total/h_score=50.97\n",
      "Loss: 1.6844662053931143\n",
      "Loss: 0.29024416739421505\n",
      "Loss: 0.17287795482984475\n",
      "Loss: 0.13215888688160526\n",
      "Loss: 0.10884104914242221\n",
      "Loss: 0.09783218634284792\n",
      "Loss: 0.07440343328991965\n",
      "Loss: 0.06550547279147131\n",
      "Loss: 0.05526195717374644\n",
      "Loss: 0.05418430703782266\n",
      "______\n",
      "Iteration t=3\n",
      "all:  cs/acc_i=54.02 cs/acc_c=53.53 os/recall_knw=51.50 os/recall_unk=79.84 total/acc_i=55.90 total/acc_c=44.42 total/h_score=55.59\n",
      "selected:  cs/acc_i=49.92 cs/acc_c=49.67 os/recall_knw=44.67 os/recall_unk=86.98 total/acc_i=55.25 total/acc_c=39.67 total/h_score=52.22\n",
      "Loss: 1.6689676542766392\n",
      "Loss: 0.29250604957342147\n",
      "Loss: 0.16439730258425697\n",
      "Loss: 0.12636432388098912\n",
      "Loss: 0.1021716661285609\n",
      "Loss: 0.08282984141551424\n",
      "Loss: 0.07160255515191238\n",
      "Loss: 0.06502735274989391\n",
      "Loss: 0.059084020415320994\n",
      "Loss: 0.04765484615782043\n",
      "______\n",
      "Iteration t=4\n",
      "all:  cs/acc_i=54.60 cs/acc_c=54.00 os/recall_knw=50.80 os/recall_unk=80.58 total/acc_i=55.92 total/acc_c=44.11 total/h_score=55.47\n",
      "selected:  cs/acc_i=52.40 cs/acc_c=51.98 os/recall_knw=47.49 os/recall_unk=84.91 total/acc_i=55.61 total/acc_c=41.72 total/h_score=53.98\n",
      "Loss: 1.6777405168459965\n",
      "Loss: 0.29359632377441114\n",
      "Loss: 0.16632093767707165\n",
      "Loss: 0.12352681976671402\n",
      "Loss: 0.09964513385811677\n",
      "Loss: 0.08851936927495094\n",
      "Loss: 0.06835669581420147\n",
      "Loss: 0.061041326169640975\n",
      "Loss: 0.055086349159335864\n",
      "Loss: 0.05164563985254902\n",
      "______\n",
      "Iteration t=5\n",
      "all:  cs/acc_i=54.89 cs/acc_c=54.40 os/recall_knw=50.40 os/recall_unk=80.92 total/acc_i=55.83 total/acc_c=43.84 total/h_score=55.28\n",
      "selected:  cs/acc_i=53.89 cs/acc_c=53.48 os/recall_knw=48.93 os/recall_unk=83.18 total/acc_i=55.74 total/acc_c=42.77 total/h_score=54.70\n",
      "Loss: 1.6500498951387261\n",
      "Loss: 0.28051458550532177\n",
      "Loss: 0.16636171301764557\n",
      "Loss: 0.12643064290715386\n",
      "Loss: 0.10298679431328567\n",
      "Loss: 0.08107037806606039\n",
      "Loss: 0.07053640247025389\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.0637787007188883\n",
      "Loss: 0.054748480954125385\n",
      "Loss: 0.04559494962202425\n",
      "______\n",
      "Iteration t=6\n",
      "all:  cs/acc_i=55.30 cs/acc_c=54.67 os/recall_knw=50.37 os/recall_unk=80.92 total/acc_i=55.81 total/acc_c=43.80 total/h_score=55.25\n",
      "selected:  cs/acc_i=55.12 cs/acc_c=54.53 os/recall_knw=50.13 os/recall_unk=81.64 total/acc_i=55.87 total/acc_c=43.66 total/h_score=55.25\n",
      "Loss: 1.6438358760921352\n",
      "Loss: 0.28408658864672287\n",
      "Loss: 0.16521529222737594\n",
      "Loss: 0.12056483288508761\n",
      "Loss: 0.10126864363955536\n",
      "Loss: 0.08150133075675063\n",
      "Loss: 0.07104537535335374\n",
      "Loss: 0.058126353794787394\n",
      "Loss: 0.05575601866536112\n",
      "Loss: 0.052437108347377547\n",
      "______\n",
      "Iteration t=7\n",
      "all:  cs/acc_i=55.62 cs/acc_c=55.11 os/recall_knw=50.37 os/recall_unk=80.92 total/acc_i=55.81 total/acc_c=43.80 total/h_score=55.25\n",
      "selected:  cs/acc_i=55.59 cs/acc_c=55.10 os/recall_knw=50.33 os/recall_unk=80.92 total/acc_i=55.79 total/acc_c=43.78 total/h_score=55.23\n",
      "Loss: 1.6549326096134014\n",
      "Loss: 0.28189417935279476\n",
      "Loss: 0.16456757674375214\n",
      "Loss: 0.12586324723123246\n",
      "Loss: 0.10057280848015952\n",
      "Loss: 0.08314552209171724\n",
      "Loss: 0.07054134427446378\n",
      "Loss: 0.06233600926086172\n",
      "Loss: 0.05543842513102993\n",
      "Loss: 0.04991564905924543\n",
      "______\n",
      "Iteration t=8\n",
      "all:  cs/acc_i=56.14 cs/acc_c=55.60 os/recall_knw=50.37 os/recall_unk=80.92 total/acc_i=55.81 total/acc_c=43.80 total/h_score=55.25\n",
      "selected:  cs/acc_i=56.14 cs/acc_c=55.60 os/recall_knw=50.37 os/recall_unk=80.92 total/acc_i=55.81 total/acc_c=43.80 total/h_score=55.25\n",
      "Loss: 1.6467724185627144\n",
      "Loss: 0.27961334418337624\n",
      "Loss: 0.1626842676944382\n",
      "Loss: 0.12338762248197833\n",
      "Loss: 0.09676045893940392\n",
      "Loss: 0.08960384401764061\n",
      "Loss: 0.07411468823722846\n",
      "Loss: 0.06246803048718441\n",
      "Loss: 0.05336955219350598\n",
      "Loss: 0.04439773468941159\n",
      "______\n",
      "Iteration t=9\n",
      "all:  cs/acc_i=55.77 cs/acc_c=55.34 os/recall_knw=50.37 os/recall_unk=80.92 total/acc_i=55.81 total/acc_c=43.80 total/h_score=55.25\n",
      "selected:  cs/acc_i=55.77 cs/acc_c=55.34 os/recall_knw=50.37 os/recall_unk=80.92 total/acc_i=55.81 total/acc_c=43.80 total/h_score=55.25\n",
      "tensor(0)\n",
      "all:  cs/acc_i=55.77 cs/acc_c=55.34 os/recall_knw=50.37 os/recall_unk=80.92 total/acc_i=55.81 total/acc_c=43.80 total/h_score=55.25\n",
      "real -> sketch lr= 0.001 seed= 1\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19]\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20]\n",
      "Loss: 1.8150292149217953\n",
      "Loss: 0.33522533031439017\n",
      "Loss: 0.19982706768656966\n",
      "Loss: 0.14560110595912484\n",
      "Loss: 0.12248491355652169\n",
      "Loss: 0.10829704580331401\n",
      "Loss: 0.0913695527167719\n",
      "Loss: 0.07918811926876736\n",
      "Loss: 0.07477342501428522\n",
      "Loss: 0.059514914930953886\n",
      "tensor(True) tensor(True)\n",
      "______\n",
      "Iteration t=1\n",
      "all:  cs/acc_i=55.84 cs/acc_c=55.35 os/recall_knw=92.18 os/recall_unk=14.05 total/acc_i=40.66 total/acc_c=52.58 total/h_score=22.34\n",
      "selected:  cs/acc_i=67.84 cs/acc_c=63.07 os/recall_knw=67.38 os/recall_unk=85.89 total/acc_i=70.01 total/acc_c=60.55 total/h_score=70.15\n",
      "Loss: 1.7203865532536764\n",
      "Loss: 0.30220710440866044\n",
      "Loss: 0.17343932892372077\n",
      "Loss: 0.13891991535579232\n",
      "Loss: 0.11165466240758228\n",
      "Loss: 0.09511319675791152\n",
      "Loss: 0.0828519336552032\n",
      "Loss: 0.0702241902661233\n",
      "Loss: 0.06347498625856698\n",
      "Loss: 0.06138862110989017\n",
      "______\n",
      "Iteration t=2\n",
      "all:  cs/acc_i=55.66 cs/acc_c=55.00 os/recall_knw=53.40 os/recall_unk=76.44 total/acc_i=55.90 total/acc_c=45.97 total/h_score=56.21\n",
      "selected:  cs/acc_i=49.88 cs/acc_c=49.36 os/recall_knw=39.61 os/recall_unk=91.25 total/acc_i=56.29 total/acc_c=38.17 total/h_score=51.13\n",
      "Loss: 1.7037657331074438\n",
      "Loss: 0.29016177560533246\n",
      "Loss: 0.16723549453721892\n",
      "Loss: 0.13157680271373642\n",
      "Loss: 0.104488498678491\n",
      "Loss: 0.09411575247443492\n",
      "Loss: 0.0745280456218508\n",
      "Loss: 0.0654315392667007\n",
      "Loss: 0.05575689889130092\n",
      "Loss: 0.05387158935679303\n",
      "______\n",
      "Iteration t=3\n",
      "all:  cs/acc_i=54.93 cs/acc_c=54.27 os/recall_knw=49.34 os/recall_unk=81.60 total/acc_i=56.45 total/acc_c=44.35 total/h_score=55.88\n",
      "selected:  cs/acc_i=50.69 cs/acc_c=50.36 os/recall_knw=42.33 os/recall_unk=88.19 total/acc_i=55.52 total/acc_c=39.51 total/h_score=52.20\n",
      "Loss: 1.6898064826753236\n",
      "Loss: 0.2875945470310536\n",
      "Loss: 0.16604849546912717\n",
      "Loss: 0.12377602473336158\n",
      "Loss: 0.09574547704097694\n",
      "Loss: 0.08386579243765926\n",
      "Loss: 0.07575918135471195\n",
      "Loss: 0.06654923931146128\n",
      "Loss: 0.05327342343678234\n",
      "Loss: 0.04580613027388459\n",
      "______\n",
      "Iteration t=4\n",
      "all:  cs/acc_i=55.62 cs/acc_c=55.07 os/recall_knw=48.43 os/recall_unk=82.28 total/acc_i=56.21 total/acc_c=43.75 total/h_score=55.45\n",
      "selected:  cs/acc_i=53.54 cs/acc_c=53.13 os/recall_knw=45.33 os/recall_unk=86.20 total/acc_i=55.83 total/acc_c=41.41 total/h_score=53.86\n",
      "Loss: 1.66935679943938\n",
      "Loss: 0.27838172777426134\n",
      "Loss: 0.16230410482769042\n",
      "Loss: 0.1276417647894968\n",
      "Loss: 0.09658867098252655\n",
      "Loss: 0.07871607683264527\n",
      "Loss: 0.07480988329443677\n",
      "Loss: 0.06457565707549591\n",
      "Loss: 0.053871679374942374\n",
      "Loss: 0.048929685558085745\n",
      "______\n",
      "Iteration t=5\n",
      "all:  cs/acc_i=55.62 cs/acc_c=55.01 os/recall_knw=48.28 os/recall_unk=82.42 total/acc_i=56.16 total/acc_c=43.59 total/h_score=55.34\n",
      "selected:  cs/acc_i=54.75 cs/acc_c=54.22 os/recall_knw=47.01 os/recall_unk=84.31 total/acc_i=56.06 total/acc_c=42.64 total/h_score=54.77\n",
      "Loss: 1.6673077415071131\n",
      "Loss: 0.2842941833745449\n",
      "Loss: 0.16243244501383297\n",
      "Loss: 0.12604134619828394\n",
      "Loss: 0.10369613902238896\n",
      "Loss: 0.08167468894284435\n",
      "Loss: 0.06718096825143248\n",
      "Loss: 0.0671704301471033\n",
      "Loss: 0.05209630492231623\n",
      "Loss: 0.049066157686874404\n",
      "______\n",
      "Iteration t=6\n",
      "all:  cs/acc_i=56.03 cs/acc_c=55.39 os/recall_knw=48.25 os/recall_unk=82.42 total/acc_i=56.16 total/acc_c=43.59 total/h_score=55.34\n",
      "selected:  cs/acc_i=55.92 cs/acc_c=55.31 os/recall_knw=48.04 os/recall_unk=82.98 total/acc_i=56.23 total/acc_c=43.50 total/h_score=55.36\n",
      "Loss: 1.6486019423305083\n",
      "Loss: 0.276476495375568\n",
      "Loss: 0.16275652776554364\n",
      "Loss: 0.12103534030153397\n",
      "Loss: 0.09901816771566686\n",
      "Loss: 0.08230753684427736\n",
      "Loss: 0.07486159231451461\n",
      "Loss: 0.06308368506903639\n",
      "Loss: 0.05447280432994967\n",
      "Loss: 0.04497400229643906\n",
      "______\n",
      "Iteration t=7\n",
      "all:  cs/acc_i=56.39 cs/acc_c=55.74 os/recall_knw=48.25 os/recall_unk=82.42 total/acc_i=56.16 total/acc_c=43.59 total/h_score=55.34\n",
      "selected:  cs/acc_i=56.39 cs/acc_c=55.74 os/recall_knw=48.25 os/recall_unk=82.47 total/acc_i=56.18 total/acc_c=43.59 total/h_score=55.35\n",
      "Loss: 1.6571682168678803\n",
      "Loss: 0.27353308245991215\n",
      "Loss: 0.169125601197734\n",
      "Loss: 0.12304372035079833\n",
      "Loss: 0.09677471235450921\n",
      "Loss: 0.08077501719817519\n",
      "Loss: 0.07163291134391771\n",
      "Loss: 0.06369029995985329\n",
      "Loss: 0.055138865595852786\n",
      "Loss: 0.04582422270270234\n",
      "______\n",
      "Iteration t=8\n",
      "all:  cs/acc_i=56.87 cs/acc_c=56.17 os/recall_knw=48.25 os/recall_unk=82.42 total/acc_i=56.16 total/acc_c=43.59 total/h_score=55.34\n",
      "selected:  cs/acc_i=56.87 cs/acc_c=56.17 os/recall_knw=48.25 os/recall_unk=82.42 total/acc_i=56.16 total/acc_c=43.59 total/h_score=55.34\n",
      "Loss: 1.6568726262359907\n",
      "Loss: 0.2820382855155251\n",
      "Loss: 0.16803778677501463\n",
      "Loss: 0.12256334797112328\n",
      "Loss: 0.10031800826051922\n",
      "Loss: 0.08234048789705742\n",
      "Loss: 0.07114624574103139\n",
      "Loss: 0.0641173908049523\n",
      "Loss: 0.051350526504613685\n",
      "Loss: 0.048754844351699855\n",
      "______\n",
      "Iteration t=9\n",
      "all:  cs/acc_i=56.03 cs/acc_c=55.51 os/recall_knw=48.25 os/recall_unk=82.42 total/acc_i=56.16 total/acc_c=43.59 total/h_score=55.34\n",
      "selected:  cs/acc_i=56.03 cs/acc_c=55.51 os/recall_knw=48.25 os/recall_unk=82.42 total/acc_i=56.16 total/acc_c=43.59 total/h_score=55.34\n",
      "tensor(0)\n",
      "all:  cs/acc_i=56.03 cs/acc_c=55.51 os/recall_knw=48.25 os/recall_unk=82.42 total/acc_i=56.16 total/acc_c=43.59 total/h_score=55.34\n",
      "real -> sketch lr= 0.001 seed= 2\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19]\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20]\n",
      "Loss: 1.8040292978923091\n",
      "Loss: 0.32610120059544506\n",
      "Loss: 0.19496929857654505\n",
      "Loss: 0.14698027623187604\n",
      "Loss: 0.1210969205733614\n",
      "Loss: 0.11026276006393161\n",
      "Loss: 0.09502600703812684\n",
      "Loss: 0.07883688249356806\n",
      "Loss: 0.07402126032037137\n",
      "Loss: 0.06208669783686722\n",
      "tensor(True) tensor(True)\n",
      "______\n",
      "Iteration t=1\n",
      "all:  cs/acc_i=55.11 cs/acc_c=54.54 os/recall_knw=92.37 os/recall_unk=14.39 total/acc_i=40.39 total/acc_c=51.99 total/h_score=22.72\n",
      "selected:  cs/acc_i=69.03 cs/acc_c=62.83 os/recall_knw=68.43 os/recall_unk=89.08 total/acc_i=72.11 total/acc_c=61.06 total/h_score=71.46\n",
      "Loss: 1.7157802312962107\n",
      "Loss: 0.30074254322696375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.18080323504133\n",
      "Loss: 0.13631343744644844\n",
      "Loss: 0.11239371513884917\n",
      "Loss: 0.09721885740165473\n",
      "Loss: 0.08186094582433233\n",
      "Loss: 0.06823229300789535\n",
      "Loss: 0.06211137297607304\n",
      "Loss: 0.057636093894158164\n",
      "______\n",
      "Iteration t=2\n",
      "all:  cs/acc_i=54.93 cs/acc_c=54.24 os/recall_knw=50.33 os/recall_unk=81.53 total/acc_i=56.47 total/acc_c=44.41 total/h_score=55.92\n",
      "selected:  cs/acc_i=48.34 cs/acc_c=48.24 os/recall_knw=38.15 os/recall_unk=91.89 total/acc_i=55.25 total/acc_c=36.23 total/h_score=49.04\n",
      "Loss: 1.6966327240390162\n",
      "Loss: 0.2858843444335845\n",
      "Loss: 0.16985026750593415\n",
      "Loss: 0.12760598360891304\n",
      "Loss: 0.10252376411470675\n",
      "Loss: 0.08804173875419843\n",
      "Loss: 0.07586941369508783\n",
      "Loss: 0.06619928937345262\n",
      "Loss: 0.057598094771345774\n",
      "Loss: 0.054205878760906\n",
      "______\n",
      "Iteration t=3\n",
      "all:  cs/acc_i=54.27 cs/acc_c=53.68 os/recall_knw=48.61 os/recall_unk=82.82 total/acc_i=56.11 total/acc_c=43.31 total/h_score=55.15\n",
      "selected:  cs/acc_i=50.74 cs/acc_c=50.34 os/recall_knw=42.52 os/recall_unk=89.05 total/acc_i=55.50 total/acc_c=39.00 total/h_score=51.78\n",
      "Loss: 1.6592152091504644\n",
      "Loss: 0.27694045316498234\n",
      "Loss: 0.16597098133192872\n",
      "Loss: 0.1231285533282039\n",
      "Loss: 0.1029487817823512\n",
      "Loss: 0.0834265732844858\n",
      "Loss: 0.07522139269580373\n",
      "Loss: 0.06558645402927701\n",
      "Loss: 0.05361498858627377\n",
      "Loss: 0.05024846814318015\n",
      "______\n",
      "Iteration t=4\n",
      "all:  cs/acc_i=54.35 cs/acc_c=53.65 os/recall_knw=48.32 os/recall_unk=82.96 total/acc_i=56.07 total/acc_c=43.18 total/h_score=55.05\n",
      "selected:  cs/acc_i=52.28 cs/acc_c=51.67 os/recall_knw=45.28 os/recall_unk=87.04 total/acc_i=55.76 total/acc_c=40.83 total/h_score=53.41\n",
      "Loss: 1.678864026678605\n",
      "Loss: 0.29479015380974527\n",
      "Loss: 0.1685436230798716\n",
      "Loss: 0.1274354268361356\n",
      "Loss: 0.09987578951485525\n",
      "Loss: 0.08670495569002426\n",
      "Loss: 0.06692979777745049\n",
      "Loss: 0.06379947966561529\n",
      "Loss: 0.057776983015689044\n",
      "Loss: 0.05152369560616166\n",
      "______\n",
      "Iteration t=5\n",
      "all:  cs/acc_i=54.49 cs/acc_c=53.85 os/recall_knw=48.28 os/recall_unk=83.16 total/acc_i=56.11 total/acc_c=43.15 total/h_score=55.05\n",
      "selected:  cs/acc_i=53.81 cs/acc_c=53.17 os/recall_knw=47.12 os/recall_unk=85.01 total/acc_i=56.13 total/acc_c=42.32 total/h_score=54.57\n",
      "Loss: 1.6463056907559024\n",
      "Loss: 0.2791276683501147\n",
      "Loss: 0.16249690865044017\n",
      "Loss: 0.12297905424455984\n",
      "Loss: 0.10284319521705491\n",
      "Loss: 0.08045036605180494\n",
      "Loss: 0.07724185130453529\n",
      "Loss: 0.05983035835730829\n",
      "Loss: 0.054217152620042\n",
      "Loss: 0.04435276937747904\n",
      "______\n",
      "Iteration t=6\n",
      "all:  cs/acc_i=55.84 cs/acc_c=55.27 os/recall_knw=48.21 os/recall_unk=83.23 total/acc_i=56.11 total/acc_c=43.13 total/h_score=55.05\n",
      "selected:  cs/acc_i=55.74 cs/acc_c=55.18 os/recall_knw=48.00 os/recall_unk=83.63 total/acc_i=56.14 total/acc_c=43.01 total/h_score=55.01\n",
      "Loss: 1.6620510869113145\n",
      "Loss: 0.28145649850277915\n",
      "Loss: 0.1617812120205635\n",
      "Loss: 0.12741095263590205\n",
      "Loss: 0.09950626950914827\n",
      "Loss: 0.07919725400358892\n",
      "Loss: 0.06914805844822462\n",
      "Loss: 0.06455129762265073\n",
      "Loss: 0.05205649520641357\n",
      "Loss: 0.048993673563388525\n",
      "______\n",
      "Iteration t=7\n",
      "all:  cs/acc_i=55.48 cs/acc_c=54.87 os/recall_knw=48.21 os/recall_unk=83.23 total/acc_i=56.11 total/acc_c=43.13 total/h_score=55.05\n",
      "selected:  cs/acc_i=55.48 cs/acc_c=54.87 os/recall_knw=48.21 os/recall_unk=83.23 total/acc_i=56.11 total/acc_c=43.13 total/h_score=55.05\n",
      "Loss: 1.645303003264196\n",
      "Loss: 0.2763873613241947\n",
      "Loss: 0.1666078967691371\n",
      "Loss: 0.12439078302263762\n",
      "Loss: 0.09622047901097121\n",
      "Loss: 0.08494776848590735\n",
      "Loss: 0.06730331072837792\n",
      "Loss: 0.058459071304197564\n",
      "Loss: 0.055752774879731466\n",
      "Loss: 0.04242455383170057\n",
      "______\n",
      "Iteration t=8\n",
      "all:  cs/acc_i=56.32 cs/acc_c=55.61 os/recall_knw=48.21 os/recall_unk=83.23 total/acc_i=56.11 total/acc_c=43.13 total/h_score=55.05\n",
      "selected:  cs/acc_i=56.32 cs/acc_c=55.61 os/recall_knw=48.21 os/recall_unk=83.23 total/acc_i=56.11 total/acc_c=43.13 total/h_score=55.05\n",
      "Loss: 1.628035235314658\n",
      "Loss: 0.27374777096239006\n",
      "Loss: 0.16137185454594366\n",
      "Loss: 0.12818507216870784\n",
      "Loss: 0.10154464587738568\n",
      "Loss: 0.08526558581401002\n",
      "Loss: 0.07313955881011983\n",
      "Loss: 0.06540833587165583\n",
      "Loss: 0.0512699025414997\n",
      "Loss: 0.046081848788272706\n",
      "______\n",
      "Iteration t=9\n",
      "all:  cs/acc_i=56.06 cs/acc_c=55.49 os/recall_knw=48.21 os/recall_unk=83.23 total/acc_i=56.11 total/acc_c=43.13 total/h_score=55.05\n",
      "selected:  cs/acc_i=56.06 cs/acc_c=55.49 os/recall_knw=48.21 os/recall_unk=83.23 total/acc_i=56.11 total/acc_c=43.13 total/h_score=55.05\n",
      "tensor(0)\n",
      "all:  cs/acc_i=56.06 cs/acc_c=55.49 os/recall_knw=48.21 os/recall_unk=83.23 total/acc_i=56.11 total/acc_c=43.13 total/h_score=55.05\n",
      "real -> sketch lr= 0.001 seed= 3\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19]\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20]\n",
      "Loss: 1.7965997698256129\n",
      "Loss: 0.32774957627376206\n",
      "Loss: 0.19702747754514005\n",
      "Loss: 0.15707145603473077\n",
      "Loss: 0.12789763944402496\n",
      "Loss: 0.10365495518897246\n",
      "Loss: 0.08816159975937041\n",
      "Loss: 0.08100677335310025\n",
      "Loss: 0.071737389065312\n",
      "Loss: 0.06672832611583678\n",
      "tensor(True) tensor(True)\n",
      "______\n",
      "Iteration t=1\n",
      "all:  cs/acc_i=54.89 cs/acc_c=54.38 os/recall_knw=92.84 os/recall_unk=15.27 total/acc_i=40.58 total/acc_c=51.82 total/h_score=23.78\n",
      "selected:  cs/acc_i=69.78 cs/acc_c=64.18 os/recall_knw=69.47 os/recall_unk=88.24 total/acc_i=72.91 total/acc_c=62.21 total/h_score=72.07\n",
      "Loss: 1.7284460318450992\n",
      "Loss: 0.2955203039219251\n",
      "Loss: 0.1720556492753629\n",
      "Loss: 0.13982401554145524\n",
      "Loss: 0.11625574671386464\n",
      "Loss: 0.0960584863787517\n",
      "Loss: 0.07928151832232755\n",
      "Loss: 0.06776570560995841\n",
      "Loss: 0.06587164713434775\n",
      "Loss: 0.0558258520228461\n",
      "______\n",
      "Iteration t=2\n",
      "all:  cs/acc_i=55.59 cs/acc_c=55.13 os/recall_knw=56.72 os/recall_unk=73.93 total/acc_i=55.76 total/acc_c=46.97 total/h_score=56.42\n",
      "selected:  cs/acc_i=49.19 cs/acc_c=48.99 os/recall_knw=41.60 os/recall_unk=91.51 total/acc_i=56.66 total/acc_c=38.56 total/h_score=51.58\n",
      "Loss: 1.6803855877730154\n",
      "Loss: 0.2856588772948711\n",
      "Loss: 0.17067461463232195\n",
      "Loss: 0.12807663644874287\n",
      "Loss: 0.10580140409630633\n",
      "Loss: 0.08500025572195169\n",
      "Loss: 0.07775925699801695\n",
      "Loss: 0.06604003899941041\n",
      "Loss: 0.060946895683845204\n",
      "Loss: 0.051952323703576\n",
      "______\n",
      "Iteration t=3\n",
      "all:  cs/acc_i=54.02 cs/acc_c=53.43 os/recall_knw=52.08 os/recall_unk=79.09 total/acc_i=55.85 total/acc_c=44.72 total/h_score=55.72\n",
      "selected:  cs/acc_i=49.77 cs/acc_c=49.51 os/recall_knw=45.04 os/recall_unk=86.23 total/acc_i=55.14 total/acc_c=39.78 total/h_score=52.22\n",
      "Loss: 1.6590992805548013\n",
      "Loss: 0.2782702743075788\n",
      "Loss: 0.17007460896857082\n",
      "Loss: 0.1214396029652562\n",
      "Loss: 0.10157683482975699\n",
      "Loss: 0.08091427412146004\n",
      "Loss: 0.07117803111905233\n",
      "Loss: 0.06245123772969237\n",
      "Loss: 0.05363908851577435\n",
      "Loss: 0.050827296861098145\n",
      "______\n",
      "Iteration t=4\n",
      "all:  cs/acc_i=54.49 cs/acc_c=53.80 os/recall_knw=51.57 os/recall_unk=79.84 total/acc_i=55.97 total/acc_c=44.56 total/h_score=55.73\n",
      "selected:  cs/acc_i=52.21 cs/acc_c=51.63 os/recall_knw=48.10 os/recall_unk=83.88 total/acc_i=55.57 total/acc_c=42.00 total/h_score=54.08\n",
      "Loss: 1.664677213397494\n",
      "Loss: 0.2856399535310049\n",
      "Loss: 0.1545902953191769\n",
      "Loss: 0.12502346158119068\n",
      "Loss: 0.09758431305594605\n",
      "Loss: 0.07979359381769333\n",
      "Loss: 0.06808533334098985\n",
      "Loss: 0.05921198449817492\n",
      "Loss: 0.05180971269592917\n",
      "Loss: 0.04914759018135605\n",
      "______\n",
      "Iteration t=5\n",
      "all:  cs/acc_i=55.04 cs/acc_c=54.16 os/recall_knw=51.28 os/recall_unk=79.90 total/acc_i=55.83 total/acc_c=44.32 total/h_score=55.52\n",
      "selected:  cs/acc_i=53.87 cs/acc_c=52.97 os/recall_knw=49.43 os/recall_unk=82.31 total/acc_i=55.68 total/acc_c=42.95 total/h_score=54.72\n",
      "Loss: 1.659159827377296\n",
      "Loss: 0.28315291614880317\n",
      "Loss: 0.16643696025829186\n",
      "Loss: 0.11353980871002363\n",
      "Loss: 0.09968873357972113\n",
      "Loss: 0.08786602113056237\n",
      "Loss: 0.0679097032248068\n",
      "Loss: 0.059519858999704335\n",
      "Loss: 0.05450431520606201\n",
      "Loss: 0.04719149088770106\n",
      "______\n",
      "Iteration t=6\n",
      "all:  cs/acc_i=55.99 cs/acc_c=55.21 os/recall_knw=51.24 os/recall_unk=79.90 total/acc_i=55.81 total/acc_c=44.28 total/h_score=55.49\n",
      "selected:  cs/acc_i=55.79 cs/acc_c=55.01 os/recall_knw=50.94 os/recall_unk=80.56 total/acc_i=55.83 total/acc_c=44.06 total/h_score=55.41\n",
      "Loss: 1.6599347807981588\n",
      "Loss: 0.27821205476964556\n",
      "Loss: 0.16069042253624033\n",
      "Loss: 0.1184036925983232\n",
      "Loss: 0.10375191961826237\n",
      "Loss: 0.08200604548851201\n",
      "Loss: 0.07265489628991566\n",
      "Loss: 0.062136993023312395\n",
      "Loss: 0.05358342297078745\n",
      "Loss: 0.04791553886803063\n",
      "______\n",
      "Iteration t=7\n",
      "all:  cs/acc_i=55.51 cs/acc_c=54.79 os/recall_knw=51.24 os/recall_unk=79.90 total/acc_i=55.81 total/acc_c=44.28 total/h_score=55.49\n",
      "selected:  cs/acc_i=55.49 cs/acc_c=54.75 os/recall_knw=51.17 os/recall_unk=79.90 total/acc_i=55.79 total/acc_c=44.23 total/h_score=55.44\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 1.630606045712254\n",
      "Loss: 0.27392739195845084\n",
      "Loss: 0.16797184641333576\n",
      "Loss: 0.12135309617252585\n",
      "Loss: 0.09708065025140336\n",
      "Loss: 0.07934122812560575\n",
      "Loss: 0.0714606262386559\n",
      "Loss: 0.05912991912971379\n",
      "Loss: 0.05303744863702018\n",
      "Loss: 0.046967248334744555\n",
      "______\n",
      "Iteration t=8\n",
      "all:  cs/acc_i=55.59 cs/acc_c=54.94 os/recall_knw=51.21 os/recall_unk=79.90 total/acc_i=55.81 total/acc_c=44.28 total/h_score=55.49\n",
      "selected:  cs/acc_i=55.59 cs/acc_c=54.94 os/recall_knw=51.21 os/recall_unk=79.90 total/acc_i=55.81 total/acc_c=44.28 total/h_score=55.49\n",
      "Loss: 1.6318741857470154\n",
      "Loss: 0.27674169546205124\n",
      "Loss: 0.16094103367430365\n",
      "Loss: 0.12723841174633918\n",
      "Loss: 0.09054512286859893\n",
      "Loss: 0.08292411778590636\n",
      "Loss: 0.07445441293223443\n",
      "Loss: 0.058901260254213106\n",
      "Loss: 0.051472518878185866\n",
      "Loss: 0.046068705859577314\n",
      "______\n",
      "Iteration t=9\n",
      "all:  cs/acc_i=56.36 cs/acc_c=55.52 os/recall_knw=51.21 os/recall_unk=79.90 total/acc_i=55.81 total/acc_c=44.28 total/h_score=55.49\n",
      "selected:  cs/acc_i=56.36 cs/acc_c=55.52 os/recall_knw=51.21 os/recall_unk=79.90 total/acc_i=55.81 total/acc_c=44.28 total/h_score=55.49\n",
      "tensor(0)\n",
      "all:  cs/acc_i=56.36 cs/acc_c=55.52 os/recall_knw=51.21 os/recall_unk=79.90 total/acc_i=55.81 total/acc_c=44.28 total/h_score=55.49\n",
      "real -> sketch lr= 0.001 seed= 4\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19]\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20]\n",
      "Loss: 1.7981106884963147\n",
      "Loss: 0.34210926403036324\n",
      "Loss: 0.19485181208792743\n",
      "Loss: 0.14464671594949166\n",
      "Loss: 0.12477432743536832\n",
      "Loss: 0.11099821335745452\n",
      "Loss: 0.09107007163169122\n",
      "Loss: 0.08283715117457605\n",
      "Loss: 0.06830743701425895\n",
      "Loss: 0.061379808899399646\n",
      "tensor(True) tensor(True)\n",
      "______\n",
      "Iteration t=1\n",
      "all:  cs/acc_i=55.44 cs/acc_c=54.86 os/recall_knw=93.06 os/recall_unk=15.68 total/acc_i=41.11 total/acc_c=52.40 total/h_score=24.33\n",
      "selected:  cs/acc_i=69.69 cs/acc_c=62.84 os/recall_knw=70.31 os/recall_unk=89.19 total/acc_i=73.30 total/acc_c=61.32 total/h_score=71.69\n",
      "Loss: 1.7354672235008832\n",
      "Loss: 0.31029741959394636\n",
      "Loss: 0.17648692789009293\n",
      "Loss: 0.13339945979768764\n",
      "Loss: 0.11473958120316367\n",
      "Loss: 0.10141580466281723\n",
      "Loss: 0.0761295943615354\n",
      "Loss: 0.06897070434265393\n",
      "Loss: 0.061690687566894935\n",
      "Loss: 0.05650199425243143\n",
      "______\n",
      "Iteration t=2\n",
      "all:  cs/acc_i=56.03 cs/acc_c=55.58 os/recall_knw=51.17 os/recall_unk=80.45 total/acc_i=56.35 total/acc_c=44.83 total/h_score=56.09\n",
      "selected:  cs/acc_i=49.56 cs/acc_c=49.55 os/recall_knw=38.36 os/recall_unk=91.36 total/acc_i=55.22 total/acc_c=36.41 total/h_score=49.19\n",
      "Loss: 1.6874868161255314\n",
      "Loss: 0.2836835419699069\n",
      "Loss: 0.1699280889764909\n",
      "Loss: 0.12757122624184816\n",
      "Loss: 0.10051533467166367\n",
      "Loss: 0.08661430645133218\n",
      "Loss: 0.07679087008920409\n",
      "Loss: 0.06732745799987067\n",
      "Loss: 0.05898042689903729\n",
      "Loss: 0.053672162435888765\n",
      "______\n",
      "Iteration t=3\n",
      "all:  cs/acc_i=54.02 cs/acc_c=53.52 os/recall_knw=48.61 os/recall_unk=83.50 total/acc_i=56.40 total/acc_c=43.54 total/h_score=55.49\n",
      "selected:  cs/acc_i=49.55 cs/acc_c=49.34 os/recall_knw=41.91 os/recall_unk=89.13 total/acc_i=55.13 total/acc_c=38.33 total/h_score=51.08\n",
      "Loss: 1.6750263325423473\n",
      "Loss: 0.2770402106435893\n",
      "Loss: 0.15931109599886634\n",
      "Loss: 0.12553471027747126\n",
      "Loss: 0.10339143324631622\n",
      "Loss: 0.08954602767263865\n",
      "Loss: 0.07861980760605178\n",
      "Loss: 0.06633616597920491\n",
      "Loss: 0.05640459548511575\n",
      "Loss: 0.04779722519976907\n",
      "______\n",
      "Iteration t=4\n",
      "all:  cs/acc_i=54.57 cs/acc_c=53.98 os/recall_knw=48.14 os/recall_unk=84.05 total/acc_i=56.38 total/acc_c=43.22 total/h_score=55.28\n",
      "selected:  cs/acc_i=52.29 cs/acc_c=51.89 os/recall_knw=44.83 os/recall_unk=87.49 total/acc_i=55.80 total/acc_c=40.70 total/h_score=53.33\n",
      "Loss: 1.665843605624963\n",
      "Loss: 0.2766485299614275\n",
      "Loss: 0.16164494848445707\n",
      "Loss: 0.1191819038311517\n",
      "Loss: 0.10056433015393082\n",
      "Loss: 0.08825298872492883\n",
      "Loss: 0.07210593629680481\n",
      "Loss: 0.06536164836125066\n",
      "Loss: 0.05987269089048185\n",
      "Loss: 0.051074493943962344\n",
      "______\n",
      "Iteration t=5\n",
      "all:  cs/acc_i=55.19 cs/acc_c=54.46 os/recall_knw=47.99 os/recall_unk=84.18 total/acc_i=56.33 total/acc_c=43.11 total/h_score=55.20\n",
      "selected:  cs/acc_i=54.40 cs/acc_c=53.73 os/recall_knw=46.65 os/recall_unk=85.81 total/acc_i=56.22 total/acc_c=42.19 total/h_score=54.58\n",
      "Loss: 1.657850276655946\n",
      "Loss: 0.2854698269965093\n",
      "Loss: 0.16155449922647944\n",
      "Loss: 0.1179209342397795\n",
      "Loss: 0.10131509954315479\n",
      "Loss: 0.07620712480810614\n",
      "Loss: 0.07053426599438571\n",
      "Loss: 0.061217147632690566\n",
      "Loss: 0.057712787893697895\n",
      "Loss: 0.04826100803111777\n",
      "______\n",
      "Iteration t=6\n",
      "all:  cs/acc_i=55.41 cs/acc_c=54.88 os/recall_knw=47.99 os/recall_unk=84.18 total/acc_i=56.33 total/acc_c=43.11 total/h_score=55.20\n",
      "selected:  cs/acc_i=55.29 cs/acc_c=54.77 os/recall_knw=47.82 os/recall_unk=84.30 total/acc_i=56.29 total/acc_c=42.99 total/h_score=55.10\n",
      "Loss: 1.6548000069555904\n",
      "Loss: 0.2786271562488427\n",
      "Loss: 0.1656681899785271\n",
      "Loss: 0.11640046512577852\n",
      "Loss: 0.09924722005157395\n",
      "Loss: 0.08322043585842956\n",
      "Loss: 0.07129215773783829\n",
      "Loss: 0.06294497434406522\n",
      "Loss: 0.052852283987021326\n",
      "Loss: 0.0488288246893457\n",
      "______\n",
      "Iteration t=7\n",
      "all:  cs/acc_i=55.51 cs/acc_c=55.04 os/recall_knw=47.99 os/recall_unk=84.18 total/acc_i=56.33 total/acc_c=43.11 total/h_score=55.20\n",
      "selected:  cs/acc_i=55.50 cs/acc_c=55.01 os/recall_knw=47.97 os/recall_unk=84.18 total/acc_i=56.32 total/acc_c=43.08 total/h_score=55.17\n",
      "Loss: 1.6466487974019035\n",
      "Loss: 0.2829195165434869\n",
      "Loss: 0.16183897987642187\n",
      "Loss: 0.1251570563593534\n",
      "Loss: 0.10230129032670364\n",
      "Loss: 0.08869731037574607\n",
      "Loss: 0.07054845422596917\n",
      "Loss: 0.05986289496287296\n",
      "Loss: 0.055225848919488375\n",
      "Loss: 0.04363485695341302\n",
      "______\n",
      "Iteration t=8\n",
      "all:  cs/acc_i=55.99 cs/acc_c=55.51 os/recall_knw=47.99 os/recall_unk=84.18 total/acc_i=56.33 total/acc_c=43.11 total/h_score=55.20\n",
      "selected:  cs/acc_i=55.99 cs/acc_c=55.51 os/recall_knw=47.99 os/recall_unk=84.18 total/acc_i=56.33 total/acc_c=43.11 total/h_score=55.20\n",
      "Loss: 1.6646250349591205\n",
      "Loss: 0.280938721536503\n",
      "Loss: 0.16035578866973293\n",
      "Loss: 0.13311529435262673\n",
      "Loss: 0.10031742860186607\n",
      "Loss: 0.09065623630098658\n",
      "Loss: 0.07366936082037387\n",
      "Loss: 0.06052673431424747\n",
      "Loss: 0.05900829419703152\n",
      "Loss: 0.04802022838404566\n",
      "______\n",
      "Iteration t=9\n",
      "all:  cs/acc_i=56.32 cs/acc_c=55.85 os/recall_knw=47.99 os/recall_unk=84.18 total/acc_i=56.33 total/acc_c=43.11 total/h_score=55.20\n",
      "selected:  cs/acc_i=56.32 cs/acc_c=55.85 os/recall_knw=47.99 os/recall_unk=84.18 total/acc_i=56.33 total/acc_c=43.11 total/h_score=55.20\n",
      "tensor(0)\n",
      "all:  cs/acc_i=56.32 cs/acc_c=55.85 os/recall_knw=47.99 os/recall_unk=84.18 total/acc_i=56.33 total/acc_c=43.11 total/h_score=55.20\n",
      "real -> sketch lr= 0.001 seed= 0\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19]\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20]\n",
      "Loss: 1.8087628958912507\n",
      "Loss: 0.3348964371609094\n",
      "Loss: 0.187550747548346\n",
      "Loss: 0.1448966288322656\n",
      "Loss: 0.12284395392997409\n",
      "Loss: 0.10663879023089315\n",
      "Loss: 0.09187392947790991\n",
      "Loss: 0.07958000342384829\n",
      "Loss: 0.07660902423777508\n",
      "Loss: 0.06395210524079692\n",
      "tensor(True) tensor(True)\n",
      "______\n",
      "Iteration t=1\n",
      "all:  cs/acc_i=54.46 cs/acc_c=53.93 os/recall_knw=92.66 os/recall_unk=14.94 total/acc_i=40.18 total/acc_c=51.38 total/h_score=23.32\n",
      "selected:  cs/acc_i=68.82 cs/acc_c=62.90 os/recall_knw=69.12 os/recall_unk=89.43 total/acc_i=72.35 total/acc_c=60.94 total/h_score=71.47\n",
      "Loss: 1.7329173421336186\n",
      "Loss: 0.30188148393220193\n",
      "Loss: 0.174643052207004\n",
      "Loss: 0.1325755304203847\n",
      "Loss: 0.1059228476243899\n",
      "Loss: 0.09756999170074139\n",
      "Loss: 0.08805219918439114\n",
      "Loss: 0.07332389463192306\n",
      "Loss: 0.0674423743086565\n",
      "Loss: 0.05784761295905588\n",
      "______\n",
      "Iteration t=2\n",
      "all:  cs/acc_i=54.57 cs/acc_c=54.05 os/recall_knw=57.63 os/recall_unk=73.39 total/acc_i=55.24 total/acc_c=46.53 total/h_score=55.93\n",
      "selected:  cs/acc_i=48.90 cs/acc_c=48.19 os/recall_knw=41.94 os/recall_unk=91.07 total/acc_i=56.80 total/acc_c=38.52 total/h_score=51.49\n",
      "Loss: 1.6967270061854394\n",
      "Loss: 0.2866091991143842\n",
      "Loss: 0.16426081959638864\n",
      "Loss: 0.12722607552404366\n",
      "Loss: 0.10671693293317672\n",
      "Loss: 0.08653579350981501\n",
      "Loss: 0.07672644997646491\n",
      "Loss: 0.061138412317321186\n",
      "Loss: 0.0590166921441954\n",
      "Loss: 0.048471640419935985\n",
      "______\n",
      "Iteration t=3\n",
      "all:  cs/acc_i=53.94 cs/acc_c=53.34 os/recall_knw=52.34 os/recall_unk=80.11 total/acc_i=55.83 total/acc_c=44.20 total/h_score=55.46\n",
      "selected:  cs/acc_i=50.06 cs/acc_c=49.52 os/recall_knw=45.69 os/recall_unk=86.19 total/acc_i=55.06 total/acc_c=39.39 total/h_score=51.82\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 1.6661767094306115\n",
      "Loss: 0.28496219670382616\n",
      "Loss: 0.16402746409734834\n",
      "Loss: 0.12605176655999226\n",
      "Loss: 0.10155367462480923\n",
      "Loss: 0.08468589295757893\n",
      "Loss: 0.07395285231603826\n",
      "Loss: 0.06302182010383667\n",
      "Loss: 0.05177049649258455\n",
      "Loss: 0.04724260612689771\n",
      "______\n",
      "Iteration t=4\n",
      "all:  cs/acc_i=53.76 cs/acc_c=53.08 os/recall_knw=51.86 os/recall_unk=80.52 total/acc_i=55.85 total/acc_c=44.03 total/h_score=55.39\n",
      "selected:  cs/acc_i=51.50 cs/acc_c=51.00 os/recall_knw=48.62 os/recall_unk=84.17 total/acc_i=55.39 total/acc_c=41.51 total/h_score=53.65\n",
      "Loss: 1.6734755396478402\n",
      "Loss: 0.28699821830707223\n",
      "Loss: 0.15655795526363253\n",
      "Loss: 0.12046700190262875\n",
      "Loss: 0.09448890436429314\n",
      "Loss: 0.08739570566433102\n",
      "Loss: 0.06983676995649159\n",
      "Loss: 0.0639789157592626\n",
      "Loss: 0.05516525957055549\n",
      "Loss: 0.04662827409758298\n",
      "______\n",
      "Iteration t=5\n",
      "all:  cs/acc_i=53.69 cs/acc_c=53.18 os/recall_knw=51.64 os/recall_unk=80.92 total/acc_i=55.92 total/acc_c=43.97 total/h_score=55.41\n",
      "selected:  cs/acc_i=52.58 cs/acc_c=52.09 os/recall_knw=50.06 os/recall_unk=82.89 total/acc_i=55.73 total/acc_c=42.72 total/h_score=54.61\n",
      "Loss: 1.6568065838380293\n",
      "Loss: 0.2751682078522263\n",
      "Loss: 0.1568949717802532\n",
      "Loss: 0.12466101037959258\n",
      "Loss: 0.0945743579191692\n",
      "Loss: 0.08325471705898191\n",
      "Loss: 0.07498578242957592\n",
      "Loss: 0.06119384474939469\n",
      "Loss: 0.05294191090982746\n",
      "Loss: 0.04593452667097815\n",
      "______\n",
      "Iteration t=6\n",
      "all:  cs/acc_i=54.86 cs/acc_c=54.25 os/recall_knw=51.61 os/recall_unk=80.92 total/acc_i=55.90 total/acc_c=43.95 total/h_score=55.39\n",
      "selected:  cs/acc_i=54.68 cs/acc_c=54.10 os/recall_knw=51.34 os/recall_unk=81.42 total/acc_i=55.91 total/acc_c=43.79 total/h_score=55.33\n",
      "Loss: 1.6266652397565298\n",
      "Loss: 0.28112065070518505\n",
      "Loss: 0.1700614767076375\n",
      "Loss: 0.11903381051758567\n",
      "Loss: 0.09428304600230118\n",
      "Loss: 0.07572707619417358\n",
      "Loss: 0.07038626032000458\n",
      "Loss: 0.06014474765775171\n",
      "Loss: 0.05335079485413481\n",
      "Loss: 0.05455409639512186\n",
      "______\n",
      "Iteration t=7\n",
      "all:  cs/acc_i=55.77 cs/acc_c=55.12 os/recall_knw=51.61 os/recall_unk=80.92 total/acc_i=55.90 total/acc_c=43.95 total/h_score=55.39\n",
      "selected:  cs/acc_i=55.74 cs/acc_c=55.06 os/recall_knw=51.57 os/recall_unk=80.92 total/acc_i=55.88 total/acc_c=43.89 total/h_score=55.33\n",
      "Loss: 1.61892755624063\n",
      "Loss: 0.27500446515525884\n",
      "Loss: 0.16246228080666708\n",
      "Loss: 0.12071372721968832\n",
      "Loss: 0.10192807748757615\n",
      "Loss: 0.07718544460632308\n",
      "Loss: 0.07081132461902445\n",
      "Loss: 0.06372998306990607\n",
      "Loss: 0.05652054365651827\n",
      "Loss: 0.05395806182460291\n",
      "______\n",
      "Iteration t=8\n",
      "all:  cs/acc_i=55.77 cs/acc_c=55.25 os/recall_knw=51.61 os/recall_unk=80.92 total/acc_i=55.90 total/acc_c=43.95 total/h_score=55.39\n",
      "selected:  cs/acc_i=55.77 cs/acc_c=55.25 os/recall_knw=51.61 os/recall_unk=80.92 total/acc_i=55.90 total/acc_c=43.95 total/h_score=55.39\n",
      "Loss: 1.6409941726994373\n",
      "Loss: 0.28286365912613753\n",
      "Loss: 0.16340343174552488\n",
      "Loss: 0.11886353924045127\n",
      "Loss: 0.09694180770325446\n",
      "Loss: 0.07917996029185499\n",
      "Loss: 0.07281168174098976\n",
      "Loss: 0.061546696444783736\n",
      "Loss: 0.05357352571846349\n",
      "Loss: 0.046371392304116785\n",
      "______\n",
      "Iteration t=9\n",
      "all:  cs/acc_i=55.51 cs/acc_c=55.02 os/recall_knw=51.61 os/recall_unk=80.92 total/acc_i=55.90 total/acc_c=43.95 total/h_score=55.39\n",
      "selected:  cs/acc_i=55.51 cs/acc_c=55.02 os/recall_knw=51.61 os/recall_unk=80.92 total/acc_i=55.90 total/acc_c=43.95 total/h_score=55.39\n",
      "tensor(0)\n",
      "all:  cs/acc_i=55.51 cs/acc_c=55.02 os/recall_knw=51.61 os/recall_unk=80.92 total/acc_i=55.90 total/acc_c=43.95 total/h_score=55.39\n",
      "real -> sketch lr= 0.001 seed= 1\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19]\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20]\n",
      "Loss: 1.8172910134987474\n",
      "Loss: 0.33756110989538374\n",
      "Loss: 0.20024606472815906\n",
      "Loss: 0.14567093097097722\n",
      "Loss: 0.12238597111557727\n",
      "Loss: 0.1078637955259545\n",
      "Loss: 0.09159941211660985\n",
      "Loss: 0.07910149200120112\n",
      "Loss: 0.07418832427977826\n",
      "Loss: 0.05998738758842663\n",
      "tensor(True) tensor(True)\n",
      "______\n",
      "Iteration t=1\n",
      "all:  cs/acc_i=55.62 cs/acc_c=55.13 os/recall_knw=92.44 os/recall_unk=14.53 total/acc_i=40.80 total/acc_c=52.54 total/h_score=22.94\n",
      "selected:  cs/acc_i=68.15 cs/acc_c=63.07 os/recall_knw=68.15 os/recall_unk=86.64 total/acc_i=71.13 total/acc_c=61.38 total/h_score=70.98\n",
      "Loss: 1.724104493453696\n",
      "Loss: 0.2959058572210976\n",
      "Loss: 0.18113466022485816\n",
      "Loss: 0.13959388082494606\n",
      "Loss: 0.10905876106934974\n",
      "Loss: 0.1041608235509311\n",
      "Loss: 0.07773964832587218\n",
      "Loss: 0.07203537406481651\n",
      "Loss: 0.067193929271181\n",
      "Loss: 0.059422523842029576\n",
      "______\n",
      "Iteration t=2\n",
      "all:  cs/acc_i=55.84 cs/acc_c=55.29 os/recall_knw=61.72 os/recall_unk=66.87 total/acc_i=54.62 total/acc_c=48.49 total/h_score=55.59\n",
      "selected:  cs/acc_i=51.06 cs/acc_c=50.26 os/recall_knw=44.67 os/recall_unk=90.87 total/acc_i=58.36 total/acc_c=41.60 total/h_score=54.71\n",
      "Loss: 1.690641008942358\n",
      "Loss: 0.2831441342830658\n",
      "Loss: 0.15941305744551842\n",
      "Loss: 0.12406184065245814\n",
      "Loss: 0.10394595952464207\n",
      "Loss: 0.09720624664257611\n",
      "Loss: 0.07828313823218548\n",
      "Loss: 0.06396003119767674\n",
      "Loss: 0.05698237630778984\n",
      "Loss: 0.05157163966139178\n",
      "______\n",
      "Iteration t=3\n",
      "all:  cs/acc_i=54.89 cs/acc_c=54.32 os/recall_knw=52.12 os/recall_unk=79.16 total/acc_i=55.88 total/acc_c=44.75 total/h_score=55.75\n",
      "selected:  cs/acc_i=51.01 cs/acc_c=50.47 os/recall_knw=45.71 os/recall_unk=85.80 total/acc_i=55.17 total/acc_c=40.00 total/h_score=52.40\n",
      "Loss: 1.6687682919041762\n",
      "Loss: 0.2861210299058124\n",
      "Loss: 0.1665149966481133\n",
      "Loss: 0.12488418197218688\n",
      "Loss: 0.10167447545469921\n",
      "Loss: 0.07998787038132688\n",
      "Loss: 0.07513235205337637\n",
      "Loss: 0.06205748269810251\n",
      "Loss: 0.050789538103611295\n",
      "Loss: 0.047990294385518634\n",
      "______\n",
      "Iteration t=4\n",
      "all:  cs/acc_i=54.57 cs/acc_c=53.91 os/recall_knw=51.83 os/recall_unk=79.77 total/acc_i=55.95 total/acc_c=44.56 total/h_score=55.71\n",
      "selected:  cs/acc_i=52.19 cs/acc_c=51.72 os/recall_knw=47.97 os/recall_unk=84.47 total/acc_i=55.65 total/acc_c=41.92 total/h_score=54.10\n",
      "Loss: 1.6565406991885259\n",
      "Loss: 0.2750094381433267\n",
      "Loss: 0.16643778865153974\n",
      "Loss: 0.11994228857641037\n",
      "Loss: 0.09895928981785591\n",
      "Loss: 0.08943339316031107\n",
      "Loss: 0.07185338479968217\n",
      "Loss: 0.06093332661459079\n",
      "Loss: 0.055448425814795956\n",
      "Loss: 0.04428072948438617\n",
      "______\n",
      "Iteration t=5\n",
      "all:  cs/acc_i=55.37 cs/acc_c=54.79 os/recall_knw=51.61 os/recall_unk=79.84 total/acc_i=55.88 total/acc_c=44.41 total/h_score=55.59\n",
      "selected:  cs/acc_i=54.31 cs/acc_c=53.77 os/recall_knw=50.09 os/recall_unk=82.01 total/acc_i=55.73 total/acc_c=43.23 total/h_score=54.93\n",
      "Loss: 1.653362547267567\n",
      "Loss: 0.2874096488410776\n",
      "Loss: 0.16750204941314278\n",
      "Loss: 0.11259803781003663\n",
      "Loss: 0.09470451471649788\n",
      "Loss: 0.08325339792239847\n",
      "Loss: 0.07350873943756928\n",
      "Loss: 0.06114781372616011\n",
      "Loss: 0.05731756369809084\n",
      "Loss: 0.04781160346429908\n",
      "______\n",
      "Iteration t=6\n",
      "all:  cs/acc_i=55.99 cs/acc_c=55.29 os/recall_knw=51.50 os/recall_unk=80.18 total/acc_i=55.92 total/acc_c=44.33 total/h_score=55.59\n",
      "selected:  cs/acc_i=55.83 cs/acc_c=55.14 os/recall_knw=51.19 os/recall_unk=81.06 total/acc_i=56.03 total/acc_c=44.18 total/h_score=55.62\n",
      "Loss: 1.6444244014697749\n",
      "Loss: 0.2796649594452825\n",
      "Loss: 0.16536106055115793\n",
      "Loss: 0.12145167515353039\n",
      "Loss: 0.09942453898008431\n",
      "Loss: 0.08032617326993663\n",
      "Loss: 0.0694819680770283\n",
      "Loss: 0.0613639999052381\n",
      "Loss: 0.052813437570154935\n",
      "Loss: 0.04426437237806193\n",
      "______\n",
      "Iteration t=7\n",
      "all:  cs/acc_i=56.54 cs/acc_c=55.82 os/recall_knw=51.50 os/recall_unk=80.18 total/acc_i=55.92 total/acc_c=44.33 total/h_score=55.59\n",
      "selected:  cs/acc_i=56.56 cs/acc_c=55.84 os/recall_knw=51.48 os/recall_unk=80.18 total/acc_i=55.94 total/acc_c=44.35 total/h_score=55.60\n",
      "Loss: 1.633414173286832\n",
      "Loss: 0.27022132790552644\n",
      "Loss: 0.1636657256488047\n",
      "Loss: 0.11784506608414168\n",
      "Loss: 0.0923660568374315\n",
      "Loss: 0.08542835930485033\n",
      "Loss: 0.0743966737865264\n",
      "Loss: 0.06068569647070177\n",
      "Loss: 0.050356007788977225\n",
      "Loss: 0.04432323127901349\n",
      "______\n",
      "Iteration t=8\n",
      "all:  cs/acc_i=55.51 cs/acc_c=54.95 os/recall_knw=51.46 os/recall_unk=80.18 total/acc_i=55.90 total/acc_c=44.30 total/h_score=55.56\n",
      "selected:  cs/acc_i=55.51 cs/acc_c=54.95 os/recall_knw=51.46 os/recall_unk=80.18 total/acc_i=55.90 total/acc_c=44.30 total/h_score=55.56\n",
      "Loss: 1.6296604535358394\n",
      "Loss: 0.2763483048957622\n",
      "Loss: 0.15253395134371198\n",
      "Loss: 0.12183724484590445\n",
      "Loss: 0.09815958553289403\n",
      "Loss: 0.07739927311160205\n",
      "Loss: 0.07252666512002309\n",
      "Loss: 0.06033286748559934\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.05257260385053065\n",
      "Loss: 0.04782414941596771\n",
      "______\n",
      "Iteration t=9\n",
      "all:  cs/acc_i=56.21 cs/acc_c=55.48 os/recall_knw=51.46 os/recall_unk=80.18 total/acc_i=55.90 total/acc_c=44.30 total/h_score=55.56\n",
      "selected:  cs/acc_i=56.21 cs/acc_c=55.48 os/recall_knw=51.46 os/recall_unk=80.18 total/acc_i=55.90 total/acc_c=44.30 total/h_score=55.56\n",
      "tensor(0)\n",
      "all:  cs/acc_i=56.21 cs/acc_c=55.48 os/recall_knw=51.46 os/recall_unk=80.18 total/acc_i=55.90 total/acc_c=44.30 total/h_score=55.56\n",
      "real -> sketch lr= 0.001 seed= 2\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19]\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20]\n",
      "Loss: 1.8056390396852935\n",
      "Loss: 0.3265396885017059\n",
      "Loss: 0.19543256996418235\n",
      "Loss: 0.1473192429879276\n",
      "Loss: 0.12121106375313738\n",
      "Loss: 0.11038650086421348\n",
      "Loss: 0.09526801442071212\n",
      "Loss: 0.07938125688463343\n",
      "Loss: 0.07427099277182513\n",
      "Loss: 0.06241527791847591\n",
      "tensor(True) tensor(True)\n",
      "______\n",
      "Iteration t=1\n",
      "all:  cs/acc_i=55.30 cs/acc_c=54.73 os/recall_knw=92.37 os/recall_unk=14.39 total/acc_i=40.30 total/acc_c=51.81 total/h_score=22.70\n",
      "selected:  cs/acc_i=70.30 cs/acc_c=64.35 os/recall_knw=68.33 os/recall_unk=89.08 total/acc_i=72.05 total/acc_c=61.14 total/h_score=71.52\n",
      "Loss: 1.7163933202422954\n",
      "Loss: 0.30503884292635564\n",
      "Loss: 0.17555327270482038\n",
      "Loss: 0.1367183879168855\n",
      "Loss: 0.1080754305160529\n",
      "Loss: 0.09596687084617647\n",
      "Loss: 0.0808160842720394\n",
      "Loss: 0.06596820903123936\n",
      "Loss: 0.06440089551757115\n",
      "Loss: 0.0599646334146225\n",
      "______\n",
      "Iteration t=2\n",
      "all:  cs/acc_i=55.33 cs/acc_c=54.85 os/recall_knw=58.69 os/recall_unk=71.76 total/acc_i=55.14 total/acc_c=47.08 total/h_score=55.95\n",
      "selected:  cs/acc_i=50.13 cs/acc_c=49.44 os/recall_knw=42.68 os/recall_unk=91.20 total/acc_i=57.34 total/acc_c=39.44 total/h_score=52.49\n",
      "Loss: 1.6920659934320756\n",
      "Loss: 0.29069528315336474\n",
      "Loss: 0.1753970589008062\n",
      "Loss: 0.12652745105686689\n",
      "Loss: 0.10477002381437248\n",
      "Loss: 0.0915810888543004\n",
      "Loss: 0.07304040111541267\n",
      "Loss: 0.0648290699543131\n",
      "Loss: 0.06095712733034405\n",
      "Loss: 0.05088901955168694\n",
      "______\n",
      "Iteration t=3\n",
      "all:  cs/acc_i=54.13 cs/acc_c=53.65 os/recall_knw=51.50 os/recall_unk=80.45 total/acc_i=55.92 total/acc_c=44.20 total/h_score=55.52\n",
      "selected:  cs/acc_i=50.23 cs/acc_c=50.00 os/recall_knw=44.83 os/recall_unk=86.75 total/acc_i=55.18 total/acc_c=39.59 total/h_score=52.10\n",
      "Loss: 1.6699583155103028\n",
      "Loss: 0.2805449022445828\n",
      "Loss: 0.16617088605416938\n",
      "Loss: 0.12132191263372079\n",
      "Loss: 0.09602685582940466\n",
      "Loss: 0.08415555267420131\n",
      "Loss: 0.07665881989814807\n",
      "Loss: 0.0628402801201446\n",
      "Loss: 0.053679850323533174\n",
      "Loss: 0.04816503944384749\n",
      "______\n",
      "Iteration t=4\n",
      "all:  cs/acc_i=53.54 cs/acc_c=52.94 os/recall_knw=50.18 os/recall_unk=81.26 total/acc_i=55.62 total/acc_c=43.39 total/h_score=54.94\n",
      "selected:  cs/acc_i=51.25 cs/acc_c=50.74 os/recall_knw=46.93 os/recall_unk=85.01 total/acc_i=55.13 total/acc_c=40.85 total/h_score=53.13\n",
      "Loss: 1.6583193256304813\n",
      "Loss: 0.2815512083585446\n",
      "Loss: 0.16496272641878862\n",
      "Loss: 0.12058751452427643\n",
      "Loss: 0.10004230758891657\n",
      "Loss: 0.0811220036704953\n",
      "Loss: 0.06643729592601841\n",
      "Loss: 0.07135206739060007\n",
      "Loss: 0.05838582065242987\n",
      "Loss: 0.04615062275614876\n",
      "______\n",
      "Iteration t=5\n",
      "all:  cs/acc_i=54.24 cs/acc_c=53.51 os/recall_knw=49.96 os/recall_unk=81.53 total/acc_i=55.57 total/acc_c=43.19 total/h_score=54.81\n",
      "selected:  cs/acc_i=53.18 cs/acc_c=52.46 os/recall_knw=48.48 os/recall_unk=83.40 total/acc_i=55.35 total/acc_c=41.96 total/h_score=53.97\n",
      "Loss: 1.6532641144969114\n",
      "Loss: 0.28499325517019847\n",
      "Loss: 0.16473312570327303\n",
      "Loss: 0.1261605512203149\n",
      "Loss: 0.09919540315480312\n",
      "Loss: 0.08011636797270578\n",
      "Loss: 0.06882094934855293\n",
      "Loss: 0.06180045502856601\n",
      "Loss: 0.057792798813330236\n",
      "Loss: 0.047888693536728304\n",
      "______\n",
      "Iteration t=6\n",
      "all:  cs/acc_i=54.78 cs/acc_c=54.20 os/recall_knw=49.89 os/recall_unk=81.60 total/acc_i=55.57 total/acc_c=43.16 total/h_score=54.78\n",
      "selected:  cs/acc_i=54.62 cs/acc_c=54.10 os/recall_knw=49.71 os/recall_unk=82.27 total/acc_i=55.62 total/acc_c=43.06 total/h_score=54.82\n",
      "Loss: 1.6535109249126514\n",
      "Loss: 0.2833564907447449\n",
      "Loss: 0.16634449475301358\n",
      "Loss: 0.1215960287187935\n",
      "Loss: 0.09949607622677466\n",
      "Loss: 0.07983994858868397\n",
      "Loss: 0.07373324449081255\n",
      "Loss: 0.05908701609640053\n",
      "Loss: 0.0558483440322053\n",
      "Loss: 0.04677894505534287\n",
      "______\n",
      "Iteration t=7\n",
      "all:  cs/acc_i=55.04 cs/acc_c=54.59 os/recall_knw=49.89 os/recall_unk=81.60 total/acc_i=55.57 total/acc_c=43.16 total/h_score=54.78\n",
      "selected:  cs/acc_i=55.04 cs/acc_c=54.59 os/recall_knw=49.89 os/recall_unk=81.60 total/acc_i=55.57 total/acc_c=43.16 total/h_score=54.78\n",
      "Loss: 1.647988228643515\n",
      "Loss: 0.2840400732021375\n",
      "Loss: 0.16855031184582825\n",
      "Loss: 0.1198692426382822\n",
      "Loss: 0.10324524608384593\n",
      "Loss: 0.08249938930384815\n",
      "Loss: 0.07123367933567658\n",
      "Loss: 0.06286607400362705\n",
      "Loss: 0.05527608374593757\n",
      "Loss: 0.04688600403907518\n",
      "______\n",
      "Iteration t=8\n",
      "all:  cs/acc_i=55.37 cs/acc_c=54.84 os/recall_knw=49.89 os/recall_unk=81.60 total/acc_i=55.57 total/acc_c=43.16 total/h_score=54.78\n",
      "selected:  cs/acc_i=55.37 cs/acc_c=54.84 os/recall_knw=49.89 os/recall_unk=81.60 total/acc_i=55.57 total/acc_c=43.16 total/h_score=54.78\n",
      "Loss: 1.640882122947509\n",
      "Loss: 0.28308919086738166\n",
      "Loss: 0.16616552227726542\n",
      "Loss: 0.12204904590048883\n",
      "Loss: 0.09539017116045018\n",
      "Loss: 0.08341224430162594\n",
      "Loss: 0.07259143435772149\n",
      "Loss: 0.06376011009013886\n",
      "Loss: 0.0479097119911226\n",
      "Loss: 0.0449277564479285\n",
      "______\n",
      "Iteration t=9\n",
      "all:  cs/acc_i=55.73 cs/acc_c=55.18 os/recall_knw=49.89 os/recall_unk=81.60 total/acc_i=55.57 total/acc_c=43.16 total/h_score=54.78\n",
      "selected:  cs/acc_i=55.73 cs/acc_c=55.18 os/recall_knw=49.89 os/recall_unk=81.60 total/acc_i=55.57 total/acc_c=43.16 total/h_score=54.78\n",
      "tensor(0)\n",
      "all:  cs/acc_i=55.73 cs/acc_c=55.18 os/recall_knw=49.89 os/recall_unk=81.60 total/acc_i=55.57 total/acc_c=43.16 total/h_score=54.78\n",
      "real -> sketch lr= 0.001 seed= 3\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19]\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20]\n",
      "Loss: 1.7976896792544164\n",
      "Loss: 0.32775988297212166\n",
      "Loss: 0.19699760456155205\n",
      "Loss: 0.15715664788232156\n",
      "Loss: 0.12792789079646624\n",
      "Loss: 0.10403513657161137\n",
      "Loss: 0.08834424283143358\n",
      "Loss: 0.08119785998454085\n",
      "Loss: 0.07173664717076618\n",
      "Loss: 0.06651078816669002\n",
      "tensor(True) tensor(True)\n",
      "______\n",
      "Iteration t=1\n",
      "all:  cs/acc_i=54.82 cs/acc_c=54.33 os/recall_knw=92.95 os/recall_unk=15.48 total/acc_i=40.61 total/acc_c=51.80 total/h_score=24.02\n",
      "selected:  cs/acc_i=70.00 cs/acc_c=63.88 os/recall_knw=69.84 os/recall_unk=88.37 total/acc_i=73.16 total/acc_c=62.01 total/h_score=71.97\n",
      "Loss: 1.7257585305015783\n",
      "Loss: 0.29775537366701943\n",
      "Loss: 0.17785862499747324\n",
      "Loss: 0.13464541820733733\n",
      "Loss: 0.11886857348066326\n",
      "Loss: 0.09657652051867666\n",
      "Loss: 0.08308458075594358\n",
      "Loss: 0.07023792153985768\n",
      "Loss: 0.06226790916627726\n",
      "Loss: 0.05506982132037346\n",
      "______\n",
      "Iteration t=2\n",
      "all:  cs/acc_i=55.04 cs/acc_c=54.64 os/recall_knw=52.19 os/recall_unk=79.77 total/acc_i=56.04 total/acc_c=44.67 total/h_score=55.80\n",
      "selected:  cs/acc_i=49.39 cs/acc_c=49.36 os/recall_knw=39.06 os/recall_unk=91.65 total/acc_i=55.80 total/acc_c=37.00 total/h_score=49.89\n",
      "Loss: 1.6820851773023606\n",
      "Loss: 0.28854680421852297\n",
      "Loss: 0.16131787426889904\n",
      "Loss: 0.1332687787651535\n",
      "Loss: 0.10423025209156256\n",
      "Loss: 0.09244638020172716\n",
      "Loss: 0.07374914340194194\n",
      "Loss: 0.0707913055505243\n",
      "Loss: 0.05649769985147061\n",
      "Loss: 0.050690623025800435\n",
      "______\n",
      "Iteration t=3\n",
      "all:  cs/acc_i=54.49 cs/acc_c=53.94 os/recall_knw=49.60 os/recall_unk=82.96 total/acc_i=56.47 total/acc_c=43.78 total/h_score=55.61\n",
      "selected:  cs/acc_i=50.62 cs/acc_c=50.26 os/recall_knw=43.02 os/recall_unk=88.94 total/acc_i=55.64 total/acc_c=39.17 total/h_score=51.94\n",
      "Loss: 1.6649873327909026\n",
      "Loss: 0.2751426118068725\n",
      "Loss: 0.17595450168932383\n",
      "Loss: 0.12795715295246937\n",
      "Loss: 0.11240218036497633\n",
      "Loss: 0.08375167810363965\n",
      "Loss: 0.07123685851195277\n",
      "Loss: 0.05919658384321012\n",
      "Loss: 0.05173328330699331\n",
      "Loss: 0.05069808871631727\n",
      "______\n",
      "Iteration t=4\n",
      "all:  cs/acc_i=54.27 cs/acc_c=53.61 os/recall_knw=49.31 os/recall_unk=83.50 total/acc_i=56.54 total/acc_c=43.64 total/h_score=55.58\n",
      "selected:  cs/acc_i=52.21 cs/acc_c=51.69 os/recall_knw=46.16 os/recall_unk=86.86 total/acc_i=56.11 total/acc_c=41.35 total/h_score=53.90\n",
      "Loss: 1.6669260024288555\n",
      "Loss: 0.2818220613731278\n",
      "Loss: 0.16373146306378422\n",
      "Loss: 0.11565818303023223\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.10390036292144178\n",
      "Loss: 0.08346071098873645\n",
      "Loss: 0.07266239708657433\n",
      "Loss: 0.0659403528308174\n",
      "Loss: 0.05480493898331015\n",
      "Loss: 0.04911606177834242\n",
      "______\n",
      "Iteration t=5\n",
      "all:  cs/acc_i=55.22 cs/acc_c=54.54 os/recall_knw=49.01 os/recall_unk=83.57 total/acc_i=56.47 total/acc_c=43.52 total/h_score=55.47\n",
      "selected:  cs/acc_i=54.32 cs/acc_c=53.75 os/recall_knw=47.56 os/recall_unk=85.31 total/acc_i=56.32 total/acc_c=42.57 total/h_score=54.86\n",
      "Loss: 1.6550589007886543\n",
      "Loss: 0.2843791816030438\n",
      "Loss: 0.17078164561626014\n",
      "Loss: 0.12420761571849613\n",
      "Loss: 0.096958882702281\n",
      "Loss: 0.0865309231712366\n",
      "Loss: 0.0752099360074472\n",
      "Loss: 0.06484819991679275\n",
      "Loss: 0.05266533391151452\n",
      "Loss: 0.04683439419761482\n",
      "______\n",
      "Iteration t=6\n",
      "all:  cs/acc_i=56.50 cs/acc_c=55.85 os/recall_knw=49.01 os/recall_unk=83.57 total/acc_i=56.47 total/acc_c=43.52 total/h_score=55.47\n",
      "selected:  cs/acc_i=56.35 cs/acc_c=55.76 os/recall_knw=48.79 os/recall_unk=84.20 total/acc_i=56.52 total/acc_c=43.42 total/h_score=55.49\n",
      "Loss: 1.6552903035310265\n",
      "Loss: 0.2798631270062235\n",
      "Loss: 0.17042159710339863\n",
      "Loss: 0.12700779561666733\n",
      "Loss: 0.10469855387952734\n",
      "Loss: 0.0797295814498942\n",
      "Loss: 0.07293084220773906\n",
      "Loss: 0.06526361209394178\n",
      "Loss: 0.05982040396769811\n",
      "Loss: 0.049035475906380944\n",
      "______\n",
      "Iteration t=7\n",
      "all:  cs/acc_i=55.77 cs/acc_c=55.17 os/recall_knw=48.98 os/recall_unk=83.57 total/acc_i=56.45 total/acc_c=43.48 total/h_score=55.43\n",
      "selected:  cs/acc_i=55.75 cs/acc_c=55.16 os/recall_knw=48.96 os/recall_unk=83.57 total/acc_i=56.44 total/acc_c=43.46 total/h_score=55.42\n",
      "Loss: 1.6593782120581828\n",
      "Loss: 0.288690362927137\n",
      "Loss: 0.16369220315281188\n",
      "Loss: 0.12630491569412478\n",
      "Loss: 0.10218272820735971\n",
      "Loss: 0.08553486611186104\n",
      "Loss: 0.06993553732719385\n",
      "Loss: 0.0631044596320752\n",
      "Loss: 0.05517102751288224\n",
      "Loss: 0.05118572577185026\n",
      "______\n",
      "Iteration t=8\n",
      "all:  cs/acc_i=56.17 cs/acc_c=55.61 os/recall_knw=48.98 os/recall_unk=83.57 total/acc_i=56.45 total/acc_c=43.48 total/h_score=55.43\n",
      "selected:  cs/acc_i=56.17 cs/acc_c=55.61 os/recall_knw=48.98 os/recall_unk=83.57 total/acc_i=56.45 total/acc_c=43.48 total/h_score=55.43\n",
      "Loss: 1.662381987138228\n",
      "Loss: 0.2868164537305182\n",
      "Loss: 0.16737419700419362\n",
      "Loss: 0.12950118642977693\n",
      "Loss: 0.10300915769837571\n",
      "Loss: 0.08181878607437917\n",
      "Loss: 0.06802871428768743\n",
      "Loss: 0.06204418834496402\n",
      "Loss: 0.052641770122290564\n",
      "Loss: 0.04783182400984295\n",
      "______\n",
      "Iteration t=9\n",
      "all:  cs/acc_i=56.32 cs/acc_c=55.74 os/recall_knw=48.98 os/recall_unk=83.57 total/acc_i=56.45 total/acc_c=43.48 total/h_score=55.43\n",
      "selected:  cs/acc_i=56.32 cs/acc_c=55.74 os/recall_knw=48.98 os/recall_unk=83.57 total/acc_i=56.45 total/acc_c=43.48 total/h_score=55.43\n",
      "tensor(0)\n",
      "all:  cs/acc_i=56.32 cs/acc_c=55.74 os/recall_knw=48.98 os/recall_unk=83.57 total/acc_i=56.45 total/acc_c=43.48 total/h_score=55.43\n",
      "real -> sketch lr= 0.001 seed= 4\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19]\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20]\n",
      "Loss: 1.7998360298918659\n",
      "Loss: 0.3423480660094485\n",
      "Loss: 0.1948879456604927\n",
      "Loss: 0.14490820490672282\n",
      "Loss: 0.12458143474739641\n",
      "Loss: 0.11057497303124213\n",
      "Loss: 0.09112649639650808\n",
      "Loss: 0.08249457653784242\n",
      "Loss: 0.06775261536638295\n",
      "Loss: 0.06103008579847227\n",
      "tensor(True) tensor(True)\n",
      "______\n",
      "Iteration t=1\n",
      "all:  cs/acc_i=55.37 cs/acc_c=54.74 os/recall_knw=92.91 os/recall_unk=15.41 total/acc_i=40.92 total/acc_c=52.21 total/h_score=23.98\n",
      "selected:  cs/acc_i=69.78 cs/acc_c=63.98 os/recall_knw=69.78 os/recall_unk=89.02 total/acc_i=73.02 total/acc_c=62.02 total/h_score=72.16\n",
      "Loss: 1.7351489033852074\n",
      "Loss: 0.30112181070285876\n",
      "Loss: 0.1745432741700898\n",
      "Loss: 0.13704100815025536\n",
      "Loss: 0.10997357565242596\n",
      "Loss: 0.09616961958267525\n",
      "Loss: 0.08245117204716883\n",
      "Loss: 0.07038272790786987\n",
      "Loss: 0.06139184160762139\n",
      "Loss: 0.05560641396771865\n",
      "______\n",
      "Iteration t=2\n",
      "all:  cs/acc_i=55.26 cs/acc_c=54.78 os/recall_knw=54.53 os/recall_unk=78.21 total/acc_i=56.47 total/acc_c=46.02 total/h_score=56.65\n",
      "selected:  cs/acc_i=49.23 cs/acc_c=49.11 os/recall_knw=40.26 os/recall_unk=91.50 total/acc_i=56.57 total/acc_c=37.97 total/h_score=50.94\n",
      "Loss: 1.6975014301077012\n",
      "Loss: 0.28528923344227575\n",
      "Loss: 0.16976366610296312\n",
      "Loss: 0.12433498136458858\n",
      "Loss: 0.09753495377127923\n",
      "Loss: 0.08567765597103824\n",
      "Loss: 0.0768468038569535\n",
      "Loss: 0.06849081841627917\n",
      "Loss: 0.060008542857042727\n",
      "Loss: 0.04994838163557072\n",
      "______\n",
      "Iteration t=3\n",
      "all:  cs/acc_i=54.09 cs/acc_c=53.30 os/recall_knw=50.11 os/recall_unk=82.21 total/acc_i=56.28 total/acc_c=43.83 total/h_score=55.52\n",
      "selected:  cs/acc_i=49.75 cs/acc_c=49.19 os/recall_knw=43.32 os/recall_unk=88.27 total/acc_i=55.21 total/acc_c=38.79 total/h_score=51.46\n",
      "Loss: 1.6767904129605624\n",
      "Loss: 0.28509434905348335\n",
      "Loss: 0.166591406442553\n",
      "Loss: 0.12405077604073211\n",
      "Loss: 0.10376729577510331\n",
      "Loss: 0.08361350508178321\n",
      "Loss: 0.07595522993144656\n",
      "Loss: 0.06308389127359919\n",
      "Loss: 0.05821935841725823\n",
      "Loss: 0.052991995148641884\n",
      "______\n",
      "Iteration t=4\n",
      "all:  cs/acc_i=54.09 cs/acc_c=53.50 os/recall_knw=49.53 os/recall_unk=82.69 total/acc_i=56.11 total/acc_c=43.44 total/h_score=55.24\n",
      "selected:  cs/acc_i=51.90 cs/acc_c=51.38 os/recall_knw=46.48 os/recall_unk=86.14 total/acc_i=55.61 total/acc_c=40.95 total/h_score=53.40\n",
      "Loss: 1.6513143645392523\n",
      "Loss: 0.27490537576837304\n",
      "Loss: 0.1682846239986427\n",
      "Loss: 0.12831569356084974\n",
      "Loss: 0.09761592801545321\n",
      "Loss: 0.08924955632365136\n",
      "Loss: 0.0691203961758242\n",
      "Loss: 0.0593580850859943\n",
      "Loss: 0.05258400989322705\n",
      "Loss: 0.047980562941153986\n",
      "______\n",
      "Iteration t=5\n",
      "all:  cs/acc_i=54.97 cs/acc_c=54.31 os/recall_knw=49.45 os/recall_unk=82.82 total/acc_i=56.11 total/acc_c=43.38 total/h_score=55.21\n",
      "selected:  cs/acc_i=54.11 cs/acc_c=53.55 os/recall_knw=48.11 os/recall_unk=85.02 total/acc_i=56.09 total/acc_c=42.46 total/h_score=54.71\n",
      "Loss: 1.6577422304437794\n",
      "Loss: 0.2694854435570743\n",
      "Loss: 0.16398181794752403\n",
      "Loss: 0.12262712942510387\n",
      "Loss: 0.10185574260554547\n",
      "Loss: 0.08101348683454483\n",
      "Loss: 0.07116731491782888\n",
      "Loss: 0.05889177865089581\n",
      "Loss: 0.05574779037175421\n",
      "Loss: 0.04464679035936291\n",
      "______\n",
      "Iteration t=6\n",
      "all:  cs/acc_i=55.26 cs/acc_c=54.70 os/recall_knw=49.42 os/recall_unk=82.89 total/acc_i=56.11 total/acc_c=43.36 total/h_score=55.20\n",
      "selected:  cs/acc_i=55.11 cs/acc_c=54.58 os/recall_knw=49.12 os/recall_unk=83.46 total/acc_i=56.15 total/acc_c=43.21 total/h_score=55.16\n",
      "Loss: 1.644945110787045\n",
      "Loss: 0.28382495420448706\n",
      "Loss: 0.16311482326550916\n",
      "Loss: 0.12016392455464511\n",
      "Loss: 0.09688350261104378\n",
      "Loss: 0.07990135995276046\n",
      "Loss: 0.07522104330304445\n",
      "Loss: 0.05996732149329601\n",
      "Loss: 0.05568749399883955\n",
      "Loss: 0.048338661499490794\n",
      "______\n",
      "Iteration t=7\n",
      "all:  cs/acc_i=55.66 cs/acc_c=55.17 os/recall_knw=49.42 os/recall_unk=82.96 total/acc_i=56.14 total/acc_c=43.36 total/h_score=55.22\n",
      "selected:  cs/acc_i=55.67 cs/acc_c=55.19 os/recall_knw=49.38 os/recall_unk=83.07 total/acc_i=56.17 total/acc_c=43.37 total/h_score=55.25\n",
      "Loss: 1.646408992861693\n",
      "Loss: 0.27571233880798984\n",
      "Loss: 0.15443466578995713\n",
      "Loss: 0.11388355176727037\n",
      "Loss: 0.09810648869801865\n",
      "Loss: 0.08299458856072581\n",
      "Loss: 0.06942329185331111\n",
      "Loss: 0.05924235197175238\n",
      "Loss: 0.054442030903841074\n",
      "Loss: 0.04815858021361635\n",
      "______\n",
      "Iteration t=8\n",
      "all:  cs/acc_i=55.62 cs/acc_c=55.02 os/recall_knw=49.42 os/recall_unk=82.96 total/acc_i=56.14 total/acc_c=43.36 total/h_score=55.22\n",
      "selected:  cs/acc_i=55.62 cs/acc_c=55.02 os/recall_knw=49.42 os/recall_unk=82.96 total/acc_i=56.14 total/acc_c=43.36 total/h_score=55.22\n",
      "Loss: 1.6454581051074486\n",
      "Loss: 0.2715990017322975\n",
      "Loss: 0.1650447764988212\n",
      "Loss: 0.1212061994070373\n",
      "Loss: 0.09762520527922945\n",
      "Loss: 0.09476358017791343\n",
      "Loss: 0.06882852623154749\n",
      "Loss: 0.06067245918131937\n",
      "Loss: 0.054865727111066936\n",
      "Loss: 0.04689286210647365\n",
      "______\n",
      "Iteration t=9\n",
      "all:  cs/acc_i=55.51 cs/acc_c=54.92 os/recall_knw=49.42 os/recall_unk=82.96 total/acc_i=56.14 total/acc_c=43.36 total/h_score=55.22\n",
      "selected:  cs/acc_i=55.51 cs/acc_c=54.92 os/recall_knw=49.42 os/recall_unk=82.96 total/acc_i=56.14 total/acc_c=43.36 total/h_score=55.22\n",
      "tensor(0)\n",
      "all:  cs/acc_i=55.51 cs/acc_c=54.92 os/recall_knw=49.42 os/recall_unk=82.96 total/acc_i=56.14 total/acc_c=43.36 total/h_score=55.22\n",
      "real -> sketch lr= 0.001 seed= 0\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19]\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 1.8073210374740518\n",
      "Loss: 0.33539200629840116\n",
      "Loss: 0.18768756825384084\n",
      "Loss: 0.14491907528392786\n",
      "Loss: 0.12274532586177049\n",
      "Loss: 0.10688372832984792\n",
      "Loss: 0.09169934647906823\n",
      "Loss: 0.07940383625359297\n",
      "Loss: 0.07683350249223438\n",
      "Loss: 0.06347407541135028\n",
      "tensor(True) tensor(True)\n",
      "______\n",
      "Iteration t=1\n",
      "all:  cs/acc_i=54.78 cs/acc_c=54.21 os/recall_knw=92.70 os/recall_unk=15.00 total/acc_i=40.35 total/acc_c=51.55 total/h_score=23.42\n",
      "selected:  cs/acc_i=69.44 cs/acc_c=63.55 os/recall_knw=69.14 os/recall_unk=89.47 total/acc_i=72.51 total/acc_c=61.13 total/h_score=71.63\n",
      "Loss: 1.734359756263636\n",
      "Loss: 0.3029834779894958\n",
      "Loss: 0.17839865445206732\n",
      "Loss: 0.130418688778655\n",
      "Loss: 0.11539379512038776\n",
      "Loss: 0.09574771341315265\n",
      "Loss: 0.08418509359392574\n",
      "Loss: 0.06904688479568241\n",
      "Loss: 0.0653251648359632\n",
      "Loss: 0.058472854822432085\n",
      "______\n",
      "Iteration t=2\n",
      "all:  cs/acc_i=54.82 cs/acc_c=54.25 os/recall_knw=55.26 os/recall_unk=76.58 total/acc_i=56.00 total/acc_c=46.06 total/h_score=56.32\n",
      "selected:  cs/acc_i=48.74 cs/acc_c=48.40 os/recall_knw=40.53 os/recall_unk=91.19 total/acc_i=56.45 total/acc_c=38.01 total/h_score=50.95\n",
      "Loss: 1.6703341436962929\n",
      "Loss: 0.29212794375996437\n",
      "Loss: 0.16495029239524756\n",
      "Loss: 0.12757119499146938\n",
      "Loss: 0.10097380102041267\n",
      "Loss: 0.08539052761850818\n",
      "Loss: 0.07480802276442128\n",
      "Loss: 0.07027624892972169\n",
      "Loss: 0.06261649194263642\n",
      "Loss: 0.05265200392853829\n",
      "______\n",
      "Iteration t=3\n",
      "all:  cs/acc_i=54.02 cs/acc_c=53.48 os/recall_knw=52.05 os/recall_unk=79.84 total/acc_i=56.16 total/acc_c=44.84 total/h_score=55.97\n",
      "selected:  cs/acc_i=50.06 cs/acc_c=49.73 os/recall_knw=45.09 os/recall_unk=86.85 total/acc_i=55.62 total/acc_c=40.08 total/h_score=52.62\n",
      "Loss: 1.659657366387546\n",
      "Loss: 0.285313038690947\n",
      "Loss: 0.16905184861971065\n",
      "Loss: 0.12657546510454268\n",
      "Loss: 0.10876760435930918\n",
      "Loss: 0.0835956534196157\n",
      "Loss: 0.07477491552272113\n",
      "Loss: 0.062201324885245414\n",
      "Loss: 0.05329927092898288\n",
      "Loss: 0.05135019076260505\n",
      "______\n",
      "Iteration t=4\n",
      "all:  cs/acc_i=54.16 cs/acc_c=53.47 os/recall_knw=51.31 os/recall_unk=80.79 total/acc_i=56.26 total/acc_c=44.53 total/h_score=55.89\n",
      "selected:  cs/acc_i=52.09 cs/acc_c=51.44 os/recall_knw=47.95 os/recall_unk=84.64 total/acc_i=55.96 total/acc_c=42.09 total/h_score=54.29\n",
      "Loss: 1.6522415360790088\n",
      "Loss: 0.28884866255466923\n",
      "Loss: 0.1583758336520451\n",
      "Loss: 0.1193245829088739\n",
      "Loss: 0.10071303192354693\n",
      "Loss: 0.08806085117744064\n",
      "Loss: 0.06703152978061441\n",
      "Loss: 0.06187840529211848\n",
      "Loss: 0.05468647995895129\n",
      "Loss: 0.04847530275868949\n",
      "______\n",
      "Iteration t=5\n",
      "all:  cs/acc_i=54.82 cs/acc_c=54.13 os/recall_knw=51.24 os/recall_unk=80.86 total/acc_i=56.26 total/acc_c=44.51 total/h_score=55.88\n",
      "selected:  cs/acc_i=53.82 cs/acc_c=53.22 os/recall_knw=49.76 os/recall_unk=83.00 total/acc_i=56.16 total/acc_c=43.43 total/h_score=55.29\n",
      "Loss: 1.6484890561212193\n",
      "Loss: 0.2796029875450062\n",
      "Loss: 0.1608155151998455\n",
      "Loss: 0.1234249555562256\n",
      "Loss: 0.1011782408042839\n",
      "Loss: 0.0826253811010357\n",
      "Loss: 0.07080484232441946\n",
      "Loss: 0.059861992013104486\n",
      "Loss: 0.055050851871033736\n",
      "Loss: 0.04818207035123399\n",
      "______\n",
      "Iteration t=6\n",
      "all:  cs/acc_i=54.86 cs/acc_c=54.26 os/recall_knw=51.24 os/recall_unk=80.92 total/acc_i=56.28 total/acc_c=44.51 total/h_score=55.89\n",
      "selected:  cs/acc_i=54.57 cs/acc_c=53.93 os/recall_knw=50.85 os/recall_unk=81.64 total/acc_i=56.27 total/acc_c=44.16 total/h_score=55.71\n",
      "Loss: 1.655739271497152\n",
      "Loss: 0.2769709060821368\n",
      "Loss: 0.1691493888845645\n",
      "Loss: 0.11985736823337803\n",
      "Loss: 0.10524841891994408\n",
      "Loss: 0.08324052553051656\n",
      "Loss: 0.0691148161015709\n",
      "Loss: 0.05457411683164537\n",
      "Loss: 0.05498824024528085\n",
      "Loss: 0.048512320487243854\n",
      "______\n",
      "Iteration t=7\n",
      "all:  cs/acc_i=55.77 cs/acc_c=55.10 os/recall_knw=51.21 os/recall_unk=80.92 total/acc_i=56.28 total/acc_c=44.51 total/h_score=55.89\n",
      "selected:  cs/acc_i=55.77 cs/acc_c=55.10 os/recall_knw=51.21 os/recall_unk=81.09 total/acc_i=56.32 total/acc_c=44.52 total/h_score=55.93\n",
      "Loss: 1.657084541367339\n",
      "Loss: 0.2806304475745639\n",
      "Loss: 0.16072947686319952\n",
      "Loss: 0.12018776818125455\n",
      "Loss: 0.10011343646224018\n",
      "Loss: 0.08082531441797365\n",
      "Loss: 0.0724835078212413\n",
      "Loss: 0.05962519618254658\n",
      "Loss: 0.05163663175158404\n",
      "Loss: 0.04687988778503539\n",
      "______\n",
      "Iteration t=8\n",
      "all:  cs/acc_i=55.88 cs/acc_c=55.24 os/recall_knw=51.21 os/recall_unk=80.92 total/acc_i=56.28 total/acc_c=44.51 total/h_score=55.89\n",
      "selected:  cs/acc_i=55.88 cs/acc_c=55.24 os/recall_knw=51.21 os/recall_unk=80.92 total/acc_i=56.28 total/acc_c=44.51 total/h_score=55.89\n",
      "Loss: 1.6544341086983323\n",
      "Loss: 0.28067065050473083\n",
      "Loss: 0.1628807104184284\n",
      "Loss: 0.12359934813110857\n",
      "Loss: 0.0972300971530982\n",
      "Loss: 0.08464567650769565\n",
      "Loss: 0.06996741788825384\n",
      "Loss: 0.06692749479024841\n",
      "Loss: 0.05434052562257191\n",
      "Loss: 0.04555342279796911\n",
      "______\n",
      "Iteration t=9\n",
      "all:  cs/acc_i=55.66 cs/acc_c=55.02 os/recall_knw=51.21 os/recall_unk=80.92 total/acc_i=56.28 total/acc_c=44.51 total/h_score=55.89\n",
      "selected:  cs/acc_i=55.66 cs/acc_c=55.02 os/recall_knw=51.21 os/recall_unk=80.92 total/acc_i=56.28 total/acc_c=44.51 total/h_score=55.89\n",
      "tensor(0)\n",
      "all:  cs/acc_i=55.66 cs/acc_c=55.02 os/recall_knw=51.21 os/recall_unk=80.92 total/acc_i=56.28 total/acc_c=44.51 total/h_score=55.89\n",
      "real -> sketch lr= 0.001 seed= 1\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19]\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20]\n",
      "Loss: 1.8160016246113488\n",
      "Loss: 0.33560116997393\n",
      "Loss: 0.19978517198477774\n",
      "Loss: 0.14572063823532166\n",
      "Loss: 0.12243641701815285\n",
      "Loss: 0.108116642217354\n",
      "Loss: 0.09176194678753402\n",
      "Loss: 0.07948307744045062\n",
      "Loss: 0.07505318688334785\n",
      "Loss: 0.059988256237300586\n",
      "tensor(True) tensor(True)\n",
      "______\n",
      "Iteration t=1\n",
      "all:  cs/acc_i=55.84 cs/acc_c=55.37 os/recall_knw=92.33 os/recall_unk=14.32 total/acc_i=40.85 total/acc_c=52.71 total/h_score=22.70\n",
      "selected:  cs/acc_i=67.63 cs/acc_c=62.85 os/recall_knw=67.94 os/recall_unk=86.48 total/acc_i=70.52 total/acc_c=60.81 total/h_score=70.51\n",
      "Loss: 1.7261527301491917\n",
      "Loss: 0.2974597414502421\n",
      "Loss: 0.1782044513100708\n",
      "Loss: 0.14196908358811727\n",
      "Loss: 0.11870498226552799\n",
      "Loss: 0.09406686425712463\n",
      "Loss: 0.08276882265518243\n",
      "Loss: 0.07064223830034402\n",
      "Loss: 0.06348511764962175\n",
      "Loss: 0.05907962954055669\n",
      "______\n",
      "Iteration t=2\n",
      "all:  cs/acc_i=55.59 cs/acc_c=54.96 os/recall_knw=55.11 os/recall_unk=76.24 total/acc_i=56.19 total/acc_c=46.47 total/h_score=56.58\n",
      "selected:  cs/acc_i=48.91 cs/acc_c=48.61 os/recall_knw=40.37 os/recall_unk=90.93 total/acc_i=56.19 total/acc_c=37.90 total/h_score=50.81\n",
      "Loss: 1.6890173887052844\n",
      "Loss: 0.28982771314199895\n",
      "Loss: 0.171008797951283\n",
      "Loss: 0.13020927356856485\n",
      "Loss: 0.11189935030115228\n",
      "Loss: 0.09032834344092877\n",
      "Loss: 0.07686044142821864\n",
      "Loss: 0.06589959549807733\n",
      "Loss: 0.06130500329703453\n",
      "Loss: 0.05338497193334925\n",
      "______\n",
      "Iteration t=3\n",
      "all:  cs/acc_i=54.97 cs/acc_c=54.39 os/recall_knw=51.53 os/recall_unk=80.72 total/acc_i=56.38 total/acc_c=44.76 total/h_score=56.08\n",
      "selected:  cs/acc_i=50.40 cs/acc_c=50.21 os/recall_knw=44.41 os/recall_unk=87.56 total/acc_i=55.33 total/acc_c=39.52 total/h_score=52.13\n",
      "Loss: 1.6557796293852098\n",
      "Loss: 0.27592961215720657\n",
      "Loss: 0.16806994930937372\n",
      "Loss: 0.12184903447787776\n",
      "Loss: 0.09848926721438532\n",
      "Loss: 0.08528897696726467\n",
      "Loss: 0.07472792894325474\n",
      "Loss: 0.06218270685371934\n",
      "Loss: 0.05393971563287687\n",
      "Loss: 0.052158686437506846\n",
      "______\n",
      "Iteration t=4\n",
      "all:  cs/acc_i=54.82 cs/acc_c=54.31 os/recall_knw=50.55 os/recall_unk=81.33 total/acc_i=56.07 total/acc_c=44.05 total/h_score=55.56\n",
      "selected:  cs/acc_i=52.72 cs/acc_c=52.29 os/recall_knw=47.48 os/recall_unk=85.09 total/acc_i=55.67 total/acc_c=41.67 total/h_score=53.95\n",
      "Loss: 1.6611593913114988\n",
      "Loss: 0.26789404101096664\n",
      "Loss: 0.1627713843377737\n",
      "Loss: 0.12004753595361342\n",
      "Loss: 0.10191206314242802\n",
      "Loss: 0.08367101891109577\n",
      "Loss: 0.07083277048972937\n",
      "Loss: 0.06295627907205087\n",
      "Loss: 0.056004743663450846\n",
      "Loss: 0.051236650821967766\n",
      "______\n",
      "Iteration t=5\n",
      "all:  cs/acc_i=55.48 cs/acc_c=54.96 os/recall_knw=50.44 os/recall_unk=81.40 total/acc_i=56.04 total/acc_c=43.98 total/h_score=55.50\n",
      "selected:  cs/acc_i=54.54 cs/acc_c=54.05 os/recall_knw=49.14 os/recall_unk=83.32 total/acc_i=55.90 total/acc_c=42.94 total/h_score=54.88\n",
      "Loss: 1.6467053137470524\n",
      "Loss: 0.2845947996325406\n",
      "Loss: 0.1666152388321683\n",
      "Loss: 0.12373441555126823\n",
      "Loss: 0.10201689824009014\n",
      "Loss: 0.08220844473803025\n",
      "Loss: 0.07117758746510852\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.06424446708287783\n",
      "Loss: 0.052844878903230634\n",
      "Loss: 0.04482721436930124\n",
      "______\n",
      "Iteration t=6\n",
      "all:  cs/acc_i=55.92 cs/acc_c=55.25 os/recall_knw=50.44 os/recall_unk=81.40 total/acc_i=56.04 total/acc_c=43.98 total/h_score=55.50\n",
      "selected:  cs/acc_i=55.74 cs/acc_c=55.05 os/recall_knw=50.20 os/recall_unk=81.56 total/acc_i=55.97 total/acc_c=43.73 total/h_score=55.31\n",
      "Loss: 1.631852104721299\n",
      "Loss: 0.27340943803898543\n",
      "Loss: 0.15430183077500348\n",
      "Loss: 0.12042032562600202\n",
      "Loss: 0.09450363120939358\n",
      "Loss: 0.08352220931135297\n",
      "Loss: 0.06947993201832006\n",
      "Loss: 0.06245922781134316\n",
      "Loss: 0.05493674748885748\n",
      "Loss: 0.043474418861533415\n",
      "______\n",
      "Iteration t=7\n",
      "all:  cs/acc_i=55.81 cs/acc_c=55.34 os/recall_knw=50.44 os/recall_unk=81.40 total/acc_i=56.04 total/acc_c=43.98 total/h_score=55.50\n",
      "selected:  cs/acc_i=55.79 cs/acc_c=55.31 os/recall_knw=50.42 os/recall_unk=81.40 total/acc_i=56.03 total/acc_c=43.95 total/h_score=55.48\n",
      "Loss: 1.654611191297152\n",
      "Loss: 0.2804470222488225\n",
      "Loss: 0.1734358292852854\n",
      "Loss: 0.12209885025183749\n",
      "Loss: 0.09159398922719152\n",
      "Loss: 0.08350231768900013\n",
      "Loss: 0.07542361249215901\n",
      "Loss: 0.061650511854979016\n",
      "Loss: 0.05093324724697026\n",
      "Loss: 0.04899506279791941\n",
      "______\n",
      "Iteration t=8\n",
      "all:  cs/acc_i=55.81 cs/acc_c=55.26 os/recall_knw=50.44 os/recall_unk=81.40 total/acc_i=56.04 total/acc_c=43.98 total/h_score=55.50\n",
      "selected:  cs/acc_i=55.81 cs/acc_c=55.26 os/recall_knw=50.44 os/recall_unk=81.40 total/acc_i=56.04 total/acc_c=43.98 total/h_score=55.50\n",
      "Loss: 1.6393717387354518\n",
      "Loss: 0.28033968972333945\n",
      "Loss: 0.1559694508056953\n",
      "Loss: 0.1253514979090766\n",
      "Loss: 0.09626623032423835\n",
      "Loss: 0.08101552262823715\n",
      "Loss: 0.0718322036050103\n",
      "Loss: 0.06190422212800393\n",
      "Loss: 0.05302717378895999\n",
      "Loss: 0.04629256480923259\n",
      "______\n",
      "Iteration t=9\n",
      "all:  cs/acc_i=55.66 cs/acc_c=55.13 os/recall_knw=50.44 os/recall_unk=81.40 total/acc_i=56.04 total/acc_c=43.98 total/h_score=55.50\n",
      "selected:  cs/acc_i=55.66 cs/acc_c=55.13 os/recall_knw=50.44 os/recall_unk=81.40 total/acc_i=56.04 total/acc_c=43.98 total/h_score=55.50\n",
      "tensor(0)\n",
      "all:  cs/acc_i=55.66 cs/acc_c=55.13 os/recall_knw=50.44 os/recall_unk=81.40 total/acc_i=56.04 total/acc_c=43.98 total/h_score=55.50\n",
      "real -> sketch lr= 0.001 seed= 2\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19]\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20]\n",
      "Loss: 1.8050857186317444\n",
      "Loss: 0.32564802550018046\n",
      "Loss: 0.19491170699380048\n",
      "Loss: 0.14689304358806474\n",
      "Loss: 0.12134496300245944\n",
      "Loss: 0.11042758640153764\n",
      "Loss: 0.09514990546889736\n",
      "Loss: 0.07947092682945134\n",
      "Loss: 0.07430801321039791\n",
      "Loss: 0.06274069070292378\n",
      "tensor(True) tensor(True)\n",
      "______\n",
      "Iteration t=1\n",
      "all:  cs/acc_i=55.59 cs/acc_c=55.02 os/recall_knw=92.73 os/recall_unk=15.07 total/acc_i=40.94 total/acc_c=52.40 total/h_score=23.59\n",
      "selected:  cs/acc_i=70.02 cs/acc_c=63.33 os/recall_knw=69.24 os/recall_unk=89.52 total/acc_i=73.18 total/acc_c=61.68 total/h_score=72.05\n",
      "Loss: 1.7296791239310119\n",
      "Loss: 0.30219674191232454\n",
      "Loss: 0.17128234008106136\n",
      "Loss: 0.13601372192724276\n",
      "Loss: 0.11565812789219415\n",
      "Loss: 0.09584123563273983\n",
      "Loss: 0.08340643735255225\n",
      "Loss: 0.0695053412942058\n",
      "Loss: 0.062470561600590155\n",
      "Loss: 0.059369954512596634\n",
      "______\n",
      "Iteration t=2\n",
      "all:  cs/acc_i=55.77 cs/acc_c=55.30 os/recall_knw=64.35 os/recall_unk=64.15 total/acc_i=54.19 total/acc_c=49.17 total/h_score=55.19\n",
      "selected:  cs/acc_i=51.55 cs/acc_c=50.48 os/recall_knw=46.08 os/recall_unk=89.57 total/acc_i=58.92 total/acc_c=42.29 total/h_score=55.24\n",
      "Loss: 1.693205312855782\n",
      "Loss: 0.2867409471061922\n",
      "Loss: 0.1708766121056772\n",
      "Loss: 0.1256181644846595\n",
      "Loss: 0.10829489582308358\n",
      "Loss: 0.08718511238093338\n",
      "Loss: 0.07706403559103848\n",
      "Loss: 0.06893263352554171\n",
      "Loss: 0.056429243284548\n",
      "Loss: 0.04682275746318121\n",
      "______\n",
      "Iteration t=3\n",
      "all:  cs/acc_i=55.08 cs/acc_c=54.58 os/recall_knw=56.25 os/recall_unk=75.15 total/acc_i=55.88 total/acc_c=46.47 total/h_score=56.32\n",
      "selected:  cs/acc_i=50.88 cs/acc_c=50.52 os/recall_knw=48.43 os/recall_unk=84.96 total/acc_i=55.90 total/acc_c=41.44 total/h_score=53.71\n",
      "Loss: 1.6653903956924165\n",
      "Loss: 0.2811077111487433\n",
      "Loss: 0.16108719593851092\n",
      "Loss: 0.12291136856613137\n",
      "Loss: 0.0949160122856359\n",
      "Loss: 0.0812774631512924\n",
      "Loss: 0.07635731810576613\n",
      "Loss: 0.06263355101944636\n",
      "Loss: 0.050984230021199915\n",
      "Loss: 0.04833426742643835\n",
      "______\n",
      "Iteration t=4\n",
      "all:  cs/acc_i=53.98 cs/acc_c=53.45 os/recall_knw=54.42 os/recall_unk=77.39 total/acc_i=55.92 total/acc_c=45.53 total/h_score=56.05\n",
      "selected:  cs/acc_i=51.40 cs/acc_c=50.96 os/recall_knw=50.65 os/recall_unk=82.19 total/acc_i=55.59 total/acc_c=42.69 total/h_score=54.45\n",
      "Loss: 1.6622394891228618\n",
      "Loss: 0.2819815575395052\n",
      "Loss: 0.16067187560767662\n",
      "Loss: 0.1209145483061126\n",
      "Loss: 0.101893394254148\n",
      "Loss: 0.08139640751306149\n",
      "Loss: 0.06962634993734111\n",
      "Loss: 0.058774102685785645\n",
      "Loss: 0.04904424528259125\n",
      "Loss: 0.048764226856292225\n",
      "______\n",
      "Iteration t=5\n",
      "all:  cs/acc_i=54.02 cs/acc_c=53.32 os/recall_knw=54.09 os/recall_unk=77.46 total/acc_i=55.78 total/acc_c=45.28 total/h_score=55.85\n",
      "selected:  cs/acc_i=52.73 cs/acc_c=51.97 os/recall_knw=52.42 os/recall_unk=80.35 total/acc_i=55.71 total/acc_c=43.84 total/h_score=55.18\n",
      "Loss: 1.629936625023146\n",
      "Loss: 0.28253043411640794\n",
      "Loss: 0.15877653418987006\n",
      "Loss: 0.11362743756926812\n",
      "Loss: 0.09334240335266332\n",
      "Loss: 0.0769449784238641\n",
      "Loss: 0.07136539462953806\n",
      "Loss: 0.058992581082614244\n",
      "Loss: 0.05369421824471684\n",
      "Loss: 0.05310726976833186\n",
      "______\n",
      "Iteration t=6\n",
      "all:  cs/acc_i=54.86 cs/acc_c=54.19 os/recall_knw=53.83 os/recall_unk=77.53 total/acc_i=55.66 total/acc_c=45.09 total/h_score=55.71\n",
      "selected:  cs/acc_i=54.56 cs/acc_c=53.89 os/recall_knw=53.53 os/recall_unk=78.70 total/acc_i=55.77 total/acc_c=44.82 total/h_score=55.72\n",
      "Loss: 1.6348549356417996\n",
      "Loss: 0.27097437284620746\n",
      "Loss: 0.16461468390410855\n",
      "Loss: 0.11699127148105097\n",
      "Loss: 0.10061933398191329\n",
      "Loss: 0.08620146031691027\n",
      "Loss: 0.06990676168407801\n",
      "Loss: 0.05692342623868691\n",
      "Loss: 0.053558723919975036\n",
      "Loss: 0.0407278733445786\n",
      "______\n",
      "Iteration t=7\n",
      "all:  cs/acc_i=55.70 cs/acc_c=55.03 os/recall_knw=53.83 os/recall_unk=77.53 total/acc_i=55.66 total/acc_c=45.09 total/h_score=55.71\n",
      "selected:  cs/acc_i=55.65 cs/acc_c=54.97 os/recall_knw=53.78 os/recall_unk=77.63 total/acc_i=55.66 total/acc_c=45.03 total/h_score=55.68\n",
      "Loss: 1.6362713182715352\n",
      "Loss: 0.2814766127251376\n",
      "Loss: 0.16551890406613887\n",
      "Loss: 0.12679129558164925\n",
      "Loss: 0.09906856684727201\n",
      "Loss: 0.08656615873339976\n",
      "Loss: 0.07293410027863939\n",
      "Loss: 0.060057596215088396\n",
      "Loss: 0.05313215661346249\n",
      "Loss: 0.04364546025876586\n",
      "______\n",
      "Iteration t=8\n",
      "all:  cs/acc_i=55.30 cs/acc_c=54.82 os/recall_knw=53.83 os/recall_unk=77.53 total/acc_i=55.66 total/acc_c=45.09 total/h_score=55.71\n",
      "selected:  cs/acc_i=55.30 cs/acc_c=54.82 os/recall_knw=53.83 os/recall_unk=77.53 total/acc_i=55.66 total/acc_c=45.09 total/h_score=55.71\n",
      "Loss: 1.6306015597960362\n",
      "Loss: 0.2795187664226538\n",
      "Loss: 0.16357439661326678\n",
      "Loss: 0.11964707310623779\n",
      "Loss: 0.09999916121330477\n",
      "Loss: 0.07996901972302255\n",
      "Loss: 0.07284210908063618\n",
      "Loss: 0.05918651043771813\n",
      "Loss: 0.051894954184639526\n",
      "Loss: 0.04806547162871951\n",
      "______\n",
      "Iteration t=9\n",
      "all:  cs/acc_i=55.92 cs/acc_c=55.35 os/recall_knw=53.83 os/recall_unk=77.53 total/acc_i=55.66 total/acc_c=45.09 total/h_score=55.71\n",
      "selected:  cs/acc_i=55.92 cs/acc_c=55.35 os/recall_knw=53.83 os/recall_unk=77.53 total/acc_i=55.66 total/acc_c=45.09 total/h_score=55.71\n",
      "tensor(0)\n",
      "all:  cs/acc_i=55.92 cs/acc_c=55.35 os/recall_knw=53.83 os/recall_unk=77.53 total/acc_i=55.66 total/acc_c=45.09 total/h_score=55.71\n",
      "real -> sketch lr= 0.001 seed= 3\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19]\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20]\n",
      "Loss: 1.7977224781419883\n",
      "Loss: 0.32832842108087607\n",
      "Loss: 0.19725248159250755\n",
      "Loss: 0.15710583628151978\n",
      "Loss: 0.1279800344470663\n",
      "Loss: 0.10385572755530317\n",
      "Loss: 0.08809909919853524\n",
      "Loss: 0.08099815246791602\n",
      "Loss: 0.07177988874802227\n",
      "Loss: 0.06670490200747321\n",
      "tensor(True) tensor(True)\n",
      "______\n",
      "Iteration t=1\n",
      "all:  cs/acc_i=54.89 cs/acc_c=54.35 os/recall_knw=92.99 os/recall_unk=15.55 total/acc_i=40.73 total/acc_c=51.93 total/h_score=24.12\n",
      "selected:  cs/acc_i=69.89 cs/acc_c=64.32 os/recall_knw=70.05 os/recall_unk=88.42 total/acc_i=73.33 total/acc_c=62.96 total/h_score=72.67\n",
      "Loss: 1.7203793182364993\n",
      "Loss: 0.2963478976759959\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.17825562348337592\n",
      "Loss: 0.1384095127845334\n",
      "Loss: 0.1155347216156991\n",
      "Loss: 0.09685806804525389\n",
      "Loss: 0.08281323663902947\n",
      "Loss: 0.07275833169665388\n",
      "Loss: 0.06415591054797373\n",
      "Loss: 0.054539386876795846\n",
      "______\n",
      "Iteration t=2\n",
      "all:  cs/acc_i=54.71 cs/acc_c=54.13 os/recall_knw=58.55 os/recall_unk=72.78 total/acc_i=55.38 total/acc_c=46.99 total/h_score=56.14\n",
      "selected:  cs/acc_i=49.14 cs/acc_c=48.34 os/recall_knw=42.50 os/recall_unk=91.23 total/acc_i=57.29 total/acc_c=38.96 total/h_score=51.99\n",
      "Loss: 1.6995117272100142\n",
      "Loss: 0.2815554603213264\n",
      "Loss: 0.17295723138076644\n",
      "Loss: 0.12871767531239217\n",
      "Loss: 0.10838196233155266\n",
      "Loss: 0.09520102410667365\n",
      "Loss: 0.07640913529621977\n",
      "Loss: 0.06407173114618467\n",
      "Loss: 0.05874191585838074\n",
      "Loss: 0.04988388317306676\n",
      "______\n",
      "Iteration t=3\n",
      "all:  cs/acc_i=55.30 cs/acc_c=54.64 os/recall_knw=52.99 os/recall_unk=79.09 total/acc_i=56.14 total/acc_c=45.07 total/h_score=56.02\n",
      "selected:  cs/acc_i=51.31 cs/acc_c=50.69 os/recall_knw=45.79 os/recall_unk=86.17 total/acc_i=55.50 total/acc_c=40.05 total/h_score=52.50\n",
      "Loss: 1.6694174207746983\n",
      "Loss: 0.27616705957334486\n",
      "Loss: 0.17124546056729742\n",
      "Loss: 0.12375671362970024\n",
      "Loss: 0.10548010198981501\n",
      "Loss: 0.0846352054271847\n",
      "Loss: 0.0748684991223854\n",
      "Loss: 0.06382770197524223\n",
      "Loss: 0.05817323631927138\n",
      "Loss: 0.05246804355992936\n",
      "______\n",
      "Iteration t=4\n",
      "all:  cs/acc_i=53.98 cs/acc_c=53.36 os/recall_knw=51.86 os/recall_unk=80.24 total/acc_i=56.09 total/acc_c=44.42 total/h_score=55.68\n",
      "selected:  cs/acc_i=51.60 cs/acc_c=50.91 os/recall_knw=48.52 os/recall_unk=84.01 total/acc_i=55.58 total/acc_c=41.66 total/h_score=53.77\n",
      "Loss: 1.640676878164151\n",
      "Loss: 0.28098082471570357\n",
      "Loss: 0.1644562583736664\n",
      "Loss: 0.11950953026513564\n",
      "Loss: 0.09944404669083153\n",
      "Loss: 0.08493810132905795\n",
      "Loss: 0.06620709867319492\n",
      "Loss: 0.060634751449927596\n",
      "Loss: 0.05257942534674622\n",
      "Loss: 0.048074436626837025\n",
      "______\n",
      "Iteration t=5\n",
      "all:  cs/acc_i=54.67 cs/acc_c=53.79 os/recall_knw=51.86 os/recall_unk=80.31 total/acc_i=56.11 total/acc_c=44.43 total/h_score=55.70\n",
      "selected:  cs/acc_i=53.48 cs/acc_c=52.49 os/recall_knw=50.19 os/recall_unk=82.38 total/acc_i=55.88 total/acc_c=42.98 total/h_score=54.76\n",
      "Loss: 1.649954385468454\n",
      "Loss: 0.2789465871272665\n",
      "Loss: 0.16511506202320259\n",
      "Loss: 0.12327447558442751\n",
      "Loss: 0.0972548538931843\n",
      "Loss: 0.08401094471584215\n",
      "Loss: 0.06967963991602036\n",
      "Loss: 0.05957441327416084\n",
      "Loss: 0.05608742477964949\n",
      "Loss: 0.04729895764736063\n",
      "______\n",
      "Iteration t=6\n",
      "all:  cs/acc_i=55.33 cs/acc_c=54.63 os/recall_knw=51.75 os/recall_unk=80.31 total/acc_i=56.07 total/acc_c=44.35 total/h_score=55.63\n",
      "selected:  cs/acc_i=55.06 cs/acc_c=54.36 os/recall_knw=51.42 os/recall_unk=80.97 total/acc_i=56.05 total/acc_c=44.08 total/h_score=55.51\n",
      "Loss: 1.654519553567554\n",
      "Loss: 0.2797128194243879\n",
      "Loss: 0.16638632771466766\n",
      "Loss: 0.12291476765351074\n",
      "Loss: 0.09897305753764447\n",
      "Loss: 0.08464857569249633\n",
      "Loss: 0.0678878699823677\n",
      "Loss: 0.057880049002253346\n",
      "Loss: 0.05348501191894012\n",
      "Loss: 0.046653081067941256\n",
      "______\n",
      "Iteration t=7\n",
      "all:  cs/acc_i=55.08 cs/acc_c=54.57 os/recall_knw=51.75 os/recall_unk=80.31 total/acc_i=56.07 total/acc_c=44.35 total/h_score=55.63\n",
      "selected:  cs/acc_i=55.04 cs/acc_c=54.56 os/recall_knw=51.72 os/recall_unk=80.31 total/acc_i=56.05 total/acc_c=44.34 total/h_score=55.62\n",
      "Loss: 1.6501040980665984\n",
      "Loss: 0.28479139709811724\n",
      "Loss: 0.1565752052283751\n",
      "Loss: 0.12323386492040343\n",
      "Loss: 0.10120475501335131\n",
      "Loss: 0.08416132643975005\n",
      "Loss: 0.0781134246251808\n",
      "Loss: 0.06244964889685685\n",
      "Loss: 0.051637110254353656\n",
      "Loss: 0.04418340630963177\n",
      "______\n",
      "Iteration t=8\n",
      "all:  cs/acc_i=55.81 cs/acc_c=55.10 os/recall_knw=51.75 os/recall_unk=80.31 total/acc_i=56.07 total/acc_c=44.35 total/h_score=55.63\n",
      "selected:  cs/acc_i=55.81 cs/acc_c=55.10 os/recall_knw=51.75 os/recall_unk=80.31 total/acc_i=56.07 total/acc_c=44.35 total/h_score=55.63\n",
      "Loss: 1.6515067096598848\n",
      "Loss: 0.2808992657252771\n",
      "Loss: 0.171028755906367\n",
      "Loss: 0.12895313407779632\n",
      "Loss: 0.09778461475650262\n",
      "Loss: 0.07779674437789325\n",
      "Loss: 0.07020098722991562\n",
      "Loss: 0.05977684077193325\n",
      "Loss: 0.05399664285771192\n",
      "Loss: 0.04493561758475746\n",
      "______\n",
      "Iteration t=9\n",
      "all:  cs/acc_i=55.51 cs/acc_c=54.64 os/recall_knw=51.75 os/recall_unk=80.31 total/acc_i=56.07 total/acc_c=44.35 total/h_score=55.63\n",
      "selected:  cs/acc_i=55.51 cs/acc_c=54.64 os/recall_knw=51.75 os/recall_unk=80.31 total/acc_i=56.07 total/acc_c=44.35 total/h_score=55.63\n",
      "tensor(0)\n",
      "all:  cs/acc_i=55.51 cs/acc_c=54.64 os/recall_knw=51.75 os/recall_unk=80.31 total/acc_i=56.07 total/acc_c=44.35 total/h_score=55.63\n",
      "real -> sketch lr= 0.001 seed= 4\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19]\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20]\n",
      "Loss: 1.7992775546274151\n",
      "Loss: 0.34207858076299213\n",
      "Loss: 0.19446723781579117\n",
      "Loss: 0.14450899406843337\n",
      "Loss: 0.12445680266809633\n",
      "Loss: 0.11039776878689957\n",
      "Loss: 0.09070223612624662\n",
      "Loss: 0.08256374651175058\n",
      "Loss: 0.06789814507807489\n",
      "Loss: 0.061132102014888015\n",
      "tensor(True) tensor(True)\n",
      "______\n",
      "Iteration t=1\n",
      "all:  cs/acc_i=55.41 cs/acc_c=54.75 os/recall_knw=93.32 os/recall_unk=16.16 total/acc_i=41.30 total/acc_c=52.40 total/h_score=24.89\n",
      "selected:  cs/acc_i=70.32 cs/acc_c=63.31 os/recall_knw=70.95 os/recall_unk=89.14 total/acc_i=74.14 total/acc_c=62.15 total/h_score=72.29\n",
      "Loss: 1.7354998810065758\n",
      "Loss: 0.3025076866552636\n",
      "Loss: 0.17609864270088035\n",
      "Loss: 0.13069862216660702\n",
      "Loss: 0.11166382285552351\n",
      "Loss: 0.10059798805112322\n",
      "Loss: 0.0816486815928255\n",
      "Loss: 0.07066844998405793\n",
      "Loss: 0.05926644020694988\n",
      "Loss: 0.0547835319712003\n",
      "______\n",
      "Iteration t=2\n",
      "all:  cs/acc_i=56.28 cs/acc_c=55.77 os/recall_knw=51.46 os/recall_unk=80.65 total/acc_i=56.68 total/acc_c=45.23 total/h_score=56.48\n",
      "selected:  cs/acc_i=50.12 cs/acc_c=49.69 os/recall_knw=38.67 os/recall_unk=91.81 total/acc_i=55.82 total/acc_c=36.92 total/h_score=49.80\n",
      "Loss: 1.6945809421039397\n",
      "Loss: 0.2968674780861024\n",
      "Loss: 0.17061942750888487\n",
      "Loss: 0.12921178947773673\n",
      "Loss: 0.10561211261177256\n",
      "Loss: 0.09256030337644681\n",
      "Loss: 0.08194544145597085\n",
      "Loss: 0.0699250461999327\n",
      "Loss: 0.0562403371655232\n",
      "Loss: 0.05058957754574235\n",
      "______\n",
      "Iteration t=3\n",
      "all:  cs/acc_i=54.02 cs/acc_c=53.38 os/recall_knw=49.09 os/recall_unk=82.42 total/acc_i=56.45 total/acc_c=44.00 total/h_score=55.72\n",
      "selected:  cs/acc_i=49.81 cs/acc_c=49.38 os/recall_knw=42.28 os/recall_unk=88.94 total/acc_i=55.58 total/acc_c=39.16 total/h_score=51.93\n",
      "Loss: 1.6759905278306655\n",
      "Loss: 0.28832821458672125\n",
      "Loss: 0.1671973873188349\n",
      "Loss: 0.12323126167482006\n",
      "Loss: 0.10272574396539562\n",
      "Loss: 0.08399522816762328\n",
      "Loss: 0.07501871462570568\n",
      "Loss: 0.06225005006241357\n",
      "Loss: 0.05794237693918616\n",
      "Loss: 0.050305601928826736\n",
      "______\n",
      "Iteration t=4\n",
      "all:  cs/acc_i=55.04 cs/acc_c=54.31 os/recall_knw=48.28 os/recall_unk=82.96 total/acc_i=56.28 total/acc_c=43.50 total/h_score=55.35\n",
      "selected:  cs/acc_i=52.83 cs/acc_c=52.14 os/recall_knw=45.03 os/recall_unk=86.48 total/acc_i=55.75 total/acc_c=40.95 total/h_score=53.44\n",
      "Loss: 1.6461684605100946\n",
      "Loss: 0.28164518449236364\n",
      "Loss: 0.16487188532302624\n",
      "Loss: 0.12620302272424241\n",
      "Loss: 0.10269972773401453\n",
      "Loss: 0.08389114967948143\n",
      "Loss: 0.07443240971301593\n",
      "Loss: 0.06365934983991525\n",
      "Loss: 0.054287632904231733\n",
      "Loss: 0.04715408420769769\n",
      "______\n",
      "Iteration t=5\n",
      "all:  cs/acc_i=55.62 cs/acc_c=55.02 os/recall_knw=47.92 os/recall_unk=83.71 total/acc_i=56.30 total/acc_c=43.20 total/h_score=55.20\n",
      "selected:  cs/acc_i=54.89 cs/acc_c=54.43 os/recall_knw=46.61 os/recall_unk=85.62 total/acc_i=56.29 total/acc_c=42.44 total/h_score=54.79\n",
      "Loss: 1.6610764222093886\n",
      "Loss: 0.28299527802716\n",
      "Loss: 0.1663284537788092\n",
      "Loss: 0.11783095706322808\n",
      "Loss: 0.10375403380021453\n",
      "Loss: 0.08319647632185027\n",
      "Loss: 0.07460537290006328\n",
      "Loss: 0.05846158644481579\n",
      "Loss: 0.05854261241870378\n",
      "Loss: 0.04972099606519097\n",
      "______\n",
      "Iteration t=6\n",
      "all:  cs/acc_i=56.10 cs/acc_c=55.59 os/recall_knw=47.88 os/recall_unk=83.71 total/acc_i=56.28 total/acc_c=43.17 total/h_score=55.17\n",
      "selected:  cs/acc_i=56.04 cs/acc_c=55.53 os/recall_knw=47.73 os/recall_unk=83.99 total/acc_i=56.31 total/acc_c=43.10 total/h_score=55.16\n",
      "Loss: 1.6410896494576996\n",
      "Loss: 0.28524652907007736\n",
      "Loss: 0.16805553235860943\n",
      "Loss: 0.12963807018400145\n",
      "Loss: 0.10105922675513207\n",
      "Loss: 0.08268754604048914\n",
      "Loss: 0.07539920643606085\n",
      "Loss: 0.05634838111959058\n",
      "Loss: 0.055985993834489836\n",
      "Loss: 0.04939714752174461\n",
      "______\n",
      "Iteration t=7\n",
      "all:  cs/acc_i=56.32 cs/acc_c=55.59 os/recall_knw=47.88 os/recall_unk=83.71 total/acc_i=56.28 total/acc_c=43.17 total/h_score=55.17\n",
      "selected:  cs/acc_i=56.34 cs/acc_c=55.61 os/recall_knw=47.86 os/recall_unk=83.76 total/acc_i=56.31 total/acc_c=43.19 total/h_score=55.20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 1.660081192262267\n",
      "Loss: 0.2766841127789129\n",
      "Loss: 0.15671348046386857\n",
      "Loss: 0.11679831570110603\n",
      "Loss: 0.10209209020150468\n",
      "Loss: 0.08454984579076792\n",
      "Loss: 0.0703265792732679\n",
      "Loss: 0.060432917007463095\n",
      "Loss: 0.05659832402010728\n",
      "Loss: 0.046939978418492435\n",
      "______\n",
      "Iteration t=8\n",
      "all:  cs/acc_i=55.26 cs/acc_c=54.70 os/recall_knw=47.88 os/recall_unk=83.71 total/acc_i=56.28 total/acc_c=43.17 total/h_score=55.17\n",
      "selected:  cs/acc_i=55.28 cs/acc_c=54.72 os/recall_knw=47.86 os/recall_unk=83.71 total/acc_i=56.29 total/acc_c=43.19 total/h_score=55.19\n",
      "Loss: 1.641033053669886\n",
      "Loss: 0.2812043432044403\n",
      "Loss: 0.1645863681499447\n",
      "Loss: 0.12302990595733684\n",
      "Loss: 0.10273741888827828\n",
      "Loss: 0.0859741667755469\n",
      "Loss: 0.07269756024346706\n",
      "Loss: 0.06046943456616739\n",
      "Loss: 0.054282947403794905\n",
      "Loss: 0.04349472916099076\n",
      "______\n",
      "Iteration t=9\n",
      "all:  cs/acc_i=56.03 cs/acc_c=55.53 os/recall_knw=47.88 os/recall_unk=83.71 total/acc_i=56.28 total/acc_c=43.17 total/h_score=55.17\n",
      "selected:  cs/acc_i=56.03 cs/acc_c=55.53 os/recall_knw=47.88 os/recall_unk=83.71 total/acc_i=56.28 total/acc_c=43.17 total/h_score=55.17\n",
      "tensor(0)\n",
      "all:  cs/acc_i=56.03 cs/acc_c=55.53 os/recall_knw=47.88 os/recall_unk=83.71 total/acc_i=56.28 total/acc_c=43.17 total/h_score=55.17\n",
      "real -> sketch lr= 0.001 seed= 0\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19]\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20]\n",
      "Loss: 1.808261473620065\n",
      "Loss: 0.3352163382060163\n",
      "Loss: 0.18747055883854097\n",
      "Loss: 0.1446275030829516\n",
      "Loss: 0.12258451194021838\n",
      "Loss: 0.10668225485990586\n",
      "Loss: 0.0914689092300302\n",
      "Loss: 0.07940650978573065\n",
      "Loss: 0.07659149580068382\n",
      "Loss: 0.0638295677821964\n",
      "tensor(True) tensor(True)\n",
      "______\n",
      "Iteration t=1\n",
      "all:  cs/acc_i=54.60 cs/acc_c=54.04 os/recall_knw=80.31 os/recall_unk=34.83 total/acc_i=45.71 total/acc_c=50.34 total/h_score=41.43\n",
      "selected:  cs/acc_i=51.82 cs/acc_c=48.91 os/recall_knw=45.56 os/recall_unk=95.00 total/acc_i=61.63 total/acc_c=43.30 total/h_score=57.00\n",
      "Loss: 1.732252754573081\n",
      "Loss: 0.300112919856769\n",
      "Loss: 0.17858671298804316\n",
      "Loss: 0.1314166628604604\n",
      "Loss: 0.10903070256667766\n",
      "Loss: 0.10327032586005894\n",
      "Loss: 0.08387529879581888\n",
      "Loss: 0.06937163393013179\n",
      "Loss: 0.06094931769562331\n",
      "Loss: 0.057666527360639964\n",
      "______\n",
      "Iteration t=2\n",
      "all:  cs/acc_i=54.49 cs/acc_c=54.08 os/recall_knw=49.09 os/recall_unk=83.50 total/acc_i=56.45 total/acc_c=43.64 total/h_score=55.57\n",
      "selected:  cs/acc_i=47.71 cs/acc_c=47.74 os/recall_knw=37.43 os/recall_unk=91.86 total/acc_i=54.61 total/acc_c=35.18 total/h_score=47.85\n",
      "Loss: 1.6946617161073991\n",
      "Loss: 0.2950958475710884\n",
      "Loss: 0.16897320820679587\n",
      "Loss: 0.13095954891534584\n",
      "Loss: 0.10272960623485908\n",
      "Loss: 0.08628241197401357\n",
      "Loss: 0.0774812949641097\n",
      "Loss: 0.0653806197021397\n",
      "Loss: 0.060462825211335815\n",
      "Loss: 0.05062269101279878\n",
      "______\n",
      "Iteration t=3\n",
      "all:  cs/acc_i=54.49 cs/acc_c=53.89 os/recall_knw=47.44 os/recall_unk=84.79 total/acc_i=56.30 total/acc_c=42.82 total/h_score=55.02\n",
      "selected:  cs/acc_i=50.67 cs/acc_c=50.33 os/recall_knw=41.38 os/recall_unk=89.92 total/acc_i=55.23 total/acc_c=38.32 total/h_score=51.15\n",
      "Loss: 1.6687995170005112\n",
      "Loss: 0.28345029474432915\n",
      "Loss: 0.17332017342985992\n",
      "Loss: 0.12773396110026994\n",
      "Loss: 0.10681632530731545\n",
      "Loss: 0.087886008936383\n",
      "Loss: 0.07039905330518771\n",
      "Loss: 0.06590642846168873\n",
      "Loss: 0.05790362349338242\n",
      "Loss: 0.052243430734456336\n",
      "______\n",
      "Iteration t=4\n",
      "all:  cs/acc_i=54.38 cs/acc_c=53.85 os/recall_knw=47.01 os/recall_unk=84.86 total/acc_i=56.14 total/acc_c=42.52 total/h_score=54.74\n",
      "selected:  cs/acc_i=52.42 cs/acc_c=52.09 os/recall_knw=44.24 os/recall_unk=87.97 total/acc_i=55.65 total/acc_c=40.43 total/h_score=53.12\n",
      "Loss: 1.6532167123156305\n",
      "Loss: 0.2897718286384707\n",
      "Loss: 0.16127106642223293\n",
      "Loss: 0.1260607541822221\n",
      "Loss: 0.10204519613744309\n",
      "Loss: 0.082479293394533\n",
      "Loss: 0.0753687395777854\n",
      "Loss: 0.06625439667848651\n",
      "Loss: 0.05320715264746954\n",
      "Loss: 0.04840733631230567\n",
      "______\n",
      "Iteration t=5\n",
      "all:  cs/acc_i=54.67 cs/acc_c=54.07 os/recall_knw=46.79 os/recall_unk=85.00 total/acc_i=56.04 total/acc_c=42.33 total/h_score=54.58\n",
      "selected:  cs/acc_i=53.94 cs/acc_c=53.49 os/recall_knw=45.65 os/recall_unk=86.82 total/acc_i=56.00 total/acc_c=41.62 total/h_score=54.16\n",
      "Loss: 1.6558816019388345\n",
      "Loss: 0.29142844184086875\n",
      "Loss: 0.15565092380230244\n",
      "Loss: 0.11864913526062781\n",
      "Loss: 0.10340780986902806\n",
      "Loss: 0.08302350047116096\n",
      "Loss: 0.0715415842544574\n",
      "Loss: 0.06382970299571752\n",
      "Loss: 0.05523297774677093\n",
      "Loss: 0.046469227622191495\n",
      "______\n",
      "Iteration t=6\n",
      "all:  cs/acc_i=55.92 cs/acc_c=55.58 os/recall_knw=46.71 os/recall_unk=85.00 total/acc_i=56.00 total/acc_c=42.27 total/h_score=54.52\n",
      "selected:  cs/acc_i=55.80 cs/acc_c=55.53 os/recall_knw=46.58 os/recall_unk=85.64 total/acc_i=56.07 total/acc_c=42.24 total/h_score=54.60\n",
      "Loss: 1.6597095181088928\n",
      "Loss: 0.2801881593392894\n",
      "Loss: 0.16490896943876868\n",
      "Loss: 0.11427633016333212\n",
      "Loss: 0.09748892756093533\n",
      "Loss: 0.0877154279010376\n",
      "Loss: 0.07056949493569245\n",
      "Loss: 0.06573314573302501\n",
      "Loss: 0.0522521961372152\n",
      "Loss: 0.050799301207430134\n",
      "______\n",
      "Iteration t=7\n",
      "all:  cs/acc_i=56.17 cs/acc_c=55.68 os/recall_knw=46.71 os/recall_unk=85.00 total/acc_i=56.00 total/acc_c=42.27 total/h_score=54.52\n",
      "selected:  cs/acc_i=56.17 cs/acc_c=55.68 os/recall_knw=46.71 os/recall_unk=85.00 total/acc_i=56.00 total/acc_c=42.27 total/h_score=54.52\n",
      "Loss: 1.6552394333227378\n",
      "Loss: 0.2795855678708815\n",
      "Loss: 0.15998330854288326\n",
      "Loss: 0.12215658382330907\n",
      "Loss: 0.09629364232191952\n",
      "Loss: 0.08097298281755662\n",
      "Loss: 0.07625806368404726\n",
      "Loss: 0.06526759128858585\n",
      "Loss: 0.05655855383218562\n",
      "Loss: 0.04759265866170342\n",
      "______\n",
      "Iteration t=8\n",
      "all:  cs/acc_i=55.48 cs/acc_c=55.05 os/recall_knw=46.71 os/recall_unk=85.00 total/acc_i=56.00 total/acc_c=42.27 total/h_score=54.52\n",
      "selected:  cs/acc_i=55.48 cs/acc_c=55.05 os/recall_knw=46.71 os/recall_unk=85.00 total/acc_i=56.00 total/acc_c=42.27 total/h_score=54.52\n",
      "Loss: 1.6558619147030318\n",
      "Loss: 0.27509460484654435\n",
      "Loss: 0.16834893314985605\n",
      "Loss: 0.1310914615793835\n",
      "Loss: 0.0988308111455564\n",
      "Loss: 0.08541521701745962\n",
      "Loss: 0.07165473659818129\n",
      "Loss: 0.06259181211764993\n",
      "Loss: 0.05577726347908582\n",
      "Loss: 0.04519962460489762\n",
      "______\n",
      "Iteration t=9\n",
      "all:  cs/acc_i=56.76 cs/acc_c=56.38 os/recall_knw=46.71 os/recall_unk=85.00 total/acc_i=56.00 total/acc_c=42.27 total/h_score=54.52\n",
      "selected:  cs/acc_i=56.76 cs/acc_c=56.38 os/recall_knw=46.71 os/recall_unk=85.00 total/acc_i=56.00 total/acc_c=42.27 total/h_score=54.52\n",
      "tensor(0)\n",
      "all:  cs/acc_i=56.76 cs/acc_c=56.38 os/recall_knw=46.71 os/recall_unk=85.00 total/acc_i=56.00 total/acc_c=42.27 total/h_score=54.52\n",
      "real -> sketch lr= 0.001 seed= 1\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19]\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20]\n",
      "Loss: 1.8153337164917875\n",
      "Loss: 0.33576920503929414\n",
      "Loss: 0.19996477846467198\n",
      "Loss: 0.1456660569390262\n",
      "Loss: 0.12259251316114465\n",
      "Loss: 0.1082720960957724\n",
      "Loss: 0.09173772677288679\n",
      "Loss: 0.07959682015483384\n",
      "Loss: 0.07502456936899082\n",
      "Loss: 0.05997953634523518\n",
      "tensor(True) tensor(True)\n",
      "______\n",
      "Iteration t=1\n",
      "all:  cs/acc_i=55.70 cs/acc_c=55.25 os/recall_knw=80.64 os/recall_unk=35.44 total/acc_i=46.76 total/acc_c=51.62 total/h_score=42.29\n",
      "selected:  cs/acc_i=51.28 cs/acc_c=50.00 os/recall_knw=45.53 os/recall_unk=94.05 total/acc_i=61.71 total/acc_c=44.51 total/h_score=58.10\n",
      "Loss: 1.7265869795873359\n",
      "Loss: 0.2940735491496083\n",
      "Loss: 0.1832596474780223\n",
      "Loss: 0.14024601463303976\n",
      "Loss: 0.10984096655974517\n",
      "Loss: 0.10678070183289615\n",
      "Loss: 0.07543716642917511\n",
      "Loss: 0.07246741638330088\n",
      "Loss: 0.06656792646390386\n",
      "Loss: 0.06038365315809544\n",
      "______\n",
      "Iteration t=2\n",
      "all:  cs/acc_i=55.48 cs/acc_c=54.87 os/recall_knw=47.77 os/recall_unk=83.03 total/acc_i=56.21 total/acc_c=43.37 total/h_score=55.24\n",
      "selected:  cs/acc_i=49.67 cs/acc_c=49.50 os/recall_knw=36.81 os/recall_unk=91.89 total/acc_i=54.87 total/acc_c=35.87 total/h_score=48.64\n",
      "Loss: 1.704008097994712\n",
      "Loss: 0.28451189908289143\n",
      "Loss: 0.16914714364515196\n",
      "Loss: 0.12372422610079088\n",
      "Loss: 0.10461370567040097\n",
      "Loss: 0.09359352673373876\n",
      "Loss: 0.07593477328698481\n",
      "Loss: 0.06414632589946831\n",
      "Loss: 0.05748177318938918\n",
      "Loss: 0.05512340637975403\n",
      "______\n",
      "Iteration t=3\n",
      "all:  cs/acc_i=55.44 cs/acc_c=54.82 os/recall_knw=46.35 os/recall_unk=84.73 total/acc_i=56.38 total/acc_c=42.81 total/h_score=55.00\n",
      "selected:  cs/acc_i=51.99 cs/acc_c=51.76 os/recall_knw=40.43 os/recall_unk=90.04 total/acc_i=55.50 total/acc_c=38.79 total/h_score=51.66\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 1.6734174053314366\n",
      "Loss: 0.2864907226419147\n",
      "Loss: 0.17149185074516868\n",
      "Loss: 0.12908611470491543\n",
      "Loss: 0.1060447948513246\n",
      "Loss: 0.08629967019704607\n",
      "Loss: 0.07360858114176913\n",
      "Loss: 0.06698896015826258\n",
      "Loss: 0.055496633677637276\n",
      "Loss: 0.05529041528477793\n",
      "______\n",
      "Iteration t=4\n",
      "all:  cs/acc_i=55.37 cs/acc_c=54.81 os/recall_knw=45.51 os/recall_unk=85.40 total/acc_i=56.23 total/acc_c=42.31 total/h_score=54.63\n",
      "selected:  cs/acc_i=53.80 cs/acc_c=53.44 os/recall_knw=42.94 os/recall_unk=88.65 total/acc_i=56.00 total/acc_c=40.56 total/h_score=53.35\n",
      "Loss: 1.6521102075821885\n",
      "Loss: 0.27376117380887177\n",
      "Loss: 0.1701053140214949\n",
      "Loss: 0.12251164069010462\n",
      "Loss: 0.09906007899870846\n",
      "Loss: 0.08393337157180655\n",
      "Loss: 0.0722889204442826\n",
      "Loss: 0.06367652316511002\n",
      "Loss: 0.05714380156359058\n",
      "Loss: 0.048648657742887735\n",
      "______\n",
      "Iteration t=5\n",
      "all:  cs/acc_i=56.25 cs/acc_c=55.64 os/recall_knw=45.47 os/recall_unk=85.40 total/acc_i=56.21 total/acc_c=42.27 total/h_score=54.59\n",
      "selected:  cs/acc_i=55.79 cs/acc_c=55.32 os/recall_knw=44.62 os/recall_unk=86.76 total/acc_i=56.22 total/acc_c=41.84 total/h_score=54.37\n",
      "Loss: 1.6514928272844833\n",
      "Loss: 0.28236793676092303\n",
      "Loss: 0.1689614718205031\n",
      "Loss: 0.13089549066613854\n",
      "Loss: 0.10093243702107833\n",
      "Loss: 0.08501296704577535\n",
      "Loss: 0.07472442591240928\n",
      "Loss: 0.0630770314493458\n",
      "Loss: 0.05545831711267202\n",
      "Loss: 0.04942174971586576\n",
      "______\n",
      "Iteration t=6\n",
      "all:  cs/acc_i=56.46 cs/acc_c=55.73 os/recall_knw=45.47 os/recall_unk=85.40 total/acc_i=56.21 total/acc_c=42.27 total/h_score=54.59\n",
      "selected:  cs/acc_i=56.41 cs/acc_c=55.69 os/recall_knw=45.35 os/recall_unk=85.75 total/acc_i=56.25 total/acc_c=42.23 total/h_score=54.60\n",
      "Loss: 1.638977904444092\n",
      "Loss: 0.2776315604433692\n",
      "Loss: 0.16502533542232278\n",
      "Loss: 0.11626666471179277\n",
      "Loss: 0.10047192711303113\n",
      "Loss: 0.08617261154548568\n",
      "Loss: 0.06935734796749166\n",
      "Loss: 0.061943400994034635\n",
      "Loss: 0.059630733790401756\n",
      "Loss: 0.046850555226423896\n",
      "______\n",
      "Iteration t=7\n",
      "all:  cs/acc_i=56.17 cs/acc_c=55.42 os/recall_knw=45.47 os/recall_unk=85.40 total/acc_i=56.21 total/acc_c=42.27 total/h_score=54.59\n",
      "selected:  cs/acc_i=56.17 cs/acc_c=55.42 os/recall_knw=45.47 os/recall_unk=85.40 total/acc_i=56.21 total/acc_c=42.27 total/h_score=54.59\n",
      "Loss: 1.656482975907121\n",
      "Loss: 0.29361757656639337\n",
      "Loss: 0.16417787447457483\n",
      "Loss: 0.12080370618796056\n",
      "Loss: 0.10114728038319232\n",
      "Loss: 0.0854713764310203\n",
      "Loss: 0.06799701549272778\n",
      "Loss: 0.0621990316898842\n",
      "Loss: 0.05420192157095469\n",
      "Loss: 0.04736511030040133\n",
      "______\n",
      "Iteration t=8\n",
      "all:  cs/acc_i=57.20 cs/acc_c=56.49 os/recall_knw=45.47 os/recall_unk=85.40 total/acc_i=56.21 total/acc_c=42.27 total/h_score=54.59\n",
      "selected:  cs/acc_i=57.20 cs/acc_c=56.49 os/recall_knw=45.47 os/recall_unk=85.40 total/acc_i=56.21 total/acc_c=42.27 total/h_score=54.59\n",
      "Loss: 1.6494684594174835\n",
      "Loss: 0.27507174344150565\n",
      "Loss: 0.1585008077083464\n",
      "Loss: 0.12307518382950977\n",
      "Loss: 0.10294012405389658\n",
      "Loss: 0.08229623701526252\n",
      "Loss: 0.07103408515836152\n",
      "Loss: 0.0552453610666119\n",
      "Loss: 0.051835318737337654\n",
      "Loss: 0.049716343551137104\n",
      "______\n",
      "Iteration t=9\n",
      "all:  cs/acc_i=56.90 cs/acc_c=56.17 os/recall_knw=45.47 os/recall_unk=85.40 total/acc_i=56.21 total/acc_c=42.27 total/h_score=54.59\n",
      "selected:  cs/acc_i=56.90 cs/acc_c=56.17 os/recall_knw=45.47 os/recall_unk=85.40 total/acc_i=56.21 total/acc_c=42.27 total/h_score=54.59\n",
      "tensor(0)\n",
      "all:  cs/acc_i=56.90 cs/acc_c=56.17 os/recall_knw=45.47 os/recall_unk=85.40 total/acc_i=56.21 total/acc_c=42.27 total/h_score=54.59\n",
      "real -> sketch lr= 0.001 seed= 2\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19]\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20]\n",
      "Loss: 1.8070640463209662\n",
      "Loss: 0.326094837428412\n",
      "Loss: 0.19518741822115468\n",
      "Loss: 0.1472453142506372\n",
      "Loss: 0.12111583991751765\n",
      "Loss: 0.11058880213740882\n",
      "Loss: 0.0954568479574713\n",
      "Loss: 0.07923657326458612\n",
      "Loss: 0.07459508048476539\n",
      "Loss: 0.06253802295595248\n",
      "tensor(True) tensor(True)\n",
      "______\n",
      "Iteration t=1\n",
      "all:  cs/acc_i=55.59 cs/acc_c=55.07 os/recall_knw=81.19 os/recall_unk=36.46 total/acc_i=46.78 total/acc_c=51.17 total/h_score=42.83\n",
      "selected:  cs/acc_i=54.05 cs/acc_c=51.61 os/recall_knw=46.58 os/recall_unk=95.38 total/acc_i=63.46 total/acc_c=44.87 total/h_score=58.65\n",
      "Loss: 1.725627228971255\n",
      "Loss: 0.3042572551359565\n",
      "Loss: 0.17136607598197662\n",
      "Loss: 0.13968050300569856\n",
      "Loss: 0.12110624305146225\n",
      "Loss: 0.09669735881863004\n",
      "Loss: 0.08609934948005919\n",
      "Loss: 0.06862483802330444\n",
      "Loss: 0.06439119034320495\n",
      "Loss: 0.056349383267747646\n",
      "______\n",
      "Iteration t=2\n",
      "all:  cs/acc_i=55.77 cs/acc_c=55.33 os/recall_knw=49.45 os/recall_unk=82.08 total/acc_i=56.68 total/acc_c=44.51 total/h_score=56.11\n",
      "selected:  cs/acc_i=49.19 cs/acc_c=49.38 os/recall_knw=37.60 os/recall_unk=91.73 total/acc_i=55.18 total/acc_c=36.45 total/h_score=49.27\n",
      "Loss: 1.7033610160312345\n",
      "Loss: 0.2916149788566174\n",
      "Loss: 0.17240031845867634\n",
      "Loss: 0.13007388938098186\n",
      "Loss: 0.10624177097793548\n",
      "Loss: 0.09308908859327916\n",
      "Loss: 0.07467691872509256\n",
      "Loss: 0.06350103561135549\n",
      "Loss: 0.060962130288563426\n",
      "Loss: 0.04815603864844888\n",
      "______\n",
      "Iteration t=3\n",
      "all:  cs/acc_i=54.75 cs/acc_c=54.21 os/recall_knw=47.99 os/recall_unk=83.57 total/acc_i=56.59 total/acc_c=43.68 total/h_score=55.63\n",
      "selected:  cs/acc_i=50.44 cs/acc_c=50.35 os/recall_knw=40.99 os/recall_unk=89.85 total/acc_i=55.54 total/acc_c=38.77 total/h_score=51.62\n",
      "Loss: 1.6700858459631098\n",
      "Loss: 0.2846949290295568\n",
      "Loss: 0.17034570205532298\n",
      "Loss: 0.12492901108027259\n",
      "Loss: 0.09694317266156402\n",
      "Loss: 0.08785474165401692\n",
      "Loss: 0.07070800848599948\n",
      "Loss: 0.06312996225248833\n",
      "Loss: 0.05669057857587085\n",
      "Loss: 0.050077528937401465\n",
      "______\n",
      "Iteration t=4\n",
      "all:  cs/acc_i=55.33 cs/acc_c=54.71 os/recall_knw=47.74 os/recall_unk=83.91 total/acc_i=56.59 total/acc_c=43.53 total/h_score=55.54\n",
      "selected:  cs/acc_i=53.21 cs/acc_c=52.59 os/recall_knw=44.34 os/recall_unk=87.78 total/acc_i=56.20 total/acc_c=41.07 total/h_score=53.75\n",
      "Loss: 1.6648134603078322\n",
      "Loss: 0.2801351489279396\n",
      "Loss: 0.16427134858988088\n",
      "Loss: 0.12244491260035993\n",
      "Loss: 0.1052249591936421\n",
      "Loss: 0.0810228936484095\n",
      "Loss: 0.07102832739148868\n",
      "Loss: 0.06705326702653991\n",
      "Loss: 0.05553687429446033\n",
      "Loss: 0.05147354433064274\n",
      "______\n",
      "Iteration t=5\n",
      "all:  cs/acc_i=56.21 cs/acc_c=55.57 os/recall_knw=47.70 os/recall_unk=83.91 total/acc_i=56.57 total/acc_c=43.51 total/h_score=55.52\n",
      "selected:  cs/acc_i=55.36 cs/acc_c=54.73 os/recall_knw=46.33 os/recall_unk=86.07 total/acc_i=56.53 total/acc_c=42.54 total/h_score=54.95\n",
      "Loss: 1.6365847969713387\n",
      "Loss: 0.27938508064103273\n",
      "Loss: 0.1677437506250443\n",
      "Loss: 0.12406408621363936\n",
      "Loss: 0.09012427619812678\n",
      "Loss: 0.07775588149913341\n",
      "Loss: 0.07463243618561811\n",
      "Loss: 0.060196262050100084\n",
      "Loss: 0.054534718055746584\n",
      "Loss: 0.05127466362729623\n",
      "______\n",
      "Iteration t=6\n",
      "all:  cs/acc_i=56.43 cs/acc_c=56.05 os/recall_knw=47.70 os/recall_unk=83.91 total/acc_i=56.57 total/acc_c=43.51 total/h_score=55.52\n",
      "selected:  cs/acc_i=56.14 cs/acc_c=55.78 os/recall_knw=47.35 os/recall_unk=84.37 total/acc_i=56.49 total/acc_c=43.23 total/h_score=55.34\n",
      "Loss: 1.6550109530912667\n",
      "Loss: 0.28726269068514426\n",
      "Loss: 0.16354722496712717\n",
      "Loss: 0.12848141066525587\n",
      "Loss: 0.09450261583324612\n",
      "Loss: 0.0890572548151107\n",
      "Loss: 0.07243329707374115\n",
      "Loss: 0.0662567769077879\n",
      "Loss: 0.055375890475527455\n",
      "Loss: 0.04665913210653632\n",
      "______\n",
      "Iteration t=7\n",
      "all:  cs/acc_i=56.79 cs/acc_c=56.20 os/recall_knw=47.70 os/recall_unk=83.91 total/acc_i=56.57 total/acc_c=43.51 total/h_score=55.52\n",
      "selected:  cs/acc_i=56.78 cs/acc_c=56.17 os/recall_knw=47.68 os/recall_unk=83.91 total/acc_i=56.56 total/acc_c=43.48 total/h_score=55.50\n",
      "Loss: 1.6634069783528163\n",
      "Loss: 0.28355946862860654\n",
      "Loss: 0.16158176840801008\n",
      "Loss: 0.13580505356849326\n",
      "Loss: 0.09138307853468827\n",
      "Loss: 0.08741293616287162\n",
      "Loss: 0.07138150720503238\n",
      "Loss: 0.06101556017281527\n",
      "Loss: 0.05167775476877903\n",
      "Loss: 0.04821441479035764\n",
      "______\n",
      "Iteration t=8\n",
      "all:  cs/acc_i=57.01 cs/acc_c=56.61 os/recall_knw=47.70 os/recall_unk=83.91 total/acc_i=56.57 total/acc_c=43.51 total/h_score=55.52\n",
      "selected:  cs/acc_i=57.01 cs/acc_c=56.61 os/recall_knw=47.70 os/recall_unk=83.91 total/acc_i=56.57 total/acc_c=43.51 total/h_score=55.52\n",
      "Loss: 1.637505194698786\n",
      "Loss: 0.2821459674409458\n",
      "Loss: 0.162732491801892\n",
      "Loss: 0.1280180179318668\n",
      "Loss: 0.09743485091633437\n",
      "Loss: 0.08896614948576345\n",
      "Loss: 0.07431103311490414\n",
      "Loss: 0.06326398136671689\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.05303326297104132\n",
      "Loss: 0.04848407950580664\n",
      "______\n",
      "Iteration t=9\n",
      "all:  cs/acc_i=56.87 cs/acc_c=56.26 os/recall_knw=47.70 os/recall_unk=83.91 total/acc_i=56.57 total/acc_c=43.51 total/h_score=55.52\n",
      "selected:  cs/acc_i=56.87 cs/acc_c=56.26 os/recall_knw=47.70 os/recall_unk=83.91 total/acc_i=56.57 total/acc_c=43.51 total/h_score=55.52\n",
      "tensor(0)\n",
      "all:  cs/acc_i=56.87 cs/acc_c=56.26 os/recall_knw=47.70 os/recall_unk=83.91 total/acc_i=56.57 total/acc_c=43.51 total/h_score=55.52\n",
      "real -> sketch lr= 0.001 seed= 3\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19]\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20]\n",
      "Loss: 1.7964883293969776\n",
      "Loss: 0.32780935957338464\n",
      "Loss: 0.19704356194337916\n",
      "Loss: 0.1571943590424133\n",
      "Loss: 0.12792587778083583\n",
      "Loss: 0.10386846609267794\n",
      "Loss: 0.08834759657042518\n",
      "Loss: 0.0809244653442046\n",
      "Loss: 0.07181536881551412\n",
      "Loss: 0.06688895268743572\n",
      "tensor(True) tensor(True)\n",
      "______\n",
      "Iteration t=1\n",
      "all:  cs/acc_i=54.53 cs/acc_c=54.01 os/recall_knw=80.64 os/recall_unk=35.44 total/acc_i=46.45 total/acc_c=51.11 total/h_score=42.12\n",
      "selected:  cs/acc_i=50.10 cs/acc_c=47.83 os/recall_knw=45.81 os/recall_unk=94.57 total/acc_i=62.29 total/acc_c=44.23 total/h_score=57.89\n",
      "Loss: 1.7218535812319935\n",
      "Loss: 0.2974956874811166\n",
      "Loss: 0.1729390141617104\n",
      "Loss: 0.1340731989995048\n",
      "Loss: 0.11648328427061741\n",
      "Loss: 0.09830138666832165\n",
      "Loss: 0.08878882836575645\n",
      "Loss: 0.07260517568038022\n",
      "Loss: 0.06447031638408834\n",
      "Loss: 0.05767728999804554\n",
      "______\n",
      "Iteration t=2\n",
      "all:  cs/acc_i=55.08 cs/acc_c=54.70 os/recall_knw=52.63 os/recall_unk=79.50 total/acc_i=56.38 total/acc_c=45.39 total/h_score=56.38\n",
      "selected:  cs/acc_i=48.48 cs/acc_c=48.65 os/recall_knw=39.42 os/recall_unk=92.06 total/acc_i=55.79 total/acc_c=37.16 total/h_score=50.11\n",
      "Loss: 1.6906779262327378\n",
      "Loss: 0.2972339217941607\n",
      "Loss: 0.16766064453028864\n",
      "Loss: 0.13132031751616347\n",
      "Loss: 0.10491710643794748\n",
      "Loss: 0.09436306251933979\n",
      "Loss: 0.07811486377651172\n",
      "Loss: 0.0712050944626812\n",
      "Loss: 0.05871685390931464\n",
      "Loss: 0.053727861052198754\n",
      "______\n",
      "Iteration t=3\n",
      "all:  cs/acc_i=54.20 cs/acc_c=53.81 os/recall_knw=50.73 os/recall_unk=81.81 total/acc_i=56.49 total/acc_c=44.49 total/h_score=56.04\n",
      "selected:  cs/acc_i=50.00 cs/acc_c=49.98 os/recall_knw=43.79 os/recall_unk=88.93 total/acc_i=55.79 total/acc_c=39.77 total/h_score=52.57\n",
      "Loss: 1.677645464175902\n",
      "Loss: 0.2782388796221535\n",
      "Loss: 0.16527284419386642\n",
      "Loss: 0.13630358784594251\n",
      "Loss: 0.10519589279608438\n",
      "Loss: 0.08592917271977607\n",
      "Loss: 0.07688781445986538\n",
      "Loss: 0.058044966831569025\n",
      "Loss: 0.05519121534003636\n",
      "Loss: 0.05099523863052281\n",
      "______\n",
      "Iteration t=4\n",
      "all:  cs/acc_i=53.80 cs/acc_c=53.20 os/recall_knw=49.53 os/recall_unk=83.16 total/acc_i=56.49 total/acc_c=43.82 total/h_score=55.68\n",
      "selected:  cs/acc_i=51.33 cs/acc_c=50.84 os/recall_knw=45.97 os/recall_unk=86.94 total/acc_i=55.94 total/acc_c=41.14 total/h_score=53.70\n",
      "Loss: 1.6615898491981966\n",
      "Loss: 0.2760678842525364\n",
      "Loss: 0.157670030528939\n",
      "Loss: 0.12342983466968079\n",
      "Loss: 0.10142867495204919\n",
      "Loss: 0.08588450174524966\n",
      "Loss: 0.07266131990615152\n",
      "Loss: 0.06554659675726027\n",
      "Loss: 0.05481427172256559\n",
      "Loss: 0.05235532394267226\n",
      "______\n",
      "Iteration t=5\n",
      "all:  cs/acc_i=54.46 cs/acc_c=53.82 os/recall_knw=49.38 os/recall_unk=83.23 total/acc_i=56.45 total/acc_c=43.71 total/h_score=55.59\n",
      "selected:  cs/acc_i=53.39 cs/acc_c=52.82 os/recall_knw=47.78 os/recall_unk=85.26 total/acc_i=56.28 total/acc_c=42.53 total/h_score=54.82\n",
      "Loss: 1.661769503573759\n",
      "Loss: 0.27394961192064693\n",
      "Loss: 0.16949640560769888\n",
      "Loss: 0.1239277958835757\n",
      "Loss: 0.09979917282175944\n",
      "Loss: 0.08450232790241913\n",
      "Loss: 0.0699542213889232\n",
      "Loss: 0.06498109250377852\n",
      "Loss: 0.056958603573000394\n",
      "Loss: 0.048923582707984595\n",
      "______\n",
      "Iteration t=6\n",
      "all:  cs/acc_i=55.84 cs/acc_c=55.14 os/recall_knw=49.38 os/recall_unk=83.23 total/acc_i=56.45 total/acc_c=43.71 total/h_score=55.59\n",
      "selected:  cs/acc_i=55.67 cs/acc_c=54.93 os/recall_knw=49.14 os/recall_unk=83.34 total/acc_i=56.36 total/acc_c=43.46 total/h_score=55.38\n",
      "Loss: 1.6424363188671343\n",
      "Loss: 0.2755931934398232\n",
      "Loss: 0.16624023697592996\n",
      "Loss: 0.12035124821193291\n",
      "Loss: 0.10217737077142705\n",
      "Loss: 0.08135930742842681\n",
      "Loss: 0.07439308265844981\n",
      "Loss: 0.06465201925373439\n",
      "Loss: 0.05799599673711892\n",
      "Loss: 0.047967005521059036\n",
      "______\n",
      "Iteration t=7\n",
      "all:  cs/acc_i=56.46 cs/acc_c=55.86 os/recall_knw=49.38 os/recall_unk=83.30 total/acc_i=56.47 total/acc_c=43.71 total/h_score=55.60\n",
      "selected:  cs/acc_i=56.46 cs/acc_c=55.86 os/recall_knw=49.38 os/recall_unk=83.36 total/acc_i=56.48 total/acc_c=43.71 total/h_score=55.62\n",
      "Loss: 1.6486702620803049\n",
      "Loss: 0.28827043528193075\n",
      "Loss: 0.16608364845195567\n",
      "Loss: 0.12648295157580577\n",
      "Loss: 0.09990550798231741\n",
      "Loss: 0.08324422895362504\n",
      "Loss: 0.07604160898975645\n",
      "Loss: 0.06280220352293321\n",
      "Loss: 0.05640360519987759\n",
      "Loss: 0.04827498083194194\n",
      "______\n",
      "Iteration t=8\n",
      "all:  cs/acc_i=56.06 cs/acc_c=55.49 os/recall_knw=49.38 os/recall_unk=83.30 total/acc_i=56.47 total/acc_c=43.71 total/h_score=55.60\n",
      "selected:  cs/acc_i=56.06 cs/acc_c=55.49 os/recall_knw=49.38 os/recall_unk=83.30 total/acc_i=56.47 total/acc_c=43.71 total/h_score=55.60\n",
      "Loss: 1.6496591105201814\n",
      "Loss: 0.27312752256715767\n",
      "Loss: 0.15179837268307309\n",
      "Loss: 0.1301249525315632\n",
      "Loss: 0.1001114291096742\n",
      "Loss: 0.08423583779562817\n",
      "Loss: 0.07062484249134979\n",
      "Loss: 0.060501257171488604\n",
      "Loss: 0.04872943446661973\n",
      "Loss: 0.04666650090563559\n",
      "______\n",
      "Iteration t=9\n",
      "all:  cs/acc_i=56.68 cs/acc_c=56.11 os/recall_knw=49.38 os/recall_unk=83.30 total/acc_i=56.47 total/acc_c=43.71 total/h_score=55.60\n",
      "selected:  cs/acc_i=56.68 cs/acc_c=56.11 os/recall_knw=49.38 os/recall_unk=83.30 total/acc_i=56.47 total/acc_c=43.71 total/h_score=55.60\n",
      "tensor(0)\n",
      "all:  cs/acc_i=56.68 cs/acc_c=56.11 os/recall_knw=49.38 os/recall_unk=83.30 total/acc_i=56.47 total/acc_c=43.71 total/h_score=55.60\n",
      "real -> sketch lr= 0.001 seed= 4\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19]\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20]\n",
      "Loss: 1.7984603263729408\n",
      "Loss: 0.3419647061421778\n",
      "Loss: 0.1945345399377609\n",
      "Loss: 0.14440058650336232\n",
      "Loss: 0.12452681278113899\n",
      "Loss: 0.11060786880950486\n",
      "Loss: 0.09086397975298752\n",
      "Loss: 0.08275087001431879\n",
      "Loss: 0.06822192384877981\n",
      "Loss: 0.06121078218429538\n",
      "tensor(True) tensor(True)\n",
      "______\n",
      "Iteration t=1\n",
      "all:  cs/acc_i=55.26 cs/acc_c=54.63 os/recall_knw=80.93 os/recall_unk=35.98 total/acc_i=46.78 total/acc_c=51.21 total/h_score=42.52\n",
      "selected:  cs/acc_i=51.60 cs/acc_c=48.86 os/recall_knw=46.13 os/recall_unk=94.98 total/acc_i=62.67 total/acc_c=43.78 total/h_score=57.49\n",
      "Loss: 1.7429827753770148\n",
      "Loss: 0.2970205401717606\n",
      "Loss: 0.18043314953476697\n",
      "Loss: 0.1361721205509315\n",
      "Loss: 0.11541700365053395\n",
      "Loss: 0.09703913062684617\n",
      "Loss: 0.08113373050750312\n",
      "Loss: 0.06962055953187962\n",
      "Loss: 0.0610866263666648\n",
      "Loss: 0.05656684559801499\n",
      "______\n",
      "Iteration t=2\n",
      "all:  cs/acc_i=56.14 cs/acc_c=55.62 os/recall_knw=48.87 os/recall_unk=82.89 total/acc_i=56.42 total/acc_c=43.81 total/h_score=55.62\n",
      "selected:  cs/acc_i=49.51 cs/acc_c=49.61 os/recall_knw=37.16 os/recall_unk=91.74 total/acc_i=54.57 total/acc_c=35.49 total/h_score=48.19\n",
      "Loss: 1.6951050662225293\n",
      "Loss: 0.28787171803414824\n",
      "Loss: 0.17240550148511125\n",
      "Loss: 0.12770864020792708\n",
      "Loss: 0.10698499140600043\n",
      "Loss: 0.0867597573226498\n",
      "Loss: 0.08451647799942763\n",
      "Loss: 0.06617610086837122\n",
      "Loss: 0.059957390877928944\n",
      "Loss: 0.05241683384613885\n",
      "______\n",
      "Iteration t=3\n",
      "all:  cs/acc_i=53.69 cs/acc_c=53.05 os/recall_knw=46.49 os/recall_unk=85.40 total/acc_i=56.19 total/acc_c=42.29 total/h_score=54.60\n",
      "selected:  cs/acc_i=49.75 cs/acc_c=49.46 os/recall_knw=40.16 os/recall_unk=90.18 total/acc_i=55.01 total/acc_c=37.65 total/h_score=50.45\n",
      "Loss: 1.6906235562283782\n",
      "Loss: 0.2874829790000863\n",
      "Loss: 0.16197052810199652\n",
      "Loss: 0.1286985950391221\n",
      "Loss: 0.10994649385514704\n",
      "Loss: 0.08328755422719294\n",
      "Loss: 0.07033296441954054\n",
      "Loss: 0.07145712677466011\n",
      "Loss: 0.0558560585287765\n",
      "Loss: 0.04905665788690477\n",
      "______\n",
      "Iteration t=4\n",
      "all:  cs/acc_i=55.22 cs/acc_c=54.39 os/recall_knw=46.24 os/recall_unk=85.47 total/acc_i=56.09 total/acc_c=42.09 total/h_score=54.43\n",
      "selected:  cs/acc_i=53.57 cs/acc_c=52.76 os/recall_knw=43.51 os/recall_unk=88.41 total/acc_i=55.73 total/acc_c=40.07 total/h_score=52.82\n",
      "Loss: 1.6808266267412548\n",
      "Loss: 0.280953987550884\n",
      "Loss: 0.16325585093825035\n",
      "Loss: 0.129475705981301\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.10131588261400427\n",
      "Loss: 0.08163361663051019\n",
      "Loss: 0.07411705133159908\n",
      "Loss: 0.061261331859825185\n",
      "Loss: 0.057714907522095696\n",
      "Loss: 0.04800058534438504\n",
      "______\n",
      "Iteration t=5\n",
      "all:  cs/acc_i=55.62 cs/acc_c=54.97 os/recall_knw=46.13 os/recall_unk=85.47 total/acc_i=56.04 total/acc_c=42.01 total/h_score=54.35\n",
      "selected:  cs/acc_i=55.18 cs/acc_c=54.62 os/recall_knw=45.27 os/recall_unk=86.89 total/acc_i=56.08 total/acc_c=41.58 total/h_score=54.13\n",
      "Loss: 1.6664129456189962\n",
      "Loss: 0.2845267508121637\n",
      "Loss: 0.16169093056366993\n",
      "Loss: 0.1218159279284569\n",
      "Loss: 0.10339606584837803\n",
      "Loss: 0.07869224041127242\n",
      "Loss: 0.07426658251537727\n",
      "Loss: 0.06059232329663176\n",
      "Loss: 0.05719972745443766\n",
      "Loss: 0.05047185839153826\n",
      "______\n",
      "Iteration t=6\n",
      "all:  cs/acc_i=55.70 cs/acc_c=55.15 os/recall_knw=46.02 os/recall_unk=85.54 total/acc_i=56.02 total/acc_c=41.95 total/h_score=54.29\n",
      "selected:  cs/acc_i=55.62 cs/acc_c=55.13 os/recall_knw=45.88 os/recall_unk=85.83 total/acc_i=56.04 total/acc_c=41.92 total/h_score=54.31\n",
      "Loss: 1.6491954290976554\n",
      "Loss: 0.27552120970344984\n",
      "Loss: 0.16339933829370634\n",
      "Loss: 0.12191510986125359\n",
      "Loss: 0.0989123334496802\n",
      "Loss: 0.08017180064133157\n",
      "Loss: 0.073334969595886\n",
      "Loss: 0.06032404673937137\n",
      "Loss: 0.057774793838030816\n",
      "Loss: 0.04803712979070499\n",
      "______\n",
      "Iteration t=7\n",
      "all:  cs/acc_i=55.73 cs/acc_c=55.23 os/recall_knw=46.02 os/recall_unk=85.54 total/acc_i=56.02 total/acc_c=41.95 total/h_score=54.29\n",
      "selected:  cs/acc_i=55.73 cs/acc_c=55.23 os/recall_knw=46.02 os/recall_unk=85.54 total/acc_i=56.02 total/acc_c=41.95 total/h_score=54.29\n",
      "Loss: 1.6607231548802204\n",
      "Loss: 0.27710925900471317\n",
      "Loss: 0.1604814634854914\n",
      "Loss: 0.11796335805355591\n",
      "Loss: 0.10857326865469644\n",
      "Loss: 0.08567423642034833\n",
      "Loss: 0.06665622180937263\n",
      "Loss: 0.060676233355947046\n",
      "Loss: 0.05250782694166316\n",
      "Loss: 0.04768695955845422\n",
      "______\n",
      "Iteration t=8\n",
      "all:  cs/acc_i=56.14 cs/acc_c=55.51 os/recall_knw=46.02 os/recall_unk=85.54 total/acc_i=56.02 total/acc_c=41.95 total/h_score=54.29\n",
      "selected:  cs/acc_i=56.14 cs/acc_c=55.51 os/recall_knw=46.02 os/recall_unk=85.54 total/acc_i=56.02 total/acc_c=41.95 total/h_score=54.29\n",
      "Loss: 1.6489549610046073\n",
      "Loss: 0.27820408551609116\n",
      "Loss: 0.16245698532380096\n",
      "Loss: 0.12266875707205464\n",
      "Loss: 0.10495109788629167\n",
      "Loss: 0.0877772878787113\n",
      "Loss: 0.06763919955404299\n",
      "Loss: 0.0623573775172507\n",
      "Loss: 0.0566591895114209\n",
      "Loss: 0.049909417786626914\n",
      "______\n",
      "Iteration t=9\n",
      "all:  cs/acc_i=56.28 cs/acc_c=55.79 os/recall_knw=46.02 os/recall_unk=85.54 total/acc_i=56.02 total/acc_c=41.95 total/h_score=54.29\n",
      "selected:  cs/acc_i=56.28 cs/acc_c=55.79 os/recall_knw=46.02 os/recall_unk=85.54 total/acc_i=56.02 total/acc_c=41.95 total/h_score=54.29\n",
      "tensor(0)\n",
      "all:  cs/acc_i=56.28 cs/acc_c=55.79 os/recall_knw=46.02 os/recall_unk=85.54 total/acc_i=56.02 total/acc_c=41.95 total/h_score=54.29\n",
      "real -> sketch lr= 0.001 seed= 0\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19]\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20]\n",
      "Loss: 1.8066114904193267\n",
      "Loss: 0.33488426259403975\n",
      "Loss: 0.1873769255560488\n",
      "Loss: 0.1446317875711413\n",
      "Loss: 0.12252957279068083\n",
      "Loss: 0.10647267685851805\n",
      "Loss: 0.0914978805558219\n",
      "Loss: 0.0790970840265981\n",
      "Loss: 0.07634226192995322\n",
      "Loss: 0.0637366544037686\n",
      "tensor(True) tensor(True)\n",
      "______\n",
      "Iteration t=1\n",
      "all:  cs/acc_i=54.64 cs/acc_c=54.14 os/recall_knw=80.28 os/recall_unk=34.76 total/acc_i=45.57 total/acc_c=50.12 total/h_score=41.31\n",
      "selected:  cs/acc_i=52.52 cs/acc_c=49.84 os/recall_knw=45.56 os/recall_unk=95.34 total/acc_i=61.74 total/acc_c=43.41 total/h_score=57.16\n",
      "Loss: 1.7327484728114024\n",
      "Loss: 0.2949232497076328\n",
      "Loss: 0.18154733757664626\n",
      "Loss: 0.139415300677757\n",
      "Loss: 0.10929553536698222\n",
      "Loss: 0.0937234094835239\n",
      "Loss: 0.08160191883861616\n",
      "Loss: 0.07633248235514337\n",
      "Loss: 0.06262436929486088\n",
      "Loss: 0.058498166287569583\n",
      "______\n",
      "Iteration t=2\n",
      "all:  cs/acc_i=55.00 cs/acc_c=54.44 os/recall_knw=49.71 os/recall_unk=82.69 total/acc_i=56.61 total/acc_c=44.08 total/h_score=55.83\n",
      "selected:  cs/acc_i=48.85 cs/acc_c=48.89 os/recall_knw=38.11 os/recall_unk=92.76 total/acc_i=55.54 total/acc_c=36.47 total/h_score=49.40\n",
      "Loss: 1.6703152297004578\n",
      "Loss: 0.2906481806789675\n",
      "Loss: 0.1732067043021802\n",
      "Loss: 0.12867246020224787\n",
      "Loss: 0.10419999772021847\n",
      "Loss: 0.09104102868286353\n",
      "Loss: 0.07379226479679346\n",
      "Loss: 0.0687754422846821\n",
      "Loss: 0.058905957681277106\n",
      "Loss: 0.04385128271195196\n",
      "______\n",
      "Iteration t=3\n",
      "all:  cs/acc_i=54.49 cs/acc_c=53.94 os/recall_knw=47.70 os/recall_unk=84.05 total/acc_i=56.23 total/acc_c=42.92 total/h_score=54.99\n",
      "selected:  cs/acc_i=50.96 cs/acc_c=50.65 os/recall_knw=41.72 os/recall_unk=89.52 total/acc_i=55.42 total/acc_c=38.69 total/h_score=51.50\n",
      "Loss: 1.6795866938795576\n",
      "Loss: 0.2860904437275339\n",
      "Loss: 0.16621359013467557\n",
      "Loss: 0.1304235997894773\n",
      "Loss: 0.1005374109871944\n",
      "Loss: 0.08790293693460219\n",
      "Loss: 0.06958558749148992\n",
      "Loss: 0.059065616287126525\n",
      "Loss: 0.058354367980915665\n",
      "Loss: 0.05027648869957716\n",
      "______\n",
      "Iteration t=4\n",
      "all:  cs/acc_i=54.89 cs/acc_c=54.22 os/recall_knw=47.30 os/recall_unk=84.32 total/acc_i=56.16 total/acc_c=42.69 total/h_score=54.81\n",
      "selected:  cs/acc_i=53.11 cs/acc_c=52.62 os/recall_knw=44.31 os/recall_unk=87.90 total/acc_i=55.89 total/acc_c=40.67 total/h_score=53.36\n",
      "Loss: 1.6675036735601307\n",
      "Loss: 0.2852805592119694\n",
      "Loss: 0.16491711322472702\n",
      "Loss: 0.12456517953784292\n",
      "Loss: 0.10215005260655043\n",
      "Loss: 0.08740898522820255\n",
      "Loss: 0.07307609385573623\n",
      "Loss: 0.0592189536962126\n",
      "Loss: 0.05871822374948063\n",
      "Loss: 0.050136322952425164\n",
      "______\n",
      "Iteration t=5\n",
      "all:  cs/acc_i=55.81 cs/acc_c=55.05 os/recall_knw=47.30 os/recall_unk=84.32 total/acc_i=56.16 total/acc_c=42.69 total/h_score=54.81\n",
      "selected:  cs/acc_i=55.06 cs/acc_c=54.45 os/recall_knw=46.14 os/recall_unk=86.25 total/acc_i=56.13 total/acc_c=41.96 total/h_score=54.42\n",
      "Loss: 1.6536483349249913\n",
      "Loss: 0.27753524355017223\n",
      "Loss: 0.16571437504429085\n",
      "Loss: 0.1195754289569763\n",
      "Loss: 0.10895267308904574\n",
      "Loss: 0.0906713463452\n",
      "Loss: 0.07612351134706002\n",
      "Loss: 0.06407498782070783\n",
      "Loss: 0.05288072644231411\n",
      "Loss: 0.050317900696626075\n",
      "______\n",
      "Iteration t=6\n",
      "all:  cs/acc_i=55.33 cs/acc_c=54.70 os/recall_knw=47.26 os/recall_unk=84.32 total/acc_i=56.14 total/acc_c=42.65 total/h_score=54.78\n",
      "selected:  cs/acc_i=55.24 cs/acc_c=54.65 os/recall_knw=47.11 os/recall_unk=84.49 total/acc_i=56.12 total/acc_c=42.59 total/h_score=54.75\n",
      "Loss: 1.6562923754497272\n",
      "Loss: 0.27833357912192985\n",
      "Loss: 0.16207292268802298\n",
      "Loss: 0.11981421674420012\n",
      "Loss: 0.10464888802025377\n",
      "Loss: 0.08091888088937395\n",
      "Loss: 0.06615307429811076\n",
      "Loss: 0.06296793247925163\n",
      "Loss: 0.0529724980673253\n",
      "Loss: 0.04624853537151045\n",
      "______\n",
      "Iteration t=7\n",
      "all:  cs/acc_i=56.28 cs/acc_c=55.69 os/recall_knw=47.22 os/recall_unk=84.32 total/acc_i=56.11 total/acc_c=42.63 total/h_score=54.76\n",
      "selected:  cs/acc_i=56.27 cs/acc_c=55.66 os/recall_knw=47.20 os/recall_unk=84.32 total/acc_i=56.10 total/acc_c=42.60 total/h_score=54.73\n",
      "Loss: 1.6590787290436466\n",
      "Loss: 0.2789255428559533\n",
      "Loss: 0.16492254397173117\n",
      "Loss: 0.12067999937798737\n",
      "Loss: 0.09763675435764216\n",
      "Loss: 0.08557527463048378\n",
      "Loss: 0.07184488750517187\n",
      "Loss: 0.059873909367924194\n",
      "Loss: 0.05593451093768746\n",
      "Loss: 0.04651083468981996\n",
      "______\n",
      "Iteration t=8\n",
      "all:  cs/acc_i=56.46 cs/acc_c=55.91 os/recall_knw=47.22 os/recall_unk=84.32 total/acc_i=56.11 total/acc_c=42.63 total/h_score=54.76\n",
      "selected:  cs/acc_i=56.46 cs/acc_c=55.91 os/recall_knw=47.22 os/recall_unk=84.32 total/acc_i=56.11 total/acc_c=42.63 total/h_score=54.76\n",
      "Loss: 1.6603654152372989\n",
      "Loss: 0.2762207920640344\n",
      "Loss: 0.157310574519925\n",
      "Loss: 0.11742559702294629\n",
      "Loss: 0.0972104256904525\n",
      "Loss: 0.0857470935812538\n",
      "Loss: 0.07213977109867989\n",
      "Loss: 0.06311803685910092\n",
      "Loss: 0.05177337510323879\n",
      "Loss: 0.04500208332319744\n",
      "______\n",
      "Iteration t=9\n",
      "all:  cs/acc_i=55.62 cs/acc_c=55.08 os/recall_knw=47.22 os/recall_unk=84.32 total/acc_i=56.11 total/acc_c=42.63 total/h_score=54.76\n",
      "selected:  cs/acc_i=55.62 cs/acc_c=55.08 os/recall_knw=47.22 os/recall_unk=84.32 total/acc_i=56.11 total/acc_c=42.63 total/h_score=54.76\n",
      "tensor(0)\n",
      "all:  cs/acc_i=55.62 cs/acc_c=55.08 os/recall_knw=47.22 os/recall_unk=84.32 total/acc_i=56.11 total/acc_c=42.63 total/h_score=54.76\n",
      "real -> sketch lr= 0.001 seed= 1\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19]\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20]\n",
      "Loss: 1.8162587346555499\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.33713823334178045\n",
      "Loss: 0.2000296240891214\n",
      "Loss: 0.14532440874950953\n",
      "Loss: 0.12211203447864573\n",
      "Loss: 0.10801193148587097\n",
      "Loss: 0.09104634102539978\n",
      "Loss: 0.07912072402116879\n",
      "Loss: 0.07459158828197\n",
      "Loss: 0.05971715579081154\n",
      "tensor(True) tensor(True)\n",
      "______\n",
      "Iteration t=1\n",
      "all:  cs/acc_i=56.06 cs/acc_c=55.58 os/recall_knw=80.86 os/recall_unk=35.85 total/acc_i=46.97 total/acc_c=51.77 total/h_score=42.63\n",
      "selected:  cs/acc_i=52.73 cs/acc_c=51.34 os/recall_knw=45.92 os/recall_unk=94.29 total/acc_i=62.39 total/acc_c=44.97 total/h_score=58.59\n",
      "Loss: 1.723555739767648\n",
      "Loss: 0.29932163320985194\n",
      "Loss: 0.17955247006957997\n",
      "Loss: 0.1395142127105312\n",
      "Loss: 0.10937181821193646\n",
      "Loss: 0.10118188709649886\n",
      "Loss: 0.08046156610047596\n",
      "Loss: 0.07354378697267305\n",
      "Loss: 0.0644473033403424\n",
      "Loss: 0.061617120419238766\n",
      "______\n",
      "Iteration t=2\n",
      "all:  cs/acc_i=56.39 cs/acc_c=55.86 os/recall_knw=48.76 os/recall_unk=82.76 total/acc_i=56.80 total/acc_c=44.38 total/h_score=56.12\n",
      "selected:  cs/acc_i=50.07 cs/acc_c=50.20 os/recall_knw=37.56 os/recall_unk=92.28 total/acc_i=55.30 total/acc_c=36.53 total/h_score=49.42\n",
      "Loss: 1.6767350129542813\n",
      "Loss: 0.2830678368287702\n",
      "Loss: 0.18068703415413057\n",
      "Loss: 0.12854300584163397\n",
      "Loss: 0.10321558572412018\n",
      "Loss: 0.08972391404752289\n",
      "Loss: 0.07463914455785867\n",
      "Loss: 0.06549008583890334\n",
      "Loss: 0.057665263322903025\n",
      "Loss: 0.050404650578275326\n",
      "______\n",
      "Iteration t=3\n",
      "all:  cs/acc_i=55.66 cs/acc_c=55.13 os/recall_knw=46.57 os/recall_unk=85.81 total/acc_i=56.92 total/acc_c=43.12 total/h_score=55.48\n",
      "selected:  cs/acc_i=51.63 cs/acc_c=51.56 os/recall_knw=40.29 os/recall_unk=90.80 total/acc_i=55.65 total/acc_c=38.53 total/h_score=51.47\n",
      "Loss: 1.6844206022837804\n",
      "Loss: 0.2944776455679583\n",
      "Loss: 0.1681100693013933\n",
      "Loss: 0.1227572285023237\n",
      "Loss: 0.10481820383242198\n",
      "Loss: 0.08304035805224899\n",
      "Loss: 0.07415180220786068\n",
      "Loss: 0.07007184967339512\n",
      "Loss: 0.056539977341890334\n",
      "Loss: 0.05245385373395587\n",
      "______\n",
      "Iteration t=4\n",
      "all:  cs/acc_i=55.59 cs/acc_c=55.03 os/recall_knw=46.49 os/recall_unk=85.88 total/acc_i=56.90 total/acc_c=43.06 total/h_score=55.43\n",
      "selected:  cs/acc_i=53.61 cs/acc_c=53.19 os/recall_knw=43.46 os/recall_unk=89.08 total/acc_i=56.42 total/acc_c=40.89 total/h_score=53.74\n",
      "Loss: 1.6660734102640569\n",
      "Loss: 0.2729429317133449\n",
      "Loss: 0.17233202923843607\n",
      "Loss: 0.12184348358044465\n",
      "Loss: 0.09492988192485036\n",
      "Loss: 0.0876236370491949\n",
      "Loss: 0.07480564431615197\n",
      "Loss: 0.06348954757379595\n",
      "Loss: 0.05487824832103752\n",
      "Loss: 0.05251538041236337\n",
      "______\n",
      "Iteration t=5\n",
      "all:  cs/acc_i=56.46 cs/acc_c=55.75 os/recall_knw=46.42 os/recall_unk=86.08 total/acc_i=56.92 total/acc_c=42.99 total/h_score=55.39\n",
      "selected:  cs/acc_i=55.43 cs/acc_c=54.85 os/recall_knw=44.87 os/recall_unk=87.75 total/acc_i=56.65 total/acc_c=41.92 total/h_score=54.60\n",
      "Loss: 1.6660993226541454\n",
      "Loss: 0.285246535951139\n",
      "Loss: 0.15643895182170367\n",
      "Loss: 0.12388531815825786\n",
      "Loss: 0.10085397277419504\n",
      "Loss: 0.08791700756644409\n",
      "Loss: 0.07184618967513182\n",
      "Loss: 0.06803945610559207\n",
      "Loss: 0.05642987761485042\n",
      "Loss: 0.04845504862063164\n",
      "______\n",
      "Iteration t=6\n",
      "all:  cs/acc_i=56.87 cs/acc_c=56.21 os/recall_knw=46.42 os/recall_unk=86.08 total/acc_i=56.92 total/acc_c=42.99 total/h_score=55.39\n",
      "selected:  cs/acc_i=56.77 cs/acc_c=56.14 os/recall_knw=46.20 os/recall_unk=86.49 total/acc_i=56.95 total/acc_c=42.90 total/h_score=55.37\n",
      "Loss: 1.6395326849141736\n",
      "Loss: 0.2764668739372236\n",
      "Loss: 0.1685876363054192\n",
      "Loss: 0.12740502827600833\n",
      "Loss: 0.10615379519566345\n",
      "Loss: 0.08640597747821659\n",
      "Loss: 0.07225310876308455\n",
      "Loss: 0.06191077316322712\n",
      "Loss: 0.06116888894088155\n",
      "Loss: 0.05175845520970829\n",
      "______\n",
      "Iteration t=7\n",
      "all:  cs/acc_i=57.38 cs/acc_c=56.78 os/recall_knw=46.42 os/recall_unk=86.08 total/acc_i=56.92 total/acc_c=42.99 total/h_score=55.39\n",
      "selected:  cs/acc_i=57.38 cs/acc_c=56.78 os/recall_knw=46.42 os/recall_unk=86.08 total/acc_i=56.92 total/acc_c=42.99 total/h_score=55.39\n",
      "Loss: 1.6562711429705315\n",
      "Loss: 0.28315908407126\n",
      "Loss: 0.16838263113063046\n",
      "Loss: 0.12305125117370296\n",
      "Loss: 0.10087972212958773\n",
      "Loss: 0.08184752580268302\n",
      "Loss: 0.06851877749325075\n",
      "Loss: 0.0648676794241624\n",
      "Loss: 0.05605881839893781\n",
      "Loss: 0.045835534834789984\n",
      "______\n",
      "Iteration t=8\n",
      "all:  cs/acc_i=57.09 cs/acc_c=56.31 os/recall_knw=46.42 os/recall_unk=86.08 total/acc_i=56.92 total/acc_c=42.99 total/h_score=55.39\n",
      "selected:  cs/acc_i=57.09 cs/acc_c=56.31 os/recall_knw=46.42 os/recall_unk=86.08 total/acc_i=56.92 total/acc_c=42.99 total/h_score=55.39\n",
      "Loss: 1.6560143701709373\n",
      "Loss: 0.2790037776579915\n",
      "Loss: 0.1669742162325149\n",
      "Loss: 0.13061596993755675\n",
      "Loss: 0.09834094504207737\n",
      "Loss: 0.08348147430391668\n",
      "Loss: 0.07397169310781843\n",
      "Loss: 0.061880942402743604\n",
      "Loss: 0.05759612164126897\n",
      "Loss: 0.04898111523764168\n",
      "______\n",
      "Iteration t=9\n",
      "all:  cs/acc_i=57.60 cs/acc_c=57.00 os/recall_knw=46.42 os/recall_unk=86.08 total/acc_i=56.92 total/acc_c=42.99 total/h_score=55.39\n",
      "selected:  cs/acc_i=57.60 cs/acc_c=57.00 os/recall_knw=46.42 os/recall_unk=86.08 total/acc_i=56.92 total/acc_c=42.99 total/h_score=55.39\n",
      "tensor(0)\n",
      "all:  cs/acc_i=57.60 cs/acc_c=57.00 os/recall_knw=46.42 os/recall_unk=86.08 total/acc_i=56.92 total/acc_c=42.99 total/h_score=55.39\n",
      "real -> sketch lr= 0.001 seed= 2\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19]\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20]\n",
      "Loss: 1.8032659898873327\n",
      "Loss: 0.32675742628417404\n",
      "Loss: 0.19555274220813212\n",
      "Loss: 0.14710972521759014\n",
      "Loss: 0.12116301786220796\n",
      "Loss: 0.11009648736579562\n",
      "Loss: 0.09519984449004734\n",
      "Loss: 0.0791431132478646\n",
      "Loss: 0.07416940892274322\n",
      "Loss: 0.0621794961903284\n",
      "tensor(True) tensor(True)\n",
      "______\n",
      "Iteration t=1\n",
      "all:  cs/acc_i=55.33 cs/acc_c=54.78 os/recall_knw=80.86 os/recall_unk=35.85 total/acc_i=46.52 total/acc_c=51.06 total/h_score=42.38\n",
      "selected:  cs/acc_i=53.13 cs/acc_c=50.42 os/recall_knw=46.15 os/recall_unk=95.14 total/acc_i=62.89 total/acc_c=44.26 total/h_score=57.99\n",
      "Loss: 1.7081868243781295\n",
      "Loss: 0.3011748637702014\n",
      "Loss: 0.17247568063337254\n",
      "Loss: 0.1331181589425919\n",
      "Loss: 0.11675306283113723\n",
      "Loss: 0.09455194329603801\n",
      "Loss: 0.08110847442121422\n",
      "Loss: 0.07295859185664134\n",
      "Loss: 0.067496195986137\n",
      "Loss: 0.05817692772236753\n",
      "______\n",
      "Iteration t=2\n",
      "all:  cs/acc_i=55.66 cs/acc_c=55.29 os/recall_knw=49.49 os/recall_unk=82.76 total/acc_i=56.68 total/acc_c=44.29 total/h_score=56.04\n",
      "selected:  cs/acc_i=49.30 cs/acc_c=49.58 os/recall_knw=37.67 os/recall_unk=91.72 total/acc_i=55.16 total/acc_c=36.21 total/h_score=49.00\n",
      "Loss: 1.689444574521434\n",
      "Loss: 0.29493562367654613\n",
      "Loss: 0.17112075410062266\n",
      "Loss: 0.13139445469864913\n",
      "Loss: 0.10742160370873828\n",
      "Loss: 0.08458526553586125\n",
      "Loss: 0.07881588550554888\n",
      "Loss: 0.06496417739638878\n",
      "Loss: 0.06144029821659769\n",
      "Loss: 0.05062671502030665\n",
      "______\n",
      "Iteration t=3\n",
      "all:  cs/acc_i=55.00 cs/acc_c=54.56 os/recall_knw=47.15 os/recall_unk=84.59 total/acc_i=56.42 total/acc_c=43.09 total/h_score=55.24\n",
      "selected:  cs/acc_i=51.32 cs/acc_c=51.21 os/recall_knw=41.35 os/recall_unk=89.70 total/acc_i=55.39 total/acc_c=38.77 total/h_score=51.60\n",
      "Loss: 1.6727761405311548\n",
      "Loss: 0.2792380744303439\n",
      "Loss: 0.15945390177073915\n",
      "Loss: 0.12862163423692766\n",
      "Loss: 0.10803138007547954\n",
      "Loss: 0.09185343636170452\n",
      "Loss: 0.07342345065698733\n",
      "Loss: 0.0641604184910467\n",
      "Loss: 0.054996250502835686\n",
      "Loss: 0.05073668835067693\n",
      "______\n",
      "Iteration t=4\n",
      "all:  cs/acc_i=55.04 cs/acc_c=54.51 os/recall_knw=46.93 os/recall_unk=84.79 total/acc_i=56.40 total/acc_c=42.97 total/h_score=55.16\n",
      "selected:  cs/acc_i=53.16 cs/acc_c=52.59 os/recall_knw=44.07 os/recall_unk=87.90 total/acc_i=55.96 total/acc_c=40.66 total/h_score=53.35\n",
      "Loss: 1.652874584708895\n",
      "Loss: 0.28175727238658793\n",
      "Loss: 0.16337973332923392\n",
      "Loss: 0.12601980769729115\n",
      "Loss: 0.10028034526426692\n",
      "Loss: 0.08708533768756141\n",
      "Loss: 0.06794807681183314\n",
      "Loss: 0.06414692849210053\n",
      "Loss: 0.055198303849714005\n",
      "Loss: 0.051560301748711776\n",
      "______\n",
      "Iteration t=5\n",
      "all:  cs/acc_i=55.44 cs/acc_c=54.79 os/recall_knw=46.93 os/recall_unk=84.79 total/acc_i=56.40 total/acc_c=42.97 total/h_score=55.16\n",
      "selected:  cs/acc_i=54.61 cs/acc_c=54.01 os/recall_knw=45.76 os/recall_unk=86.62 total/acc_i=56.30 total/acc_c=42.06 total/h_score=54.57\n",
      "Loss: 1.6552344299279727\n",
      "Loss: 0.28497870658452695\n",
      "Loss: 0.16007353229591478\n",
      "Loss: 0.11901820195408967\n",
      "Loss: 0.10081345750735356\n",
      "Loss: 0.08316278373822569\n",
      "Loss: 0.06953001763958197\n",
      "Loss: 0.06373112948754658\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.05724276967489949\n",
      "Loss: 0.04716133973776148\n",
      "______\n",
      "Iteration t=6\n",
      "all:  cs/acc_i=56.10 cs/acc_c=55.56 os/recall_knw=46.93 os/recall_unk=84.79 total/acc_i=56.40 total/acc_c=42.97 total/h_score=55.16\n",
      "selected:  cs/acc_i=55.98 cs/acc_c=55.40 os/recall_knw=46.74 os/recall_unk=85.02 total/acc_i=56.37 total/acc_c=42.79 total/h_score=55.03\n",
      "Loss: 1.6732853877981868\n",
      "Loss: 0.27786511805945213\n",
      "Loss: 0.15794093595299336\n",
      "Loss: 0.13102929214932685\n",
      "Loss: 0.09479298264597079\n",
      "Loss: 0.08482278944690931\n",
      "Loss: 0.0717974283806524\n",
      "Loss: 0.06485811671219333\n",
      "Loss: 0.05837268110390308\n",
      "Loss: 0.047160919593356616\n",
      "______\n",
      "Iteration t=7\n",
      "all:  cs/acc_i=56.50 cs/acc_c=55.99 os/recall_knw=46.93 os/recall_unk=84.79 total/acc_i=56.40 total/acc_c=42.97 total/h_score=55.16\n",
      "selected:  cs/acc_i=56.45 cs/acc_c=55.93 os/recall_knw=46.87 os/recall_unk=84.79 total/acc_i=56.37 total/acc_c=42.90 total/h_score=55.10\n",
      "Loss: 1.6459358629838723\n",
      "Loss: 0.27840183457223383\n",
      "Loss: 0.16005694604955795\n",
      "Loss: 0.12740142771224605\n",
      "Loss: 0.1062942024990462\n",
      "Loss: 0.08763899269979447\n",
      "Loss: 0.07142795937663944\n",
      "Loss: 0.06068719021277502\n",
      "Loss: 0.0549390358387538\n",
      "Loss: 0.047250972573770346\n",
      "______\n",
      "Iteration t=8\n",
      "all:  cs/acc_i=57.16 cs/acc_c=56.66 os/recall_knw=46.93 os/recall_unk=84.79 total/acc_i=56.40 total/acc_c=42.97 total/h_score=55.16\n",
      "selected:  cs/acc_i=57.16 cs/acc_c=56.66 os/recall_knw=46.93 os/recall_unk=84.79 total/acc_i=56.40 total/acc_c=42.97 total/h_score=55.16\n",
      "Loss: 1.6340703955147324\n",
      "Loss: 0.2753452404697494\n",
      "Loss: 0.16135153939902055\n",
      "Loss: 0.11925534473834332\n",
      "Loss: 0.10071239745380675\n",
      "Loss: 0.08818690656831987\n",
      "Loss: 0.0733319771583987\n",
      "Loss: 0.06690091234717019\n",
      "Loss: 0.05058231506292231\n",
      "Loss: 0.04464748218263749\n",
      "______\n",
      "Iteration t=9\n",
      "all:  cs/acc_i=56.39 cs/acc_c=55.84 os/recall_knw=46.93 os/recall_unk=84.79 total/acc_i=56.40 total/acc_c=42.97 total/h_score=55.16\n",
      "selected:  cs/acc_i=56.39 cs/acc_c=55.84 os/recall_knw=46.93 os/recall_unk=84.79 total/acc_i=56.40 total/acc_c=42.97 total/h_score=55.16\n",
      "tensor(0)\n",
      "all:  cs/acc_i=56.39 cs/acc_c=55.84 os/recall_knw=46.93 os/recall_unk=84.79 total/acc_i=56.40 total/acc_c=42.97 total/h_score=55.16\n",
      "real -> sketch lr= 0.001 seed= 3\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19]\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20]\n",
      "Loss: 1.7960517931451152\n",
      "Loss: 0.3283307718848843\n",
      "Loss: 0.19711420325781104\n",
      "Loss: 0.1572742267342755\n",
      "Loss: 0.12805284564366756\n",
      "Loss: 0.10381147105021409\n",
      "Loss: 0.0880827021675708\n",
      "Loss: 0.0810047269490584\n",
      "Loss: 0.07180089582904536\n",
      "Loss: 0.06670080747263128\n",
      "tensor(True) tensor(True)\n",
      "______\n",
      "Iteration t=1\n",
      "all:  cs/acc_i=54.71 cs/acc_c=54.18 os/recall_knw=80.35 os/recall_unk=34.89 total/acc_i=46.24 total/acc_c=51.03 total/h_score=41.71\n",
      "selected:  cs/acc_i=50.10 cs/acc_c=47.45 os/recall_knw=45.33 os/recall_unk=94.14 total/acc_i=61.57 total/acc_c=43.57 total/h_score=57.16\n",
      "Loss: 1.720583522239247\n",
      "Loss: 0.28864241882252534\n",
      "Loss: 0.17182620360541181\n",
      "Loss: 0.13730143556824406\n",
      "Loss: 0.10930835561059113\n",
      "Loss: 0.10088878100725344\n",
      "Loss: 0.08176197968045804\n",
      "Loss: 0.06899256668701717\n",
      "Loss: 0.06686817373564416\n",
      "Loss: 0.05972692115244934\n",
      "______\n",
      "Iteration t=2\n",
      "all:  cs/acc_i=55.15 cs/acc_c=54.73 os/recall_knw=49.12 os/recall_unk=83.77 total/acc_i=56.52 total/acc_c=43.57 total/h_score=55.56\n",
      "selected:  cs/acc_i=49.42 cs/acc_c=49.38 os/recall_knw=37.70 os/recall_unk=92.37 total/acc_i=55.29 total/acc_c=35.94 total/h_score=48.76\n",
      "Loss: 1.6786996752023697\n",
      "Loss: 0.2831937585626879\n",
      "Loss: 0.15791819790197956\n",
      "Loss: 0.12363224477176704\n",
      "Loss: 0.10242707372733181\n",
      "Loss: 0.08995021628215909\n",
      "Loss: 0.07964665057858633\n",
      "Loss: 0.06782205086802283\n",
      "Loss: 0.059180024107016865\n",
      "Loss: 0.04933245672108305\n",
      "______\n",
      "Iteration t=3\n",
      "all:  cs/acc_i=54.49 cs/acc_c=54.11 os/recall_knw=46.64 os/recall_unk=85.81 total/acc_i=56.40 total/acc_c=42.44 total/h_score=54.81\n",
      "selected:  cs/acc_i=51.15 cs/acc_c=51.16 os/recall_knw=41.21 os/recall_unk=89.90 total/acc_i=55.36 total/acc_c=38.50 total/h_score=51.34\n",
      "Loss: 1.6814020350340413\n",
      "Loss: 0.2848224363962559\n",
      "Loss: 0.1667242786532697\n",
      "Loss: 0.1318996932110764\n",
      "Loss: 0.10428422972947735\n",
      "Loss: 0.08704599321523111\n",
      "Loss: 0.07501906103657247\n",
      "Loss: 0.05961447821971182\n",
      "Loss: 0.05561794864663073\n",
      "Loss: 0.04671788284825367\n",
      "______\n",
      "Iteration t=4\n",
      "all:  cs/acc_i=54.35 cs/acc_c=53.86 os/recall_knw=46.35 os/recall_unk=86.01 total/acc_i=56.35 total/acc_c=42.26 total/h_score=54.68\n",
      "selected:  cs/acc_i=52.68 cs/acc_c=52.34 os/recall_knw=43.72 os/recall_unk=88.85 total/acc_i=56.00 total/acc_c=40.35 total/h_score=53.16\n",
      "Loss: 1.653061285475704\n",
      "Loss: 0.27721918553021097\n",
      "Loss: 0.1663099211347623\n",
      "Loss: 0.12432117502544528\n",
      "Loss: 0.1004229317567198\n",
      "Loss: 0.08105039520543127\n",
      "Loss: 0.0711531743633552\n",
      "Loss: 0.0640796184687762\n",
      "Loss: 0.05435127392411232\n",
      "Loss: 0.04610978833013838\n",
      "______\n",
      "Iteration t=5\n",
      "all:  cs/acc_i=56.10 cs/acc_c=55.31 os/recall_knw=46.31 os/recall_unk=86.01 total/acc_i=56.33 total/acc_c=42.23 total/h_score=54.65\n",
      "selected:  cs/acc_i=55.62 cs/acc_c=54.84 os/recall_knw=45.49 os/recall_unk=86.96 total/acc_i=56.23 total/acc_c=41.62 total/h_score=54.19\n",
      "Loss: 1.659221127491731\n",
      "Loss: 0.2830366234137462\n",
      "Loss: 0.16615678234742237\n",
      "Loss: 0.12324956750067381\n",
      "Loss: 0.10240613368268196\n",
      "Loss: 0.08730766182622084\n",
      "Loss: 0.07249456767279368\n",
      "Loss: 0.06314278598301686\n",
      "Loss: 0.05674510548392741\n",
      "Loss: 0.05008107557892799\n",
      "______\n",
      "Iteration t=6\n",
      "all:  cs/acc_i=55.92 cs/acc_c=55.25 os/recall_knw=46.27 os/recall_unk=86.08 total/acc_i=56.33 total/acc_c=42.21 total/h_score=54.64\n",
      "selected:  cs/acc_i=55.78 cs/acc_c=55.10 os/recall_knw=46.06 os/recall_unk=86.26 total/acc_i=56.28 total/acc_c=42.03 total/h_score=54.48\n",
      "Loss: 1.6475229871236474\n",
      "Loss: 0.2879723524046273\n",
      "Loss: 0.16380480599183977\n",
      "Loss: 0.11898330413376444\n",
      "Loss: 0.09769172218279695\n",
      "Loss: 0.08036685730702033\n",
      "Loss: 0.07416568435671414\n",
      "Loss: 0.06687651373777379\n",
      "Loss: 0.0584980459680975\n",
      "Loss: 0.045023280538709985\n",
      "______\n",
      "Iteration t=7\n",
      "all:  cs/acc_i=56.03 cs/acc_c=55.50 os/recall_knw=46.27 os/recall_unk=86.08 total/acc_i=56.33 total/acc_c=42.21 total/h_score=54.64\n",
      "selected:  cs/acc_i=56.03 cs/acc_c=55.50 os/recall_knw=46.27 os/recall_unk=86.08 total/acc_i=56.33 total/acc_c=42.21 total/h_score=54.64\n",
      "Loss: 1.659899372026461\n",
      "Loss: 0.2753624186740009\n",
      "Loss: 0.16778244939988723\n",
      "Loss: 0.12302653350801825\n",
      "Loss: 0.10749900430463688\n",
      "Loss: 0.082108037158938\n",
      "Loss: 0.07691748775912033\n",
      "Loss: 0.061156987705316385\n",
      "Loss: 0.05640859050755973\n",
      "Loss: 0.04968645376443795\n",
      "______\n",
      "Iteration t=8\n",
      "all:  cs/acc_i=56.28 cs/acc_c=55.60 os/recall_knw=46.27 os/recall_unk=86.08 total/acc_i=56.33 total/acc_c=42.21 total/h_score=54.64\n",
      "selected:  cs/acc_i=56.28 cs/acc_c=55.60 os/recall_knw=46.27 os/recall_unk=86.08 total/acc_i=56.33 total/acc_c=42.21 total/h_score=54.64\n",
      "Loss: 1.6727423387200826\n",
      "Loss: 0.27755831188838415\n",
      "Loss: 0.16341843937925243\n",
      "Loss: 0.12213662189263452\n",
      "Loss: 0.10277638561021116\n",
      "Loss: 0.08531432614493717\n",
      "Loss: 0.07456554748995133\n",
      "Loss: 0.06375176098414152\n",
      "Loss: 0.05927376975860754\n",
      "Loss: 0.04638716525794078\n",
      "______\n",
      "Iteration t=9\n",
      "all:  cs/acc_i=56.76 cs/acc_c=56.38 os/recall_knw=46.27 os/recall_unk=86.08 total/acc_i=56.33 total/acc_c=42.21 total/h_score=54.64\n",
      "selected:  cs/acc_i=56.76 cs/acc_c=56.38 os/recall_knw=46.27 os/recall_unk=86.08 total/acc_i=56.33 total/acc_c=42.21 total/h_score=54.64\n",
      "tensor(0)\n",
      "all:  cs/acc_i=56.76 cs/acc_c=56.38 os/recall_knw=46.27 os/recall_unk=86.08 total/acc_i=56.33 total/acc_c=42.21 total/h_score=54.64\n",
      "real -> sketch lr= 0.001 seed= 4\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19]\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20]\n",
      "Loss: 1.8000969266339977\n",
      "Loss: 0.3419938230641796\n",
      "Loss: 0.19457226357956373\n",
      "Loss: 0.14467237584186832\n",
      "Loss: 0.12441335860440951\n",
      "Loss: 0.11042553095604389\n",
      "Loss: 0.09074604680622493\n",
      "Loss: 0.08248586616283315\n",
      "Loss: 0.0678801297432216\n",
      "Loss: 0.06110446265769386\n",
      "tensor(True) tensor(True)\n",
      "______\n",
      "Iteration t=1\n",
      "all:  cs/acc_i=55.48 cs/acc_c=54.85 os/recall_knw=80.93 os/recall_unk=35.98 total/acc_i=46.66 total/acc_c=51.05 total/h_score=42.47\n",
      "selected:  cs/acc_i=52.58 cs/acc_c=49.97 os/recall_knw=46.19 os/recall_unk=95.15 total/acc_i=62.61 total/acc_c=43.52 total/h_score=57.25\n",
      "Loss: 1.7407750451968889\n",
      "Loss: 0.3061683083742352\n",
      "Loss: 0.1753364085645999\n",
      "Loss: 0.13811163248146996\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.11710598589694601\n",
      "Loss: 0.09535256967390493\n",
      "Loss: 0.07841777030094448\n",
      "Loss: 0.07010616093116291\n",
      "Loss: 0.06200906350514141\n",
      "Loss: 0.05838512896512777\n",
      "______\n",
      "Iteration t=2\n",
      "all:  cs/acc_i=55.11 cs/acc_c=54.74 os/recall_knw=49.82 os/recall_unk=82.55 total/acc_i=56.54 total/acc_c=44.14 total/h_score=55.86\n",
      "selected:  cs/acc_i=48.73 cs/acc_c=48.95 os/recall_knw=37.72 os/recall_unk=91.84 total/acc_i=55.16 total/acc_c=36.10 total/h_score=48.90\n",
      "Loss: 1.6958588569395003\n",
      "Loss: 0.2882703355002788\n",
      "Loss: 0.15891643515036952\n",
      "Loss: 0.131969191596633\n",
      "Loss: 0.11207607495147855\n",
      "Loss: 0.08724478968989945\n",
      "Loss: 0.07397440485055408\n",
      "Loss: 0.06588020332518124\n",
      "Loss: 0.05802387526378997\n",
      "Loss: 0.049599997865997496\n",
      "______\n",
      "Iteration t=3\n",
      "all:  cs/acc_i=53.83 cs/acc_c=53.27 os/recall_knw=48.36 os/recall_unk=83.77 total/acc_i=56.47 total/acc_c=43.45 total/h_score=55.45\n",
      "selected:  cs/acc_i=49.83 cs/acc_c=49.64 os/recall_knw=41.52 os/recall_unk=89.68 total/acc_i=55.59 total/acc_c=38.88 total/h_score=51.72\n",
      "Loss: 1.6761563212811192\n",
      "Loss: 0.28379574625552456\n",
      "Loss: 0.16305376299880917\n",
      "Loss: 0.12302003460464693\n",
      "Loss: 0.10392553485411254\n",
      "Loss: 0.08435106255803729\n",
      "Loss: 0.06794994536203722\n",
      "Loss: 0.06745411356899274\n",
      "Loss: 0.057372957963166354\n",
      "Loss: 0.04740004085337366\n",
      "______\n",
      "Iteration t=4\n",
      "all:  cs/acc_i=54.71 cs/acc_c=54.05 os/recall_knw=47.70 os/recall_unk=84.45 total/acc_i=56.45 total/acc_c=43.12 total/h_score=55.25\n",
      "selected:  cs/acc_i=52.48 cs/acc_c=51.96 os/recall_knw=44.13 os/recall_unk=87.85 total/acc_i=55.89 total/acc_c=40.61 total/h_score=53.29\n",
      "Loss: 1.656190709208031\n",
      "Loss: 0.285691898188487\n",
      "Loss: 0.1630682282996976\n",
      "Loss: 0.11995867467441848\n",
      "Loss: 0.10777559800137333\n",
      "Loss: 0.07985385939206151\n",
      "Loss: 0.06997014507448236\n",
      "Loss: 0.0623157542790765\n",
      "Loss: 0.0561842917496588\n",
      "Loss: 0.050092066968921746\n",
      "______\n",
      "Iteration t=5\n",
      "all:  cs/acc_i=55.19 cs/acc_c=54.59 os/recall_knw=47.63 os/recall_unk=84.66 total/acc_i=56.49 total/acc_c=43.09 total/h_score=55.25\n",
      "selected:  cs/acc_i=54.62 cs/acc_c=54.03 os/recall_knw=46.53 os/recall_unk=86.06 total/acc_i=56.48 total/acc_c=42.39 total/h_score=54.81\n",
      "Loss: 1.6728859243034586\n",
      "Loss: 0.2859268506611783\n",
      "Loss: 0.16835771653047002\n",
      "Loss: 0.12322974716387461\n",
      "Loss: 0.09046976687100951\n",
      "Loss: 0.07868590777271364\n",
      "Loss: 0.07326668739158866\n",
      "Loss: 0.05782663275807685\n",
      "Loss: 0.06158700224977741\n",
      "Loss: 0.049534027143295835\n",
      "______\n",
      "Iteration t=6\n",
      "all:  cs/acc_i=55.81 cs/acc_c=55.24 os/recall_knw=47.63 os/recall_unk=84.66 total/acc_i=56.49 total/acc_c=43.09 total/h_score=55.25\n",
      "selected:  cs/acc_i=55.73 cs/acc_c=55.20 os/recall_knw=47.36 os/recall_unk=85.00 total/acc_i=56.53 total/acc_c=43.01 total/h_score=55.24\n",
      "Loss: 1.6653891948119897\n",
      "Loss: 0.2880812824317595\n",
      "Loss: 0.16821120235864528\n",
      "Loss: 0.1253246603272401\n",
      "Loss: 0.09902697734012292\n",
      "Loss: 0.07864397710257369\n",
      "Loss: 0.07174714654542097\n",
      "Loss: 0.057746526213056155\n",
      "Loss: 0.052552155358148965\n",
      "Loss: 0.0494521800244068\n",
      "______\n",
      "Iteration t=7\n",
      "all:  cs/acc_i=56.36 cs/acc_c=55.86 os/recall_knw=47.63 os/recall_unk=84.66 total/acc_i=56.49 total/acc_c=43.09 total/h_score=55.25\n",
      "selected:  cs/acc_i=56.36 cs/acc_c=55.86 os/recall_knw=47.63 os/recall_unk=84.66 total/acc_i=56.49 total/acc_c=43.09 total/h_score=55.25\n",
      "Loss: 1.646652499259245\n",
      "Loss: 0.2924184604979506\n",
      "Loss: 0.15739098583666108\n",
      "Loss: 0.11909870300214828\n",
      "Loss: 0.10086430049580862\n",
      "Loss: 0.08021504935672188\n",
      "Loss: 0.07152181289374555\n",
      "Loss: 0.06614099932329093\n",
      "Loss: 0.05099577545869823\n",
      "Loss: 0.046487299576344926\n",
      "______\n",
      "Iteration t=8\n",
      "all:  cs/acc_i=56.03 cs/acc_c=55.57 os/recall_knw=47.63 os/recall_unk=84.66 total/acc_i=56.49 total/acc_c=43.09 total/h_score=55.25\n",
      "selected:  cs/acc_i=56.03 cs/acc_c=55.57 os/recall_knw=47.63 os/recall_unk=84.66 total/acc_i=56.49 total/acc_c=43.09 total/h_score=55.25\n",
      "Loss: 1.6706580528762283\n",
      "Loss: 0.27627199547501596\n",
      "Loss: 0.17470390448437595\n",
      "Loss: 0.12963443581105732\n",
      "Loss: 0.1035466956644796\n",
      "Loss: 0.07969128673544108\n",
      "Loss: 0.07444270603889713\n",
      "Loss: 0.06005262103635908\n",
      "Loss: 0.056563395728561575\n",
      "Loss: 0.046978929020441706\n",
      "______\n",
      "Iteration t=9\n",
      "all:  cs/acc_i=55.95 cs/acc_c=55.52 os/recall_knw=47.63 os/recall_unk=84.66 total/acc_i=56.49 total/acc_c=43.09 total/h_score=55.25\n",
      "selected:  cs/acc_i=55.95 cs/acc_c=55.52 os/recall_knw=47.63 os/recall_unk=84.66 total/acc_i=56.49 total/acc_c=43.09 total/h_score=55.25\n",
      "tensor(0)\n",
      "all:  cs/acc_i=55.95 cs/acc_c=55.52 os/recall_knw=47.63 os/recall_unk=84.66 total/acc_i=56.49 total/acc_c=43.09 total/h_score=55.25\n",
      "real -> sketch lr= 0.001 seed= 0\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19]\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20]\n",
      "Loss: 1.81071367159857\n",
      "Loss: 0.33596610916891134\n",
      "Loss: 0.1879270625602308\n",
      "Loss: 0.14495690489101665\n",
      "Loss: 0.12271021521282366\n",
      "Loss: 0.10668216288765872\n",
      "Loss: 0.09172999365686098\n",
      "Loss: 0.07923711995756605\n",
      "Loss: 0.07653882150336093\n",
      "Loss: 0.06360035837425775\n",
      "tensor(True) tensor(True)\n",
      "______\n",
      "Iteration t=1\n",
      "all:  cs/acc_i=54.71 cs/acc_c=54.14 os/recall_knw=80.46 os/recall_unk=35.10 total/acc_i=45.74 total/acc_c=50.22 total/h_score=41.57\n",
      "selected:  cs/acc_i=52.59 cs/acc_c=49.59 os/recall_knw=45.69 os/recall_unk=95.21 total/acc_i=61.91 total/acc_c=43.24 total/h_score=56.97\n",
      "Loss: 1.7300260796941616\n",
      "Loss: 0.3055748342460877\n",
      "Loss: 0.1810838064254337\n",
      "Loss: 0.12996163102168892\n",
      "Loss: 0.10831471504895268\n",
      "Loss: 0.09790354609061536\n",
      "Loss: 0.0902063390019828\n",
      "Loss: 0.07108571234385709\n",
      "Loss: 0.06448315896370725\n",
      "Loss: 0.05463616530146651\n",
      "______\n",
      "Iteration t=2\n",
      "all:  cs/acc_i=54.60 cs/acc_c=54.00 os/recall_knw=48.47 os/recall_unk=83.30 total/acc_i=56.26 total/acc_c=43.37 total/h_score=55.29\n",
      "selected:  cs/acc_i=48.29 cs/acc_c=47.91 os/recall_knw=37.26 os/recall_unk=92.19 total/acc_i=54.75 total/acc_c=35.24 total/h_score=47.94\n",
      "Loss: 1.684578834906701\n",
      "Loss: 0.2851317861868489\n",
      "Loss: 0.16753968830190358\n",
      "Loss: 0.1330779752904369\n",
      "Loss: 0.10336055772739552\n",
      "Loss: 0.0898386596912338\n",
      "Loss: 0.0704392660589468\n",
      "Loss: 0.06546185883813568\n",
      "Loss: 0.058785727660682414\n",
      "Loss: 0.04869376386050135\n",
      "______\n",
      "Iteration t=3\n",
      "all:  cs/acc_i=54.27 cs/acc_c=53.56 os/recall_knw=46.57 os/recall_unk=84.86 total/acc_i=56.00 total/acc_c=42.25 total/h_score=54.48\n",
      "selected:  cs/acc_i=50.67 cs/acc_c=50.06 os/recall_knw=40.75 os/recall_unk=90.25 total/acc_i=55.09 total/acc_c=37.82 total/h_score=50.64\n",
      "Loss: 1.6720059808296492\n",
      "Loss: 0.2894378386296426\n",
      "Loss: 0.16860145633403636\n",
      "Loss: 0.13039096197867883\n",
      "Loss: 0.10655148386589805\n",
      "Loss: 0.08881895666163933\n",
      "Loss: 0.0764859011323085\n",
      "Loss: 0.06569323452967632\n",
      "Loss: 0.05505723423837342\n",
      "Loss: 0.04894430220460142\n",
      "______\n",
      "Iteration t=4\n",
      "all:  cs/acc_i=55.41 cs/acc_c=54.69 os/recall_knw=46.24 os/recall_unk=85.20 total/acc_i=55.97 total/acc_c=42.06 total/h_score=54.35\n",
      "selected:  cs/acc_i=53.65 cs/acc_c=53.09 os/recall_knw=43.38 os/recall_unk=88.63 total/acc_i=55.65 total/acc_c=40.03 total/h_score=52.80\n",
      "Loss: 1.680533169028915\n",
      "Loss: 0.2963289107164119\n",
      "Loss: 0.16076642408317124\n",
      "Loss: 0.12590209741110556\n",
      "Loss: 0.10111841031950768\n",
      "Loss: 0.08861945879665954\n",
      "Loss: 0.07444295566238904\n",
      "Loss: 0.06542436190738671\n",
      "Loss: 0.05489961238653396\n",
      "Loss: 0.047373723512880994\n",
      "______\n",
      "Iteration t=5\n",
      "all:  cs/acc_i=55.26 cs/acc_c=54.65 os/recall_knw=46.24 os/recall_unk=85.40 total/acc_i=56.04 total/acc_c=42.07 total/h_score=54.40\n",
      "selected:  cs/acc_i=54.65 cs/acc_c=54.12 os/recall_knw=45.24 os/recall_unk=87.00 total/acc_i=56.02 total/acc_c=41.42 total/h_score=53.99\n",
      "Loss: 1.657839069549854\n",
      "Loss: 0.2759756806492806\n",
      "Loss: 0.16472290189220354\n",
      "Loss: 0.12626120079022188\n",
      "Loss: 0.09744669357171426\n",
      "Loss: 0.08519110556405324\n",
      "Loss: 0.07260248088062955\n",
      "Loss: 0.06389667428743381\n",
      "Loss: 0.053483511107758834\n",
      "Loss: 0.04960088256889811\n",
      "______\n",
      "Iteration t=6\n",
      "all:  cs/acc_i=55.99 cs/acc_c=55.44 os/recall_knw=46.20 os/recall_unk=85.40 total/acc_i=56.02 total/acc_c=42.04 total/h_score=54.36\n",
      "selected:  cs/acc_i=55.88 cs/acc_c=55.36 os/recall_knw=46.06 os/recall_unk=85.87 total/acc_i=56.05 total/acc_c=41.95 total/h_score=54.35\n",
      "Loss: 1.6651066686112457\n",
      "Loss: 0.2760708228073603\n",
      "Loss: 0.16159998361546934\n",
      "Loss: 0.12361937060815059\n",
      "Loss: 0.10317393895124365\n",
      "Loss: 0.08474542150571028\n",
      "Loss: 0.07270256955993641\n",
      "Loss: 0.06442233778827715\n",
      "Loss: 0.05449846994268931\n",
      "Loss: 0.050185690593957166\n",
      "______\n",
      "Iteration t=7\n",
      "all:  cs/acc_i=56.65 cs/acc_c=56.05 os/recall_knw=46.20 os/recall_unk=85.40 total/acc_i=56.02 total/acc_c=42.04 total/h_score=54.36\n",
      "selected:  cs/acc_i=56.65 cs/acc_c=56.05 os/recall_knw=46.20 os/recall_unk=85.40 total/acc_i=56.02 total/acc_c=42.04 total/h_score=54.36\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 1.6574580192748196\n",
      "Loss: 0.2777378080179203\n",
      "Loss: 0.1696542228375553\n",
      "Loss: 0.12683357596853093\n",
      "Loss: 0.09674853944028827\n",
      "Loss: 0.08158121653903697\n",
      "Loss: 0.07160771193569497\n",
      "Loss: 0.05607485283587686\n",
      "Loss: 0.05472115156545506\n",
      "Loss: 0.05054372021948366\n",
      "______\n",
      "Iteration t=8\n",
      "all:  cs/acc_i=56.46 cs/acc_c=56.06 os/recall_knw=46.20 os/recall_unk=85.40 total/acc_i=56.02 total/acc_c=42.04 total/h_score=54.36\n",
      "selected:  cs/acc_i=56.46 cs/acc_c=56.06 os/recall_knw=46.20 os/recall_unk=85.40 total/acc_i=56.02 total/acc_c=42.04 total/h_score=54.36\n",
      "Loss: 1.6571648718749348\n",
      "Loss: 0.2803378498198789\n",
      "Loss: 0.1616656264512364\n",
      "Loss: 0.12449424504231241\n",
      "Loss: 0.09856894057221277\n",
      "Loss: 0.08485194601813496\n",
      "Loss: 0.07093129170466135\n",
      "Loss: 0.06251612603123263\n",
      "Loss: 0.05241125096518558\n",
      "Loss: 0.049438893158467265\n",
      "______\n",
      "Iteration t=9\n",
      "all:  cs/acc_i=55.66 cs/acc_c=55.11 os/recall_knw=46.20 os/recall_unk=85.40 total/acc_i=56.02 total/acc_c=42.04 total/h_score=54.36\n",
      "selected:  cs/acc_i=55.66 cs/acc_c=55.11 os/recall_knw=46.20 os/recall_unk=85.40 total/acc_i=56.02 total/acc_c=42.04 total/h_score=54.36\n",
      "tensor(0)\n",
      "all:  cs/acc_i=55.66 cs/acc_c=55.11 os/recall_knw=46.20 os/recall_unk=85.40 total/acc_i=56.02 total/acc_c=42.04 total/h_score=54.36\n",
      "real -> sketch lr= 0.001 seed= 1\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19]\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20]\n",
      "Loss: 1.814970758037635\n",
      "Loss: 0.3355012287607821\n",
      "Loss: 0.19974350684000927\n",
      "Loss: 0.14542913662925946\n",
      "Loss: 0.12269933309631416\n",
      "Loss: 0.10835879461780137\n",
      "Loss: 0.09185954688441711\n",
      "Loss: 0.07968630539617928\n",
      "Loss: 0.07504842010429427\n",
      "Loss: 0.060135519201618706\n",
      "tensor(True) tensor(True)\n",
      "______\n",
      "Iteration t=1\n",
      "all:  cs/acc_i=55.88 cs/acc_c=55.40 os/recall_knw=80.68 os/recall_unk=35.51 total/acc_i=46.88 total/acc_c=51.78 total/h_score=42.39\n",
      "selected:  cs/acc_i=51.49 cs/acc_c=50.68 os/recall_knw=45.52 os/recall_unk=93.90 total/acc_i=61.78 total/acc_c=44.97 total/h_score=58.54\n",
      "Loss: 1.7175826866280388\n",
      "Loss: 0.2904534484637347\n",
      "Loss: 0.18226773431524634\n",
      "Loss: 0.13743431728358405\n",
      "Loss: 0.10738601485531576\n",
      "Loss: 0.10077642852667014\n",
      "Loss: 0.07836328183829382\n",
      "Loss: 0.07491154019324411\n",
      "Loss: 0.0660308087952561\n",
      "Loss: 0.06165230677721116\n",
      "______\n",
      "Iteration t=2\n",
      "all:  cs/acc_i=55.73 cs/acc_c=55.20 os/recall_knw=49.63 os/recall_unk=82.15 total/acc_i=56.73 total/acc_c=44.55 total/h_score=56.17\n",
      "selected:  cs/acc_i=49.37 cs/acc_c=49.47 os/recall_knw=37.94 os/recall_unk=92.30 total/acc_i=55.48 total/acc_c=36.68 total/h_score=49.59\n",
      "Loss: 1.7009710120577965\n",
      "Loss: 0.28853729994546984\n",
      "Loss: 0.17438438210275867\n",
      "Loss: 0.12963289856430024\n",
      "Loss: 0.10949120144810408\n",
      "Loss: 0.08893982948615185\n",
      "Loss: 0.07485819582887475\n",
      "Loss: 0.06585298029014901\n",
      "Loss: 0.06163249343348246\n",
      "Loss: 0.05166790221156853\n",
      "______\n",
      "Iteration t=3\n",
      "all:  cs/acc_i=55.59 cs/acc_c=54.98 os/recall_knw=47.26 os/recall_unk=84.39 total/acc_i=56.47 total/acc_c=43.13 total/h_score=55.24\n",
      "selected:  cs/acc_i=51.81 cs/acc_c=51.56 os/recall_knw=41.32 os/recall_unk=89.68 total/acc_i=55.39 total/acc_c=38.75 total/h_score=51.59\n",
      "Loss: 1.6858146080647358\n",
      "Loss: 0.28791339070262967\n",
      "Loss: 0.1765474255199688\n",
      "Loss: 0.12565238446537816\n",
      "Loss: 0.10162366336146927\n",
      "Loss: 0.08478166749083939\n",
      "Loss: 0.07290336175906921\n",
      "Loss: 0.06975769799802017\n",
      "Loss: 0.055681211468455165\n",
      "Loss: 0.0506351985983339\n",
      "______\n",
      "Iteration t=4\n",
      "all:  cs/acc_i=55.55 cs/acc_c=54.87 os/recall_knw=46.68 os/recall_unk=84.86 total/acc_i=56.33 total/acc_c=42.77 total/h_score=54.98\n",
      "selected:  cs/acc_i=53.48 cs/acc_c=53.02 os/recall_knw=43.50 os/recall_unk=88.03 total/acc_i=55.77 total/acc_c=40.44 total/h_score=53.15\n",
      "Loss: 1.6750091614195863\n",
      "Loss: 0.2733380947482549\n",
      "Loss: 0.16465970488537882\n",
      "Loss: 0.11786759857123143\n",
      "Loss: 0.0980295469212662\n",
      "Loss: 0.08935952004962064\n",
      "Loss: 0.06729162874199288\n",
      "Loss: 0.06468040715450439\n",
      "Loss: 0.05963515750396521\n",
      "Loss: 0.04840564031032062\n",
      "______\n",
      "Iteration t=5\n",
      "all:  cs/acc_i=56.14 cs/acc_c=55.57 os/recall_knw=46.57 os/recall_unk=84.86 total/acc_i=56.28 total/acc_c=42.69 total/h_score=54.91\n",
      "selected:  cs/acc_i=55.51 cs/acc_c=55.03 os/recall_knw=45.53 os/recall_unk=86.27 total/acc_i=56.20 total/acc_c=42.03 total/h_score=54.49\n",
      "Loss: 1.643359962610098\n",
      "Loss: 0.2721249807568697\n",
      "Loss: 0.1562973597072638\n",
      "Loss: 0.12149046131624626\n",
      "Loss: 0.09904779990132039\n",
      "Loss: 0.08881109267473221\n",
      "Loss: 0.07561769120968305\n",
      "Loss: 0.06358706386043475\n",
      "Loss: 0.05726247194294746\n",
      "Loss: 0.048459069218056705\n",
      "______\n",
      "Iteration t=6\n",
      "all:  cs/acc_i=56.54 cs/acc_c=56.03 os/recall_knw=46.53 os/recall_unk=84.86 total/acc_i=56.26 total/acc_c=42.65 total/h_score=54.87\n",
      "selected:  cs/acc_i=56.46 cs/acc_c=55.96 os/recall_knw=46.43 os/recall_unk=84.98 total/acc_i=56.23 total/acc_c=42.58 total/h_score=54.81\n",
      "Loss: 1.6499367240554332\n",
      "Loss: 0.27452587789716343\n",
      "Loss: 0.16711567928986082\n",
      "Loss: 0.12757069951304967\n",
      "Loss: 0.10116281681366561\n",
      "Loss: 0.07921581197136995\n",
      "Loss: 0.07422210146823972\n",
      "Loss: 0.06055639159583717\n",
      "Loss: 0.053356396266478555\n",
      "Loss: 0.04843373309296844\n",
      "______\n",
      "Iteration t=7\n",
      "all:  cs/acc_i=56.90 cs/acc_c=56.35 os/recall_knw=46.53 os/recall_unk=84.86 total/acc_i=56.26 total/acc_c=42.65 total/h_score=54.87\n",
      "selected:  cs/acc_i=56.90 cs/acc_c=56.35 os/recall_knw=46.53 os/recall_unk=84.86 total/acc_i=56.26 total/acc_c=42.65 total/h_score=54.87\n",
      "Loss: 1.641394775759554\n",
      "Loss: 0.28085643741151245\n",
      "Loss: 0.16234878027976835\n",
      "Loss: 0.12669560770057028\n",
      "Loss: 0.09863423792195339\n",
      "Loss: 0.0863503007337861\n",
      "Loss: 0.07495935207135998\n",
      "Loss: 0.06255473375508408\n",
      "Loss: 0.05459226632279996\n",
      "Loss: 0.04944297915398619\n",
      "______\n",
      "Iteration t=8\n",
      "all:  cs/acc_i=56.72 cs/acc_c=56.22 os/recall_knw=46.53 os/recall_unk=84.86 total/acc_i=56.26 total/acc_c=42.65 total/h_score=54.87\n",
      "selected:  cs/acc_i=56.72 cs/acc_c=56.22 os/recall_knw=46.53 os/recall_unk=84.86 total/acc_i=56.26 total/acc_c=42.65 total/h_score=54.87\n",
      "Loss: 1.6380818793350769\n",
      "Loss: 0.27570220992105815\n",
      "Loss: 0.15937006708792772\n",
      "Loss: 0.12750328085257098\n",
      "Loss: 0.10035340920865353\n",
      "Loss: 0.08789845065723546\n",
      "Loss: 0.07577985244025605\n",
      "Loss: 0.06280096901711703\n",
      "Loss: 0.05078887819548904\n",
      "Loss: 0.04581215322467667\n",
      "______\n",
      "Iteration t=9\n",
      "all:  cs/acc_i=56.87 cs/acc_c=56.33 os/recall_knw=46.53 os/recall_unk=84.86 total/acc_i=56.26 total/acc_c=42.65 total/h_score=54.87\n",
      "selected:  cs/acc_i=56.87 cs/acc_c=56.33 os/recall_knw=46.53 os/recall_unk=84.86 total/acc_i=56.26 total/acc_c=42.65 total/h_score=54.87\n",
      "tensor(0)\n",
      "all:  cs/acc_i=56.87 cs/acc_c=56.33 os/recall_knw=46.53 os/recall_unk=84.86 total/acc_i=56.26 total/acc_c=42.65 total/h_score=54.87\n",
      "real -> sketch lr= 0.001 seed= 2\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19]\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20]\n",
      "Loss: 1.805472157179673\n",
      "Loss: 0.3259386887435811\n",
      "Loss: 0.19518740224615536\n",
      "Loss: 0.1468826252039111\n",
      "Loss: 0.12093751636264163\n",
      "Loss: 0.11020456977665849\n",
      "Loss: 0.09489316754937967\n",
      "Loss: 0.07896181884026188\n",
      "Loss: 0.07430195314577678\n",
      "Loss: 0.062108627043240223\n",
      "tensor(True) tensor(True)\n",
      "______\n",
      "Iteration t=1\n",
      "all:  cs/acc_i=55.55 cs/acc_c=54.93 os/recall_knw=80.86 os/recall_unk=35.85 total/acc_i=46.52 total/acc_c=51.06 total/h_score=42.38\n",
      "selected:  cs/acc_i=54.00 cs/acc_c=51.00 os/recall_knw=46.31 os/recall_unk=95.48 total/acc_i=63.11 total/acc_c=44.71 total/h_score=58.50\n",
      "Loss: 1.7230561407836709\n",
      "Loss: 0.30238243368630474\n",
      "Loss: 0.17681117803865187\n",
      "Loss: 0.13184946377107218\n",
      "Loss: 0.11027234899056321\n",
      "Loss: 0.09877719538840088\n",
      "Loss: 0.0824253974620857\n",
      "Loss: 0.06683707626605709\n",
      "Loss: 0.0635166682619161\n",
      "Loss: 0.05971298330759227\n",
      "______\n",
      "Iteration t=2\n",
      "all:  cs/acc_i=55.19 cs/acc_c=54.73 os/recall_knw=47.48 os/recall_unk=83.64 total/acc_i=56.30 total/acc_c=43.22 total/h_score=55.20\n",
      "selected:  cs/acc_i=48.79 cs/acc_c=48.99 os/recall_knw=36.79 os/recall_unk=91.80 total/acc_i=54.47 total/acc_c=35.45 total/h_score=48.15\n",
      "Loss: 1.6906935901411118\n",
      "Loss: 0.28231389962377085\n",
      "Loss: 0.18106896480725657\n",
      "Loss: 0.12324503707669435\n",
      "Loss: 0.10555596314370633\n",
      "Loss: 0.09176059534112292\n",
      "Loss: 0.07918818369207363\n",
      "Loss: 0.06444677714438689\n",
      "Loss: 0.061286580893060855\n",
      "Loss: 0.04704954987316723\n",
      "______\n",
      "Iteration t=3\n",
      "all:  cs/acc_i=54.42 cs/acc_c=53.76 os/recall_knw=45.87 os/recall_unk=85.27 total/acc_i=56.04 total/acc_c=42.12 total/h_score=54.42\n",
      "selected:  cs/acc_i=51.00 cs/acc_c=50.44 os/recall_knw=40.53 os/recall_unk=89.91 total/acc_i=55.05 total/acc_c=37.89 total/h_score=50.69\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 1.6653773214914822\n",
      "Loss: 0.27845479216579383\n",
      "Loss: 0.15971487413868543\n",
      "Loss: 0.13202657738013035\n",
      "Loss: 0.10666649181642555\n",
      "Loss: 0.09205198297952816\n",
      "Loss: 0.07364410964466561\n",
      "Loss: 0.06413021565000718\n",
      "Loss: 0.052167100316260234\n",
      "Loss: 0.05018367333637333\n",
      "______\n",
      "Iteration t=4\n",
      "all:  cs/acc_i=54.86 cs/acc_c=54.26 os/recall_knw=45.58 os/recall_unk=85.47 total/acc_i=55.97 total/acc_c=41.91 total/h_score=54.25\n",
      "selected:  cs/acc_i=53.33 cs/acc_c=52.90 os/recall_knw=43.00 os/recall_unk=88.66 total/acc_i=55.75 total/acc_c=40.12 total/h_score=52.90\n",
      "Loss: 1.6660215842575299\n",
      "Loss: 0.2796649492093336\n",
      "Loss: 0.1667657617792905\n",
      "Loss: 0.12542639135722525\n",
      "Loss: 0.09660154553217308\n",
      "Loss: 0.0897419906026942\n",
      "Loss: 0.07218960275571805\n",
      "Loss: 0.06607466008270456\n",
      "Loss: 0.05831798254381691\n",
      "Loss: 0.05058574228405349\n",
      "______\n",
      "Iteration t=5\n",
      "all:  cs/acc_i=55.33 cs/acc_c=54.76 os/recall_knw=45.51 os/recall_unk=85.47 total/acc_i=55.92 total/acc_c=41.86 total/h_score=54.20\n",
      "selected:  cs/acc_i=54.97 cs/acc_c=54.42 os/recall_knw=44.88 os/recall_unk=86.65 total/acc_i=55.96 total/acc_c=41.42 total/h_score=53.94\n",
      "Loss: 1.6612855040110075\n",
      "Loss: 0.28276079173271473\n",
      "Loss: 0.16587150376003523\n",
      "Loss: 0.12179296542532168\n",
      "Loss: 0.1019793314830615\n",
      "Loss: 0.07810472112435561\n",
      "Loss: 0.07201599564833136\n",
      "Loss: 0.06227668411743183\n",
      "Loss: 0.0533888724560921\n",
      "Loss: 0.04760897293901788\n",
      "______\n",
      "Iteration t=6\n",
      "all:  cs/acc_i=56.68 cs/acc_c=56.14 os/recall_knw=45.51 os/recall_unk=85.47 total/acc_i=55.92 total/acc_c=41.86 total/h_score=54.20\n",
      "selected:  cs/acc_i=56.64 cs/acc_c=56.08 os/recall_knw=45.45 os/recall_unk=85.47 total/acc_i=55.89 total/acc_c=41.79 total/h_score=54.13\n",
      "Loss: 1.6615857964644403\n",
      "Loss: 0.2822468130409352\n",
      "Loss: 0.16109371084742752\n",
      "Loss: 0.1262513769653403\n",
      "Loss: 0.1015712851258509\n",
      "Loss: 0.08752661776026151\n",
      "Loss: 0.07394209419565698\n",
      "Loss: 0.06844051375462348\n",
      "Loss: 0.05711096695030074\n",
      "Loss: 0.051721725382904975\n",
      "______\n",
      "Iteration t=7\n",
      "all:  cs/acc_i=56.87 cs/acc_c=56.28 os/recall_knw=45.51 os/recall_unk=85.47 total/acc_i=55.92 total/acc_c=41.86 total/h_score=54.20\n",
      "selected:  cs/acc_i=56.87 cs/acc_c=56.28 os/recall_knw=45.51 os/recall_unk=85.47 total/acc_i=55.92 total/acc_c=41.86 total/h_score=54.20\n",
      "Loss: 1.6584184265758362\n",
      "Loss: 0.2874066385617651\n",
      "Loss: 0.16084739130470285\n",
      "Loss: 0.11810636199850795\n",
      "Loss: 0.10198016043900987\n",
      "Loss: 0.07934098965859761\n",
      "Loss: 0.08002767255358352\n",
      "Loss: 0.06218648863316405\n",
      "Loss: 0.05459733639466662\n",
      "Loss: 0.049993841378932445\n",
      "______\n",
      "Iteration t=8\n",
      "all:  cs/acc_i=56.68 cs/acc_c=56.03 os/recall_knw=45.51 os/recall_unk=85.47 total/acc_i=55.92 total/acc_c=41.86 total/h_score=54.20\n",
      "selected:  cs/acc_i=56.68 cs/acc_c=56.03 os/recall_knw=45.51 os/recall_unk=85.47 total/acc_i=55.92 total/acc_c=41.86 total/h_score=54.20\n",
      "Loss: 1.654593340366896\n",
      "Loss: 0.2827058686000621\n",
      "Loss: 0.16022073568924805\n",
      "Loss: 0.12749112212881902\n",
      "Loss: 0.10171877479386385\n",
      "Loss: 0.08716711532781643\n",
      "Loss: 0.07718057286542801\n",
      "Loss: 0.06373077740698505\n",
      "Loss: 0.05415806109571338\n",
      "Loss: 0.0474290619032926\n",
      "______\n",
      "Iteration t=9\n",
      "all:  cs/acc_i=55.95 cs/acc_c=55.28 os/recall_knw=45.51 os/recall_unk=85.47 total/acc_i=55.92 total/acc_c=41.86 total/h_score=54.20\n",
      "selected:  cs/acc_i=55.95 cs/acc_c=55.28 os/recall_knw=45.51 os/recall_unk=85.47 total/acc_i=55.92 total/acc_c=41.86 total/h_score=54.20\n",
      "tensor(0)\n",
      "all:  cs/acc_i=55.95 cs/acc_c=55.28 os/recall_knw=45.51 os/recall_unk=85.47 total/acc_i=55.92 total/acc_c=41.86 total/h_score=54.20\n",
      "real -> sketch lr= 0.001 seed= 3\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19]\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20]\n",
      "Loss: 1.796558023347549\n",
      "Loss: 0.327729981087705\n",
      "Loss: 0.1969133251979682\n",
      "Loss: 0.15709981793584135\n",
      "Loss: 0.1277434164890191\n",
      "Loss: 0.10380486957728863\n",
      "Loss: 0.08806348278177273\n",
      "Loss: 0.08097173211585691\n",
      "Loss: 0.07181930406768126\n",
      "Loss: 0.06660340533316719\n",
      "tensor(True) tensor(True)\n",
      "______\n",
      "Iteration t=1\n",
      "all:  cs/acc_i=54.64 cs/acc_c=54.09 os/recall_knw=80.46 os/recall_unk=35.10 total/acc_i=46.33 total/acc_c=51.10 total/h_score=41.88\n",
      "selected:  cs/acc_i=50.15 cs/acc_c=47.06 os/recall_knw=45.57 os/recall_unk=94.86 total/acc_i=62.04 total/acc_c=43.46 total/h_score=57.14\n",
      "Loss: 1.7315921205523852\n",
      "Loss: 0.29470328251655037\n",
      "Loss: 0.1690178192786973\n",
      "Loss: 0.13891056387030795\n",
      "Loss: 0.11853826095387843\n",
      "Loss: 0.10037557395942812\n",
      "Loss: 0.07997261010412429\n",
      "Loss: 0.06932712700910161\n",
      "Loss: 0.06301756199870913\n",
      "Loss: 0.05565495345728925\n",
      "______\n",
      "Iteration t=2\n",
      "all:  cs/acc_i=55.37 cs/acc_c=54.93 os/recall_knw=50.69 os/recall_unk=82.21 total/acc_i=56.85 total/acc_c=44.71 total/h_score=56.33\n",
      "selected:  cs/acc_i=49.04 cs/acc_c=49.00 os/recall_knw=38.41 os/recall_unk=92.30 total/acc_i=55.74 total/acc_c=36.61 total/h_score=49.51\n",
      "Loss: 1.6796082113058337\n",
      "Loss: 0.28797251471588686\n",
      "Loss: 0.17235485362189432\n",
      "Loss: 0.1317853911749778\n",
      "Loss: 0.11369423163574069\n",
      "Loss: 0.0901188074370786\n",
      "Loss: 0.07691791128487356\n",
      "Loss: 0.07175636165775359\n",
      "Loss: 0.05802438629701013\n",
      "Loss: 0.04877995439549728\n",
      "______\n",
      "Iteration t=3\n",
      "all:  cs/acc_i=54.71 cs/acc_c=54.07 os/recall_knw=47.81 os/recall_unk=84.45 total/acc_i=56.61 total/acc_c=43.30 total/h_score=55.42\n",
      "selected:  cs/acc_i=50.70 cs/acc_c=50.44 os/recall_knw=41.14 os/recall_unk=90.01 total/acc_i=55.56 total/acc_c=38.61 total/h_score=51.47\n",
      "Loss: 1.6874424105014982\n",
      "Loss: 0.2841757061077824\n",
      "Loss: 0.174097233546214\n",
      "Loss: 0.1262485220132372\n",
      "Loss: 0.09931987497802305\n",
      "Loss: 0.08971606499715885\n",
      "Loss: 0.07429500615601486\n",
      "Loss: 0.06432438878080206\n",
      "Loss: 0.05831756551095721\n",
      "Loss: 0.054203640633480786\n",
      "______\n",
      "Iteration t=4\n",
      "all:  cs/acc_i=55.26 cs/acc_c=54.55 os/recall_knw=47.37 os/recall_unk=84.66 total/acc_i=56.40 total/acc_c=42.87 total/h_score=55.04\n",
      "selected:  cs/acc_i=53.37 cs/acc_c=52.63 os/recall_knw=44.23 os/recall_unk=87.76 total/acc_i=55.96 total/acc_c=40.53 total/h_score=53.20\n",
      "Loss: 1.6588778977993852\n",
      "Loss: 0.28722856216919346\n",
      "Loss: 0.16052499419274907\n",
      "Loss: 0.12944101435219094\n",
      "Loss: 0.1059560966301964\n",
      "Loss: 0.08474685019316001\n",
      "Loss: 0.07522674632600006\n",
      "Loss: 0.06559294102581865\n",
      "Loss: 0.05872026402561098\n",
      "Loss: 0.0514162562090487\n",
      "______\n",
      "Iteration t=5\n",
      "all:  cs/acc_i=55.51 cs/acc_c=54.88 os/recall_knw=47.15 os/recall_unk=84.66 total/acc_i=56.30 total/acc_c=42.74 total/h_score=54.92\n",
      "selected:  cs/acc_i=54.96 cs/acc_c=54.29 os/recall_knw=46.23 os/recall_unk=86.00 total/acc_i=56.27 total/acc_c=42.05 total/h_score=54.46\n",
      "Loss: 1.6510657415799568\n",
      "Loss: 0.2749069846960847\n",
      "Loss: 0.16390501032440574\n",
      "Loss: 0.12791857033670861\n",
      "Loss: 0.09747361552050235\n",
      "Loss: 0.08345174767574055\n",
      "Loss: 0.07312528693340033\n",
      "Loss: 0.06664855342409773\n",
      "Loss: 0.05395133600090316\n",
      "Loss: 0.04687567395329521\n",
      "______\n",
      "Iteration t=6\n",
      "all:  cs/acc_i=55.62 cs/acc_c=55.00 os/recall_knw=47.11 os/recall_unk=84.66 total/acc_i=56.28 total/acc_c=42.69 total/h_score=54.88\n",
      "selected:  cs/acc_i=55.53 cs/acc_c=54.88 os/recall_knw=46.96 os/recall_unk=85.00 total/acc_i=56.30 total/acc_c=42.57 total/h_score=54.81\n",
      "Loss: 1.6521849519595868\n",
      "Loss: 0.2824869698208825\n",
      "Loss: 0.16273753951508096\n",
      "Loss: 0.12341258429252065\n",
      "Loss: 0.10902155143004365\n",
      "Loss: 0.08570767508354038\n",
      "Loss: 0.06763284398021358\n",
      "Loss: 0.06427241994704051\n",
      "Loss: 0.05282548568268284\n",
      "Loss: 0.048604492580790706\n",
      "______\n",
      "Iteration t=7\n",
      "all:  cs/acc_i=56.39 cs/acc_c=55.64 os/recall_knw=47.11 os/recall_unk=84.66 total/acc_i=56.28 total/acc_c=42.69 total/h_score=54.88\n",
      "selected:  cs/acc_i=56.39 cs/acc_c=55.64 os/recall_knw=47.11 os/recall_unk=84.66 total/acc_i=56.28 total/acc_c=42.69 total/h_score=54.88\n",
      "Loss: 1.6419557157631328\n",
      "Loss: 0.2793507507048184\n",
      "Loss: 0.16443682092855252\n",
      "Loss: 0.12630571630533513\n",
      "Loss: 0.097971806683146\n",
      "Loss: 0.08433108587987811\n",
      "Loss: 0.07269016205100343\n",
      "Loss: 0.06539948740065461\n",
      "Loss: 0.0583844932886522\n",
      "Loss: 0.04800716816396566\n",
      "______\n",
      "Iteration t=8\n",
      "all:  cs/acc_i=55.77 cs/acc_c=55.11 os/recall_knw=47.11 os/recall_unk=84.66 total/acc_i=56.28 total/acc_c=42.69 total/h_score=54.88\n",
      "selected:  cs/acc_i=55.77 cs/acc_c=55.11 os/recall_knw=47.11 os/recall_unk=84.66 total/acc_i=56.28 total/acc_c=42.69 total/h_score=54.88\n",
      "Loss: 1.665543497699063\n",
      "Loss: 0.28014006245336154\n",
      "Loss: 0.16425097396415544\n",
      "Loss: 0.12732740970919046\n",
      "Loss: 0.10062089510171152\n",
      "Loss: 0.08076954360699236\n",
      "Loss: 0.0710289281560108\n",
      "Loss: 0.07006990518307359\n",
      "Loss: 0.056580136087155196\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.046585143073149614\n",
      "______\n",
      "Iteration t=9\n",
      "all:  cs/acc_i=56.43 cs/acc_c=55.85 os/recall_knw=47.11 os/recall_unk=84.66 total/acc_i=56.28 total/acc_c=42.69 total/h_score=54.88\n",
      "selected:  cs/acc_i=56.43 cs/acc_c=55.85 os/recall_knw=47.11 os/recall_unk=84.66 total/acc_i=56.28 total/acc_c=42.69 total/h_score=54.88\n",
      "tensor(0)\n",
      "all:  cs/acc_i=56.43 cs/acc_c=55.85 os/recall_knw=47.11 os/recall_unk=84.66 total/acc_i=56.28 total/acc_c=42.69 total/h_score=54.88\n",
      "real -> sketch lr= 0.001 seed= 4\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19]\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20]\n",
      "Loss: 1.797177776747327\n",
      "Loss: 0.3416707492914064\n",
      "Loss: 0.19446342826234275\n",
      "Loss: 0.14439499805751008\n",
      "Loss: 0.1244543242695811\n",
      "Loss: 0.11036591216577117\n",
      "Loss: 0.09057603287262\n",
      "Loss: 0.08227210980094306\n",
      "Loss: 0.06749014106986785\n",
      "Loss: 0.06073185927781452\n",
      "tensor(True) tensor(True)\n",
      "______\n",
      "Iteration t=1\n",
      "all:  cs/acc_i=55.62 cs/acc_c=54.99 os/recall_knw=80.83 os/recall_unk=35.78 total/acc_i=46.71 total/acc_c=51.22 total/h_score=42.39\n",
      "selected:  cs/acc_i=52.36 cs/acc_c=49.93 os/recall_knw=46.10 os/recall_unk=94.78 total/acc_i=62.35 total/acc_c=43.86 total/h_score=57.55\n",
      "Loss: 1.7334698430589728\n",
      "Loss: 0.30377551248750173\n",
      "Loss: 0.17908926131958897\n",
      "Loss: 0.14565979075819455\n",
      "Loss: 0.11098357068211143\n",
      "Loss: 0.09647935348235674\n",
      "Loss: 0.0770606390040091\n",
      "Loss: 0.06813469202559744\n",
      "Loss: 0.059717887246389746\n",
      "Loss: 0.054449642633994086\n",
      "______\n",
      "Iteration t=2\n",
      "all:  cs/acc_i=55.51 cs/acc_c=55.02 os/recall_knw=49.89 os/recall_unk=82.28 total/acc_i=56.30 total/acc_c=43.91 total/h_score=55.60\n",
      "selected:  cs/acc_i=49.27 cs/acc_c=49.09 os/recall_knw=37.69 os/recall_unk=91.27 total/acc_i=54.84 total/acc_c=35.55 total/h_score=48.22\n",
      "Loss: 1.6964781433343887\n",
      "Loss: 0.2805664423732988\n",
      "Loss: 0.16983934166210313\n",
      "Loss: 0.12927315300630945\n",
      "Loss: 0.10009598285861072\n",
      "Loss: 0.08841849651127573\n",
      "Loss: 0.07446505071955824\n",
      "Loss: 0.06296688774300198\n",
      "Loss: 0.057299710601387964\n",
      "Loss: 0.05108826179883533\n",
      "______\n",
      "Iteration t=3\n",
      "all:  cs/acc_i=54.38 cs/acc_c=53.92 os/recall_knw=48.10 os/recall_unk=84.11 total/acc_i=56.26 total/acc_c=43.06 total/h_score=55.14\n",
      "selected:  cs/acc_i=51.04 cs/acc_c=50.69 os/recall_knw=42.26 os/recall_unk=89.01 total/acc_i=55.44 total/acc_c=38.83 total/h_score=51.59\n",
      "Loss: 1.6800390976779866\n",
      "Loss: 0.2927677665585242\n",
      "Loss: 0.1750058510557473\n",
      "Loss: 0.1258885063195847\n",
      "Loss: 0.09993653753245214\n",
      "Loss: 0.079947699775111\n",
      "Loss: 0.07455690900953311\n",
      "Loss: 0.06406254543916984\n",
      "Loss: 0.05296107432394986\n",
      "Loss: 0.05017376595774209\n",
      "______\n",
      "Iteration t=4\n",
      "all:  cs/acc_i=54.86 cs/acc_c=54.24 os/recall_knw=47.81 os/recall_unk=84.66 total/acc_i=56.33 total/acc_c=42.90 total/h_score=55.08\n",
      "selected:  cs/acc_i=53.04 cs/acc_c=52.48 os/recall_knw=44.95 os/recall_unk=87.45 total/acc_i=55.87 total/acc_c=40.74 total/h_score=53.37\n",
      "Loss: 1.6626357919660515\n",
      "Loss: 0.2766973539125809\n",
      "Loss: 0.1636508764416533\n",
      "Loss: 0.1258126119607281\n",
      "Loss: 0.1021249631863814\n",
      "Loss: 0.08496806029253423\n",
      "Loss: 0.07112567584050514\n",
      "Loss: 0.06025334670361212\n",
      "Loss: 0.05369274377615275\n",
      "Loss: 0.04484872230625605\n",
      "______\n",
      "Iteration t=5\n",
      "all:  cs/acc_i=55.30 cs/acc_c=54.95 os/recall_knw=47.77 os/recall_unk=84.66 total/acc_i=56.30 total/acc_c=42.88 total/h_score=55.05\n",
      "selected:  cs/acc_i=54.62 cs/acc_c=54.39 os/recall_knw=46.54 os/recall_unk=86.24 total/acc_i=56.25 total/acc_c=42.13 total/h_score=54.58\n",
      "Loss: 1.6655620381327494\n",
      "Loss: 0.2775299562815508\n",
      "Loss: 0.1691986204816337\n",
      "Loss: 0.12941763299214512\n",
      "Loss: 0.09866417801590419\n",
      "Loss: 0.08673545266244492\n",
      "Loss: 0.07076661067049196\n",
      "Loss: 0.05753013169524357\n",
      "Loss: 0.053334220081133525\n",
      "Loss: 0.05049799901913234\n",
      "______\n",
      "Iteration t=6\n",
      "all:  cs/acc_i=55.95 cs/acc_c=55.45 os/recall_knw=47.77 os/recall_unk=84.66 total/acc_i=56.30 total/acc_c=42.88 total/h_score=55.05\n",
      "selected:  cs/acc_i=55.90 cs/acc_c=55.42 os/recall_knw=47.62 os/recall_unk=84.83 total/acc_i=56.31 total/acc_c=42.81 total/h_score=55.02\n",
      "Loss: 1.6558319733637135\n",
      "Loss: 0.27834101875380773\n",
      "Loss: 0.16575026367904572\n",
      "Loss: 0.1248691462366501\n",
      "Loss: 0.09380617958959192\n",
      "Loss: 0.08363623618398135\n",
      "Loss: 0.07131625225599969\n",
      "Loss: 0.05613200802202677\n",
      "Loss: 0.049529556704616944\n",
      "Loss: 0.04606227608107984\n",
      "______\n",
      "Iteration t=7\n",
      "all:  cs/acc_i=56.36 cs/acc_c=55.89 os/recall_knw=47.74 os/recall_unk=84.66 total/acc_i=56.30 total/acc_c=42.88 total/h_score=55.05\n",
      "selected:  cs/acc_i=56.36 cs/acc_c=55.89 os/recall_knw=47.74 os/recall_unk=84.66 total/acc_i=56.30 total/acc_c=42.88 total/h_score=55.05\n",
      "Loss: 1.6517902439669636\n",
      "Loss: 0.2862701979451629\n",
      "Loss: 0.16375342858983571\n",
      "Loss: 0.12264388741919698\n",
      "Loss: 0.10184904323511483\n",
      "Loss: 0.07733194973025369\n",
      "Loss: 0.06873945880250999\n",
      "Loss: 0.06289937011727718\n",
      "Loss: 0.05194476348882977\n",
      "Loss: 0.0454926928016994\n",
      "______\n",
      "Iteration t=8\n",
      "all:  cs/acc_i=56.61 cs/acc_c=55.99 os/recall_knw=47.74 os/recall_unk=84.66 total/acc_i=56.30 total/acc_c=42.88 total/h_score=55.05\n",
      "selected:  cs/acc_i=56.61 cs/acc_c=55.99 os/recall_knw=47.74 os/recall_unk=84.66 total/acc_i=56.30 total/acc_c=42.88 total/h_score=55.05\n",
      "Loss: 1.6692637755878066\n",
      "Loss: 0.27690143738292994\n",
      "Loss: 0.16426873874021156\n",
      "Loss: 0.12940341493505475\n",
      "Loss: 0.0994843226435699\n",
      "Loss: 0.07819700708731692\n",
      "Loss: 0.07710638205240562\n",
      "Loss: 0.06072204191900088\n",
      "Loss: 0.05192729063886911\n",
      "Loss: 0.04528797390420658\n",
      "______\n",
      "Iteration t=9\n",
      "all:  cs/acc_i=55.59 cs/acc_c=55.14 os/recall_knw=47.74 os/recall_unk=84.66 total/acc_i=56.30 total/acc_c=42.88 total/h_score=55.05\n",
      "selected:  cs/acc_i=55.59 cs/acc_c=55.14 os/recall_knw=47.74 os/recall_unk=84.66 total/acc_i=56.30 total/acc_c=42.88 total/h_score=55.05\n",
      "tensor(0)\n",
      "all:  cs/acc_i=55.59 cs/acc_c=55.14 os/recall_knw=47.74 os/recall_unk=84.66 total/acc_i=56.30 total/acc_c=42.88 total/h_score=55.05\n",
      "real -> sketch lr= 0.001 seed= 0\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19]\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20]\n",
      "Loss: 1.8070432222398574\n",
      "Loss: 0.3351436912536197\n",
      "Loss: 0.18740055439629164\n",
      "Loss: 0.14481810722301228\n",
      "Loss: 0.12272877763174607\n",
      "Loss: 0.10663471250294367\n",
      "Loss: 0.09139384650144713\n",
      "Loss: 0.07932915127408621\n",
      "Loss: 0.07651279933147424\n",
      "Loss: 0.06351604152908316\n",
      "tensor(True) tensor(True)\n",
      "______\n",
      "Iteration t=1\n",
      "all:  cs/acc_i=54.64 cs/acc_c=54.05 os/recall_knw=80.39 os/recall_unk=34.96 total/acc_i=45.81 total/acc_c=50.40 total/h_score=41.54\n",
      "selected:  cs/acc_i=52.18 cs/acc_c=49.49 os/recall_knw=45.59 os/recall_unk=95.02 total/acc_i=62.00 total/acc_c=43.94 total/h_score=57.66\n",
      "Loss: 1.7331696040928364\n",
      "Loss: 0.2994635311785985\n",
      "Loss: 0.1831047325772611\n",
      "Loss: 0.1378307425215639\n",
      "Loss: 0.11283122214513856\n",
      "Loss: 0.09712633756429863\n",
      "Loss: 0.08075370531013185\n",
      "Loss: 0.07375022950519279\n",
      "Loss: 0.06982158516326013\n",
      "Loss: 0.05497055093134829\n",
      "______\n",
      "Iteration t=2\n",
      "all:  cs/acc_i=54.89 cs/acc_c=54.33 os/recall_knw=48.32 os/recall_unk=84.45 total/acc_i=56.57 total/acc_c=43.31 total/h_score=55.43\n",
      "selected:  cs/acc_i=48.33 cs/acc_c=48.28 os/recall_knw=37.03 os/recall_unk=91.81 total/acc_i=54.55 total/acc_c=35.01 total/h_score=47.65\n",
      "Loss: 1.679516890068208\n",
      "Loss: 0.29549951490855986\n",
      "Loss: 0.16959534849851363\n",
      "Loss: 0.1252162472975831\n",
      "Loss: 0.10770926348144008\n",
      "Loss: 0.08948997997288262\n",
      "Loss: 0.07656821334554303\n",
      "Loss: 0.06336853033412368\n",
      "Loss: 0.06401265340466653\n",
      "Loss: 0.04755345414272479\n",
      "______\n",
      "Iteration t=3\n",
      "all:  cs/acc_i=54.71 cs/acc_c=54.14 os/recall_knw=47.08 os/recall_unk=85.27 total/acc_i=56.33 total/acc_c=42.59 total/h_score=54.88\n",
      "selected:  cs/acc_i=51.27 cs/acc_c=50.80 os/recall_knw=41.60 os/recall_unk=89.65 total/acc_i=55.28 total/acc_c=38.36 total/h_score=51.17\n",
      "Loss: 1.6702683456124567\n",
      "Loss: 0.279499594933039\n",
      "Loss: 0.16848511467408683\n",
      "Loss: 0.12569500306732834\n",
      "Loss: 0.10582874363952255\n",
      "Loss: 0.08091382341524028\n",
      "Loss: 0.07502419905507884\n",
      "Loss: 0.06824174447408186\n",
      "Loss: 0.05783868978264204\n",
      "Loss: 0.050919634576487335\n",
      "______\n",
      "Iteration t=4\n",
      "all:  cs/acc_i=55.26 cs/acc_c=54.61 os/recall_knw=46.82 os/recall_unk=85.47 total/acc_i=56.28 total/acc_c=42.44 total/h_score=54.76\n",
      "selected:  cs/acc_i=53.51 cs/acc_c=53.07 os/recall_knw=44.11 os/recall_unk=88.41 total/acc_i=55.87 total/acc_c=40.48 total/h_score=53.23\n",
      "Loss: 1.6743004409978108\n",
      "Loss: 0.2967808986811534\n",
      "Loss: 0.16322908383904036\n",
      "Loss: 0.12258342724085225\n",
      "Loss: 0.10008618097625072\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.08719090769148391\n",
      "Loss: 0.07043813741389916\n",
      "Loss: 0.05908290801066558\n",
      "Loss: 0.05975185026941092\n",
      "Loss: 0.045910239694003735\n",
      "______\n",
      "Iteration t=5\n",
      "all:  cs/acc_i=55.41 cs/acc_c=54.87 os/recall_knw=46.82 os/recall_unk=85.54 total/acc_i=56.30 total/acc_c=42.44 total/h_score=54.77\n",
      "selected:  cs/acc_i=54.71 cs/acc_c=54.31 os/recall_knw=45.73 os/recall_unk=87.02 total/acc_i=56.21 total/acc_c=41.73 total/h_score=54.30\n",
      "Loss: 1.6634642753234277\n",
      "Loss: 0.28368032994178627\n",
      "Loss: 0.16694113183480042\n",
      "Loss: 0.12054771450276558\n",
      "Loss: 0.10113288554721153\n",
      "Loss: 0.08174744127604824\n",
      "Loss: 0.07001251949140659\n",
      "Loss: 0.06449722794457698\n",
      "Loss: 0.0530019845140095\n",
      "Loss: 0.04931294518236357\n",
      "______\n",
      "Iteration t=6\n",
      "all:  cs/acc_i=55.77 cs/acc_c=55.24 os/recall_knw=46.71 os/recall_unk=85.54 total/acc_i=56.23 total/acc_c=42.32 total/h_score=54.65\n",
      "selected:  cs/acc_i=55.66 cs/acc_c=55.18 os/recall_knw=46.54 os/recall_unk=85.54 total/acc_i=56.16 total/acc_c=42.20 total/h_score=54.54\n",
      "Loss: 1.6549708687384195\n",
      "Loss: 0.27215098598772597\n",
      "Loss: 0.16461126410063437\n",
      "Loss: 0.12213944090068887\n",
      "Loss: 0.09515277731776328\n",
      "Loss: 0.08323552088658197\n",
      "Loss: 0.07422414784595963\n",
      "Loss: 0.06282778824636832\n",
      "Loss: 0.05449310968422106\n",
      "Loss: 0.0467197368952477\n",
      "______\n",
      "Iteration t=7\n",
      "all:  cs/acc_i=55.73 cs/acc_c=55.18 os/recall_knw=46.71 os/recall_unk=85.54 total/acc_i=56.23 total/acc_c=42.32 total/h_score=54.65\n",
      "selected:  cs/acc_i=55.73 cs/acc_c=55.18 os/recall_knw=46.71 os/recall_unk=85.54 total/acc_i=56.23 total/acc_c=42.32 total/h_score=54.65\n",
      "Loss: 1.6460285256032914\n",
      "Loss: 0.2839366657608146\n",
      "Loss: 0.16608410133817875\n",
      "Loss: 0.12025088005747635\n",
      "Loss: 0.09600216267055145\n",
      "Loss: 0.08350751820854865\n",
      "Loss: 0.07514419005642609\n",
      "Loss: 0.060303294228031004\n",
      "Loss: 0.05418832147129404\n",
      "Loss: 0.05056111411610191\n",
      "______\n",
      "Iteration t=8\n",
      "all:  cs/acc_i=55.92 cs/acc_c=55.38 os/recall_knw=46.71 os/recall_unk=85.54 total/acc_i=56.23 total/acc_c=42.32 total/h_score=54.65\n",
      "selected:  cs/acc_i=55.92 cs/acc_c=55.38 os/recall_knw=46.71 os/recall_unk=85.54 total/acc_i=56.23 total/acc_c=42.32 total/h_score=54.65\n",
      "Loss: 1.652157772024837\n",
      "Loss: 0.28432039492720856\n",
      "Loss: 0.16834360628249265\n",
      "Loss: 0.1208737439245259\n",
      "Loss: 0.09965892520872734\n",
      "Loss: 0.08413938135307407\n",
      "Loss: 0.07137398277366654\n",
      "Loss: 0.06003799438918015\n",
      "Loss: 0.05320832100184207\n",
      "Loss: 0.04828805078122913\n",
      "______\n",
      "Iteration t=9\n",
      "all:  cs/acc_i=56.10 cs/acc_c=55.50 os/recall_knw=46.71 os/recall_unk=85.54 total/acc_i=56.23 total/acc_c=42.32 total/h_score=54.65\n",
      "selected:  cs/acc_i=56.10 cs/acc_c=55.50 os/recall_knw=46.71 os/recall_unk=85.54 total/acc_i=56.23 total/acc_c=42.32 total/h_score=54.65\n",
      "tensor(0)\n",
      "all:  cs/acc_i=56.10 cs/acc_c=55.50 os/recall_knw=46.71 os/recall_unk=85.54 total/acc_i=56.23 total/acc_c=42.32 total/h_score=54.65\n",
      "real -> sketch lr= 0.001 seed= 1\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19]\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20]\n",
      "Loss: 1.8162964445628305\n",
      "Loss: 0.3355776506651763\n",
      "Loss: 0.19945749706751087\n",
      "Loss: 0.14549774891328981\n",
      "Loss: 0.12218157586465951\n",
      "Loss: 0.1081089139435427\n",
      "Loss: 0.09132178191400507\n",
      "Loss: 0.079194269742936\n",
      "Loss: 0.07460121408244098\n",
      "Loss: 0.05990047815000619\n",
      "tensor(True) tensor(True)\n",
      "______\n",
      "Iteration t=1\n",
      "all:  cs/acc_i=55.48 cs/acc_c=55.06 os/recall_knw=80.75 os/recall_unk=35.64 total/acc_i=47.00 total/acc_c=51.92 total/h_score=42.54\n",
      "selected:  cs/acc_i=50.62 cs/acc_c=49.46 os/recall_knw=45.89 os/recall_unk=94.25 total/acc_i=62.25 total/acc_c=45.19 total/h_score=58.81\n",
      "Loss: 1.7334601132048142\n",
      "Loss: 0.29576413408928626\n",
      "Loss: 0.1770972080805616\n",
      "Loss: 0.14062765173337147\n",
      "Loss: 0.11351983686216881\n",
      "Loss: 0.10230545867612031\n",
      "Loss: 0.08186119512302449\n",
      "Loss: 0.06983689529777228\n",
      "Loss: 0.06592165842979543\n",
      "Loss: 0.05780823156552238\n",
      "______\n",
      "Iteration t=2\n",
      "all:  cs/acc_i=55.77 cs/acc_c=55.33 os/recall_knw=49.38 os/recall_unk=82.48 total/acc_i=56.42 total/acc_c=43.96 total/h_score=55.69\n",
      "selected:  cs/acc_i=49.78 cs/acc_c=49.86 os/recall_knw=37.79 os/recall_unk=92.12 total/acc_i=55.20 total/acc_c=36.20 total/h_score=49.03\n",
      "Loss: 1.7018771215792625\n",
      "Loss: 0.2876531967232304\n",
      "Loss: 0.17382820193926174\n",
      "Loss: 0.13161507985524593\n",
      "Loss: 0.1118075302741941\n",
      "Loss: 0.09027547925229995\n",
      "Loss: 0.0744515624933786\n",
      "Loss: 0.06569902368881289\n",
      "Loss: 0.0584860768409506\n",
      "Loss: 0.05520026039692663\n",
      "______\n",
      "Iteration t=3\n",
      "all:  cs/acc_i=54.97 cs/acc_c=54.48 os/recall_knw=46.68 os/recall_unk=84.73 total/acc_i=56.26 total/acc_c=42.77 total/h_score=54.96\n",
      "selected:  cs/acc_i=51.08 cs/acc_c=51.03 os/recall_knw=40.29 os/recall_unk=90.37 total/acc_i=55.23 total/acc_c=38.20 total/h_score=51.07\n",
      "Loss: 1.6739456280122829\n",
      "Loss: 0.2917866512567182\n",
      "Loss: 0.16597815664909496\n",
      "Loss: 0.12331426715407567\n",
      "Loss: 0.10136388090757441\n",
      "Loss: 0.0896266171932692\n",
      "Loss: 0.07934309450815184\n",
      "Loss: 0.06851575188515589\n",
      "Loss: 0.05996892305203018\n",
      "Loss: 0.05383629107971593\n",
      "______\n",
      "Iteration t=4\n",
      "all:  cs/acc_i=55.19 cs/acc_c=54.57 os/recall_knw=46.31 os/recall_unk=85.13 total/acc_i=56.19 total/acc_c=42.49 total/h_score=54.75\n",
      "selected:  cs/acc_i=53.34 cs/acc_c=52.83 os/recall_knw=43.31 os/recall_unk=88.62 total/acc_i=55.84 total/acc_c=40.31 total/h_score=53.08\n",
      "Loss: 1.6674840351874212\n",
      "Loss: 0.285265245355921\n",
      "Loss: 0.17304834167580366\n",
      "Loss: 0.130817755354667\n",
      "Loss: 0.10325923851891378\n",
      "Loss: 0.08619379275115759\n",
      "Loss: 0.0760499870091259\n",
      "Loss: 0.06454068318450376\n",
      "Loss: 0.057493753557171776\n",
      "Loss: 0.04901697940695044\n",
      "______\n",
      "Iteration t=5\n",
      "all:  cs/acc_i=56.32 cs/acc_c=55.72 os/recall_knw=46.31 os/recall_unk=85.20 total/acc_i=56.21 total/acc_c=42.49 total/h_score=54.77\n",
      "selected:  cs/acc_i=55.70 cs/acc_c=55.09 os/recall_knw=45.27 os/recall_unk=86.91 total/acc_i=56.20 total/acc_c=41.77 total/h_score=54.33\n",
      "Loss: 1.6545907286497263\n",
      "Loss: 0.2825771231376208\n",
      "Loss: 0.16430838925334124\n",
      "Loss: 0.12434227841977889\n",
      "Loss: 0.09795829140796111\n",
      "Loss: 0.08518075092767294\n",
      "Loss: 0.07520877775521233\n",
      "Loss: 0.06497699816782887\n",
      "Loss: 0.05400838170057306\n",
      "Loss: 0.04807837553465596\n",
      "______\n",
      "Iteration t=6\n",
      "all:  cs/acc_i=55.73 cs/acc_c=55.25 os/recall_knw=46.24 os/recall_unk=85.20 total/acc_i=56.16 total/acc_c=42.42 total/h_score=54.70\n",
      "selected:  cs/acc_i=55.67 cs/acc_c=55.20 os/recall_knw=46.02 os/recall_unk=85.49 total/acc_i=56.19 total/acc_c=42.34 total/h_score=54.67\n",
      "Loss: 1.6492946950849772\n",
      "Loss: 0.2716902513341802\n",
      "Loss: 0.1685833485814136\n",
      "Loss: 0.12376926442329125\n",
      "Loss: 0.10015017500813675\n",
      "Loss: 0.08480839410210057\n",
      "Loss: 0.07656600322597162\n",
      "Loss: 0.06708880537403149\n",
      "Loss: 0.05298417509000874\n",
      "Loss: 0.04977997397542547\n",
      "______\n",
      "Iteration t=7\n",
      "all:  cs/acc_i=56.72 cs/acc_c=56.07 os/recall_knw=46.24 os/recall_unk=85.20 total/acc_i=56.16 total/acc_c=42.42 total/h_score=54.70\n",
      "selected:  cs/acc_i=56.69 cs/acc_c=56.03 os/recall_knw=46.20 os/recall_unk=85.20 total/acc_i=56.14 total/acc_c=42.39 total/h_score=54.67\n",
      "Loss: 1.6519690102211197\n",
      "Loss: 0.27957997487043384\n",
      "Loss: 0.16849251502173573\n",
      "Loss: 0.12588032018336318\n",
      "Loss: 0.10106947054283334\n",
      "Loss: 0.08431370393729082\n",
      "Loss: 0.07299761370747188\n",
      "Loss: 0.06552440215283806\n",
      "Loss: 0.056211736493968954\n",
      "Loss: 0.04707417855343984\n",
      "______\n",
      "Iteration t=8\n",
      "all:  cs/acc_i=57.12 cs/acc_c=56.53 os/recall_knw=46.24 os/recall_unk=85.20 total/acc_i=56.16 total/acc_c=42.42 total/h_score=54.70\n",
      "selected:  cs/acc_i=57.12 cs/acc_c=56.53 os/recall_knw=46.24 os/recall_unk=85.20 total/acc_i=56.16 total/acc_c=42.42 total/h_score=54.70\n",
      "Loss: 1.650652256762945\n",
      "Loss: 0.27083686047692185\n",
      "Loss: 0.15720777768949304\n",
      "Loss: 0.12384054333609543\n",
      "Loss: 0.09515877552501378\n",
      "Loss: 0.08034048137035711\n",
      "Loss: 0.07497743609011037\n",
      "Loss: 0.060643643108039914\n",
      "Loss: 0.05483187623151125\n",
      "Loss: 0.045224473736211884\n",
      "______\n",
      "Iteration t=9\n",
      "all:  cs/acc_i=56.98 cs/acc_c=56.37 os/recall_knw=46.24 os/recall_unk=85.20 total/acc_i=56.16 total/acc_c=42.42 total/h_score=54.70\n",
      "selected:  cs/acc_i=56.98 cs/acc_c=56.37 os/recall_knw=46.24 os/recall_unk=85.20 total/acc_i=56.16 total/acc_c=42.42 total/h_score=54.70\n",
      "tensor(0)\n",
      "all:  cs/acc_i=56.98 cs/acc_c=56.37 os/recall_knw=46.24 os/recall_unk=85.20 total/acc_i=56.16 total/acc_c=42.42 total/h_score=54.70\n",
      "real -> sketch lr= 0.001 seed= 2\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19]\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20]\n",
      "Loss: 1.805677903080326\n",
      "Loss: 0.3273584107699343\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.19579598322192546\n",
      "Loss: 0.1475116614106499\n",
      "Loss: 0.12143809329121774\n",
      "Loss: 0.11072242678245828\n",
      "Loss: 0.09547576356473714\n",
      "Loss: 0.0794929012994272\n",
      "Loss: 0.0747083190851762\n",
      "Loss: 0.062434576663894584\n",
      "tensor(True) tensor(True)\n",
      "______\n",
      "Iteration t=1\n",
      "all:  cs/acc_i=55.26 cs/acc_c=54.66 os/recall_knw=81.41 os/recall_unk=36.86 total/acc_i=47.33 total/acc_c=51.74 total/h_score=43.31\n",
      "selected:  cs/acc_i=51.72 cs/acc_c=49.16 os/recall_knw=46.81 os/recall_unk=95.10 total/acc_i=63.81 total/acc_c=45.22 total/h_score=58.96\n",
      "Loss: 1.722858526013993\n",
      "Loss: 0.3087492953683879\n",
      "Loss: 0.17699772762638089\n",
      "Loss: 0.1352616248564241\n",
      "Loss: 0.1131539150153765\n",
      "Loss: 0.09579297868421653\n",
      "Loss: 0.07843528676312417\n",
      "Loss: 0.07041757808041733\n",
      "Loss: 0.06355096786314421\n",
      "Loss: 0.05824904677904891\n",
      "______\n",
      "Iteration t=2\n",
      "all:  cs/acc_i=55.77 cs/acc_c=55.30 os/recall_knw=49.63 os/recall_unk=82.28 total/acc_i=56.54 total/acc_c=44.33 total/h_score=55.99\n",
      "selected:  cs/acc_i=49.44 cs/acc_c=49.45 os/recall_knw=37.74 os/recall_unk=91.82 total/acc_i=55.13 total/acc_c=36.17 total/h_score=48.97\n",
      "Loss: 1.6883382152165136\n",
      "Loss: 0.29749435688699444\n",
      "Loss: 0.17657017204309663\n",
      "Loss: 0.12288199720243292\n",
      "Loss: 0.10479520496521746\n",
      "Loss: 0.08948401528440657\n",
      "Loss: 0.07203912359452055\n",
      "Loss: 0.06961845001956869\n",
      "Loss: 0.055148602064488635\n",
      "Loss: 0.05247820527142575\n",
      "______\n",
      "Iteration t=3\n",
      "all:  cs/acc_i=55.48 cs/acc_c=54.99 os/recall_knw=47.08 os/recall_unk=85.00 total/acc_i=56.33 total/acc_c=42.81 total/h_score=55.04\n",
      "selected:  cs/acc_i=52.12 cs/acc_c=51.94 os/recall_knw=41.50 os/recall_unk=89.94 total/acc_i=55.41 total/acc_c=38.79 total/h_score=51.66\n",
      "Loss: 1.6748138550516183\n",
      "Loss: 0.284863057690276\n",
      "Loss: 0.16972915738915043\n",
      "Loss: 0.11732095932112037\n",
      "Loss: 0.10363162818367737\n",
      "Loss: 0.0833432834671828\n",
      "Loss: 0.07319902815512302\n",
      "Loss: 0.06720951830451186\n",
      "Loss: 0.05361181219499147\n",
      "Loss: 0.04999528261788824\n",
      "______\n",
      "Iteration t=4\n",
      "all:  cs/acc_i=55.11 cs/acc_c=54.50 os/recall_knw=46.82 os/recall_unk=85.13 total/acc_i=56.26 total/acc_c=42.63 total/h_score=54.90\n",
      "selected:  cs/acc_i=53.24 cs/acc_c=52.80 os/recall_knw=43.91 os/recall_unk=88.50 total/acc_i=55.87 total/acc_c=40.54 total/h_score=53.31\n",
      "Loss: 1.6665834221884468\n",
      "Loss: 0.2793035948666457\n",
      "Loss: 0.16837255108950666\n",
      "Loss: 0.12665509198127878\n",
      "Loss: 0.10179563572287931\n",
      "Loss: 0.08910645098306494\n",
      "Loss: 0.07402792156926383\n",
      "Loss: 0.0618157792499875\n",
      "Loss: 0.056637269917678236\n",
      "Loss: 0.051799306235453146\n",
      "______\n",
      "Iteration t=5\n",
      "all:  cs/acc_i=56.10 cs/acc_c=55.57 os/recall_knw=46.60 os/recall_unk=85.34 total/acc_i=56.19 total/acc_c=42.41 total/h_score=54.72\n",
      "selected:  cs/acc_i=55.43 cs/acc_c=54.96 os/recall_knw=45.47 os/recall_unk=86.93 total/acc_i=56.12 total/acc_c=41.65 total/h_score=54.21\n",
      "Loss: 1.6552568380649273\n",
      "Loss: 0.2805530864458818\n",
      "Loss: 0.16880255403426978\n",
      "Loss: 0.12477722307810417\n",
      "Loss: 0.1028539060543363\n",
      "Loss: 0.08177491513582376\n",
      "Loss: 0.07632140592886852\n",
      "Loss: 0.062119452191086916\n",
      "Loss: 0.0572009944013105\n",
      "Loss: 0.04672649377813706\n",
      "______\n",
      "Iteration t=6\n",
      "all:  cs/acc_i=55.81 cs/acc_c=55.31 os/recall_knw=46.60 os/recall_unk=85.34 total/acc_i=56.19 total/acc_c=42.41 total/h_score=54.72\n",
      "selected:  cs/acc_i=55.73 cs/acc_c=55.28 os/recall_knw=46.47 os/recall_unk=85.63 total/acc_i=56.20 total/acc_c=42.37 total/h_score=54.72\n",
      "Loss: 1.6700263853649115\n",
      "Loss: 0.2807211236236475\n",
      "Loss: 0.1752822046319097\n",
      "Loss: 0.12441499905506952\n",
      "Loss: 0.09316370685211744\n",
      "Loss: 0.08332588572186113\n",
      "Loss: 0.07324142805343374\n",
      "Loss: 0.06170161757817554\n",
      "Loss: 0.0545112159379419\n",
      "Loss: 0.04917106014998225\n",
      "______\n",
      "Iteration t=7\n",
      "all:  cs/acc_i=56.06 cs/acc_c=55.39 os/recall_knw=46.60 os/recall_unk=85.34 total/acc_i=56.19 total/acc_c=42.41 total/h_score=54.72\n",
      "selected:  cs/acc_i=56.06 cs/acc_c=55.39 os/recall_knw=46.60 os/recall_unk=85.39 total/acc_i=56.20 total/acc_c=42.42 total/h_score=54.73\n",
      "Loss: 1.6778997403401483\n",
      "Loss: 0.288150740371567\n",
      "Loss: 0.16709939391560147\n",
      "Loss: 0.12579928189857836\n",
      "Loss: 0.10130161280524476\n",
      "Loss: 0.08756459885724002\n",
      "Loss: 0.07462210474757973\n",
      "Loss: 0.06056677037280406\n",
      "Loss: 0.060978350441743386\n",
      "Loss: 0.049788640629762175\n",
      "______\n",
      "Iteration t=8\n",
      "all:  cs/acc_i=55.88 cs/acc_c=55.28 os/recall_knw=46.60 os/recall_unk=85.34 total/acc_i=56.19 total/acc_c=42.41 total/h_score=54.72\n",
      "selected:  cs/acc_i=55.88 cs/acc_c=55.28 os/recall_knw=46.60 os/recall_unk=85.34 total/acc_i=56.19 total/acc_c=42.41 total/h_score=54.72\n",
      "Loss: 1.6401514620591378\n",
      "Loss: 0.279282782579963\n",
      "Loss: 0.15955338883427306\n",
      "Loss: 0.1251577456661184\n",
      "Loss: 0.09897987612320924\n",
      "Loss: 0.08122947696875496\n",
      "Loss: 0.0729939547717708\n",
      "Loss: 0.06543009541359152\n",
      "Loss: 0.05217687996098663\n",
      "Loss: 0.04587888177655159\n",
      "______\n",
      "Iteration t=9\n",
      "all:  cs/acc_i=56.46 cs/acc_c=56.02 os/recall_knw=46.60 os/recall_unk=85.34 total/acc_i=56.19 total/acc_c=42.41 total/h_score=54.72\n",
      "selected:  cs/acc_i=56.46 cs/acc_c=56.02 os/recall_knw=46.60 os/recall_unk=85.34 total/acc_i=56.19 total/acc_c=42.41 total/h_score=54.72\n",
      "tensor(0)\n",
      "all:  cs/acc_i=56.46 cs/acc_c=56.02 os/recall_knw=46.60 os/recall_unk=85.34 total/acc_i=56.19 total/acc_c=42.41 total/h_score=54.72\n",
      "real -> sketch lr= 0.001 seed= 3\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19]\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20]\n",
      "Loss: 1.7975468946309276\n",
      "Loss: 0.32789977149394905\n",
      "Loss: 0.19709508122339367\n",
      "Loss: 0.15720494845186053\n",
      "Loss: 0.12809579820766567\n",
      "Loss: 0.10402896549565936\n",
      "Loss: 0.08843342749753244\n",
      "Loss: 0.0813667377775197\n",
      "Loss: 0.0719875077388889\n",
      "Loss: 0.06717747045362707\n",
      "tensor(True) tensor(True)\n",
      "______\n",
      "Iteration t=1\n",
      "all:  cs/acc_i=55.15 cs/acc_c=54.61 os/recall_knw=80.39 os/recall_unk=34.96 total/acc_i=46.33 total/acc_c=51.11 total/h_score=41.79\n",
      "selected:  cs/acc_i=51.12 cs/acc_c=48.83 os/recall_knw=45.43 os/recall_unk=94.32 total/acc_i=61.70 total/acc_c=43.83 total/h_score=57.45\n",
      "Loss: 1.7175220057771012\n",
      "Loss: 0.2934303571646278\n",
      "Loss: 0.17687719757668674\n",
      "Loss: 0.14012150506715518\n",
      "Loss: 0.10933936285987697\n",
      "Loss: 0.09726705539631783\n",
      "Loss: 0.08207853177147037\n",
      "Loss: 0.07062698694613032\n",
      "Loss: 0.06523869588272646\n",
      "Loss: 0.05508349484188255\n",
      "______\n",
      "Iteration t=2\n",
      "all:  cs/acc_i=55.30 cs/acc_c=54.81 os/recall_knw=51.02 os/recall_unk=82.55 total/acc_i=56.87 total/acc_c=44.70 total/h_score=56.38\n",
      "selected:  cs/acc_i=49.06 cs/acc_c=48.77 os/recall_knw=38.57 os/recall_unk=92.05 total/acc_i=55.71 total/acc_c=36.27 total/h_score=49.10\n",
      "Loss: 1.6886584815479093\n",
      "Loss: 0.2910271776299323\n",
      "Loss: 0.1691857972332547\n",
      "Loss: 0.13041162300975093\n",
      "Loss: 0.10216015302726338\n",
      "Loss: 0.0968393229248543\n",
      "Loss: 0.07384898062915571\n",
      "Loss: 0.06915079560731688\n",
      "Loss: 0.061732102371752265\n",
      "Loss: 0.04906292606836125\n",
      "______\n",
      "Iteration t=3\n",
      "all:  cs/acc_i=54.64 cs/acc_c=54.08 os/recall_knw=48.54 os/recall_unk=84.39 total/acc_i=56.68 total/acc_c=43.53 total/h_score=55.62\n",
      "selected:  cs/acc_i=50.94 cs/acc_c=50.74 os/recall_knw=42.49 os/recall_unk=89.49 total/acc_i=55.72 total/acc_c=39.15 total/h_score=51.99\n",
      "Loss: 1.6792670349654912\n",
      "Loss: 0.28934749208812444\n",
      "Loss: 0.17061786314343694\n",
      "Loss: 0.12371722976647832\n",
      "Loss: 0.10531565839858176\n",
      "Loss: 0.08299727237976666\n",
      "Loss: 0.0742895433960377\n",
      "Loss: 0.06282340001853758\n",
      "Loss: 0.054681028640659164\n",
      "Loss: 0.04814883347881852\n",
      "______\n",
      "Iteration t=4\n",
      "all:  cs/acc_i=55.04 cs/acc_c=54.60 os/recall_knw=47.99 os/recall_unk=84.66 total/acc_i=56.54 total/acc_c=43.20 total/h_score=55.36\n",
      "selected:  cs/acc_i=53.42 cs/acc_c=53.05 os/recall_knw=45.27 os/recall_unk=87.88 total/acc_i=56.30 total/acc_c=41.29 total/h_score=53.99\n",
      "Loss: 1.6613083724451507\n",
      "Loss: 0.2758015324318372\n",
      "Loss: 0.1588681295352639\n",
      "Loss: 0.11894450069119687\n",
      "Loss: 0.10496445848165374\n",
      "Loss: 0.08455353781534791\n",
      "Loss: 0.07448842323272728\n",
      "Loss: 0.066428186872184\n",
      "Loss: 0.05522653498274531\n",
      "Loss: 0.050092813697277395\n",
      "______\n",
      "Iteration t=5\n",
      "all:  cs/acc_i=55.59 cs/acc_c=55.02 os/recall_knw=47.85 os/recall_unk=84.73 total/acc_i=56.47 total/acc_c=43.06 total/h_score=55.24\n",
      "selected:  cs/acc_i=55.03 cs/acc_c=54.50 os/recall_knw=46.80 os/recall_unk=86.43 total/acc_i=56.52 total/acc_c=42.41 total/h_score=54.89\n",
      "Loss: 1.6392367495898088\n",
      "Loss: 0.27504168757083225\n",
      "Loss: 0.17280878785974774\n",
      "Loss: 0.11690516111675216\n",
      "Loss: 0.10279317219038865\n",
      "Loss: 0.08168487307655574\n",
      "Loss: 0.07639227822948635\n",
      "Loss: 0.06775539743491203\n",
      "Loss: 0.0550179413828336\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.046700159751987255\n",
      "______\n",
      "Iteration t=6\n",
      "all:  cs/acc_i=56.06 cs/acc_c=55.47 os/recall_knw=47.85 os/recall_unk=84.73 total/acc_i=56.47 total/acc_c=43.06 total/h_score=55.24\n",
      "selected:  cs/acc_i=55.96 cs/acc_c=55.34 os/recall_knw=47.63 os/recall_unk=85.01 total/acc_i=56.47 total/acc_c=42.92 total/h_score=55.15\n",
      "Loss: 1.649383754083296\n",
      "Loss: 0.27957739167642304\n",
      "Loss: 0.16387833566291304\n",
      "Loss: 0.124447659316768\n",
      "Loss: 0.10849176693094395\n",
      "Loss: 0.08075247410395206\n",
      "Loss: 0.07415097894107286\n",
      "Loss: 0.06662985255867925\n",
      "Loss: 0.052918912311902315\n",
      "Loss: 0.04739612743127864\n",
      "______\n",
      "Iteration t=7\n",
      "all:  cs/acc_i=56.21 cs/acc_c=55.62 os/recall_knw=47.85 os/recall_unk=84.79 total/acc_i=56.49 total/acc_c=43.07 total/h_score=55.25\n",
      "selected:  cs/acc_i=56.23 cs/acc_c=55.65 os/recall_knw=47.83 os/recall_unk=84.79 total/acc_i=56.51 total/acc_c=43.08 total/h_score=55.27\n",
      "Loss: 1.637056685870904\n",
      "Loss: 0.28410509611426155\n",
      "Loss: 0.16342156653300968\n",
      "Loss: 0.12754548093060591\n",
      "Loss: 0.10404258218274019\n",
      "Loss: 0.08273967899987898\n",
      "Loss: 0.07086078854175823\n",
      "Loss: 0.06128201906719333\n",
      "Loss: 0.05121072355408708\n",
      "Loss: 0.04850249228953726\n",
      "______\n",
      "Iteration t=8\n",
      "all:  cs/acc_i=56.68 cs/acc_c=56.14 os/recall_knw=47.85 os/recall_unk=84.79 total/acc_i=56.49 total/acc_c=43.07 total/h_score=55.25\n",
      "selected:  cs/acc_i=56.68 cs/acc_c=56.14 os/recall_knw=47.85 os/recall_unk=84.79 total/acc_i=56.49 total/acc_c=43.07 total/h_score=55.25\n",
      "Loss: 1.6265589320369767\n",
      "Loss: 0.26889794211166607\n",
      "Loss: 0.16210616193711758\n",
      "Loss: 0.13075188641354304\n",
      "Loss: 0.10220669230904804\n",
      "Loss: 0.08567334702210133\n",
      "Loss: 0.07118573002120916\n",
      "Loss: 0.07200578454525229\n",
      "Loss: 0.050353994970931744\n",
      "Loss: 0.04969026533586729\n",
      "______\n",
      "Iteration t=9\n",
      "all:  cs/acc_i=56.65 cs/acc_c=56.12 os/recall_knw=47.85 os/recall_unk=84.79 total/acc_i=56.49 total/acc_c=43.07 total/h_score=55.25\n",
      "selected:  cs/acc_i=56.65 cs/acc_c=56.12 os/recall_knw=47.85 os/recall_unk=84.79 total/acc_i=56.49 total/acc_c=43.07 total/h_score=55.25\n",
      "tensor(0)\n",
      "all:  cs/acc_i=56.65 cs/acc_c=56.12 os/recall_knw=47.85 os/recall_unk=84.79 total/acc_i=56.49 total/acc_c=43.07 total/h_score=55.25\n",
      "real -> sketch lr= 0.001 seed= 4\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19]\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20]\n",
      "Loss: 1.799541962316452\n",
      "Loss: 0.34275511967754024\n",
      "Loss: 0.1951124316273635\n",
      "Loss: 0.14460888226579516\n",
      "Loss: 0.12474962168794086\n",
      "Loss: 0.11090274028533081\n",
      "Loss: 0.09119249471327376\n",
      "Loss: 0.08302233308500667\n",
      "Loss: 0.06843170752331243\n",
      "Loss: 0.06137880004173496\n",
      "tensor(True) tensor(True)\n",
      "______\n",
      "Iteration t=1\n",
      "all:  cs/acc_i=55.48 cs/acc_c=54.84 os/recall_knw=81.23 os/recall_unk=36.52 total/acc_i=47.04 total/acc_c=51.33 total/h_score=42.93\n",
      "selected:  cs/acc_i=52.28 cs/acc_c=50.04 os/recall_knw=46.68 os/recall_unk=95.22 total/acc_i=63.18 total/acc_c=44.38 total/h_score=58.14\n",
      "Loss: 1.7455024918591655\n",
      "Loss: 0.29603391125596856\n",
      "Loss: 0.1828018246923347\n",
      "Loss: 0.13670922389782564\n",
      "Loss: 0.11715999540772189\n",
      "Loss: 0.0974711507237894\n",
      "Loss: 0.07935039990587865\n",
      "Loss: 0.07052627482099107\n",
      "Loss: 0.060675754861566365\n",
      "Loss: 0.05111431386762273\n",
      "______\n",
      "Iteration t=2\n",
      "all:  cs/acc_i=55.37 cs/acc_c=54.85 os/recall_knw=48.87 os/recall_unk=83.71 total/acc_i=56.92 total/acc_c=44.16 total/h_score=56.09\n",
      "selected:  cs/acc_i=48.25 cs/acc_c=48.15 os/recall_knw=37.22 os/recall_unk=91.67 total/acc_i=54.74 total/acc_c=35.33 total/h_score=48.00\n",
      "Loss: 1.7014582542642471\n",
      "Loss: 0.2851158323787874\n",
      "Loss: 0.16422458750105673\n",
      "Loss: 0.1250543344285219\n",
      "Loss: 0.09994699021861438\n",
      "Loss: 0.08889625742130222\n",
      "Loss: 0.07473752444549914\n",
      "Loss: 0.06561297986115659\n",
      "Loss: 0.05934745984812898\n",
      "Loss: 0.05389242238785711\n",
      "______\n",
      "Iteration t=3\n",
      "all:  cs/acc_i=53.47 cs/acc_c=52.94 os/recall_knw=47.48 os/recall_unk=85.00 total/acc_i=56.76 total/acc_c=43.37 total/h_score=55.58\n",
      "selected:  cs/acc_i=49.01 cs/acc_c=48.83 os/recall_knw=40.97 os/recall_unk=90.53 total/acc_i=55.51 total/acc_c=38.42 total/h_score=51.33\n",
      "Loss: 1.6648447540930555\n",
      "Loss: 0.27729061403889443\n",
      "Loss: 0.16028237782560195\n",
      "Loss: 0.126984591654773\n",
      "Loss: 0.09957782944805826\n",
      "Loss: 0.0852950672940292\n",
      "Loss: 0.07410804068675571\n",
      "Loss: 0.06737775594007837\n",
      "Loss: 0.052396528262208815\n",
      "Loss: 0.05197649540031871\n",
      "______\n",
      "Iteration t=4\n",
      "all:  cs/acc_i=55.59 cs/acc_c=55.04 os/recall_knw=47.33 os/recall_unk=85.34 total/acc_i=56.83 total/acc_c=43.31 total/h_score=55.58\n",
      "selected:  cs/acc_i=53.80 cs/acc_c=53.37 os/recall_knw=44.58 os/recall_unk=88.33 total/acc_i=56.42 total/acc_c=41.24 total/h_score=53.99\n",
      "Loss: 1.6517944218394178\n",
      "Loss: 0.27636146078013485\n",
      "Loss: 0.15862619887273874\n",
      "Loss: 0.11671004503653008\n",
      "Loss: 0.09937015869394407\n",
      "Loss: 0.0808224656954639\n",
      "Loss: 0.07582981254824478\n",
      "Loss: 0.06625061680097133\n",
      "Loss: 0.054711726602594955\n",
      "Loss: 0.047287386598395216\n",
      "______\n",
      "Iteration t=5\n",
      "all:  cs/acc_i=55.22 cs/acc_c=54.67 os/recall_knw=47.30 os/recall_unk=85.40 total/acc_i=56.83 total/acc_c=43.29 total/h_score=55.57\n",
      "selected:  cs/acc_i=54.43 cs/acc_c=53.91 os/recall_knw=46.02 os/recall_unk=87.18 total/acc_i=56.75 total/acc_c=42.39 total/h_score=54.98\n",
      "Loss: 1.6600587963140927\n",
      "Loss: 0.28171275338301294\n",
      "Loss: 0.16920148831147414\n",
      "Loss: 0.1262076616860353\n",
      "Loss: 0.09970045334731158\n",
      "Loss: 0.08232077114284038\n",
      "Loss: 0.07360571060616236\n",
      "Loss: 0.06266293215493743\n",
      "Loss: 0.05384623399720742\n",
      "Loss: 0.049376833789910264\n",
      "______\n",
      "Iteration t=6\n",
      "all:  cs/acc_i=55.62 cs/acc_c=54.91 os/recall_knw=47.30 os/recall_unk=85.40 total/acc_i=56.83 total/acc_c=43.29 total/h_score=55.57\n",
      "selected:  cs/acc_i=55.55 cs/acc_c=54.82 os/recall_knw=47.12 os/recall_unk=85.69 total/acc_i=56.85 total/acc_c=43.17 total/h_score=55.50\n",
      "Loss: 1.650405626960486\n",
      "Loss: 0.2747939446832791\n",
      "Loss: 0.16582255625943526\n",
      "Loss: 0.12203722297347831\n",
      "Loss: 0.09723093579395102\n",
      "Loss: 0.08656152080322989\n",
      "Loss: 0.07369380498686606\n",
      "Loss: 0.06039612666655343\n",
      "Loss: 0.05014095930610456\n",
      "Loss: 0.049512388461642534\n",
      "______\n",
      "Iteration t=7\n",
      "all:  cs/acc_i=56.25 cs/acc_c=55.72 os/recall_knw=47.30 os/recall_unk=85.40 total/acc_i=56.83 total/acc_c=43.29 total/h_score=55.57\n",
      "selected:  cs/acc_i=56.25 cs/acc_c=55.72 os/recall_knw=47.30 os/recall_unk=85.40 total/acc_i=56.83 total/acc_c=43.29 total/h_score=55.57\n",
      "Loss: 1.6515968193913377\n",
      "Loss: 0.28141524931188766\n",
      "Loss: 0.15606250031851232\n",
      "Loss: 0.12257706832776709\n",
      "Loss: 0.09972554781451458\n",
      "Loss: 0.08539131563724722\n",
      "Loss: 0.07090727479918292\n",
      "Loss: 0.06872069849859833\n",
      "Loss: 0.05325823031840051\n",
      "Loss: 0.04625049349851906\n",
      "______\n",
      "Iteration t=8\n",
      "all:  cs/acc_i=56.17 cs/acc_c=55.68 os/recall_knw=47.30 os/recall_unk=85.40 total/acc_i=56.83 total/acc_c=43.29 total/h_score=55.57\n",
      "selected:  cs/acc_i=56.17 cs/acc_c=55.68 os/recall_knw=47.30 os/recall_unk=85.40 total/acc_i=56.83 total/acc_c=43.29 total/h_score=55.57\n",
      "Loss: 1.6544999272176406\n",
      "Loss: 0.2775611386339112\n",
      "Loss: 0.16109919209578416\n",
      "Loss: 0.1267160685085578\n",
      "Loss: 0.10405681793089593\n",
      "Loss: 0.07976596968293917\n",
      "Loss: 0.07581128614454917\n",
      "Loss: 0.057843669963625784\n",
      "Loss: 0.06370653482665103\n",
      "Loss: 0.0467290523030409\n",
      "______\n",
      "Iteration t=9\n",
      "all:  cs/acc_i=55.84 cs/acc_c=55.36 os/recall_knw=47.30 os/recall_unk=85.40 total/acc_i=56.83 total/acc_c=43.29 total/h_score=55.57\n",
      "selected:  cs/acc_i=55.84 cs/acc_c=55.36 os/recall_knw=47.30 os/recall_unk=85.40 total/acc_i=56.83 total/acc_c=43.29 total/h_score=55.57\n",
      "tensor(0)\n",
      "all:  cs/acc_i=55.84 cs/acc_c=55.36 os/recall_knw=47.30 os/recall_unk=85.40 total/acc_i=56.83 total/acc_c=43.29 total/h_score=55.57\n",
      "sketch -> real lr= 0.001 seed= 0\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19]\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20]\n",
      "Loss: 2.6182350184010192\n",
      "Loss: 1.6027910464105353\n",
      "Loss: 1.2616609029010333\n",
      "Loss: 1.1002609075698178\n",
      "Loss: 1.0037440031239417\n",
      "Loss: 0.9427052415841448\n",
      "Loss: 0.8848775271820811\n",
      "Loss: 0.8309033994389846\n",
      "Loss: 0.7935902966862232\n",
      "Loss: 0.79126333254101\n",
      "tensor(True) tensor(True)\n",
      "______\n",
      "Iteration t=1\n",
      "all:  cs/acc_i=86.55 cs/acc_c=87.54 os/recall_knw=96.48 os/recall_unk=22.99 total/acc_i=64.88 total/acc_c=83.78 total/h_score=36.36\n",
      "selected:  cs/acc_i=85.90 cs/acc_c=87.90 os/recall_knw=82.70 os/recall_unk=99.49 total/acc_i=88.21 total/acc_c=85.27 total/h_score=91.42\n",
      "Loss: 2.537028325874297\n",
      "Loss: 1.4463085153552353\n",
      "Loss: 1.1219948405613664\n",
      "Loss: 0.9853581646915341\n",
      "Loss: 0.9060747375498053\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.8361540977827838\n",
      "Loss: 0.7813228306467416\n",
      "Loss: 0.741908855980537\n",
      "Loss: 0.716709204934171\n",
      "Loss: 0.6945752943636941\n",
      "______\n",
      "Iteration t=2\n",
      "all:  cs/acc_i=87.20 cs/acc_c=88.01 os/recall_knw=76.09 os/recall_unk=84.97 total/acc_i=77.58 total/acc_c=75.65 total/h_score=79.78\n",
      "selected:  cs/acc_i=80.80 cs/acc_c=82.73 os/recall_knw=58.23 os/recall_unk=99.58 total/acc_i=75.45 total/acc_c=62.96 total/h_score=75.75\n",
      "Loss: 2.4389110976503097\n",
      "Loss: 1.2965905650426413\n",
      "Loss: 0.9980472981474782\n",
      "Loss: 0.8793695355189666\n",
      "Loss: 0.8483706555748713\n",
      "Loss: 0.7602982588737975\n",
      "Loss: 0.7111816251550922\n",
      "Loss: 0.6729814795819857\n",
      "Loss: 0.6492229794784812\n",
      "Loss: 0.6135259785952459\n",
      "______\n",
      "Iteration t=3\n",
      "all:  cs/acc_i=88.50 cs/acc_c=89.34 os/recall_knw=73.19 os/recall_unk=90.02 total/acc_i=77.67 total/acc_c=73.71 total/h_score=80.56\n",
      "selected:  cs/acc_i=85.86 cs/acc_c=87.07 os/recall_knw=64.47 os/recall_unk=97.99 total/acc_i=76.43 total/acc_c=67.43 total/h_score=78.81\n",
      "Loss: 2.377271577876101\n",
      "Loss: 1.201707881411344\n",
      "Loss: 0.9462389568915076\n",
      "Loss: 0.8162062776985989\n",
      "Loss: 0.7766479065768608\n",
      "Loss: 0.6910902399529693\n",
      "Loss: 0.6575822176471833\n",
      "Loss: 0.6309004857548676\n",
      "Loss: 0.5960924366896297\n",
      "Loss: 0.5816840658692048\n",
      "______\n",
      "Iteration t=4\n",
      "all:  cs/acc_i=89.36 cs/acc_c=90.00 os/recall_knw=72.83 os/recall_unk=90.61 total/acc_i=77.71 total/acc_c=73.54 total/h_score=80.66\n",
      "selected:  cs/acc_i=88.45 cs/acc_c=89.04 os/recall_knw=69.05 os/recall_unk=95.61 total/acc_i=77.56 total/acc_c=70.89 total/h_score=80.59\n",
      "Loss: 2.3148938646055246\n",
      "Loss: 1.1273878161629585\n",
      "Loss: 0.8947650447283706\n",
      "Loss: 0.7979197805772905\n",
      "Loss: 0.7181765787201385\n",
      "Loss: 0.6741762230657551\n",
      "Loss: 0.6301793155502783\n",
      "Loss: 0.6018998984196414\n",
      "Loss: 0.5634697041895291\n",
      "Loss: 0.5482624367083588\n",
      "______\n",
      "Iteration t=5\n",
      "all:  cs/acc_i=90.10 cs/acc_c=90.69 os/recall_knw=72.81 os/recall_unk=90.61 total/acc_i=77.71 total/acc_c=73.54 total/h_score=80.66\n",
      "selected:  cs/acc_i=89.81 cs/acc_c=90.36 os/recall_knw=71.06 os/recall_unk=91.98 total/acc_i=77.40 total/acc_c=72.48 total/h_score=80.46\n",
      "Loss: 2.28636608686162\n",
      "Loss: 1.1021163192302286\n",
      "Loss: 0.8305951231143799\n",
      "Loss: 0.7611781542384347\n",
      "Loss: 0.7195517340569797\n",
      "Loss: 0.6585608323745157\n",
      "Loss: 0.6195256444702909\n",
      "Loss: 0.5884564636751662\n",
      "Loss: 0.549586761829465\n",
      "Loss: 0.5261562826526521\n",
      "______\n",
      "Iteration t=6\n",
      "all:  cs/acc_i=90.10 cs/acc_c=90.67 os/recall_knw=72.81 os/recall_unk=90.61 total/acc_i=77.71 total/acc_c=73.54 total/h_score=80.66\n",
      "selected:  cs/acc_i=90.12 cs/acc_c=90.66 os/recall_knw=72.21 os/recall_unk=90.88 total/acc_i=77.63 total/acc_c=73.31 total/h_score=80.61\n",
      "Loss: 2.2600223274012796\n",
      "Loss: 1.0724017470101126\n",
      "Loss: 0.8624782573943045\n",
      "Loss: 0.7671330885754691\n",
      "Loss: 0.7023148199701621\n",
      "Loss: 0.6552820287011807\n",
      "Loss: 0.5920030047106587\n",
      "Loss: 0.5768850918104446\n",
      "Loss: 0.5542498111140495\n",
      "Loss: 0.5221933215564373\n",
      "______\n",
      "Iteration t=7\n",
      "all:  cs/acc_i=89.98 cs/acc_c=90.55 os/recall_knw=72.78 os/recall_unk=90.73 total/acc_i=77.75 total/acc_c=73.54 total/h_score=80.71\n",
      "selected:  cs/acc_i=89.98 cs/acc_c=90.56 os/recall_knw=72.62 os/recall_unk=90.73 total/acc_i=77.71 total/acc_c=73.49 total/h_score=80.68\n",
      "Loss: 2.2715550140759846\n",
      "Loss: 1.0496765852751095\n",
      "Loss: 0.8585031748982905\n",
      "Loss: 0.754859277305075\n",
      "Loss: 0.6927989797502854\n",
      "Loss: 0.6417750614279645\n",
      "Loss: 0.6075206433911277\n",
      "Loss: 0.5593944243382941\n",
      "Loss: 0.566492314738637\n",
      "Loss: 0.5137433699462624\n",
      "______\n",
      "Iteration t=8\n",
      "all:  cs/acc_i=90.69 cs/acc_c=91.22 os/recall_knw=72.78 os/recall_unk=90.73 total/acc_i=77.75 total/acc_c=73.54 total/h_score=80.71\n",
      "selected:  cs/acc_i=90.69 cs/acc_c=91.22 os/recall_knw=72.78 os/recall_unk=90.73 total/acc_i=77.75 total/acc_c=73.54 total/h_score=80.71\n",
      "Loss: 2.253475099027931\n",
      "Loss: 1.0888539601068992\n",
      "Loss: 0.8245322945249545\n",
      "Loss: 0.7436936366093623\n",
      "Loss: 0.6884877031015886\n",
      "Loss: 0.6462927595167965\n",
      "Loss: 0.5903605160291319\n",
      "Loss: 0.5887988587091495\n",
      "Loss: 0.5473363430952871\n",
      "Loss: 0.5162042628538299\n",
      "______\n",
      "Iteration t=9\n",
      "all:  cs/acc_i=90.07 cs/acc_c=90.65 os/recall_knw=72.78 os/recall_unk=90.73 total/acc_i=77.75 total/acc_c=73.54 total/h_score=80.71\n",
      "selected:  cs/acc_i=90.07 cs/acc_c=90.65 os/recall_knw=72.78 os/recall_unk=90.73 total/acc_i=77.75 total/acc_c=73.54 total/h_score=80.71\n",
      "tensor(0)\n",
      "all:  cs/acc_i=90.07 cs/acc_c=90.65 os/recall_knw=72.78 os/recall_unk=90.73 total/acc_i=77.75 total/acc_c=73.54 total/h_score=80.71\n",
      "sketch -> real lr= 0.001 seed= 1\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19]\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20]\n",
      "Loss: 2.6131365046036983\n",
      "Loss: 1.6024506553611924\n",
      "Loss: 1.257304701657422\n",
      "Loss: 1.0884017717521803\n",
      "Loss: 1.0424025789298843\n",
      "Loss: 0.9420048098648544\n",
      "Loss: 0.8816658621076989\n",
      "Loss: 0.813316256071614\n",
      "Loss: 0.7880072695227851\n",
      "Loss: 0.7443242768007042\n",
      "tensor(True) tensor(True)\n",
      "______\n",
      "Iteration t=1\n",
      "all:  cs/acc_i=86.61 cs/acc_c=87.66 os/recall_knw=97.13 os/recall_unk=24.30 total/acc_i=65.61 total/acc_c=84.27 total/h_score=38.02\n",
      "selected:  cs/acc_i=86.96 cs/acc_c=87.77 os/recall_knw=85.46 os/recall_unk=99.51 total/acc_i=90.35 total/acc_c=86.40 total/h_score=92.12\n",
      "Loss: 2.534783380930541\n",
      "Loss: 1.4331041046830475\n",
      "Loss: 1.1000779280897046\n",
      "Loss: 0.9386143383921169\n",
      "Loss: 0.8844883057181953\n",
      "Loss: 0.8709937473301028\n",
      "Loss: 0.7877598761535082\n",
      "Loss: 0.7436313125930849\n",
      "Loss: 0.72383884768017\n",
      "Loss: 0.6931098406432105\n",
      "______\n",
      "Iteration t=2\n",
      "all:  cs/acc_i=87.58 cs/acc_c=88.42 os/recall_knw=84.42 os/recall_unk=74.39 total/acc_i=78.23 total/acc_c=80.97 total/h_score=77.69\n",
      "selected:  cs/acc_i=82.55 cs/acc_c=84.29 os/recall_knw=68.18 os/recall_unk=99.44 total/acc_i=81.20 total/acc_c=71.65 total/h_score=82.35\n",
      "Loss: 2.44641269663818\n",
      "Loss: 1.2934499442122365\n",
      "Loss: 1.0174604197039858\n",
      "Loss: 0.8853814874896566\n",
      "Loss: 0.8112049564605451\n",
      "Loss: 0.7585445769870555\n",
      "Loss: 0.7019093159500879\n",
      "Loss: 0.6807361623940577\n",
      "Loss: 0.6696847130096596\n",
      "Loss: 0.6238917951820461\n",
      "______\n",
      "Iteration t=3\n",
      "all:  cs/acc_i=88.00 cs/acc_c=88.70 os/recall_knw=76.47 os/recall_unk=85.62 total/acc_i=78.07 total/acc_c=75.93 total/h_score=80.21\n",
      "selected:  cs/acc_i=84.97 cs/acc_c=85.84 os/recall_knw=67.48 os/recall_unk=97.43 total/acc_i=77.87 total/acc_c=69.42 total/h_score=80.11\n",
      "Loss: 2.3732234773670045\n",
      "Loss: 1.1853929382071273\n",
      "Loss: 0.9296286938224642\n",
      "Loss: 0.8225990005077854\n",
      "Loss: 0.749645572516226\n",
      "Loss: 0.7076233213093118\n",
      "Loss: 0.6663206933219801\n",
      "Loss: 0.633772480124641\n",
      "Loss: 0.6025830403664634\n",
      "Loss: 0.5773936178949144\n",
      "______\n",
      "Iteration t=4\n",
      "all:  cs/acc_i=89.03 cs/acc_c=89.63 os/recall_knw=75.70 os/recall_unk=86.51 total/acc_i=77.97 total/acc_c=75.47 total/h_score=80.30\n",
      "selected:  cs/acc_i=87.85 cs/acc_c=88.48 os/recall_knw=71.46 os/recall_unk=93.75 total/acc_i=78.23 total/acc_c=72.70 total/h_score=81.22\n",
      "Loss: 2.316928488402643\n",
      "Loss: 1.1316890004551858\n",
      "Loss: 0.8937118025973388\n",
      "Loss: 0.7827517234628111\n",
      "Loss: 0.7172041328897248\n",
      "Loss: 0.6774019476903583\n",
      "Loss: 0.6159631024550253\n",
      "Loss: 0.6086425183169264\n",
      "Loss: 0.5717407204592188\n",
      "Loss: 0.543931770853622\n",
      "______\n",
      "Iteration t=5\n",
      "all:  cs/acc_i=89.57 cs/acc_c=90.08 os/recall_knw=75.32 os/recall_unk=86.81 total/acc_i=77.87 total/acc_c=75.20 total/h_score=80.25\n",
      "selected:  cs/acc_i=89.07 cs/acc_c=89.58 os/recall_knw=73.15 os/recall_unk=89.14 total/acc_i=77.60 total/acc_c=73.95 total/h_score=80.38\n",
      "Loss: 2.282358770716702\n",
      "Loss: 1.0754474520486574\n",
      "Loss: 0.8515428516140865\n",
      "Loss: 0.753290589296385\n",
      "Loss: 0.695126197519082\n",
      "Loss: 0.6590361486960559\n",
      "Loss: 0.6159784103875899\n",
      "Loss: 0.5782365407487347\n",
      "Loss: 0.5676273942583858\n",
      "Loss: 0.5416187747280197\n",
      "______\n",
      "Iteration t=6\n",
      "all:  cs/acc_i=89.98 cs/acc_c=90.51 os/recall_knw=75.20 os/recall_unk=86.99 total/acc_i=77.87 total/acc_c=75.14 total/h_score=80.29\n",
      "selected:  cs/acc_i=89.89 cs/acc_c=90.41 os/recall_knw=74.30 os/recall_unk=87.61 total/acc_i=77.71 total/acc_c=74.71 total/h_score=80.27\n",
      "Loss: 2.2712313161267863\n",
      "Loss: 1.0522213831737444\n",
      "Loss: 0.8290122264584938\n",
      "Loss: 0.7318817199050606\n",
      "Loss: 0.6934213994869164\n",
      "Loss: 0.6404297541004497\n",
      "Loss: 0.5953385865727028\n",
      "Loss: 0.5826781046177659\n",
      "Loss: 0.5372856669611745\n",
      "Loss: 0.5256559409491428\n",
      "______\n",
      "Iteration t=7\n",
      "all:  cs/acc_i=90.01 cs/acc_c=90.58 os/recall_knw=75.20 os/recall_unk=86.99 total/acc_i=77.87 total/acc_c=75.14 total/h_score=80.29\n",
      "selected:  cs/acc_i=89.96 cs/acc_c=90.55 os/recall_knw=75.00 os/recall_unk=87.09 total/acc_i=77.80 total/acc_c=75.05 total/h_score=80.28\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 2.2487979107178173\n",
      "Loss: 1.0502017879715333\n",
      "Loss: 0.8422487517580007\n",
      "Loss: 0.7436286227252239\n",
      "Loss: 0.6957277023257353\n",
      "Loss: 0.6338143141892476\n",
      "Loss: 0.5920914967950338\n",
      "Loss: 0.548500898700112\n",
      "Loss: 0.552097147808243\n",
      "Loss: 0.5188903247412199\n",
      "______\n",
      "Iteration t=8\n",
      "all:  cs/acc_i=90.01 cs/acc_c=90.52 os/recall_knw=75.17 os/recall_unk=86.99 total/acc_i=77.85 total/acc_c=75.09 total/h_score=80.26\n",
      "selected:  cs/acc_i=90.01 cs/acc_c=90.52 os/recall_knw=75.17 os/recall_unk=86.99 total/acc_i=77.85 total/acc_c=75.09 total/h_score=80.26\n",
      "Loss: 2.2349015176296234\n",
      "Loss: 1.0492435537087612\n",
      "Loss: 0.8442811799737123\n",
      "Loss: 0.724448948716506\n",
      "Loss: 0.6706255654780529\n",
      "Loss: 0.6575706695707945\n",
      "Loss: 0.5868945749333272\n",
      "Loss: 0.559150175883984\n",
      "Loss: 0.5459224784221405\n",
      "Loss: 0.5229029724231133\n",
      "______\n",
      "Iteration t=9\n",
      "all:  cs/acc_i=90.30 cs/acc_c=90.83 os/recall_knw=75.17 os/recall_unk=86.99 total/acc_i=77.85 total/acc_c=75.09 total/h_score=80.26\n",
      "selected:  cs/acc_i=90.30 cs/acc_c=90.83 os/recall_knw=75.17 os/recall_unk=86.99 total/acc_i=77.85 total/acc_c=75.09 total/h_score=80.26\n",
      "tensor(0)\n",
      "all:  cs/acc_i=90.30 cs/acc_c=90.83 os/recall_knw=75.17 os/recall_unk=86.99 total/acc_i=77.85 total/acc_c=75.09 total/h_score=80.26\n",
      "sketch -> real lr= 0.001 seed= 2\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19]\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20]\n",
      "Loss: 2.6124248910794217\n",
      "Loss: 1.599493599570958\n",
      "Loss: 1.2469061264949561\n",
      "Loss: 1.1107261088569607\n",
      "Loss: 1.0089464213995807\n",
      "Loss: 0.9234945574956658\n",
      "Loss: 0.8767732690393397\n",
      "Loss: 0.8378596366506762\n",
      "Loss: 0.7959527493314406\n",
      "Loss: 0.7533956276895726\n",
      "tensor(True) tensor(True)\n",
      "______\n",
      "Iteration t=1\n",
      "all:  cs/acc_i=85.81 cs/acc_c=86.74 os/recall_knw=96.51 os/recall_unk=23.05 total/acc_i=64.33 total/acc_c=82.87 total/h_score=36.35\n",
      "selected:  cs/acc_i=86.50 cs/acc_c=87.12 os/recall_knw=82.87 os/recall_unk=99.74 total/acc_i=88.31 total/acc_c=83.75 total/h_score=90.57\n",
      "Loss: 2.5482449981032826\n",
      "Loss: 1.460722920591714\n",
      "Loss: 1.1139268530685393\n",
      "Loss: 0.9772015030755371\n",
      "Loss: 0.9110958723992598\n",
      "Loss: 0.8189276255300788\n",
      "Loss: 0.7783170104271075\n",
      "Loss: 0.7613821215316897\n",
      "Loss: 0.7067477441713458\n",
      "Loss: 0.6764116554719503\n",
      "______\n",
      "Iteration t=2\n",
      "all:  cs/acc_i=86.17 cs/acc_c=87.17 os/recall_knw=78.54 os/recall_unk=81.16 total/acc_i=77.34 total/acc_c=77.14 total/h_score=79.00\n",
      "selected:  cs/acc_i=79.91 cs/acc_c=82.47 os/recall_knw=60.80 os/recall_unk=99.35 total/acc_i=76.94 total/acc_c=66.49 total/h_score=78.47\n",
      "Loss: 2.4361849677471716\n",
      "Loss: 1.3033138383890837\n",
      "Loss: 1.01252878007998\n",
      "Loss: 0.8619416168400349\n",
      "Loss: 0.8203514781389528\n",
      "Loss: 0.8066252457504054\n",
      "Loss: 0.7184110061471699\n",
      "Loss: 0.68743196362985\n",
      "Loss: 0.6486611407221728\n",
      "Loss: 0.6042134984758974\n",
      "______\n",
      "Iteration t=3\n",
      "all:  cs/acc_i=88.41 cs/acc_c=89.20 os/recall_knw=70.65 os/recall_unk=91.33 total/acc_i=76.69 total/acc_c=71.91 total/h_score=79.85\n",
      "selected:  cs/acc_i=85.78 cs/acc_c=86.87 os/recall_knw=62.54 os/recall_unk=97.77 total/acc_i=75.02 total/acc_c=65.85 total/h_score=77.55\n",
      "Loss: 2.3726797761882934\n",
      "Loss: 1.1986421229164232\n",
      "Loss: 0.9289183848434024\n",
      "Loss: 0.8202015987220204\n",
      "Loss: 0.7703263258634929\n",
      "Loss: 0.7106559328921807\n",
      "Loss: 0.6639020880917922\n",
      "Loss: 0.6297578573440565\n",
      "Loss: 0.6123283753792444\n",
      "Loss: 0.5852655117870659\n",
      "______\n",
      "Iteration t=4\n",
      "all:  cs/acc_i=89.06 cs/acc_c=89.72 os/recall_knw=70.03 os/recall_unk=91.56 total/acc_i=76.37 total/acc_c=71.36 total/h_score=79.57\n",
      "selected:  cs/acc_i=87.95 cs/acc_c=88.66 os/recall_knw=66.05 os/recall_unk=94.60 total/acc_i=75.45 total/acc_c=68.58 total/h_score=78.64\n",
      "Loss: 2.3212028856539644\n",
      "Loss: 1.1287620249892427\n",
      "Loss: 0.8926548309547385\n",
      "Loss: 0.8065576689554653\n",
      "Loss: 0.7194727744228652\n",
      "Loss: 0.6662727239000839\n",
      "Loss: 0.6376200489366997\n",
      "Loss: 0.614540259965097\n",
      "Loss: 0.5638026395409378\n",
      "Loss: 0.5902075666639813\n",
      "______\n",
      "Iteration t=5\n",
      "all:  cs/acc_i=89.68 cs/acc_c=90.29 os/recall_knw=69.91 os/recall_unk=91.62 total/acc_i=76.33 total/acc_c=71.27 total/h_score=79.52\n",
      "selected:  cs/acc_i=89.16 cs/acc_c=89.76 os/recall_knw=68.03 os/recall_unk=92.22 total/acc_i=75.62 total/acc_c=70.00 total/h_score=78.86\n",
      "Loss: 2.293446003190623\n",
      "Loss: 1.1039280153360942\n",
      "Loss: 0.8765226862574583\n",
      "Loss: 0.7767376070654632\n",
      "Loss: 0.7070236450073702\n",
      "Loss: 0.648115107177088\n",
      "Loss: 0.6134840314520286\n",
      "Loss: 0.5873251351334104\n",
      "Loss: 0.5805904158209795\n",
      "Loss: 0.5412353206700926\n",
      "______\n",
      "Iteration t=6\n",
      "all:  cs/acc_i=89.65 cs/acc_c=90.27 os/recall_knw=69.91 os/recall_unk=91.62 total/acc_i=76.33 total/acc_c=71.27 total/h_score=79.52\n",
      "selected:  cs/acc_i=89.51 cs/acc_c=90.17 os/recall_knw=69.39 os/recall_unk=91.68 total/acc_i=76.10 total/acc_c=70.99 total/h_score=79.36\n",
      "Loss: 2.267457981707633\n",
      "Loss: 1.0988946480326134\n",
      "Loss: 0.8481362983338511\n",
      "Loss: 0.7557911679099495\n",
      "Loss: 0.688496323603608\n",
      "Loss: 0.6689131259426425\n",
      "Loss: 0.6147507514202162\n",
      "Loss: 0.5804528062394744\n",
      "Loss: 0.5546902941398495\n",
      "Loss: 0.5342553860381885\n",
      "______\n",
      "Iteration t=7\n",
      "all:  cs/acc_i=90.07 cs/acc_c=90.65 os/recall_knw=69.91 os/recall_unk=91.62 total/acc_i=76.33 total/acc_c=71.27 total/h_score=79.52\n",
      "selected:  cs/acc_i=90.06 cs/acc_c=90.63 os/recall_knw=69.87 os/recall_unk=91.62 total/acc_i=76.31 total/acc_c=71.23 total/h_score=79.50\n",
      "Loss: 2.2691638316763076\n",
      "Loss: 1.0654903675772642\n",
      "Loss: 0.8451937570383674\n",
      "Loss: 0.7801431087090781\n",
      "Loss: 0.6826302437601905\n",
      "Loss: 0.6807233538282546\n",
      "Loss: 0.6163479888713673\n",
      "Loss: 0.5896414951176235\n",
      "Loss: 0.5456182300848397\n",
      "Loss: 0.5176025739331779\n",
      "______\n",
      "Iteration t=8\n",
      "all:  cs/acc_i=89.42 cs/acc_c=90.07 os/recall_knw=69.91 os/recall_unk=91.62 total/acc_i=76.33 total/acc_c=71.27 total/h_score=79.52\n",
      "selected:  cs/acc_i=89.42 cs/acc_c=90.07 os/recall_knw=69.91 os/recall_unk=91.62 total/acc_i=76.33 total/acc_c=71.27 total/h_score=79.52\n",
      "Loss: 2.2599740546000633\n",
      "Loss: 1.0803381369302147\n",
      "Loss: 0.8581660108542756\n",
      "Loss: 0.75391740714641\n",
      "Loss: 0.6918140345890271\n",
      "Loss: 0.6369926060893034\n",
      "Loss: 0.6181160435570698\n",
      "Loss: 0.5630359943269899\n",
      "Loss: 0.5549776182558975\n",
      "Loss: 0.5259246889893946\n",
      "______\n",
      "Iteration t=9\n",
      "all:  cs/acc_i=89.39 cs/acc_c=90.03 os/recall_knw=69.91 os/recall_unk=91.62 total/acc_i=76.33 total/acc_c=71.27 total/h_score=79.52\n",
      "selected:  cs/acc_i=89.39 cs/acc_c=90.03 os/recall_knw=69.91 os/recall_unk=91.62 total/acc_i=76.33 total/acc_c=71.27 total/h_score=79.52\n",
      "tensor(0)\n",
      "all:  cs/acc_i=89.39 cs/acc_c=90.03 os/recall_knw=69.91 os/recall_unk=91.62 total/acc_i=76.33 total/acc_c=71.27 total/h_score=79.52\n",
      "sketch -> real lr= 0.001 seed= 3\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19]\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20]\n",
      "Loss: 2.5996780843861336\n",
      "Loss: 1.564349099861837\n",
      "Loss: 1.2451472503949055\n",
      "Loss: 1.1032941707995085\n",
      "Loss: 1.002107739976022\n",
      "Loss: 0.9292293320187425\n",
      "Loss: 0.8871326610050371\n",
      "Loss: 0.8228205973859382\n",
      "Loss: 0.8011108119930841\n",
      "Loss: 0.7595752788855966\n",
      "tensor(True) tensor(True)\n",
      "______\n",
      "Iteration t=1\n",
      "all:  cs/acc_i=86.17 cs/acc_c=87.11 os/recall_knw=96.96 os/recall_unk=23.95 total/acc_i=65.00 total/acc_c=83.46 total/h_score=37.50\n",
      "selected:  cs/acc_i=87.46 cs/acc_c=87.98 os/recall_knw=84.63 os/recall_unk=99.26 total/acc_i=89.59 total/acc_c=85.31 total/h_score=91.35\n",
      "Loss: 2.570750621987171\n",
      "Loss: 1.4614557931657697\n",
      "Loss: 1.1138091524604892\n",
      "Loss: 0.9862469341911253\n",
      "Loss: 0.8874540955561107\n",
      "Loss: 0.8431388939746091\n",
      "Loss: 0.7990476425553932\n",
      "Loss: 0.7566772715234366\n",
      "Loss: 0.7174886537135624\n",
      "Loss: 0.7068114356427896\n",
      "______\n",
      "Iteration t=2\n",
      "all:  cs/acc_i=87.47 cs/acc_c=88.24 os/recall_knw=82.41 os/recall_unk=76.11 total/acc_i=77.93 total/acc_c=79.94 total/h_score=78.07\n",
      "selected:  cs/acc_i=81.66 cs/acc_c=82.97 os/recall_knw=65.47 os/recall_unk=99.38 total/acc_i=79.55 total/acc_c=69.19 total/h_score=80.52\n",
      "Loss: 2.434688381566346\n",
      "Loss: 1.2838211844440635\n",
      "Loss: 0.985801981150649\n",
      "Loss: 0.9006949490263262\n",
      "Loss: 0.8076432976331419\n",
      "Loss: 0.7513391878313691\n",
      "Loss: 0.7255592098217885\n",
      "Loss: 0.6978120916444837\n",
      "Loss: 0.6463524294263534\n",
      "Loss: 0.6400016432500067\n",
      "______\n",
      "Iteration t=3\n",
      "all:  cs/acc_i=88.41 cs/acc_c=89.16 os/recall_knw=71.15 os/recall_unk=91.62 total/acc_i=76.90 total/acc_c=72.03 total/h_score=80.04\n",
      "selected:  cs/acc_i=85.92 cs/acc_c=86.97 os/recall_knw=62.96 os/recall_unk=97.72 total/acc_i=75.22 total/acc_c=66.03 total/h_score=77.67\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 2.370974563783215\n",
      "Loss: 1.2020007032220081\n",
      "Loss: 0.9014655393297955\n",
      "Loss: 0.8284922713233579\n",
      "Loss: 0.7546978530383879\n",
      "Loss: 0.716720811889163\n",
      "Loss: 0.647695673195692\n",
      "Loss: 0.6176739671003861\n",
      "Loss: 0.60233725553986\n",
      "Loss: 0.5786066913583373\n",
      "______\n",
      "Iteration t=4\n",
      "all:  cs/acc_i=89.45 cs/acc_c=90.06 os/recall_knw=70.94 os/recall_unk=91.80 total/acc_i=76.83 total/acc_c=71.84 total/h_score=79.97\n",
      "selected:  cs/acc_i=88.62 cs/acc_c=89.14 os/recall_knw=67.28 os/recall_unk=94.09 total/acc_i=75.94 total/acc_c=69.29 total/h_score=78.98\n",
      "Loss: 2.3028286475024813\n",
      "Loss: 1.1200851336733935\n",
      "Loss: 0.881141696278363\n",
      "Loss: 0.7854466644460207\n",
      "Loss: 0.7149910617568721\n",
      "Loss: 0.6795801467274967\n",
      "Loss: 0.6344303376462361\n",
      "Loss: 0.6162630431354046\n",
      "Loss: 0.5698638610950072\n",
      "Loss: 0.5553324089883125\n",
      "______\n",
      "Iteration t=5\n",
      "all:  cs/acc_i=89.60 cs/acc_c=90.16 os/recall_knw=70.50 os/recall_unk=91.92 total/acc_i=76.61 total/acc_c=71.52 total/h_score=79.80\n",
      "selected:  cs/acc_i=89.12 cs/acc_c=89.69 os/recall_knw=68.63 os/recall_unk=92.52 total/acc_i=75.93 total/acc_c=70.26 total/h_score=79.15\n",
      "Loss: 2.2870588990665923\n",
      "Loss: 1.0851589457300685\n",
      "Loss: 0.8609595789805354\n",
      "Loss: 0.767611758620947\n",
      "Loss: 0.710768529932771\n",
      "Loss: 0.6768339969867828\n",
      "Loss: 0.6417666006608297\n",
      "Loss: 0.5910521364152032\n",
      "Loss: 0.5586893203724551\n",
      "Loss: 0.5405821429953079\n",
      "______\n",
      "Iteration t=6\n",
      "all:  cs/acc_i=89.65 cs/acc_c=90.16 os/recall_knw=70.50 os/recall_unk=91.92 total/acc_i=76.61 total/acc_c=71.52 total/h_score=79.80\n",
      "selected:  cs/acc_i=89.54 cs/acc_c=89.99 os/recall_knw=69.73 os/recall_unk=92.14 total/acc_i=76.37 total/acc_c=71.06 total/h_score=79.56\n",
      "Loss: 2.285768354175896\n",
      "Loss: 1.0841495347338796\n",
      "Loss: 0.8427764244426955\n",
      "Loss: 0.758494729928623\n",
      "Loss: 0.7338504958527767\n",
      "Loss: 0.6595802775874043\n",
      "Loss: 0.609967991857734\n",
      "Loss: 0.58278836408593\n",
      "Loss: 0.5587298745252439\n",
      "Loss: 0.533933954424416\n",
      "______\n",
      "Iteration t=7\n",
      "all:  cs/acc_i=90.10 cs/acc_c=90.70 os/recall_knw=70.50 os/recall_unk=91.92 total/acc_i=76.61 total/acc_c=71.52 total/h_score=79.80\n",
      "selected:  cs/acc_i=90.09 cs/acc_c=90.69 os/recall_knw=70.39 os/recall_unk=92.03 total/acc_i=76.60 total/acc_c=71.48 total/h_score=79.81\n",
      "Loss: 2.2794882094389513\n",
      "Loss: 1.0915535260972224\n",
      "Loss: 0.8337272433073897\n",
      "Loss: 0.7654683962464333\n",
      "Loss: 0.695864682232863\n",
      "Loss: 0.6479187550415334\n",
      "Loss: 0.6260656973249034\n",
      "Loss: 0.5844759059285647\n",
      "Loss: 0.5491459200060681\n",
      "Loss: 0.5304919047477213\n",
      "______\n",
      "Iteration t=8\n",
      "all:  cs/acc_i=90.39 cs/acc_c=90.98 os/recall_knw=70.50 os/recall_unk=91.92 total/acc_i=76.61 total/acc_c=71.52 total/h_score=79.80\n",
      "selected:  cs/acc_i=90.39 cs/acc_c=90.98 os/recall_knw=70.50 os/recall_unk=91.92 total/acc_i=76.61 total/acc_c=71.52 total/h_score=79.80\n",
      "Loss: 2.2743580016933502\n",
      "Loss: 1.0623314378691502\n",
      "Loss: 0.842171569046427\n",
      "Loss: 0.7643319699607911\n",
      "Loss: 0.6800909776179517\n",
      "Loss: 0.6516733620010439\n",
      "Loss: 0.6281840028332882\n",
      "Loss: 0.577121557759457\n",
      "Loss: 0.5601829447707192\n",
      "Loss: 0.5248272176893031\n",
      "______\n",
      "Iteration t=9\n",
      "all:  cs/acc_i=89.89 cs/acc_c=90.46 os/recall_knw=70.50 os/recall_unk=91.92 total/acc_i=76.61 total/acc_c=71.52 total/h_score=79.80\n",
      "selected:  cs/acc_i=89.89 cs/acc_c=90.46 os/recall_knw=70.50 os/recall_unk=91.92 total/acc_i=76.61 total/acc_c=71.52 total/h_score=79.80\n",
      "tensor(0)\n",
      "all:  cs/acc_i=89.89 cs/acc_c=90.46 os/recall_knw=70.50 os/recall_unk=91.92 total/acc_i=76.61 total/acc_c=71.52 total/h_score=79.80\n",
      "sketch -> real lr= 0.001 seed= 4\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19]\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20]\n",
      "Loss: 2.6207783538683325\n",
      "Loss: 1.5899180701348634\n",
      "Loss: 1.2471441360174027\n",
      "Loss: 1.1015371168609214\n",
      "Loss: 1.013314832892038\n",
      "Loss: 0.9461610679869104\n",
      "Loss: 0.8820233475581735\n",
      "Loss: 0.8239759333365786\n",
      "Loss: 0.7884428592118542\n",
      "Loss: 0.7569017919291438\n",
      "tensor(True) tensor(True)\n",
      "______\n",
      "Iteration t=1\n",
      "all:  cs/acc_i=86.25 cs/acc_c=87.24 os/recall_knw=96.54 os/recall_unk=23.11 total/acc_i=64.71 total/acc_c=83.44 total/h_score=36.48\n",
      "selected:  cs/acc_i=86.32 cs/acc_c=87.36 os/recall_knw=82.97 os/recall_unk=99.49 total/acc_i=88.40 total/acc_c=84.41 total/h_score=90.89\n",
      "Loss: 2.542153883175772\n",
      "Loss: 1.4308797692666289\n",
      "Loss: 1.098571104348683\n",
      "Loss: 0.973492159462366\n",
      "Loss: 0.8957187483300928\n",
      "Loss: 0.8449006900191307\n",
      "Loss: 0.7775262735906194\n",
      "Loss: 0.7557083400057965\n",
      "Loss: 0.6999789445859487\n",
      "Loss: 0.6607747306344939\n",
      "______\n",
      "Iteration t=2\n",
      "all:  cs/acc_i=87.64 cs/acc_c=88.41 os/recall_knw=81.32 os/recall_unk=78.19 total/acc_i=78.05 total/acc_c=79.16 total/h_score=78.70\n",
      "selected:  cs/acc_i=81.93 cs/acc_c=83.81 os/recall_knw=64.09 os/recall_unk=99.55 total/acc_i=78.88 total/acc_c=68.47 total/h_score=80.03\n",
      "Loss: 2.45224994466505\n",
      "Loss: 1.2787636275054843\n",
      "Loss: 1.0185957930925238\n",
      "Loss: 0.8866209775664424\n",
      "Loss: 0.8110711087707345\n",
      "Loss: 0.7576062796452573\n",
      "Loss: 0.7207080902716586\n",
      "Loss: 0.6862474929057915\n",
      "Loss: 0.6542032624929006\n",
      "Loss: 0.6213724356684976\n",
      "______\n",
      "Iteration t=3\n",
      "all:  cs/acc_i=88.62 cs/acc_c=89.26 os/recall_knw=72.24 os/recall_unk=91.74 total/acc_i=77.65 total/acc_c=72.88 total/h_score=80.64\n",
      "selected:  cs/acc_i=85.99 cs/acc_c=86.92 os/recall_knw=63.97 os/recall_unk=98.47 total/acc_i=76.11 total/acc_c=66.26 total/h_score=78.06\n",
      "Loss: 2.3692797272863353\n",
      "Loss: 1.176867401728066\n",
      "Loss: 0.9287896062310879\n",
      "Loss: 0.8219298637041481\n",
      "Loss: 0.7556253069190568\n",
      "Loss: 0.7132114594448424\n",
      "Loss: 0.6677674910714549\n",
      "Loss: 0.6370155377627273\n",
      "Loss: 0.5833180933977113\n",
      "Loss: 0.587009640524037\n",
      "______\n",
      "Iteration t=4\n",
      "all:  cs/acc_i=89.09 cs/acc_c=89.65 os/recall_knw=71.86 os/recall_unk=91.92 total/acc_i=77.54 total/acc_c=72.61 total/h_score=80.53\n",
      "selected:  cs/acc_i=87.99 cs/acc_c=88.52 os/recall_knw=68.05 os/recall_unk=95.61 total/acc_i=76.90 total/acc_c=69.63 total/h_score=79.70\n",
      "Loss: 2.3322602294079244\n",
      "Loss: 1.152163175687398\n",
      "Loss: 0.8846017671366261\n",
      "Loss: 0.7932977509008695\n",
      "Loss: 0.7400936719081174\n",
      "Loss: 0.6816086421070033\n",
      "Loss: 0.6311994961985986\n",
      "Loss: 0.610970224113497\n",
      "Loss: 0.5995422900743681\n",
      "Loss: 0.5607143966608668\n",
      "______\n",
      "Iteration t=5\n",
      "all:  cs/acc_i=89.65 cs/acc_c=90.19 os/recall_knw=71.80 os/recall_unk=91.98 total/acc_i=77.52 total/acc_c=72.55 total/h_score=80.50\n",
      "selected:  cs/acc_i=89.41 cs/acc_c=89.90 os/recall_knw=70.45 os/recall_unk=92.97 total/acc_i=77.25 total/acc_c=71.62 total/h_score=80.23\n",
      "Loss: 2.308982470898929\n",
      "Loss: 1.0955949150446642\n",
      "Loss: 0.8652300971290994\n",
      "Loss: 0.768954176938415\n",
      "Loss: 0.6908581448947868\n",
      "Loss: 0.6576056516051688\n",
      "Loss: 0.6230929100335239\n",
      "Loss: 0.5761057787460346\n",
      "Loss: 0.5466055111631603\n",
      "Loss: 0.5337829991333508\n",
      "______\n",
      "Iteration t=6\n",
      "all:  cs/acc_i=89.92 cs/acc_c=90.44 os/recall_knw=71.74 os/recall_unk=92.04 total/acc_i=77.50 total/acc_c=72.49 total/h_score=80.49\n",
      "selected:  cs/acc_i=89.87 cs/acc_c=90.44 os/recall_knw=71.26 os/recall_unk=92.26 total/acc_i=77.38 total/acc_c=72.28 total/h_score=80.42\n",
      "Loss: 2.293386752276044\n",
      "Loss: 1.0666614563057297\n",
      "Loss: 0.8543797486314648\n",
      "Loss: 0.7643846485175585\n",
      "Loss: 0.6884690005528299\n",
      "Loss: 0.6585004407128221\n",
      "Loss: 0.6070667030779939\n",
      "Loss: 0.5796211870681298\n",
      "Loss: 0.5553104653954506\n",
      "Loss: 0.5272673962049579\n",
      "______\n",
      "Iteration t=7\n",
      "all:  cs/acc_i=90.45 cs/acc_c=91.02 os/recall_knw=71.68 os/recall_unk=92.04 total/acc_i=77.46 total/acc_c=72.45 total/h_score=80.46\n",
      "selected:  cs/acc_i=90.45 cs/acc_c=91.02 os/recall_knw=71.68 os/recall_unk=92.04 total/acc_i=77.46 total/acc_c=72.45 total/h_score=80.46\n",
      "Loss: 2.2606423271247764\n",
      "Loss: 1.097542315818905\n",
      "Loss: 0.8575603565554214\n",
      "Loss: 0.7704555771124908\n",
      "Loss: 0.7038351944069458\n",
      "Loss: 0.6731238730884845\n",
      "Loss: 0.6155788551748188\n",
      "Loss: 0.5706443936850121\n",
      "Loss: 0.5353642151344056\n",
      "Loss: 0.5367510069916451\n",
      "______\n",
      "Iteration t=8\n",
      "all:  cs/acc_i=90.07 cs/acc_c=90.65 os/recall_knw=71.68 os/recall_unk=92.04 total/acc_i=77.46 total/acc_c=72.45 total/h_score=80.46\n",
      "selected:  cs/acc_i=90.07 cs/acc_c=90.65 os/recall_knw=71.68 os/recall_unk=92.04 total/acc_i=77.46 total/acc_c=72.45 total/h_score=80.46\n",
      "Loss: 2.249783614686891\n",
      "Loss: 1.0473444789063697\n",
      "Loss: 0.8631449054464017\n",
      "Loss: 0.7532016920303207\n",
      "Loss: 0.7011161945224588\n",
      "Loss: 0.6636691962679228\n",
      "Loss: 0.615340166621738\n",
      "Loss: 0.5696885899147567\n",
      "Loss: 0.5655021002771807\n",
      "Loss: 0.5277732241582247\n",
      "______\n",
      "Iteration t=9\n",
      "all:  cs/acc_i=89.54 cs/acc_c=90.19 os/recall_knw=71.68 os/recall_unk=92.04 total/acc_i=77.46 total/acc_c=72.45 total/h_score=80.46\n",
      "selected:  cs/acc_i=89.54 cs/acc_c=90.19 os/recall_knw=71.68 os/recall_unk=92.04 total/acc_i=77.46 total/acc_c=72.45 total/h_score=80.46\n",
      "tensor(0)\n",
      "all:  cs/acc_i=89.54 cs/acc_c=90.19 os/recall_knw=71.68 os/recall_unk=92.04 total/acc_i=77.46 total/acc_c=72.45 total/h_score=80.46\n",
      "sketch -> real lr= 0.001 seed= 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19]\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20]\n",
      "Loss: 2.6180287130111086\n",
      "Loss: 1.6026997835235257\n",
      "Loss: 1.2606633793463748\n",
      "Loss: 1.0985701440182407\n",
      "Loss: 1.0034009157556347\n",
      "Loss: 0.9420324813211913\n",
      "Loss: 0.884593933161381\n",
      "Loss: 0.8307085755915768\n",
      "Loss: 0.7934948594960491\n",
      "Loss: 0.7891850116769824\n",
      "tensor(True) tensor(True)\n",
      "______\n",
      "Iteration t=1\n",
      "all:  cs/acc_i=86.40 cs/acc_c=87.41 os/recall_knw=96.48 os/recall_unk=22.99 total/acc_i=64.75 total/acc_c=83.58 total/h_score=36.34\n",
      "selected:  cs/acc_i=86.21 cs/acc_c=87.94 os/recall_knw=82.73 os/recall_unk=99.23 total/acc_i=88.14 total/acc_c=84.95 total/h_score=91.12\n",
      "Loss: 2.546383345224818\n",
      "Loss: 1.447276398295262\n",
      "Loss: 1.1209228835144982\n",
      "Loss: 0.993249988702477\n",
      "Loss: 0.900413591597901\n",
      "Loss: 0.854583323246143\n",
      "Loss: 0.796173020830897\n",
      "Loss: 0.7437794423494183\n",
      "Loss: 0.7141856236047432\n",
      "Loss: 0.6905104764660851\n",
      "______\n",
      "Iteration t=2\n",
      "all:  cs/acc_i=88.06 cs/acc_c=88.79 os/recall_knw=78.39 os/recall_unk=80.51 total/acc_i=77.30 total/acc_c=77.08 total/h_score=78.67\n",
      "selected:  cs/acc_i=82.45 cs/acc_c=83.87 os/recall_knw=60.66 os/recall_unk=99.41 total/acc_i=76.65 total/acc_c=64.98 total/h_score=77.32\n",
      "Loss: 2.4455674313406908\n",
      "Loss: 1.291992691181998\n",
      "Loss: 1.0107068611692835\n",
      "Loss: 0.8994867631042277\n",
      "Loss: 0.831658175428405\n",
      "Loss: 0.7641662549199039\n",
      "Loss: 0.7265752862200482\n",
      "Loss: 0.678000975883644\n",
      "Loss: 0.640794237777022\n",
      "Loss: 0.6132619648830582\n",
      "______\n",
      "Iteration t=3\n",
      "all:  cs/acc_i=88.26 cs/acc_c=89.03 os/recall_knw=72.45 os/recall_unk=89.78 total/acc_i=77.14 total/acc_c=73.05 total/h_score=80.05\n",
      "selected:  cs/acc_i=85.95 cs/acc_c=86.88 os/recall_knw=64.02 os/recall_unk=98.12 total/acc_i=76.22 total/acc_c=67.01 total/h_score=78.52\n",
      "Loss: 2.376852795214636\n",
      "Loss: 1.2000238222460593\n",
      "Loss: 0.9369200099540013\n",
      "Loss: 0.8108005963773283\n",
      "Loss: 0.7695164546958008\n",
      "Loss: 0.7170958165413163\n",
      "Loss: 0.65953784369226\n",
      "Loss: 0.6329376124459782\n",
      "Loss: 0.6071997733526332\n",
      "Loss: 0.5883204397548484\n",
      "______\n",
      "Iteration t=4\n",
      "all:  cs/acc_i=89.21 cs/acc_c=89.82 os/recall_knw=72.30 os/recall_unk=89.84 total/acc_i=77.10 total/acc_c=72.98 total/h_score=80.02\n",
      "selected:  cs/acc_i=88.23 cs/acc_c=88.78 os/recall_knw=68.57 os/recall_unk=94.44 total/acc_i=76.78 total/acc_c=70.49 total/h_score=79.93\n",
      "Loss: 2.2994894973247124\n",
      "Loss: 1.1341806127349672\n",
      "Loss: 0.8738616435397607\n",
      "Loss: 0.7798622142739671\n",
      "Loss: 0.7092791438713009\n",
      "Loss: 0.6886035449065446\n",
      "Loss: 0.6486682005404613\n",
      "Loss: 0.6055227090881139\n",
      "Loss: 0.5737575025586952\n",
      "Loss: 0.546539537634052\n",
      "______\n",
      "Iteration t=5\n",
      "all:  cs/acc_i=89.54 cs/acc_c=90.20 os/recall_knw=71.59 os/recall_unk=90.02 total/acc_i=76.77 total/acc_c=72.43 total/h_score=79.73\n",
      "selected:  cs/acc_i=89.05 cs/acc_c=89.74 os/recall_knw=69.93 os/recall_unk=91.43 total/acc_i=76.37 total/acc_c=71.28 total/h_score=79.47\n",
      "Loss: 2.28826380332311\n",
      "Loss: 1.0800521046916645\n",
      "Loss: 0.8512423133850098\n",
      "Loss: 0.7499819964170455\n",
      "Loss: 0.7123748672008514\n",
      "Loss: 0.6641452416280905\n",
      "Loss: 0.6163912856082121\n",
      "Loss: 0.5834100956718127\n",
      "Loss: 0.5498847129940987\n",
      "Loss: 0.5407794325550397\n",
      "______\n",
      "Iteration t=6\n",
      "all:  cs/acc_i=90.01 cs/acc_c=90.54 os/recall_knw=71.56 os/recall_unk=90.02 total/acc_i=76.75 total/acc_c=72.39 total/h_score=79.71\n",
      "selected:  cs/acc_i=89.87 cs/acc_c=90.48 os/recall_knw=70.91 os/recall_unk=90.29 total/acc_i=76.53 total/acc_c=72.08 total/h_score=79.60\n",
      "Loss: 2.2774888316267416\n",
      "Loss: 1.0792417085092318\n",
      "Loss: 0.8457395182432312\n",
      "Loss: 0.7577404648457703\n",
      "Loss: 0.6926619685990246\n",
      "Loss: 0.6346019531943297\n",
      "Loss: 0.6092985747382045\n",
      "Loss: 0.576871154192639\n",
      "Loss: 0.5550500380463506\n",
      "Loss: 0.5295341869227981\n",
      "______\n",
      "Iteration t=7\n",
      "all:  cs/acc_i=90.63 cs/acc_c=91.14 os/recall_knw=71.56 os/recall_unk=90.08 total/acc_i=76.77 total/acc_c=72.40 total/h_score=79.73\n",
      "selected:  cs/acc_i=90.62 cs/acc_c=91.15 os/recall_knw=71.45 os/recall_unk=90.08 total/acc_i=76.73 total/acc_c=72.37 total/h_score=79.71\n",
      "Loss: 2.2765597749610675\n",
      "Loss: 1.0629473443140036\n",
      "Loss: 0.8323570488912663\n",
      "Loss: 0.7419476174182146\n",
      "Loss: 0.6958033408520664\n",
      "Loss: 0.6626581876790485\n",
      "Loss: 0.6174105335427418\n",
      "Loss: 0.5760685735979764\n",
      "Loss: 0.5699383066026706\n",
      "Loss: 0.531278880828755\n",
      "______\n",
      "Iteration t=8\n",
      "all:  cs/acc_i=90.07 cs/acc_c=90.66 os/recall_knw=71.56 os/recall_unk=90.08 total/acc_i=76.77 total/acc_c=72.40 total/h_score=79.73\n",
      "selected:  cs/acc_i=90.07 cs/acc_c=90.66 os/recall_knw=71.56 os/recall_unk=90.08 total/acc_i=76.77 total/acc_c=72.40 total/h_score=79.73\n",
      "Loss: 2.268734311630361\n",
      "Loss: 1.0759228242725036\n",
      "Loss: 0.8400377124450883\n",
      "Loss: 0.7378427779441548\n",
      "Loss: 0.6922727379620269\n",
      "Loss: 0.642591537646828\n",
      "Loss: 0.6057398929366848\n",
      "Loss: 0.5748885310822279\n",
      "Loss: 0.5581276857988842\n",
      "Loss: 0.5182574899557747\n",
      "______\n",
      "Iteration t=9\n",
      "all:  cs/acc_i=89.80 cs/acc_c=90.44 os/recall_knw=71.56 os/recall_unk=90.08 total/acc_i=76.77 total/acc_c=72.40 total/h_score=79.73\n",
      "selected:  cs/acc_i=89.80 cs/acc_c=90.44 os/recall_knw=71.56 os/recall_unk=90.08 total/acc_i=76.77 total/acc_c=72.40 total/h_score=79.73\n",
      "tensor(0)\n",
      "all:  cs/acc_i=89.80 cs/acc_c=90.44 os/recall_knw=71.56 os/recall_unk=90.08 total/acc_i=76.77 total/acc_c=72.40 total/h_score=79.73\n",
      "sketch -> real lr= 0.001 seed= 1\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19]\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20]\n",
      "Loss: 2.613130144840848\n",
      "Loss: 1.603090276232863\n",
      "Loss: 1.256859847665888\n",
      "Loss: 1.0882312528854978\n",
      "Loss: 1.0419927178758435\n",
      "Loss: 0.9410668516581038\n",
      "Loss: 0.8827201746470106\n",
      "Loss: 0.8135023532451782\n",
      "Loss: 0.7872755085736249\n",
      "Loss: 0.7447614452216478\n",
      "tensor(True) tensor(True)\n",
      "______\n",
      "Iteration t=1\n",
      "all:  cs/acc_i=86.55 cs/acc_c=87.58 os/recall_knw=96.96 os/recall_unk=23.95 total/acc_i=65.40 total/acc_c=84.08 total/h_score=37.56\n",
      "selected:  cs/acc_i=86.48 cs/acc_c=87.15 os/recall_knw=84.70 os/recall_unk=99.75 total/acc_i=89.79 total/acc_c=85.66 total/h_score=91.76\n",
      "Loss: 2.5298528241329508\n",
      "Loss: 1.419216460624679\n",
      "Loss: 1.110204868140768\n",
      "Loss: 0.949292361614157\n",
      "Loss: 0.8853759642262928\n",
      "Loss: 0.8492780115272178\n",
      "Loss: 0.7856695776591536\n",
      "Loss: 0.7556772596034848\n",
      "Loss: 0.7260777153929726\n",
      "Loss: 0.6776580127780555\n",
      "______\n",
      "Iteration t=2\n",
      "all:  cs/acc_i=87.41 cs/acc_c=88.31 os/recall_knw=78.69 os/recall_unk=80.81 total/acc_i=77.48 total/acc_c=77.39 total/h_score=78.97\n",
      "selected:  cs/acc_i=81.50 cs/acc_c=83.52 os/recall_knw=61.01 os/recall_unk=99.49 total/acc_i=76.96 total/acc_c=65.70 total/h_score=77.90\n",
      "Loss: 2.439163180252978\n",
      "Loss: 1.2887253556542724\n",
      "Loss: 1.014639871266052\n",
      "Loss: 0.892166307409301\n",
      "Loss: 0.8068260279206829\n",
      "Loss: 0.7580965813107163\n",
      "Loss: 0.7299240298626077\n",
      "Loss: 0.6871847257245588\n",
      "Loss: 0.6559078383991737\n",
      "Loss: 0.6284089086164955\n",
      "______\n",
      "Iteration t=3\n",
      "all:  cs/acc_i=88.65 cs/acc_c=89.25 os/recall_knw=74.08 os/recall_unk=88.77 total/acc_i=77.71 total/acc_c=74.19 total/h_score=80.39\n",
      "selected:  cs/acc_i=86.18 cs/acc_c=86.94 os/recall_knw=65.36 os/recall_unk=97.84 total/acc_i=76.87 total/acc_c=68.07 total/h_score=79.24\n",
      "Loss: 2.3922377709419496\n",
      "Loss: 1.1833560785085069\n",
      "Loss: 0.946750135404662\n",
      "Loss: 0.8135618790717107\n",
      "Loss: 0.7636150206075347\n",
      "Loss: 0.7138765798247416\n",
      "Loss: 0.6683975152644632\n",
      "Loss: 0.629970772505661\n",
      "Loss: 0.598608304789844\n",
      "Loss: 0.5714914224053796\n",
      "______\n",
      "Iteration t=4\n",
      "all:  cs/acc_i=89.42 cs/acc_c=89.98 os/recall_knw=73.40 os/recall_unk=89.66 total/acc_i=77.65 total/acc_c=73.75 total/h_score=80.45\n",
      "selected:  cs/acc_i=88.25 cs/acc_c=88.67 os/recall_knw=69.16 os/recall_unk=94.97 total/acc_i=77.30 total/acc_c=70.75 total/h_score=80.29\n",
      "Loss: 2.3300849570803446\n",
      "Loss: 1.1404497478514501\n",
      "Loss: 0.900335137158224\n",
      "Loss: 0.776587564345092\n",
      "Loss: 0.7062589243462641\n",
      "Loss: 0.6740656889056507\n",
      "Loss: 0.6436995659788994\n",
      "Loss: 0.5933250634841722\n",
      "Loss: 0.5769263564621749\n",
      "Loss: 0.566924137101598\n",
      "______\n",
      "Iteration t=5\n",
      "all:  cs/acc_i=89.98 cs/acc_c=90.47 os/recall_knw=73.28 os/recall_unk=89.78 total/acc_i=77.62 total/acc_c=73.63 total/h_score=80.42\n",
      "selected:  cs/acc_i=89.62 cs/acc_c=90.04 os/recall_knw=71.30 os/recall_unk=91.13 total/acc_i=77.18 total/acc_c=72.47 total/h_score=80.15\n",
      "Loss: 2.287974474834049\n",
      "Loss: 1.0881864929516054\n",
      "Loss: 0.866836591119386\n",
      "Loss: 0.7499871953975322\n",
      "Loss: 0.6974018368610116\n",
      "Loss: 0.6563142847975227\n",
      "Loss: 0.6166206371546584\n",
      "Loss: 0.5778048441952646\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.5576793786596222\n",
      "Loss: 0.5119015344502126\n",
      "______\n",
      "Iteration t=6\n",
      "all:  cs/acc_i=90.22 cs/acc_c=90.82 os/recall_knw=73.28 os/recall_unk=89.84 total/acc_i=77.64 total/acc_c=73.64 total/h_score=80.44\n",
      "selected:  cs/acc_i=90.16 cs/acc_c=90.71 os/recall_knw=72.54 os/recall_unk=90.11 total/acc_i=77.44 total/acc_c=73.28 total/h_score=80.31\n",
      "Loss: 2.272359644275865\n",
      "Loss: 1.0752852358459648\n",
      "Loss: 0.8319138868961459\n",
      "Loss: 0.7416428243802264\n",
      "Loss: 0.6929183233212801\n",
      "Loss: 0.6489860189506431\n",
      "Loss: 0.5849270386243958\n",
      "Loss: 0.568588979590952\n",
      "Loss: 0.5582786243822839\n",
      "Loss: 0.5336130326431171\n",
      "______\n",
      "Iteration t=7\n",
      "all:  cs/acc_i=89.83 cs/acc_c=90.40 os/recall_knw=73.25 os/recall_unk=89.84 total/acc_i=77.62 total/acc_c=73.61 total/h_score=80.43\n",
      "selected:  cs/acc_i=89.79 cs/acc_c=90.32 os/recall_knw=73.14 os/recall_unk=89.84 total/acc_i=77.55 total/acc_c=73.52 total/h_score=80.37\n",
      "Loss: 2.2672246661666153\n",
      "Loss: 1.0792092876387882\n",
      "Loss: 0.8441033508483465\n",
      "Loss: 0.73921282149174\n",
      "Loss: 0.6736793195852986\n",
      "Loss: 0.6322912390936505\n",
      "Loss: 0.5902085537937555\n",
      "Loss: 0.5839080239658232\n",
      "Loss: 0.5443507446967936\n",
      "Loss: 0.5351957258369241\n",
      "______\n",
      "Iteration t=8\n",
      "all:  cs/acc_i=89.74 cs/acc_c=90.35 os/recall_knw=73.25 os/recall_unk=89.84 total/acc_i=77.62 total/acc_c=73.61 total/h_score=80.43\n",
      "selected:  cs/acc_i=89.74 cs/acc_c=90.35 os/recall_knw=73.25 os/recall_unk=89.84 total/acc_i=77.62 total/acc_c=73.61 total/h_score=80.43\n",
      "Loss: 2.2368314918190917\n",
      "Loss: 1.0669512768007792\n",
      "Loss: 0.8328720802821002\n",
      "Loss: 0.729784980368074\n",
      "Loss: 0.6864721384441969\n",
      "Loss: 0.6466180165705172\n",
      "Loss: 0.5946595420922276\n",
      "Loss: 0.578939928881173\n",
      "Loss: 0.546728533930763\n",
      "Loss: 0.5208794634704836\n",
      "______\n",
      "Iteration t=9\n",
      "all:  cs/acc_i=90.13 cs/acc_c=90.66 os/recall_knw=73.25 os/recall_unk=89.84 total/acc_i=77.62 total/acc_c=73.61 total/h_score=80.43\n",
      "selected:  cs/acc_i=90.13 cs/acc_c=90.66 os/recall_knw=73.25 os/recall_unk=89.84 total/acc_i=77.62 total/acc_c=73.61 total/h_score=80.43\n",
      "tensor(0)\n",
      "all:  cs/acc_i=90.13 cs/acc_c=90.66 os/recall_knw=73.25 os/recall_unk=89.84 total/acc_i=77.62 total/acc_c=73.61 total/h_score=80.43\n",
      "sketch -> real lr= 0.001 seed= 2\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19]\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20]\n",
      "Loss: 2.610744641945425\n",
      "Loss: 1.5978697807387967\n",
      "Loss: 1.2455286626267221\n",
      "Loss: 1.1090059077317735\n",
      "Loss: 1.0082655113882724\n",
      "Loss: 0.9214844374002609\n",
      "Loss: 0.8750346715735123\n",
      "Loss: 0.8362727086100958\n",
      "Loss: 0.7944065248016763\n",
      "Loss: 0.7517427910218196\n",
      "tensor(True) tensor(True)\n",
      "______\n",
      "Iteration t=1\n",
      "all:  cs/acc_i=85.66 cs/acc_c=86.59 os/recall_knw=96.39 os/recall_unk=22.82 total/acc_i=64.19 total/acc_c=82.79 total/h_score=36.05\n",
      "selected:  cs/acc_i=85.71 cs/acc_c=86.22 os/recall_knw=82.40 os/recall_unk=99.48 total/acc_i=87.86 total/acc_c=83.16 total/h_score=90.11\n",
      "Loss: 2.5488196157041143\n",
      "Loss: 1.4529002321059588\n",
      "Loss: 1.1054730789094676\n",
      "Loss: 0.9833300602240641\n",
      "Loss: 0.9140057883790282\n",
      "Loss: 0.8201696724920976\n",
      "Loss: 0.7821469001594137\n",
      "Loss: 0.75040766205944\n",
      "Loss: 0.7291754476848196\n",
      "Loss: 0.6622445644413839\n",
      "______\n",
      "Iteration t=2\n",
      "all:  cs/acc_i=87.67 cs/acc_c=88.50 os/recall_knw=77.09 os/recall_unk=83.18 total/acc_i=77.38 total/acc_c=76.02 total/h_score=79.24\n",
      "selected:  cs/acc_i=82.06 cs/acc_c=83.88 os/recall_knw=59.23 os/recall_unk=99.29 total/acc_i=75.93 total/acc_c=63.60 total/h_score=76.20\n",
      "Loss: 2.4572327259842677\n",
      "Loss: 1.3149709330715296\n",
      "Loss: 1.0028106897841884\n",
      "Loss: 0.8929905958530557\n",
      "Loss: 0.8303656237953492\n",
      "Loss: 0.7684261616859728\n",
      "Loss: 0.7215534798971569\n",
      "Loss: 0.6841207868952788\n",
      "Loss: 0.6347617623005205\n",
      "Loss: 0.6335965640103544\n",
      "______\n",
      "Iteration t=3\n",
      "all:  cs/acc_i=88.41 cs/acc_c=89.13 os/recall_knw=68.58 os/recall_unk=93.58 total/acc_i=76.10 total/acc_c=69.95 total/h_score=79.28\n",
      "selected:  cs/acc_i=86.21 cs/acc_c=87.14 os/recall_knw=60.90 os/recall_unk=97.95 total/acc_i=74.14 total/acc_c=64.01 total/h_score=76.17\n",
      "Loss: 2.370341855138006\n",
      "Loss: 1.189998252844725\n",
      "Loss: 0.9317592416612905\n",
      "Loss: 0.8220569227545065\n",
      "Loss: 0.7704733725517027\n",
      "Loss: 0.7050628848507413\n",
      "Loss: 0.670236256494317\n",
      "Loss: 0.6436194261021939\n",
      "Loss: 0.6032987214010677\n",
      "Loss: 0.5834648534388525\n",
      "______\n",
      "Iteration t=4\n",
      "all:  cs/acc_i=89.30 cs/acc_c=89.84 os/recall_knw=68.08 os/recall_unk=93.94 total/acc_i=75.94 total/acc_c=69.59 total/h_score=79.15\n",
      "selected:  cs/acc_i=88.25 cs/acc_c=88.75 os/recall_knw=64.16 os/recall_unk=95.99 total/acc_i=74.79 total/acc_c=66.70 total/h_score=77.68\n",
      "Loss: 2.339951404238242\n",
      "Loss: 1.132232172678911\n",
      "Loss: 0.8936455275566932\n",
      "Loss: 0.8047526928380286\n",
      "Loss: 0.7342929931866669\n",
      "Loss: 0.6551476871162962\n",
      "Loss: 0.6639123614168497\n",
      "Loss: 0.5971360564438117\n",
      "Loss: 0.5829466035312435\n",
      "Loss: 0.5693481272685899\n",
      "______\n",
      "Iteration t=5\n",
      "all:  cs/acc_i=89.60 cs/acc_c=90.22 os/recall_knw=68.08 os/recall_unk=93.94 total/acc_i=75.94 total/acc_c=69.59 total/h_score=79.15\n",
      "selected:  cs/acc_i=89.22 cs/acc_c=89.81 os/recall_knw=66.46 os/recall_unk=94.39 total/acc_i=75.36 total/acc_c=68.49 total/h_score=78.51\n",
      "Loss: 2.320038452744484\n",
      "Loss: 1.1158654419956981\n",
      "Loss: 0.8676928757010279\n",
      "Loss: 0.7893928932781155\n",
      "Loss: 0.7175781109647171\n",
      "Loss: 0.6711714483696867\n",
      "Loss: 0.6324546700091781\n",
      "Loss: 0.5962753419739169\n",
      "Loss: 0.5737194377626922\n",
      "Loss: 0.5356139947937147\n",
      "______\n",
      "Iteration t=6\n",
      "all:  cs/acc_i=89.48 cs/acc_c=90.17 os/recall_knw=67.96 os/recall_unk=94.06 total/acc_i=75.90 total/acc_c=69.50 total/h_score=79.11\n",
      "selected:  cs/acc_i=89.38 cs/acc_c=90.00 os/recall_knw=67.49 os/recall_unk=94.17 total/acc_i=75.73 total/acc_c=69.17 total/h_score=78.92\n",
      "Loss: 2.2976674818274967\n",
      "Loss: 1.1071028783169876\n",
      "Loss: 0.8492324857608132\n",
      "Loss: 0.7525973332964856\n",
      "Loss: 0.7134930247247817\n",
      "Loss: 0.656147387414473\n",
      "Loss: 0.6117538715585019\n",
      "Loss: 0.5793144534463468\n",
      "Loss: 0.5511848558251276\n",
      "Loss: 0.5456876397431893\n",
      "______\n",
      "Iteration t=7\n",
      "all:  cs/acc_i=89.68 cs/acc_c=90.28 os/recall_knw=67.90 os/recall_unk=94.06 total/acc_i=75.86 total/acc_c=69.45 total/h_score=79.08\n",
      "selected:  cs/acc_i=89.68 cs/acc_c=90.28 os/recall_knw=67.90 os/recall_unk=94.06 total/acc_i=75.86 total/acc_c=69.45 total/h_score=79.08\n",
      "Loss: 2.28437691431901\n",
      "Loss: 1.1004183728037482\n",
      "Loss: 0.8722855096243545\n",
      "Loss: 0.7648578966376789\n",
      "Loss: 0.6880960697153478\n",
      "Loss: 0.674983451136719\n",
      "Loss: 0.6033016188299141\n",
      "Loss: 0.5958120208047949\n",
      "Loss: 0.5609117298328203\n",
      "Loss: 0.5054545654757474\n",
      "______\n",
      "Iteration t=8\n",
      "all:  cs/acc_i=89.95 cs/acc_c=90.52 os/recall_knw=67.90 os/recall_unk=94.06 total/acc_i=75.86 total/acc_c=69.45 total/h_score=79.08\n",
      "selected:  cs/acc_i=89.95 cs/acc_c=90.52 os/recall_knw=67.90 os/recall_unk=94.06 total/acc_i=75.86 total/acc_c=69.45 total/h_score=79.08\n",
      "Loss: 2.285758226020788\n",
      "Loss: 1.1011883026341662\n",
      "Loss: 0.8643288836130668\n",
      "Loss: 0.7907239404627651\n",
      "Loss: 0.7002333381346294\n",
      "Loss: 0.6479209292667649\n",
      "Loss: 0.6187626102636027\n",
      "Loss: 0.5891506250118497\n",
      "Loss: 0.5500776179110093\n",
      "Loss: 0.5468965078707153\n",
      "______\n",
      "Iteration t=9\n",
      "all:  cs/acc_i=89.68 cs/acc_c=90.22 os/recall_knw=67.90 os/recall_unk=94.06 total/acc_i=75.86 total/acc_c=69.45 total/h_score=79.08\n",
      "selected:  cs/acc_i=89.68 cs/acc_c=90.22 os/recall_knw=67.90 os/recall_unk=94.06 total/acc_i=75.86 total/acc_c=69.45 total/h_score=79.08\n",
      "tensor(0)\n",
      "all:  cs/acc_i=89.68 cs/acc_c=90.22 os/recall_knw=67.90 os/recall_unk=94.06 total/acc_i=75.86 total/acc_c=69.45 total/h_score=79.08\n",
      "sketch -> real lr= 0.001 seed= 3\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19]\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20]\n",
      "Loss: 2.599302684311318\n",
      "Loss: 1.564411961926823\n",
      "Loss: 1.2455564542154296\n",
      "Loss: 1.1045975822263059\n",
      "Loss: 1.0022511859383203\n",
      "Loss: 0.9302692764100775\n",
      "Loss: 0.8881400860516371\n",
      "Loss: 0.824522435928868\n",
      "Loss: 0.8023237757450712\n",
      "Loss: 0.7607784297613971\n",
      "tensor(True) tensor(True)\n",
      "______\n",
      "Iteration t=1\n",
      "all:  cs/acc_i=86.37 cs/acc_c=87.30 os/recall_knw=96.63 os/recall_unk=23.29 total/acc_i=64.71 total/acc_c=83.31 total/h_score=36.68\n",
      "selected:  cs/acc_i=87.68 cs/acc_c=88.13 os/recall_knw=83.28 os/recall_unk=99.24 total/acc_i=88.58 total/acc_c=83.98 total/h_score=90.53\n",
      "Loss: 2.567303216848217\n",
      "Loss: 1.458231519724502\n",
      "Loss: 1.1074863984936574\n",
      "Loss: 0.9926503099134711\n",
      "Loss: 0.8995398384381513\n",
      "Loss: 0.8283834498925288\n",
      "Loss: 0.7963092884079355\n",
      "Loss: 0.7516312932626146\n",
      "Loss: 0.7115811850936686\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.6910333569909706\n",
      "______\n",
      "Iteration t=2\n",
      "all:  cs/acc_i=87.32 cs/acc_c=88.17 os/recall_knw=78.57 os/recall_unk=82.23 total/acc_i=77.87 total/acc_c=77.29 total/h_score=79.55\n",
      "selected:  cs/acc_i=81.49 cs/acc_c=83.33 os/recall_knw=60.98 os/recall_unk=99.64 total/acc_i=77.15 total/acc_c=65.54 total/h_score=77.82\n",
      "Loss: 2.4424192100080826\n",
      "Loss: 1.2980809930626673\n",
      "Loss: 0.9921067740398509\n",
      "Loss: 0.8966570187160987\n",
      "Loss: 0.7914489605499588\n",
      "Loss: 0.769369684444129\n",
      "Loss: 0.729979912857063\n",
      "Loss: 0.6714721705394847\n",
      "Loss: 0.6365901529220225\n",
      "Loss: 0.6333657347860228\n",
      "______\n",
      "Iteration t=3\n",
      "all:  cs/acc_i=88.59 cs/acc_c=89.25 os/recall_knw=73.01 os/recall_unk=90.97 total/acc_i=77.99 total/acc_c=73.77 total/h_score=80.94\n",
      "selected:  cs/acc_i=85.90 cs/acc_c=86.72 os/recall_knw=64.54 os/recall_unk=98.39 total/acc_i=76.64 total/acc_c=67.28 total/h_score=78.81\n",
      "Loss: 2.3656837222396687\n",
      "Loss: 1.17761644667622\n",
      "Loss: 0.9160520140629088\n",
      "Loss: 0.8145713915107071\n",
      "Loss: 0.7662292725830523\n",
      "Loss: 0.7127095812324128\n",
      "Loss: 0.6560424715280533\n",
      "Loss: 0.6099234127229259\n",
      "Loss: 0.5998798542552524\n",
      "Loss: 0.6147839623540106\n",
      "______\n",
      "Iteration t=4\n",
      "all:  cs/acc_i=89.86 cs/acc_c=90.42 os/recall_knw=72.27 os/recall_unk=91.56 total/acc_i=77.81 total/acc_c=73.25 total/h_score=80.82\n",
      "selected:  cs/acc_i=88.80 cs/acc_c=89.23 os/recall_knw=68.34 os/recall_unk=94.31 total/acc_i=76.85 total/acc_c=70.20 total/h_score=79.69\n",
      "Loss: 2.3016961702745253\n",
      "Loss: 1.1344810339481863\n",
      "Loss: 0.8764492872439019\n",
      "Loss: 0.7905430010430616\n",
      "Loss: 0.7151898039020088\n",
      "Loss: 0.665704692165329\n",
      "Loss: 0.6397376268693845\n",
      "Loss: 0.6103672395422034\n",
      "Loss: 0.5756085210875289\n",
      "Loss: 0.5502558731257099\n",
      "______\n",
      "Iteration t=5\n",
      "all:  cs/acc_i=89.86 cs/acc_c=90.41 os/recall_knw=71.89 os/recall_unk=91.68 total/acc_i=77.64 total/acc_c=72.97 total/h_score=80.68\n",
      "selected:  cs/acc_i=89.30 cs/acc_c=89.80 os/recall_knw=69.90 os/recall_unk=92.17 total/acc_i=76.85 total/acc_c=71.46 total/h_score=79.85\n",
      "Loss: 2.294400245848308\n",
      "Loss: 1.0805987848286644\n",
      "Loss: 0.8568327206632366\n",
      "Loss: 0.7771460653148766\n",
      "Loss: 0.6810569060486694\n",
      "Loss: 0.6691850942114125\n",
      "Loss: 0.6123320478260716\n",
      "Loss: 0.5935859497275241\n",
      "Loss: 0.5433173979006484\n",
      "Loss: 0.5298043308549103\n",
      "______\n",
      "Iteration t=6\n",
      "all:  cs/acc_i=90.01 cs/acc_c=90.50 os/recall_knw=71.83 os/recall_unk=91.68 total/acc_i=77.60 total/acc_c=72.92 total/h_score=80.65\n",
      "selected:  cs/acc_i=89.87 cs/acc_c=90.24 os/recall_knw=71.18 os/recall_unk=91.79 total/acc_i=77.35 total/acc_c=72.40 total/h_score=80.34\n",
      "Loss: 2.273806342168858\n",
      "Loss: 1.07792639389242\n",
      "Loss: 0.8502009682553379\n",
      "Loss: 0.7600101435458974\n",
      "Loss: 0.716109488355486\n",
      "Loss: 0.6487743478072318\n",
      "Loss: 0.6134883565338034\n",
      "Loss: 0.5751875995315219\n",
      "Loss: 0.5426794941978235\n",
      "Loss: 0.5328441812705836\n",
      "______\n",
      "Iteration t=7\n",
      "all:  cs/acc_i=90.04 cs/acc_c=90.59 os/recall_knw=71.83 os/recall_unk=91.68 total/acc_i=77.60 total/acc_c=72.92 total/h_score=80.65\n",
      "selected:  cs/acc_i=90.02 cs/acc_c=90.57 os/recall_knw=71.78 os/recall_unk=91.68 total/acc_i=77.57 total/acc_c=72.88 total/h_score=80.62\n",
      "Loss: 2.275698148347194\n",
      "Loss: 1.0750048662128011\n",
      "Loss: 0.8305242079145768\n",
      "Loss: 0.7656761777946373\n",
      "Loss: 0.6757080031960618\n",
      "Loss: 0.633772139699241\n",
      "Loss: 0.5892631038536433\n",
      "Loss: 0.5790277492084535\n",
      "Loss: 0.5434020231751835\n",
      "Loss: 0.5267382563134424\n",
      "______\n",
      "Iteration t=8\n",
      "all:  cs/acc_i=90.16 cs/acc_c=90.71 os/recall_knw=71.83 os/recall_unk=91.68 total/acc_i=77.60 total/acc_c=72.92 total/h_score=80.65\n",
      "selected:  cs/acc_i=90.16 cs/acc_c=90.71 os/recall_knw=71.83 os/recall_unk=91.68 total/acc_i=77.60 total/acc_c=72.92 total/h_score=80.65\n",
      "Loss: 2.274607691110349\n",
      "Loss: 1.0724294557680492\n",
      "Loss: 0.8473005558735405\n",
      "Loss: 0.7638612846338672\n",
      "Loss: 0.6886870808461133\n",
      "Loss: 0.6549764873545154\n",
      "Loss: 0.599653164789178\n",
      "Loss: 0.5733775453142871\n",
      "Loss: 0.5573565044190759\n",
      "Loss: 0.5222531341357168\n",
      "______\n",
      "Iteration t=9\n",
      "all:  cs/acc_i=90.01 cs/acc_c=90.58 os/recall_knw=71.83 os/recall_unk=91.68 total/acc_i=77.60 total/acc_c=72.92 total/h_score=80.65\n",
      "selected:  cs/acc_i=90.01 cs/acc_c=90.58 os/recall_knw=71.83 os/recall_unk=91.68 total/acc_i=77.60 total/acc_c=72.92 total/h_score=80.65\n",
      "tensor(0)\n",
      "all:  cs/acc_i=90.01 cs/acc_c=90.58 os/recall_knw=71.83 os/recall_unk=91.68 total/acc_i=77.60 total/acc_c=72.92 total/h_score=80.65\n",
      "sketch -> real lr= 0.001 seed= 4\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19]\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20]\n",
      "Loss: 2.6206129499241313\n",
      "Loss: 1.5889818541771543\n",
      "Loss: 1.2475848788708712\n",
      "Loss: 1.101382434631871\n",
      "Loss: 1.0133953298878882\n",
      "Loss: 0.947092229022389\n",
      "Loss: 0.8824046388664076\n",
      "Loss: 0.8246341358243892\n",
      "Loss: 0.7883489055443654\n",
      "Loss: 0.7576266260801163\n",
      "tensor(True) tensor(True)\n",
      "______\n",
      "Iteration t=1\n",
      "all:  cs/acc_i=86.20 cs/acc_c=87.19 os/recall_knw=96.36 os/recall_unk=22.76 total/acc_i=64.47 total/acc_c=83.24 total/h_score=36.01\n",
      "selected:  cs/acc_i=86.02 cs/acc_c=87.22 os/recall_knw=82.28 os/recall_unk=99.48 total/acc_i=87.77 total/acc_c=83.59 total/h_score=90.37\n",
      "Loss: 2.52789200378246\n",
      "Loss: 1.4305641619396992\n",
      "Loss: 1.0857978626841405\n",
      "Loss: 0.9856012834877265\n",
      "Loss: 0.9136136418483296\n",
      "Loss: 0.8431555016851816\n",
      "Loss: 0.780798251755902\n",
      "Loss: 0.7382761744446442\n",
      "Loss: 0.7051678505100187\n",
      "Loss: 0.6780466897810091\n",
      "______\n",
      "Iteration t=2\n",
      "all:  cs/acc_i=87.47 cs/acc_c=88.24 os/recall_knw=78.19 os/recall_unk=82.35 total/acc_i=77.87 total/acc_c=77.18 total/h_score=79.55\n",
      "selected:  cs/acc_i=81.32 cs/acc_c=83.16 os/recall_knw=60.49 os/recall_unk=99.57 total/acc_i=76.84 total/acc_c=65.11 total/h_score=77.46\n",
      "Loss: 2.456047238739392\n",
      "Loss: 1.2701493326489253\n",
      "Loss: 1.0027605270156423\n",
      "Loss: 0.8852338674869246\n",
      "Loss: 0.8027670538152447\n",
      "Loss: 0.7579355775627471\n",
      "Loss: 0.7324614858126822\n",
      "Loss: 0.684209789938599\n",
      "Loss: 0.6467460067445086\n",
      "Loss: 0.6492043501548185\n",
      "______\n",
      "Iteration t=3\n",
      "all:  cs/acc_i=88.35 cs/acc_c=89.05 os/recall_knw=72.72 os/recall_unk=88.06 total/acc_i=76.92 total/acc_c=73.35 total/h_score=79.59\n",
      "selected:  cs/acc_i=85.64 cs/acc_c=86.60 os/recall_knw=64.07 os/recall_unk=97.63 total/acc_i=76.05 total/acc_c=66.94 total/h_score=78.34\n",
      "Loss: 2.372231774859958\n",
      "Loss: 1.1855184957118017\n",
      "Loss: 0.9249410811931856\n",
      "Loss: 0.8405490114911055\n",
      "Loss: 0.7711498411539207\n",
      "Loss: 0.7113051984899788\n",
      "Loss: 0.6971098630018132\n",
      "Loss: 0.6325324736402026\n",
      "Loss: 0.6030125967811085\n",
      "Loss: 0.5951116137927578\n",
      "______\n",
      "Iteration t=4\n",
      "all:  cs/acc_i=89.71 cs/acc_c=90.28 os/recall_knw=71.74 os/recall_unk=89.30 total/acc_i=76.75 total/acc_c=72.57 total/h_score=79.56\n",
      "selected:  cs/acc_i=88.61 cs/acc_c=89.15 os/recall_knw=67.96 os/recall_unk=94.65 total/acc_i=76.49 total/acc_c=69.85 total/h_score=79.55\n",
      "Loss: 2.3162296463365424\n",
      "Loss: 1.117344186730581\n",
      "Loss: 0.8813583022111082\n",
      "Loss: 0.7917870033073099\n",
      "Loss: 0.7106949112390819\n",
      "Loss: 0.676847882670899\n",
      "Loss: 0.6199886094115369\n",
      "Loss: 0.5962796919047832\n",
      "Loss: 0.5691306702792645\n",
      "Loss: 0.5561327684211405\n",
      "______\n",
      "Iteration t=5\n",
      "all:  cs/acc_i=89.74 cs/acc_c=90.32 os/recall_knw=71.71 os/recall_unk=89.30 total/acc_i=76.75 total/acc_c=72.57 total/h_score=79.56\n",
      "selected:  cs/acc_i=89.21 cs/acc_c=89.87 os/recall_knw=69.81 os/recall_unk=90.71 total/acc_i=76.24 total/acc_c=71.36 total/h_score=79.27\n",
      "Loss: 2.2917883006731667\n",
      "Loss: 1.0717492866516114\n",
      "Loss: 0.8690502747893334\n",
      "Loss: 0.7621925061941147\n",
      "Loss: 0.6962383825083573\n",
      "Loss: 0.6612789456049601\n",
      "Loss: 0.6217519957820574\n",
      "Loss: 0.5832623388369879\n",
      "Loss: 0.5440730321407318\n",
      "Loss: 0.5227742568651835\n",
      "______\n",
      "Iteration t=6\n",
      "all:  cs/acc_i=90.07 cs/acc_c=90.63 os/recall_knw=71.56 os/recall_unk=89.48 total/acc_i=76.73 total/acc_c=72.46 total/h_score=79.56\n",
      "selected:  cs/acc_i=89.95 cs/acc_c=90.54 os/recall_knw=70.88 os/recall_unk=89.86 total/acc_i=76.55 total/acc_c=72.14 total/h_score=79.48\n",
      "Loss: 2.2482528072888734\n",
      "Loss: 1.070485788876893\n",
      "Loss: 0.8240922642535851\n",
      "Loss: 0.7748194695496168\n",
      "Loss: 0.694333945141464\n",
      "Loss: 0.661929823678048\n",
      "Loss: 0.6070191529686334\n",
      "Loss: 0.5885306292870006\n",
      "Loss: 0.5532455710114026\n",
      "Loss: 0.5302598827930748\n",
      "______\n",
      "Iteration t=7\n",
      "all:  cs/acc_i=89.71 cs/acc_c=90.27 os/recall_knw=71.50 os/recall_unk=89.54 total/acc_i=76.71 total/acc_c=72.42 total/h_score=79.55\n",
      "selected:  cs/acc_i=89.69 cs/acc_c=90.26 os/recall_knw=71.45 os/recall_unk=89.54 total/acc_i=76.68 total/acc_c=72.40 total/h_score=79.53\n",
      "Loss: 2.254665394559357\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 1.0882111052930938\n",
      "Loss: 0.8526631741259696\n",
      "Loss: 0.7556623992197676\n",
      "Loss: 0.7052260100938598\n",
      "Loss: 0.6612932929581073\n",
      "Loss: 0.6147363712034318\n",
      "Loss: 0.5862095923396586\n",
      "Loss: 0.5566446985503362\n",
      "Loss: 0.5241689829562308\n",
      "______\n",
      "Iteration t=8\n",
      "all:  cs/acc_i=89.83 cs/acc_c=90.31 os/recall_knw=71.50 os/recall_unk=89.54 total/acc_i=76.71 total/acc_c=72.42 total/h_score=79.55\n",
      "selected:  cs/acc_i=89.83 cs/acc_c=90.31 os/recall_knw=71.50 os/recall_unk=89.54 total/acc_i=76.71 total/acc_c=72.42 total/h_score=79.55\n",
      "Loss: 2.2455597253886417\n",
      "Loss: 1.051638213159207\n",
      "Loss: 0.8646575424104249\n",
      "Loss: 0.7500017691609914\n",
      "Loss: 0.6911939566512061\n",
      "Loss: 0.63830175748283\n",
      "Loss: 0.6164141159492518\n",
      "Loss: 0.5913861564296853\n",
      "Loss: 0.535166816233812\n",
      "Loss: 0.5190033039460353\n",
      "______\n",
      "Iteration t=9\n",
      "all:  cs/acc_i=90.13 cs/acc_c=90.67 os/recall_knw=71.50 os/recall_unk=89.54 total/acc_i=76.71 total/acc_c=72.42 total/h_score=79.55\n",
      "selected:  cs/acc_i=90.13 cs/acc_c=90.67 os/recall_knw=71.50 os/recall_unk=89.54 total/acc_i=76.71 total/acc_c=72.42 total/h_score=79.55\n",
      "tensor(0)\n",
      "all:  cs/acc_i=90.13 cs/acc_c=90.67 os/recall_knw=71.50 os/recall_unk=89.54 total/acc_i=76.71 total/acc_c=72.42 total/h_score=79.55\n",
      "sketch -> real lr= 0.001 seed= 0\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19]\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20]\n",
      "Loss: 2.618110864035851\n",
      "Loss: 1.6023135000625544\n",
      "Loss: 1.2600405677757431\n",
      "Loss: 1.098522218718993\n",
      "Loss: 1.0016175370037028\n",
      "Loss: 0.9414293059205587\n",
      "Loss: 0.8844931963007007\n",
      "Loss: 0.8302177519133661\n",
      "Loss: 0.7947342887652659\n",
      "Loss: 0.7898081948535632\n",
      "tensor(True) tensor(True)\n",
      "______\n",
      "Iteration t=1\n",
      "all:  cs/acc_i=86.46 cs/acc_c=87.47 os/recall_knw=96.48 os/recall_unk=22.99 total/acc_i=64.84 total/acc_c=83.72 total/h_score=36.35\n",
      "selected:  cs/acc_i=85.76 cs/acc_c=87.53 os/recall_knw=82.70 os/recall_unk=99.49 total/acc_i=88.21 total/acc_c=84.88 total/h_score=91.18\n",
      "Loss: 2.5444128308139864\n",
      "Loss: 1.4492077583172283\n",
      "Loss: 1.1209211532698302\n",
      "Loss: 1.0071301137814757\n",
      "Loss: 0.8843047607873307\n",
      "Loss: 0.8325695428447645\n",
      "Loss: 0.7878685541084556\n",
      "Loss: 0.7470533521693261\n",
      "Loss: 0.718793116998477\n",
      "Loss: 0.6866206338659662\n",
      "______\n",
      "Iteration t=2\n",
      "all:  cs/acc_i=87.47 cs/acc_c=88.27 os/recall_knw=77.21 os/recall_unk=83.60 total/acc_i=77.69 total/acc_c=76.52 total/h_score=79.71\n",
      "selected:  cs/acc_i=81.43 cs/acc_c=83.24 os/recall_knw=59.34 os/recall_unk=99.29 total/acc_i=76.09 total/acc_c=64.46 total/h_score=76.87\n",
      "Loss: 2.4628590199783558\n",
      "Loss: 1.2875903772033808\n",
      "Loss: 1.010331663466592\n",
      "Loss: 0.8953159502671875\n",
      "Loss: 0.8428447633299209\n",
      "Loss: 0.7708965069010058\n",
      "Loss: 0.7164764863844136\n",
      "Loss: 0.66736029367183\n",
      "Loss: 0.653552130660938\n",
      "Loss: 0.6233015198061485\n",
      "______\n",
      "Iteration t=3\n",
      "all:  cs/acc_i=88.62 cs/acc_c=89.36 os/recall_knw=74.25 os/recall_unk=88.89 total/acc_i=77.93 total/acc_c=74.64 total/h_score=80.72\n",
      "selected:  cs/acc_i=86.02 cs/acc_c=87.08 os/recall_knw=65.41 os/recall_unk=97.59 total/acc_i=76.92 total/acc_c=68.52 total/h_score=79.50\n",
      "Loss: 2.369045464368704\n",
      "Loss: 1.1830864978092972\n",
      "Loss: 0.9470354442528072\n",
      "Loss: 0.840535962880726\n",
      "Loss: 0.7660033175167644\n",
      "Loss: 0.7075820864315101\n",
      "Loss: 0.6924319245909277\n",
      "Loss: 0.6382458220673292\n",
      "Loss: 0.6069921187282036\n",
      "Loss: 0.578879559659616\n",
      "______\n",
      "Iteration t=4\n",
      "all:  cs/acc_i=89.39 cs/acc_c=89.97 os/recall_knw=73.40 os/recall_unk=89.07 total/acc_i=77.56 total/acc_c=74.01 total/h_score=80.39\n",
      "selected:  cs/acc_i=88.29 cs/acc_c=88.85 os/recall_knw=69.44 os/recall_unk=94.34 total/acc_i=77.30 total/acc_c=71.27 total/h_score=80.44\n",
      "Loss: 2.304643862076587\n",
      "Loss: 1.1091919815987856\n",
      "Loss: 0.8724030113871187\n",
      "Loss: 0.7768775276051446\n",
      "Loss: 0.7466844803440693\n",
      "Loss: 0.6824371603161808\n",
      "Loss: 0.6457144449697013\n",
      "Loss: 0.615016557911964\n",
      "Loss: 0.5695602714811983\n",
      "Loss: 0.5404398919881\n",
      "______\n",
      "Iteration t=5\n",
      "all:  cs/acc_i=90.13 cs/acc_c=90.70 os/recall_knw=73.31 os/recall_unk=89.07 total/acc_i=77.52 total/acc_c=73.95 total/h_score=80.36\n",
      "selected:  cs/acc_i=89.60 cs/acc_c=90.14 os/recall_knw=71.27 os/recall_unk=90.46 total/acc_i=76.96 total/acc_c=72.71 total/h_score=80.08\n",
      "Loss: 2.298990497557428\n",
      "Loss: 1.0785453379946293\n",
      "Loss: 0.8333266962604269\n",
      "Loss: 0.7534255980455202\n",
      "Loss: 0.7041976224148392\n",
      "Loss: 0.6511219578525949\n",
      "Loss: 0.6032868039073342\n",
      "Loss: 0.5845229620256297\n",
      "Loss: 0.5588751026859315\n",
      "Loss: 0.5208908042737416\n",
      "______\n",
      "Iteration t=6\n",
      "all:  cs/acc_i=90.13 cs/acc_c=90.65 os/recall_knw=73.31 os/recall_unk=89.19 total/acc_i=77.56 total/acc_c=73.96 total/h_score=80.40\n",
      "selected:  cs/acc_i=90.01 cs/acc_c=90.51 os/recall_knw=72.67 os/recall_unk=89.40 total/acc_i=77.34 total/acc_c=73.60 total/h_score=80.25\n",
      "Loss: 2.2610069656993357\n",
      "Loss: 1.080036914503924\n",
      "Loss: 0.8334102432580258\n",
      "Loss: 0.7556956652127182\n",
      "Loss: 0.6850655062385025\n",
      "Loss: 0.6443174393052775\n",
      "Loss: 0.6145711892105469\n",
      "Loss: 0.5692366113588943\n",
      "Loss: 0.5429522529584189\n",
      "Loss: 0.5249963362946961\n",
      "______\n",
      "Iteration t=7\n",
      "all:  cs/acc_i=90.42 cs/acc_c=90.94 os/recall_knw=73.31 os/recall_unk=89.19 total/acc_i=77.56 total/acc_c=73.96 total/h_score=80.40\n",
      "selected:  cs/acc_i=90.32 cs/acc_c=90.86 os/recall_knw=73.02 os/recall_unk=89.19 total/acc_i=77.40 total/acc_c=73.80 total/h_score=80.30\n",
      "Loss: 2.258576871899815\n",
      "Loss: 1.0622176822129783\n",
      "Loss: 0.8558550498315266\n",
      "Loss: 0.7428396259035382\n",
      "Loss: 0.690145132797105\n",
      "Loss: 0.6364608554580768\n",
      "Loss: 0.6007574155152619\n",
      "Loss: 0.5745849530031155\n",
      "Loss: 0.5616295658439011\n",
      "Loss: 0.5189727725727218\n",
      "______\n",
      "Iteration t=8\n",
      "all:  cs/acc_i=90.27 cs/acc_c=90.83 os/recall_knw=73.31 os/recall_unk=89.19 total/acc_i=77.56 total/acc_c=73.96 total/h_score=80.40\n",
      "selected:  cs/acc_i=90.27 cs/acc_c=90.83 os/recall_knw=73.31 os/recall_unk=89.19 total/acc_i=77.56 total/acc_c=73.96 total/h_score=80.40\n",
      "Loss: 2.240368738529366\n",
      "Loss: 1.078320221897082\n",
      "Loss: 0.8450077015026488\n",
      "Loss: 0.7249298397584255\n",
      "Loss: 0.6778307438475414\n",
      "Loss: 0.6401497144915139\n",
      "Loss: 0.5944802522852197\n",
      "Loss: 0.551534318277751\n",
      "Loss: 0.5361787830645213\n",
      "Loss: 0.5324404431103117\n",
      "______\n",
      "Iteration t=9\n",
      "all:  cs/acc_i=90.39 cs/acc_c=90.91 os/recall_knw=73.31 os/recall_unk=89.19 total/acc_i=77.56 total/acc_c=73.96 total/h_score=80.40\n",
      "selected:  cs/acc_i=90.39 cs/acc_c=90.91 os/recall_knw=73.31 os/recall_unk=89.19 total/acc_i=77.56 total/acc_c=73.96 total/h_score=80.40\n",
      "tensor(0)\n",
      "all:  cs/acc_i=90.39 cs/acc_c=90.91 os/recall_knw=73.31 os/recall_unk=89.19 total/acc_i=77.56 total/acc_c=73.96 total/h_score=80.40\n",
      "sketch -> real lr= 0.001 seed= 1\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19]\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20]\n",
      "Loss: 2.614690682529348\n",
      "Loss: 1.6037963744813362\n",
      "Loss: 1.2578066584810745\n",
      "Loss: 1.0895244977643004\n",
      "Loss: 1.0433068792376898\n",
      "Loss: 0.9416310967861024\n",
      "Loss: 0.8834549886199226\n",
      "Loss: 0.8135075115524562\n",
      "Loss: 0.7891581075645127\n",
      "Loss: 0.7449921074166762\n",
      "tensor(True) tensor(True)\n",
      "______\n",
      "Iteration t=1\n",
      "all:  cs/acc_i=86.67 cs/acc_c=87.66 os/recall_knw=97.25 os/recall_unk=24.54 total/acc_i=65.73 total/acc_c=84.29 total/h_score=38.31\n",
      "selected:  cs/acc_i=87.29 cs/acc_c=88.01 os/recall_knw=85.93 os/recall_unk=99.52 total/acc_i=90.61 total/acc_c=86.84 total/h_score=92.39\n",
      "Loss: 2.532197359155436\n",
      "Loss: 1.4202175558101935\n",
      "Loss: 1.1279718746415903\n",
      "Loss: 0.9553049131006491\n",
      "Loss: 0.9168065518873637\n",
      "Loss: 0.8460081950074336\n",
      "Loss: 0.7895321925399733\n",
      "Loss: 0.764654096521315\n",
      "Loss: 0.7215699481426693\n",
      "Loss: 0.6899833223614537\n",
      "______\n",
      "Iteration t=2\n",
      "all:  cs/acc_i=88.03 cs/acc_c=88.89 os/recall_knw=81.35 os/recall_unk=79.68 total/acc_i=78.60 total/acc_c=79.33 total/h_score=79.49\n",
      "selected:  cs/acc_i=82.61 cs/acc_c=84.60 os/recall_knw=64.15 os/recall_unk=99.63 total/acc_i=79.14 total/acc_c=68.49 total/h_score=80.07\n",
      "Loss: 2.4453920758407532\n",
      "Loss: 1.3000159770932815\n",
      "Loss: 1.0029458460462002\n",
      "Loss: 0.9139797453206914\n",
      "Loss: 0.8105043305923011\n",
      "Loss: 0.77227456674321\n",
      "Loss: 0.7133084515123876\n",
      "Loss: 0.6926662944655382\n",
      "Loss: 0.6567462848798009\n",
      "Loss: 0.6231053669489067\n",
      "______\n",
      "Iteration t=3\n",
      "all:  cs/acc_i=88.47 cs/acc_c=89.15 os/recall_knw=78.27 os/recall_unk=85.15 total/acc_i=78.88 total/acc_c=77.34 total/h_score=80.84\n",
      "selected:  cs/acc_i=85.95 cs/acc_c=86.89 os/recall_knw=68.99 os/recall_unk=97.55 total/acc_i=79.19 total/acc_c=71.30 total/h_score=81.50\n",
      "Loss: 2.377672054784761\n",
      "Loss: 1.1985547250980952\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.9362223450657275\n",
      "Loss: 0.819434774436539\n",
      "Loss: 0.7552647426617232\n",
      "Loss: 0.7008586145883842\n",
      "Loss: 0.6704669595836735\n",
      "Loss: 0.6386168760468633\n",
      "Loss: 0.6207249240695144\n",
      "Loss: 0.5623093337463818\n",
      "______\n",
      "Iteration t=4\n",
      "all:  cs/acc_i=89.00 cs/acc_c=89.56 os/recall_knw=77.83 os/recall_unk=86.04 total/acc_i=78.98 total/acc_c=77.10 total/h_score=81.07\n",
      "selected:  cs/acc_i=87.73 cs/acc_c=88.29 os/recall_knw=73.41 os/recall_unk=94.09 total/acc_i=79.47 total/acc_c=74.32 total/h_score=82.43\n",
      "Loss: 2.3157954078142335\n",
      "Loss: 1.1184122213701002\n",
      "Loss: 0.8675877257269256\n",
      "Loss: 0.7736321299457226\n",
      "Loss: 0.7088124807797321\n",
      "Loss: 0.6861652509898556\n",
      "Loss: 0.6370636734629975\n",
      "Loss: 0.5859584607133249\n",
      "Loss: 0.564237252384627\n",
      "Loss: 0.5651979278646359\n",
      "______\n",
      "Iteration t=5\n",
      "all:  cs/acc_i=89.42 cs/acc_c=90.01 os/recall_knw=77.68 os/recall_unk=86.45 total/acc_i=79.08 total/acc_c=77.07 total/h_score=81.23\n",
      "selected:  cs/acc_i=88.95 cs/acc_c=89.58 os/recall_knw=75.61 os/recall_unk=89.65 total/acc_i=79.14 total/acc_c=75.98 total/h_score=81.85\n",
      "Loss: 2.2867378541513492\n",
      "Loss: 1.079116036429217\n",
      "Loss: 0.8494454512470647\n",
      "Loss: 0.750746136041064\n",
      "Loss: 0.7031891286177071\n",
      "Loss: 0.632332538352593\n",
      "Loss: 0.597371737276645\n",
      "Loss: 0.5813882502874261\n",
      "Loss: 0.5540110291422982\n",
      "Loss: 0.5316060231508393\n",
      "______\n",
      "Iteration t=6\n",
      "all:  cs/acc_i=90.19 cs/acc_c=90.77 os/recall_knw=77.56 os/recall_unk=86.63 total/acc_i=79.06 total/acc_c=76.98 total/h_score=81.25\n",
      "selected:  cs/acc_i=89.98 cs/acc_c=90.61 os/recall_knw=76.44 os/recall_unk=87.15 total/acc_i=78.71 total/acc_c=76.48 total/h_score=81.17\n",
      "Loss: 2.2711280526653415\n",
      "Loss: 1.0512712465178582\n",
      "Loss: 0.8148412739076922\n",
      "Loss: 0.7225348323583602\n",
      "Loss: 0.663431667897009\n",
      "Loss: 0.6477401580060682\n",
      "Loss: 0.6013815580837188\n",
      "Loss: 0.566906244235654\n",
      "Loss: 0.5360242016373142\n",
      "Loss: 0.5224681704034728\n",
      "______\n",
      "Iteration t=7\n",
      "all:  cs/acc_i=90.45 cs/acc_c=91.03 os/recall_knw=77.56 os/recall_unk=86.75 total/acc_i=79.10 total/acc_c=76.99 total/h_score=81.30\n",
      "selected:  cs/acc_i=90.45 cs/acc_c=91.07 os/recall_knw=77.27 os/recall_unk=86.85 total/acc_i=79.02 total/acc_c=76.94 total/h_score=81.32\n",
      "Loss: 2.2334886872844333\n",
      "Loss: 1.040107529918859\n",
      "Loss: 0.8301881092369177\n",
      "Loss: 0.7320482590395934\n",
      "Loss: 0.6675162183441175\n",
      "Loss: 0.6191257561562927\n",
      "Loss: 0.581202256119555\n",
      "Loss: 0.5636294281501679\n",
      "Loss: 0.533498581664957\n",
      "Loss: 0.517727894862746\n",
      "______\n",
      "Iteration t=8\n",
      "all:  cs/acc_i=90.42 cs/acc_c=90.98 os/recall_knw=77.56 os/recall_unk=86.75 total/acc_i=79.10 total/acc_c=76.99 total/h_score=81.30\n",
      "selected:  cs/acc_i=90.42 cs/acc_c=90.98 os/recall_knw=77.56 os/recall_unk=86.75 total/acc_i=79.10 total/acc_c=76.99 total/h_score=81.30\n",
      "Loss: 2.238049476487296\n",
      "Loss: 1.0420495218700834\n",
      "Loss: 0.8170799660304237\n",
      "Loss: 0.7266048140469051\n",
      "Loss: 0.6886143744464904\n",
      "Loss: 0.6341420784356102\n",
      "Loss: 0.6026507806210291\n",
      "Loss: 0.5427042329831729\n",
      "Loss: 0.5490367763572269\n",
      "Loss: 0.5071708102547933\n",
      "______\n",
      "Iteration t=9\n",
      "all:  cs/acc_i=90.45 cs/acc_c=90.99 os/recall_knw=77.56 os/recall_unk=86.75 total/acc_i=79.10 total/acc_c=76.99 total/h_score=81.30\n",
      "selected:  cs/acc_i=90.45 cs/acc_c=90.99 os/recall_knw=77.56 os/recall_unk=86.75 total/acc_i=79.10 total/acc_c=76.99 total/h_score=81.30\n",
      "tensor(0)\n",
      "all:  cs/acc_i=90.45 cs/acc_c=90.99 os/recall_knw=77.56 os/recall_unk=86.75 total/acc_i=79.10 total/acc_c=76.99 total/h_score=81.30\n",
      "sketch -> real lr= 0.001 seed= 2\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19]\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20]\n",
      "Loss: 2.6123079404366756\n",
      "Loss: 1.5997402710197246\n",
      "Loss: 1.2468471574572335\n",
      "Loss: 1.1111189021473438\n",
      "Loss: 1.0092086166934628\n",
      "Loss: 0.9224037389575908\n",
      "Loss: 0.8761751982754311\n",
      "Loss: 0.837975012253871\n",
      "Loss: 0.7957489168749446\n",
      "Loss: 0.7531262955306905\n",
      "tensor(True) tensor(True)\n",
      "______\n",
      "Iteration t=1\n",
      "all:  cs/acc_i=85.93 cs/acc_c=86.85 os/recall_knw=96.48 os/recall_unk=22.99 total/acc_i=64.47 total/acc_c=83.08 total/h_score=36.29\n",
      "selected:  cs/acc_i=85.71 cs/acc_c=86.67 os/recall_knw=82.65 os/recall_unk=99.23 total/acc_i=88.01 total/acc_c=83.79 total/h_score=90.40\n",
      "Loss: 2.5475703375261336\n",
      "Loss: 1.4268700685657438\n",
      "Loss: 1.0997030705702109\n",
      "Loss: 0.9894281166498778\n",
      "Loss: 0.9100266434862966\n",
      "Loss: 0.8369197261626603\n",
      "Loss: 0.7672644372357696\n",
      "Loss: 0.7740906379261955\n",
      "Loss: 0.7486431373924506\n",
      "Loss: 0.6831377480850845\n",
      "______\n",
      "Iteration t=2\n",
      "all:  cs/acc_i=87.47 cs/acc_c=88.27 os/recall_knw=81.17 os/recall_unk=78.02 total/acc_i=77.99 total/acc_c=79.10 total/h_score=78.58\n",
      "selected:  cs/acc_i=81.52 cs/acc_c=83.40 os/recall_knw=63.89 os/recall_unk=99.32 total/acc_i=78.74 total/acc_c=68.34 total/h_score=79.87\n",
      "Loss: 2.4509071830574793\n",
      "Loss: 1.3327486207921997\n",
      "Loss: 1.0334539185953504\n",
      "Loss: 0.8782670820942362\n",
      "Loss: 0.7900145157375409\n",
      "Loss: 0.7557442909433641\n",
      "Loss: 0.7228501825842238\n",
      "Loss: 0.6963265695189702\n",
      "Loss: 0.6533830140838186\n",
      "Loss: 0.627057486818037\n",
      "______\n",
      "Iteration t=3\n",
      "all:  cs/acc_i=88.41 cs/acc_c=89.08 os/recall_knw=72.83 os/recall_unk=89.25 total/acc_i=77.24 total/acc_c=73.31 total/h_score=80.01\n",
      "selected:  cs/acc_i=85.73 cs/acc_c=86.65 os/recall_knw=64.26 os/recall_unk=97.53 total/acc_i=76.04 total/acc_c=66.82 total/h_score=78.22\n",
      "Loss: 2.352318392859565\n",
      "Loss: 1.203997816022579\n",
      "Loss: 0.9523038923954024\n",
      "Loss: 0.8282623571947911\n",
      "Loss: 0.7766607037368214\n",
      "Loss: 0.7103120879033133\n",
      "Loss: 0.6800456526672541\n",
      "Loss: 0.6449776780007134\n",
      "Loss: 0.6029812957971327\n",
      "Loss: 0.572194651143098\n",
      "______\n",
      "Iteration t=4\n",
      "all:  cs/acc_i=89.27 cs/acc_c=89.88 os/recall_knw=72.27 os/recall_unk=89.84 total/acc_i=77.10 total/acc_c=72.86 total/h_score=79.94\n",
      "selected:  cs/acc_i=88.21 cs/acc_c=88.87 os/recall_knw=68.31 os/recall_unk=94.80 total/acc_i=76.77 total/acc_c=70.15 total/h_score=79.81\n",
      "Loss: 2.325593745055264\n",
      "Loss: 1.130928536800489\n",
      "Loss: 0.8977918163554309\n",
      "Loss: 0.8003537328275916\n",
      "Loss: 0.7237139125801113\n",
      "Loss: 0.6624505831668638\n",
      "Loss: 0.6199972776517476\n",
      "Loss: 0.5970860644154352\n",
      "Loss: 0.576707225956329\n",
      "Loss: 0.5556844108010808\n",
      "______\n",
      "Iteration t=5\n",
      "all:  cs/acc_i=90.04 cs/acc_c=90.68 os/recall_knw=72.01 os/recall_unk=90.02 total/acc_i=76.98 total/acc_c=72.64 total/h_score=79.87\n",
      "selected:  cs/acc_i=89.64 cs/acc_c=90.39 os/recall_knw=70.17 os/recall_unk=91.82 total/acc_i=76.68 total/acc_c=71.59 total/h_score=79.81\n",
      "Loss: 2.2815653181076048\n",
      "Loss: 1.0885838377475738\n",
      "Loss: 0.8522491377592086\n",
      "Loss: 0.7806579351425171\n",
      "Loss: 0.7114650785923005\n",
      "Loss: 0.6490663035710653\n",
      "Loss: 0.6256703662872315\n",
      "Loss: 0.591202025214831\n",
      "Loss: 0.5580671381453673\n",
      "Loss: 0.5426333241164685\n",
      "______\n",
      "Iteration t=6\n",
      "all:  cs/acc_i=90.10 cs/acc_c=90.61 os/recall_knw=71.95 os/recall_unk=90.14 total/acc_i=77.00 total/acc_c=72.63 total/h_score=79.90\n",
      "selected:  cs/acc_i=90.07 cs/acc_c=90.58 os/recall_knw=71.63 os/recall_unk=90.35 total/acc_i=76.95 total/acc_c=72.46 total/h_score=79.87\n",
      "Loss: 2.2685782052333057\n",
      "Loss: 1.0785755035923976\n",
      "Loss: 0.8389374391705382\n",
      "Loss: 0.7689512095420189\n",
      "Loss: 0.69422458511552\n",
      "Loss: 0.6422526055301716\n",
      "Loss: 0.629253520392904\n",
      "Loss: 0.5915624505164576\n",
      "Loss: 0.556274371258184\n",
      "Loss: 0.5275996535334712\n",
      "______\n",
      "Iteration t=7\n",
      "all:  cs/acc_i=90.13 cs/acc_c=90.68 os/recall_knw=71.95 os/recall_unk=90.14 total/acc_i=77.00 total/acc_c=72.63 total/h_score=79.90\n",
      "selected:  cs/acc_i=90.14 cs/acc_c=90.72 os/recall_knw=71.90 os/recall_unk=90.19 total/acc_i=77.01 total/acc_c=72.64 total/h_score=79.93\n",
      "Loss: 2.268258431447057\n",
      "Loss: 1.0797409269631104\n",
      "Loss: 0.8579207939317249\n",
      "Loss: 0.7658240180644617\n",
      "Loss: 0.6881168669617526\n",
      "Loss: 0.6422173385705544\n",
      "Loss: 0.6173408123685793\n",
      "Loss: 0.5878907591104507\n",
      "Loss: 0.5356997459253193\n",
      "Loss: 0.5241318975092922\n",
      "______\n",
      "Iteration t=8\n",
      "all:  cs/acc_i=90.60 cs/acc_c=91.23 os/recall_knw=71.95 os/recall_unk=90.14 total/acc_i=77.00 total/acc_c=72.63 total/h_score=79.90\n",
      "selected:  cs/acc_i=90.60 cs/acc_c=91.23 os/recall_knw=71.95 os/recall_unk=90.14 total/acc_i=77.00 total/acc_c=72.63 total/h_score=79.90\n",
      "Loss: 2.2594240166077006\n",
      "Loss: 1.0652148971146016\n",
      "Loss: 0.8642700359176735\n",
      "Loss: 0.7349395594690056\n",
      "Loss: 0.6858132590300097\n",
      "Loss: 0.6361947167871053\n",
      "Loss: 0.6077599933656108\n",
      "Loss: 0.5665835902240455\n",
      "Loss: 0.5426044249573437\n",
      "Loss: 0.5206815429056117\n",
      "______\n",
      "Iteration t=9\n",
      "all:  cs/acc_i=89.92 cs/acc_c=90.46 os/recall_knw=71.95 os/recall_unk=90.14 total/acc_i=77.00 total/acc_c=72.63 total/h_score=79.90\n",
      "selected:  cs/acc_i=89.92 cs/acc_c=90.46 os/recall_knw=71.95 os/recall_unk=90.14 total/acc_i=77.00 total/acc_c=72.63 total/h_score=79.90\n",
      "tensor(0)\n",
      "all:  cs/acc_i=89.92 cs/acc_c=90.46 os/recall_knw=71.95 os/recall_unk=90.14 total/acc_i=77.00 total/acc_c=72.63 total/h_score=79.90\n",
      "sketch -> real lr= 0.001 seed= 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19]\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20]\n",
      "Loss: 2.6005660675268256\n",
      "Loss: 1.564824438464325\n",
      "Loss: 1.2451776036646514\n",
      "Loss: 1.104117184349921\n",
      "Loss: 1.002673167306765\n",
      "Loss: 0.9309072088351292\n",
      "Loss: 0.8877443683094683\n",
      "Loss: 0.8236742449545227\n",
      "Loss: 0.8003799521026358\n",
      "Loss: 0.7601169703808506\n",
      "tensor(True) tensor(True)\n",
      "______\n",
      "Iteration t=1\n",
      "all:  cs/acc_i=86.43 cs/acc_c=87.37 os/recall_knw=96.75 os/recall_unk=23.53 total/acc_i=64.94 total/acc_c=83.53 total/h_score=37.00\n",
      "selected:  cs/acc_i=87.33 cs/acc_c=88.26 os/recall_knw=83.80 os/recall_unk=99.25 total/acc_i=88.96 total/acc_c=84.73 total/h_score=90.99\n",
      "Loss: 2.5749437261800296\n",
      "Loss: 1.4446322556401863\n",
      "Loss: 1.0939124060458825\n",
      "Loss: 0.9929699062323961\n",
      "Loss: 0.9076522324906021\n",
      "Loss: 0.8387700404788627\n",
      "Loss: 0.7831810015391131\n",
      "Loss: 0.7412707235236637\n",
      "Loss: 0.7049075122006604\n",
      "Loss: 0.6858262737877057\n",
      "______\n",
      "Iteration t=2\n",
      "all:  cs/acc_i=87.58 cs/acc_c=88.37 os/recall_knw=80.02 os/recall_unk=80.75 total/acc_i=78.29 total/acc_c=78.46 total/h_score=79.53\n",
      "selected:  cs/acc_i=81.71 cs/acc_c=83.44 os/recall_knw=62.53 os/recall_unk=99.63 total/acc_i=78.19 total/acc_c=67.06 total/h_score=78.99\n",
      "Loss: 2.4405329250197374\n",
      "Loss: 1.267420943911749\n",
      "Loss: 0.99530824472886\n",
      "Loss: 0.8998325376110222\n",
      "Loss: 0.8099697996641844\n",
      "Loss: 0.7544198322842139\n",
      "Loss: 0.7359396037254625\n",
      "Loss: 0.6929896468197116\n",
      "Loss: 0.6568969898778974\n",
      "Loss: 0.6288884753034315\n",
      "______\n",
      "Iteration t=3\n",
      "all:  cs/acc_i=88.86 cs/acc_c=89.53 os/recall_knw=72.10 os/recall_unk=90.26 total/acc_i=77.08 total/acc_c=72.73 total/h_score=80.01\n",
      "selected:  cs/acc_i=86.43 cs/acc_c=87.31 os/recall_knw=63.82 os/recall_unk=98.19 total/acc_i=75.89 total/acc_c=66.37 total/h_score=78.06\n",
      "Loss: 2.3718924642036465\n",
      "Loss: 1.1779388444611676\n",
      "Loss: 0.8980957580510006\n",
      "Loss: 0.8187908545723953\n",
      "Loss: 0.7599723200216942\n",
      "Loss: 0.7064945390147548\n",
      "Loss: 0.6625222444107028\n",
      "Loss: 0.6277123690719673\n",
      "Loss: 0.5975215554130547\n",
      "Loss: 0.5679904964341912\n",
      "______\n",
      "Iteration t=4\n",
      "all:  cs/acc_i=89.21 cs/acc_c=89.80 os/recall_knw=70.53 os/recall_unk=91.15 total/acc_i=76.47 total/acc_c=71.61 total/h_score=79.59\n",
      "selected:  cs/acc_i=88.11 cs/acc_c=88.77 os/recall_knw=66.80 os/recall_unk=94.28 total/acc_i=75.64 total/acc_c=68.68 total/h_score=78.61\n",
      "Loss: 2.3002834863042176\n",
      "Loss: 1.141966554400039\n",
      "Loss: 0.9024573188938506\n",
      "Loss: 0.7897151673901571\n",
      "Loss: 0.7374263617069754\n",
      "Loss: 0.6665683250925313\n",
      "Loss: 0.646418725127635\n",
      "Loss: 0.6239514102878636\n",
      "Loss: 0.5773863048382002\n",
      "Loss: 0.5556132041734375\n",
      "______\n",
      "Iteration t=5\n",
      "all:  cs/acc_i=89.62 cs/acc_c=90.21 os/recall_knw=70.53 os/recall_unk=91.15 total/acc_i=76.47 total/acc_c=71.61 total/h_score=79.59\n",
      "selected:  cs/acc_i=89.25 cs/acc_c=89.88 os/recall_knw=69.04 os/recall_unk=91.97 total/acc_i=76.02 total/acc_c=70.55 total/h_score=79.16\n",
      "Loss: 2.286606786251068\n",
      "Loss: 1.1012457696596782\n",
      "Loss: 0.8479463378588359\n",
      "Loss: 0.7826776649554571\n",
      "Loss: 0.7064149797956149\n",
      "Loss: 0.6813691214720408\n",
      "Loss: 0.6399864492317041\n",
      "Loss: 0.5817671184738477\n",
      "Loss: 0.5517665968835354\n",
      "Loss: 0.55140458141764\n",
      "______\n",
      "Iteration t=6\n",
      "all:  cs/acc_i=90.42 cs/acc_c=90.89 os/recall_knw=70.53 os/recall_unk=91.27 total/acc_i=76.51 total/acc_c=71.61 total/h_score=79.63\n",
      "selected:  cs/acc_i=90.40 cs/acc_c=90.88 os/recall_knw=70.18 os/recall_unk=91.32 total/acc_i=76.40 total/acc_c=71.42 total/h_score=79.52\n",
      "Loss: 2.2622494866189204\n",
      "Loss: 1.0610057325347473\n",
      "Loss: 0.8487345225324756\n",
      "Loss: 0.7367020011144249\n",
      "Loss: 0.7126756083024176\n",
      "Loss: 0.6342319521660867\n",
      "Loss: 0.618467988348321\n",
      "Loss: 0.5993479268723413\n",
      "Loss: 0.5483426656574011\n",
      "Loss: 0.5305216252117565\n",
      "______\n",
      "Iteration t=7\n",
      "all:  cs/acc_i=89.89 cs/acc_c=90.45 os/recall_knw=70.50 os/recall_unk=91.27 total/acc_i=76.51 total/acc_c=71.61 total/h_score=79.63\n",
      "selected:  cs/acc_i=89.90 cs/acc_c=90.46 os/recall_knw=70.45 os/recall_unk=91.27 total/acc_i=76.50 total/acc_c=71.60 total/h_score=79.62\n",
      "Loss: 2.2680713004753237\n",
      "Loss: 1.0982109753811946\n",
      "Loss: 0.851449988806834\n",
      "Loss: 0.7639639518300041\n",
      "Loss: 0.686117407337564\n",
      "Loss: 0.6478652706888856\n",
      "Loss: 0.5971204487515278\n",
      "Loss: 0.5860067867353315\n",
      "Loss: 0.5552030361333832\n",
      "Loss: 0.5325295599757648\n",
      "______\n",
      "Iteration t=8\n",
      "all:  cs/acc_i=89.98 cs/acc_c=90.56 os/recall_knw=70.50 os/recall_unk=91.27 total/acc_i=76.51 total/acc_c=71.61 total/h_score=79.63\n",
      "selected:  cs/acc_i=89.98 cs/acc_c=90.56 os/recall_knw=70.50 os/recall_unk=91.27 total/acc_i=76.51 total/acc_c=71.61 total/h_score=79.63\n",
      "Loss: 2.278891040458054\n",
      "Loss: 1.0583678224047677\n",
      "Loss: 0.8514062344050798\n",
      "Loss: 0.7527501052520315\n",
      "Loss: 0.6843514942732014\n",
      "Loss: 0.6688789851841379\n",
      "Loss: 0.6180904665931326\n",
      "Loss: 0.5791834968523901\n",
      "Loss: 0.5555901290451895\n",
      "Loss: 0.5278684877469891\n",
      "______\n",
      "Iteration t=9\n",
      "all:  cs/acc_i=90.39 cs/acc_c=90.87 os/recall_knw=70.50 os/recall_unk=91.27 total/acc_i=76.51 total/acc_c=71.61 total/h_score=79.63\n",
      "selected:  cs/acc_i=90.39 cs/acc_c=90.87 os/recall_knw=70.50 os/recall_unk=91.27 total/acc_i=76.51 total/acc_c=71.61 total/h_score=79.63\n",
      "tensor(0)\n",
      "all:  cs/acc_i=90.39 cs/acc_c=90.87 os/recall_knw=70.50 os/recall_unk=91.27 total/acc_i=76.51 total/acc_c=71.61 total/h_score=79.63\n",
      "sketch -> real lr= 0.001 seed= 4\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19]\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20]\n",
      "Loss: 2.619465008773635\n",
      "Loss: 1.589929378665654\n",
      "Loss: 1.2493617415955636\n",
      "Loss: 1.1037496489233676\n",
      "Loss: 1.015203205621348\n",
      "Loss: 0.9480972477292593\n",
      "Loss: 0.8835571639041985\n",
      "Loss: 0.8245998507579871\n",
      "Loss: 0.7894172433730775\n",
      "Loss: 0.7582148990008684\n",
      "tensor(True) tensor(True)\n",
      "______\n",
      "Iteration t=1\n",
      "all:  cs/acc_i=86.31 cs/acc_c=87.29 os/recall_knw=96.22 os/recall_unk=22.46 total/acc_i=64.45 total/acc_c=83.31 total/h_score=35.65\n",
      "selected:  cs/acc_i=85.49 cs/acc_c=86.80 os/recall_knw=81.61 os/recall_unk=99.47 total/acc_i=87.36 total/acc_c=83.20 total/h_score=90.13\n",
      "Loss: 2.5372050336149874\n",
      "Loss: 1.4250100670290775\n",
      "Loss: 1.0970838463208714\n",
      "Loss: 0.9749940968439227\n",
      "Loss: 0.8987771304415875\n",
      "Loss: 0.8485405482962484\n",
      "Loss: 0.7867622023723164\n",
      "Loss: 0.7547907029874013\n",
      "Loss: 0.7086730573753841\n",
      "Loss: 0.6608345991641772\n",
      "______\n",
      "Iteration t=2\n",
      "all:  cs/acc_i=87.73 cs/acc_c=88.57 os/recall_knw=82.77 os/recall_unk=75.88 total/acc_i=78.09 total/acc_c=80.17 total/h_score=78.07\n",
      "selected:  cs/acc_i=82.12 cs/acc_c=84.09 os/recall_knw=65.93 os/recall_unk=99.61 total/acc_i=79.95 total/acc_c=70.30 total/h_score=81.41\n",
      "Loss: 2.446204725567621\n",
      "Loss: 1.29052868439951\n",
      "Loss: 1.011748893570354\n",
      "Loss: 0.889724506676652\n",
      "Loss: 0.8152230553727113\n",
      "Loss: 0.7633337436514046\n",
      "Loss: 0.722673979310589\n",
      "Loss: 0.6866885813251706\n",
      "Loss: 0.6538041369378111\n",
      "Loss: 0.6332710087299347\n",
      "______\n",
      "Iteration t=3\n",
      "all:  cs/acc_i=88.65 cs/acc_c=89.32 os/recall_knw=70.68 os/recall_unk=89.96 total/acc_i=76.19 total/acc_c=71.59 total/h_score=79.16\n",
      "selected:  cs/acc_i=86.33 cs/acc_c=87.24 os/recall_knw=62.54 os/recall_unk=97.87 total/acc_i=75.02 total/acc_c=65.60 total/h_score=77.38\n",
      "Loss: 2.3751819424304483\n",
      "Loss: 1.19202879765555\n",
      "Loss: 0.9228140299465494\n",
      "Loss: 0.8113780322895255\n",
      "Loss: 0.7723784578102891\n",
      "Loss: 0.7297711024147635\n",
      "Loss: 0.6807538920405946\n",
      "Loss: 0.6441458603600875\n",
      "Loss: 0.6002228163903759\n",
      "Loss: 0.5884576002970391\n",
      "______\n",
      "Iteration t=4\n",
      "all:  cs/acc_i=89.62 cs/acc_c=90.21 os/recall_knw=70.62 os/recall_unk=90.08 total/acc_i=76.21 total/acc_c=71.57 total/h_score=79.18\n",
      "selected:  cs/acc_i=88.51 cs/acc_c=89.16 os/recall_knw=66.71 os/recall_unk=95.35 total/acc_i=75.87 total/acc_c=68.85 total/h_score=79.06\n",
      "Loss: 2.316804378303056\n",
      "Loss: 1.1439075771066332\n",
      "Loss: 0.8844769160772107\n",
      "Loss: 0.8041083397939033\n",
      "Loss: 0.7379525084675792\n",
      "Loss: 0.6790779964211061\n",
      "Loss: 0.6434713371123645\n",
      "Loss: 0.6180633918423832\n",
      "Loss: 0.593453934409774\n",
      "Loss: 0.5562029146554134\n",
      "______\n",
      "Iteration t=5\n",
      "all:  cs/acc_i=89.98 cs/acc_c=90.56 os/recall_knw=70.38 os/recall_unk=90.14 total/acc_i=76.08 total/acc_c=71.37 total/h_score=79.07\n",
      "selected:  cs/acc_i=89.58 cs/acc_c=90.23 os/recall_knw=68.75 os/recall_unk=91.06 total/acc_i=75.57 total/acc_c=70.37 total/h_score=78.73\n",
      "Loss: 2.2864139691988625\n",
      "Loss: 1.087355005244414\n",
      "Loss: 0.8786485425631205\n",
      "Loss: 0.7702069055040678\n",
      "Loss: 0.7055788030227025\n",
      "Loss: 0.6363286790748437\n",
      "Loss: 0.6268314222494761\n",
      "Loss: 0.5862945635120074\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.5459281965593497\n",
      "Loss: 0.5385896780590216\n",
      "______\n",
      "Iteration t=6\n",
      "all:  cs/acc_i=89.86 cs/acc_c=90.49 os/recall_knw=70.38 os/recall_unk=90.20 total/acc_i=76.10 total/acc_c=71.37 total/h_score=79.10\n",
      "selected:  cs/acc_i=89.70 cs/acc_c=90.40 os/recall_knw=69.64 os/recall_unk=90.46 total/acc_i=75.83 total/acc_c=71.04 total/h_score=78.97\n",
      "Loss: 2.278196706630216\n",
      "Loss: 1.0687266339366586\n",
      "Loss: 0.8487254869033007\n",
      "Loss: 0.7743120821002293\n",
      "Loss: 0.7082010721511179\n",
      "Loss: 0.6447711254995648\n",
      "Loss: 0.608893860488048\n",
      "Loss: 0.5815864887469673\n",
      "Loss: 0.5726708581443667\n",
      "Loss: 0.5400253730540229\n",
      "______\n",
      "Iteration t=7\n",
      "all:  cs/acc_i=90.16 cs/acc_c=90.77 os/recall_knw=70.38 os/recall_unk=90.20 total/acc_i=76.12 total/acc_c=71.40 total/h_score=79.11\n",
      "selected:  cs/acc_i=90.15 cs/acc_c=90.75 os/recall_knw=70.35 os/recall_unk=90.20 total/acc_i=76.10 total/acc_c=71.36 total/h_score=79.09\n",
      "Loss: 2.2630169843536576\n",
      "Loss: 1.0850023910695432\n",
      "Loss: 0.8385196869669397\n",
      "Loss: 0.763845859643291\n",
      "Loss: 0.7021395875737558\n",
      "Loss: 0.6471276199992966\n",
      "Loss: 0.6060548805528216\n",
      "Loss: 0.5732017133652775\n",
      "Loss: 0.5547270873695417\n",
      "Loss: 0.524730187785976\n",
      "______\n",
      "Iteration t=8\n",
      "all:  cs/acc_i=90.13 cs/acc_c=90.66 os/recall_knw=70.38 os/recall_unk=90.20 total/acc_i=76.10 total/acc_c=71.37 total/h_score=79.10\n",
      "selected:  cs/acc_i=90.13 cs/acc_c=90.66 os/recall_knw=70.38 os/recall_unk=90.20 total/acc_i=76.10 total/acc_c=71.37 total/h_score=79.10\n",
      "Loss: 2.264892977437163\n",
      "Loss: 1.042723855356765\n",
      "Loss: 0.8441394399973302\n",
      "Loss: 0.7448911806142408\n",
      "Loss: 0.6967849702227349\n",
      "Loss: 0.6317420942721024\n",
      "Loss: 0.6091122320956655\n",
      "Loss: 0.5772430111282791\n",
      "Loss: 0.5492492086357541\n",
      "Loss: 0.5221951710535031\n",
      "______\n",
      "Iteration t=9\n",
      "all:  cs/acc_i=89.95 cs/acc_c=90.52 os/recall_knw=70.38 os/recall_unk=90.20 total/acc_i=76.10 total/acc_c=71.37 total/h_score=79.10\n",
      "selected:  cs/acc_i=89.95 cs/acc_c=90.52 os/recall_knw=70.38 os/recall_unk=90.20 total/acc_i=76.10 total/acc_c=71.37 total/h_score=79.10\n",
      "tensor(0)\n",
      "all:  cs/acc_i=89.95 cs/acc_c=90.52 os/recall_knw=70.38 os/recall_unk=90.20 total/acc_i=76.10 total/acc_c=71.37 total/h_score=79.10\n",
      "sketch -> real lr= 0.001 seed= 0\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19]\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20]\n",
      "Loss: 2.618657082582997\n",
      "Loss: 1.6027593776188065\n",
      "Loss: 1.260333508516835\n",
      "Loss: 1.0978593335742444\n",
      "Loss: 1.0024385754249792\n",
      "Loss: 0.9414476102168581\n",
      "Loss: 0.8837950812504355\n",
      "Loss: 0.8298573116813086\n",
      "Loss: 0.7930356774446183\n",
      "Loss: 0.7889388766700187\n",
      "tensor(True) tensor(True)\n",
      "______\n",
      "Iteration t=1\n",
      "all:  cs/acc_i=86.64 cs/acc_c=87.66 os/recall_knw=96.48 os/recall_unk=22.99 total/acc_i=64.96 total/acc_c=83.90 total/h_score=36.37\n",
      "selected:  cs/acc_i=85.80 cs/acc_c=87.91 os/recall_knw=82.75 os/recall_unk=99.49 total/acc_i=88.23 total/acc_c=85.31 total/h_score=91.44\n",
      "Loss: 2.5459656759363707\n",
      "Loss: 1.4400427146036117\n",
      "Loss: 1.1119939022865453\n",
      "Loss: 0.9954142000098698\n",
      "Loss: 0.8962929689737617\n",
      "Loss: 0.8598739228776244\n",
      "Loss: 0.797122842708572\n",
      "Loss: 0.7487902768322678\n",
      "Loss: 0.7044748616267423\n",
      "Loss: 0.6939859181398251\n",
      "______\n",
      "Iteration t=2\n",
      "all:  cs/acc_i=87.76 cs/acc_c=88.51 os/recall_knw=75.67 os/recall_unk=86.39 total/acc_i=77.91 total/acc_c=75.59 total/h_score=80.33\n",
      "selected:  cs/acc_i=81.63 cs/acc_c=83.26 os/recall_knw=57.77 os/recall_unk=99.38 total/acc_i=75.29 total/acc_c=62.70 total/h_score=75.50\n",
      "Loss: 2.4400786916718227\n",
      "Loss: 1.2926342928682575\n",
      "Loss: 1.010247062408287\n",
      "Loss: 0.8762811041287794\n",
      "Loss: 0.8415533967373026\n",
      "Loss: 0.7729125221949498\n",
      "Loss: 0.7273526126874312\n",
      "Loss: 0.6673881148791495\n",
      "Loss: 0.6453222574395988\n",
      "Loss: 0.6096770309537421\n",
      "______\n",
      "Iteration t=3\n",
      "all:  cs/acc_i=88.94 cs/acc_c=89.63 os/recall_knw=74.22 os/recall_unk=88.29 total/acc_i=77.71 total/acc_c=74.56 total/h_score=80.44\n",
      "selected:  cs/acc_i=86.61 cs/acc_c=87.42 os/recall_knw=65.34 os/recall_unk=97.89 total/acc_i=77.02 total/acc_c=68.38 total/h_score=79.48\n",
      "Loss: 2.3848534873921237\n",
      "Loss: 1.2120748250175724\n",
      "Loss: 0.942813443837406\n",
      "Loss: 0.840707017685012\n",
      "Loss: 0.7505397920985873\n",
      "Loss: 0.6856463273866571\n",
      "Loss: 0.6886951318747706\n",
      "Loss: 0.6252746711746394\n",
      "Loss: 0.6213670357954588\n",
      "Loss: 0.5785945795958848\n",
      "______\n",
      "Iteration t=4\n",
      "all:  cs/acc_i=89.89 cs/acc_c=90.45 os/recall_knw=73.93 os/recall_unk=88.41 total/acc_i=77.60 total/acc_c=74.34 total/h_score=80.35\n",
      "selected:  cs/acc_i=89.07 cs/acc_c=89.59 os/recall_knw=69.98 os/recall_unk=93.88 total/acc_i=77.54 total/acc_c=71.71 total/h_score=80.60\n",
      "Loss: 2.293914118317614\n",
      "Loss: 1.0949832514284414\n",
      "Loss: 0.8720296700659872\n",
      "Loss: 0.7757634708702361\n",
      "Loss: 0.7106564414175705\n",
      "Loss: 0.6731947100508335\n",
      "Loss: 0.6206263784357305\n",
      "Loss: 0.6253015141133156\n",
      "Loss: 0.580876200882648\n",
      "Loss: 0.5483984660624237\n",
      "______\n",
      "Iteration t=5\n",
      "all:  cs/acc_i=90.04 cs/acc_c=90.61 os/recall_knw=73.78 os/recall_unk=88.53 total/acc_i=77.58 total/acc_c=74.28 total/h_score=80.36\n",
      "selected:  cs/acc_i=89.62 cs/acc_c=90.13 os/recall_knw=71.77 os/recall_unk=90.52 total/acc_i=77.28 total/acc_c=73.02 total/h_score=80.30\n",
      "Loss: 2.2876880826348085\n",
      "Loss: 1.0881408629227318\n",
      "Loss: 0.8452984708488186\n",
      "Loss: 0.7412171157887608\n",
      "Loss: 0.6950164801654626\n",
      "Loss: 0.6618717890542211\n",
      "Loss: 0.5923189314397863\n",
      "Loss: 0.5937019928646247\n",
      "Loss: 0.5451233891702174\n",
      "Loss: 0.5202856044535621\n",
      "______\n",
      "Iteration t=6\n",
      "all:  cs/acc_i=90.30 cs/acc_c=90.84 os/recall_knw=73.72 os/recall_unk=88.71 total/acc_i=77.60 total/acc_c=74.22 total/h_score=80.39\n",
      "selected:  cs/acc_i=90.16 cs/acc_c=90.68 os/recall_knw=72.85 os/recall_unk=88.97 total/acc_i=77.30 total/acc_c=73.73 total/h_score=80.18\n",
      "Loss: 2.2505732015067457\n",
      "Loss: 1.0628356380400314\n",
      "Loss: 0.8504421898936914\n",
      "Loss: 0.7596631849708121\n",
      "Loss: 0.6760143150691114\n",
      "Loss: 0.6371835787701451\n",
      "Loss: 0.6072622782069873\n",
      "Loss: 0.5729048294958725\n",
      "Loss: 0.5372997191704176\n",
      "Loss: 0.5337758247856221\n",
      "______\n",
      "Iteration t=7\n",
      "all:  cs/acc_i=90.39 cs/acc_c=90.95 os/recall_knw=73.72 os/recall_unk=88.71 total/acc_i=77.60 total/acc_c=74.22 total/h_score=80.39\n",
      "selected:  cs/acc_i=90.35 cs/acc_c=90.91 os/recall_knw=73.51 os/recall_unk=88.71 total/acc_i=77.50 total/acc_c=74.11 total/h_score=80.32\n",
      "Loss: 2.260776720000702\n",
      "Loss: 1.0486314757742157\n",
      "Loss: 0.851491691803855\n",
      "Loss: 0.7345495507555101\n",
      "Loss: 0.6873922150304788\n",
      "Loss: 0.6482682269078628\n",
      "Loss: 0.5999340323857891\n",
      "Loss: 0.5719946047538307\n",
      "Loss: 0.5534973920452556\n",
      "Loss: 0.5243986067166221\n",
      "______\n",
      "Iteration t=8\n",
      "all:  cs/acc_i=90.16 cs/acc_c=90.75 os/recall_knw=73.72 os/recall_unk=88.71 total/acc_i=77.60 total/acc_c=74.22 total/h_score=80.39\n",
      "selected:  cs/acc_i=90.16 cs/acc_c=90.75 os/recall_knw=73.72 os/recall_unk=88.71 total/acc_i=77.60 total/acc_c=74.22 total/h_score=80.39\n",
      "Loss: 2.263656836171304\n",
      "Loss: 1.0725445560870632\n",
      "Loss: 0.847059156529365\n",
      "Loss: 0.7551092328563813\n",
      "Loss: 0.688128283667949\n",
      "Loss: 0.6280225100055817\n",
      "Loss: 0.6033254023040494\n",
      "Loss: 0.5594961409607241\n",
      "Loss: 0.5284723616415454\n",
      "Loss: 0.5101617339878313\n",
      "______\n",
      "Iteration t=9\n",
      "all:  cs/acc_i=90.27 cs/acc_c=90.80 os/recall_knw=73.72 os/recall_unk=88.71 total/acc_i=77.60 total/acc_c=74.22 total/h_score=80.39\n",
      "selected:  cs/acc_i=90.27 cs/acc_c=90.80 os/recall_knw=73.72 os/recall_unk=88.71 total/acc_i=77.60 total/acc_c=74.22 total/h_score=80.39\n",
      "tensor(0)\n",
      "all:  cs/acc_i=90.27 cs/acc_c=90.80 os/recall_knw=73.72 os/recall_unk=88.71 total/acc_i=77.60 total/acc_c=74.22 total/h_score=80.39\n",
      "sketch -> real lr= 0.001 seed= 1\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19]\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20]\n",
      "Loss: 2.613738921363797\n",
      "Loss: 1.6019761960590835\n",
      "Loss: 1.257021880782811\n",
      "Loss: 1.0890537563678437\n",
      "Loss: 1.042925431665066\n",
      "Loss: 0.9418403063200217\n",
      "Loss: 0.8831587123923597\n",
      "Loss: 0.81417624322714\n",
      "Loss: 0.7894220596129915\n",
      "Loss: 0.7459681903102756\n",
      "tensor(True) tensor(True)\n",
      "______\n",
      "Iteration t=1\n",
      "all:  cs/acc_i=86.67 cs/acc_c=87.70 os/recall_knw=97.04 os/recall_unk=24.12 total/acc_i=65.50 total/acc_c=84.17 total/h_score=37.79\n",
      "selected:  cs/acc_i=87.33 cs/acc_c=87.97 os/recall_knw=85.10 os/recall_unk=99.51 total/acc_i=90.08 total/acc_c=86.14 total/h_score=91.96\n",
      "Loss: 2.534782080865297\n",
      "Loss: 1.411873058461752\n",
      "Loss: 1.092377056596709\n",
      "Loss: 0.9480876947035555\n",
      "Loss: 0.8923738337442523\n",
      "Loss: 0.8666387229669289\n",
      "Loss: 0.7977263017511759\n",
      "Loss: 0.7597047085644769\n",
      "Loss: 0.717963555125428\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.6815275021019529\n",
      "______\n",
      "Iteration t=2\n",
      "all:  cs/acc_i=87.50 cs/acc_c=88.31 os/recall_knw=80.40 os/recall_unk=80.93 total/acc_i=78.42 total/acc_c=78.64 total/h_score=79.71\n",
      "selected:  cs/acc_i=81.81 cs/acc_c=83.62 os/recall_knw=63.00 os/recall_unk=99.56 total/acc_i=78.45 total/acc_c=67.63 total/h_score=79.41\n",
      "Loss: 2.4450407478645557\n",
      "Loss: 1.2889742141461555\n",
      "Loss: 1.0054263083534387\n",
      "Loss: 0.8986528789951601\n",
      "Loss: 0.8141890115865315\n",
      "Loss: 0.740288985822037\n",
      "Loss: 0.6935397021415579\n",
      "Loss: 0.6944929686666445\n",
      "Loss: 0.658040558222596\n",
      "Loss: 0.6462106587550113\n",
      "______\n",
      "Iteration t=3\n",
      "all:  cs/acc_i=88.50 cs/acc_c=89.23 os/recall_knw=73.93 os/recall_unk=89.19 total/acc_i=77.77 total/acc_c=74.30 total/h_score=80.62\n",
      "selected:  cs/acc_i=86.00 cs/acc_c=86.86 os/recall_knw=65.30 os/recall_unk=97.72 total/acc_i=76.80 total/acc_c=67.92 total/h_score=79.09\n",
      "Loss: 2.3858324819140964\n",
      "Loss: 1.19049165069416\n",
      "Loss: 0.9461534780627083\n",
      "Loss: 0.8305751123735982\n",
      "Loss: 0.7512100482072455\n",
      "Loss: 0.6861838475136774\n",
      "Loss: 0.667888647926751\n",
      "Loss: 0.6330400426541606\n",
      "Loss: 0.6074697891230224\n",
      "Loss: 0.5760991988323068\n",
      "______\n",
      "Iteration t=4\n",
      "all:  cs/acc_i=89.36 cs/acc_c=89.96 os/recall_knw=73.72 os/recall_unk=89.60 total/acc_i=77.83 total/acc_c=74.22 total/h_score=80.73\n",
      "selected:  cs/acc_i=88.41 cs/acc_c=88.96 os/recall_knw=69.96 os/recall_unk=94.90 total/acc_i=77.75 total/acc_c=71.75 total/h_score=80.96\n",
      "Loss: 2.3156258022419016\n",
      "Loss: 1.1318803850701238\n",
      "Loss: 0.8893871814927957\n",
      "Loss: 0.7697209912152013\n",
      "Loss: 0.722768345180225\n",
      "Loss: 0.6664020705955427\n",
      "Loss: 0.6287221227591355\n",
      "Loss: 0.6229723133528192\n",
      "Loss: 0.5687558622490424\n",
      "Loss: 0.5440015913886829\n",
      "______\n",
      "Iteration t=5\n",
      "all:  cs/acc_i=89.74 cs/acc_c=90.36 os/recall_knw=73.66 os/recall_unk=89.66 total/acc_i=77.81 total/acc_c=74.18 total/h_score=80.72\n",
      "selected:  cs/acc_i=89.31 cs/acc_c=89.92 os/recall_knw=71.89 os/recall_unk=91.23 total/acc_i=77.47 total/acc_c=73.06 total/h_score=80.58\n",
      "Loss: 2.287905444372569\n",
      "Loss: 1.0910590012736667\n",
      "Loss: 0.8622017422851348\n",
      "Loss: 0.740543035876672\n",
      "Loss: 0.6993970122953125\n",
      "Loss: 0.6649714147807747\n",
      "Loss: 0.617404501367089\n",
      "Loss: 0.5791464185477883\n",
      "Loss: 0.559337035709659\n",
      "Loss: 0.5188408259623098\n",
      "______\n",
      "Iteration t=6\n",
      "all:  cs/acc_i=89.95 cs/acc_c=90.55 os/recall_knw=73.63 os/recall_unk=89.84 total/acc_i=77.85 total/acc_c=74.14 total/h_score=80.76\n",
      "selected:  cs/acc_i=89.80 cs/acc_c=90.37 os/recall_knw=72.76 os/recall_unk=90.00 total/acc_i=77.53 total/acc_c=73.65 total/h_score=80.51\n",
      "Loss: 2.2810292602364535\n",
      "Loss: 1.0667707382463942\n",
      "Loss: 0.8116000858592052\n",
      "Loss: 0.7550158890244228\n",
      "Loss: 0.7024782487964318\n",
      "Loss: 0.6523511233964777\n",
      "Loss: 0.6044129647947605\n",
      "Loss: 0.5814086169588799\n",
      "Loss: 0.5457258112485113\n",
      "Loss: 0.5285416246434442\n",
      "______\n",
      "Iteration t=7\n",
      "all:  cs/acc_i=90.04 cs/acc_c=90.67 os/recall_knw=73.57 os/recall_unk=89.84 total/acc_i=77.81 total/acc_c=74.10 total/h_score=80.74\n",
      "selected:  cs/acc_i=90.03 cs/acc_c=90.66 os/recall_knw=73.46 os/recall_unk=89.84 total/acc_i=77.77 total/acc_c=74.05 total/h_score=80.71\n",
      "Loss: 2.25910964830022\n",
      "Loss: 1.0662800185502925\n",
      "Loss: 0.8539410805432156\n",
      "Loss: 0.747903588134494\n",
      "Loss: 0.6924791383801154\n",
      "Loss: 0.6536016742002617\n",
      "Loss: 0.6168923913757393\n",
      "Loss: 0.5690232459877687\n",
      "Loss: 0.5420318547768886\n",
      "Loss: 0.5241644837709692\n",
      "______\n",
      "Iteration t=8\n",
      "all:  cs/acc_i=90.01 cs/acc_c=90.58 os/recall_knw=73.57 os/recall_unk=89.84 total/acc_i=77.81 total/acc_c=74.10 total/h_score=80.74\n",
      "selected:  cs/acc_i=90.01 cs/acc_c=90.58 os/recall_knw=73.57 os/recall_unk=89.84 total/acc_i=77.81 total/acc_c=74.10 total/h_score=80.74\n",
      "Loss: 2.2657805631075862\n",
      "Loss: 1.0543034233900335\n",
      "Loss: 0.8455103974319199\n",
      "Loss: 0.7445427709798597\n",
      "Loss: 0.6732738771291998\n",
      "Loss: 0.6475326926191262\n",
      "Loss: 0.6267202809983473\n",
      "Loss: 0.5591480141222284\n",
      "Loss: 0.5286845893246456\n",
      "Loss: 0.5279272440760653\n",
      "______\n",
      "Iteration t=9\n",
      "all:  cs/acc_i=90.04 cs/acc_c=90.59 os/recall_knw=73.57 os/recall_unk=89.84 total/acc_i=77.81 total/acc_c=74.10 total/h_score=80.74\n",
      "selected:  cs/acc_i=90.04 cs/acc_c=90.59 os/recall_knw=73.57 os/recall_unk=89.84 total/acc_i=77.81 total/acc_c=74.10 total/h_score=80.74\n",
      "tensor(0)\n",
      "all:  cs/acc_i=90.04 cs/acc_c=90.59 os/recall_knw=73.57 os/recall_unk=89.84 total/acc_i=77.81 total/acc_c=74.10 total/h_score=80.74\n",
      "sketch -> real lr= 0.001 seed= 2\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19]\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20]\n",
      "Loss: 2.6126605514931467\n",
      "Loss: 1.5995579863016585\n",
      "Loss: 1.246091960014495\n",
      "Loss: 1.1096598835645524\n",
      "Loss: 1.0082019741556285\n",
      "Loss: 0.9212919270570299\n",
      "Loss: 0.874763825957754\n",
      "Loss: 0.8361512959267186\n",
      "Loss: 0.7949691007358838\n",
      "Loss: 0.7506933164807548\n",
      "tensor(True) tensor(True)\n",
      "______\n",
      "Iteration t=1\n",
      "all:  cs/acc_i=85.75 cs/acc_c=86.69 os/recall_knw=96.72 os/recall_unk=23.47 total/acc_i=64.53 total/acc_c=82.97 total/h_score=36.87\n",
      "selected:  cs/acc_i=86.62 cs/acc_c=87.18 os/recall_knw=83.68 os/recall_unk=99.25 total/acc_i=88.78 total/acc_c=84.31 total/h_score=90.73\n",
      "Loss: 2.5570542475239177\n",
      "Loss: 1.4691487462794195\n",
      "Loss: 1.115219199999434\n",
      "Loss: 0.9921043375965024\n",
      "Loss: 0.8941373877593728\n",
      "Loss: 0.8184091580695794\n",
      "Loss: 0.790797939432449\n",
      "Loss: 0.7365403962550593\n",
      "Loss: 0.7142012433194723\n",
      "Loss: 0.6675506220733534\n",
      "______\n",
      "Iteration t=2\n",
      "all:  cs/acc_i=86.99 cs/acc_c=87.89 os/recall_knw=83.15 os/recall_unk=73.80 total/acc_i=77.42 total/acc_c=80.20 total/h_score=77.01\n",
      "selected:  cs/acc_i=81.24 cs/acc_c=83.69 os/recall_knw=66.37 os/recall_unk=99.36 total/acc_i=80.00 total/acc_c=70.83 total/h_score=81.72\n",
      "Loss: 2.445333883507561\n",
      "Loss: 1.3000502540865018\n",
      "Loss: 1.0174537876635108\n",
      "Loss: 0.8910230331066\n",
      "Loss: 0.8047758233911209\n",
      "Loss: 0.7733071447556256\n",
      "Loss: 0.7359817988089933\n",
      "Loss: 0.6971018985482572\n",
      "Loss: 0.6338155302610106\n",
      "Loss: 0.6381445113597936\n",
      "______\n",
      "Iteration t=3\n",
      "all:  cs/acc_i=88.77 cs/acc_c=89.54 os/recall_knw=73.25 os/recall_unk=88.24 total/acc_i=77.18 total/acc_c=73.88 total/h_score=79.99\n",
      "selected:  cs/acc_i=86.33 cs/acc_c=87.43 os/recall_knw=64.66 os/recall_unk=97.44 total/acc_i=76.33 total/acc_c=67.76 total/h_score=78.89\n",
      "Loss: 2.3580242826947173\n",
      "Loss: 1.1949937651234288\n",
      "Loss: 0.9295916888448927\n",
      "Loss: 0.829635596830785\n",
      "Loss: 0.7565960832821426\n",
      "Loss: 0.7082181008913184\n",
      "Loss: 0.6850009431334807\n",
      "Loss: 0.6413137276112819\n",
      "Loss: 0.6026376207562758\n",
      "Loss: 0.560402028663184\n",
      "______\n",
      "Iteration t=4\n",
      "all:  cs/acc_i=89.57 cs/acc_c=90.17 os/recall_knw=72.95 os/recall_unk=88.41 total/acc_i=77.08 total/acc_c=73.66 total/h_score=79.92\n",
      "selected:  cs/acc_i=88.48 cs/acc_c=88.95 os/recall_knw=68.91 os/recall_unk=94.42 total/acc_i=76.99 total/acc_c=70.89 total/h_score=80.20\n",
      "Loss: 2.320944456613227\n",
      "Loss: 1.1519652370312443\n",
      "Loss: 0.8920913655055712\n",
      "Loss: 0.7946766925184694\n",
      "Loss: 0.7096096035348226\n",
      "Loss: 0.6618673586069721\n",
      "Loss: 0.6263820762197448\n",
      "Loss: 0.5996026213038458\n",
      "Loss: 0.5663149202216978\n",
      "Loss: 0.5389853453595345\n",
      "______\n",
      "Iteration t=5\n",
      "all:  cs/acc_i=89.71 cs/acc_c=90.35 os/recall_knw=72.89 os/recall_unk=88.53 total/acc_i=77.08 total/acc_c=73.61 total/h_score=79.93\n",
      "selected:  cs/acc_i=89.21 cs/acc_c=89.89 os/recall_knw=70.99 os/recall_unk=90.74 total/acc_i=76.83 total/acc_c=72.49 total/h_score=80.03\n",
      "Loss: 2.287479119839462\n",
      "Loss: 1.0636654567480879\n",
      "Loss: 0.8594599914709199\n",
      "Loss: 0.7690455447201713\n",
      "Loss: 0.6925238220398608\n",
      "Loss: 0.6522369471895338\n",
      "Loss: 0.6144433371054374\n",
      "Loss: 0.588710422729733\n",
      "Loss: 0.5660634298261218\n",
      "Loss: 0.5294382862771468\n",
      "______\n",
      "Iteration t=6\n",
      "all:  cs/acc_i=90.01 cs/acc_c=90.63 os/recall_knw=72.81 os/recall_unk=88.53 total/acc_i=77.02 total/acc_c=73.51 total/h_score=79.88\n",
      "selected:  cs/acc_i=89.88 cs/acc_c=90.46 os/recall_knw=72.05 os/recall_unk=88.69 total/acc_i=76.75 total/acc_c=73.09 total/h_score=79.67\n",
      "Loss: 2.2602754371618134\n",
      "Loss: 1.0701810062126396\n",
      "Loss: 0.8218428841213775\n",
      "Loss: 0.7340404257373093\n",
      "Loss: 0.688674103103432\n",
      "Loss: 0.6465439385448406\n",
      "Loss: 0.6023533832695749\n",
      "Loss: 0.5750540424308745\n",
      "Loss: 0.5519188451124173\n",
      "Loss: 0.5224704486774463\n",
      "______\n",
      "Iteration t=7\n",
      "all:  cs/acc_i=90.30 cs/acc_c=90.88 os/recall_knw=72.78 os/recall_unk=88.59 total/acc_i=77.02 total/acc_c=73.49 total/h_score=79.88\n",
      "selected:  cs/acc_i=90.29 cs/acc_c=90.87 os/recall_knw=72.74 os/recall_unk=88.59 total/acc_i=77.01 total/acc_c=73.48 total/h_score=79.88\n",
      "Loss: 2.267874318419151\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 1.0721416861108206\n",
      "Loss: 0.8388842594083459\n",
      "Loss: 0.7513744938624329\n",
      "Loss: 0.6741755409919714\n",
      "Loss: 0.6586406774891232\n",
      "Loss: 0.5896389615092077\n",
      "Loss: 0.5796953359660979\n",
      "Loss: 0.5245873005548342\n",
      "Loss: 0.5181698430462177\n",
      "______\n",
      "Iteration t=8\n",
      "all:  cs/acc_i=89.95 cs/acc_c=90.61 os/recall_knw=72.78 os/recall_unk=88.59 total/acc_i=77.02 total/acc_c=73.49 total/h_score=79.88\n",
      "selected:  cs/acc_i=89.95 cs/acc_c=90.61 os/recall_knw=72.78 os/recall_unk=88.59 total/acc_i=77.02 total/acc_c=73.49 total/h_score=79.88\n",
      "Loss: 2.267071595083934\n",
      "Loss: 1.0739719730750643\n",
      "Loss: 0.8532331069889192\n",
      "Loss: 0.7637003485631788\n",
      "Loss: 0.6787877974965426\n",
      "Loss: 0.6322192909937461\n",
      "Loss: 0.6046433782982594\n",
      "Loss: 0.5832508291241421\n",
      "Loss: 0.548497917004002\n",
      "Loss: 0.513380277889832\n",
      "______\n",
      "Iteration t=9\n",
      "all:  cs/acc_i=89.95 cs/acc_c=90.62 os/recall_knw=72.78 os/recall_unk=88.59 total/acc_i=77.02 total/acc_c=73.49 total/h_score=79.88\n",
      "selected:  cs/acc_i=89.95 cs/acc_c=90.62 os/recall_knw=72.78 os/recall_unk=88.59 total/acc_i=77.02 total/acc_c=73.49 total/h_score=79.88\n",
      "tensor(0)\n",
      "all:  cs/acc_i=89.95 cs/acc_c=90.62 os/recall_knw=72.78 os/recall_unk=88.59 total/acc_i=77.02 total/acc_c=73.49 total/h_score=79.88\n",
      "sketch -> real lr= 0.001 seed= 3\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19]\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20]\n",
      "Loss: 2.5999598518937037\n",
      "Loss: 1.5647888750629086\n",
      "Loss: 1.2455369431888108\n",
      "Loss: 1.1045774224057663\n",
      "Loss: 1.0034937502536099\n",
      "Loss: 0.9298555157353393\n",
      "Loss: 0.8874914181970917\n",
      "Loss: 0.8239087782866132\n",
      "Loss: 0.8004936681384534\n",
      "Loss: 0.7599602064727682\n",
      "tensor(True) tensor(True)\n",
      "______\n",
      "Iteration t=1\n",
      "all:  cs/acc_i=86.20 cs/acc_c=87.15 os/recall_knw=96.87 os/recall_unk=23.77 total/acc_i=64.98 total/acc_c=83.49 total/h_score=37.29\n",
      "selected:  cs/acc_i=86.96 cs/acc_c=87.75 os/recall_knw=84.30 os/recall_unk=99.26 total/acc_i=89.33 total/acc_c=85.01 total/h_score=91.17\n",
      "Loss: 2.566781258973919\n",
      "Loss: 1.4562018777503343\n",
      "Loss: 1.1037954026069798\n",
      "Loss: 0.9936863518640643\n",
      "Loss: 0.8872205830011212\n",
      "Loss: 0.8579489863553985\n",
      "Loss: 0.7922881400731744\n",
      "Loss: 0.7605003630284404\n",
      "Loss: 0.7218432094230026\n",
      "Loss: 0.6984441982673817\n",
      "______\n",
      "Iteration t=2\n",
      "all:  cs/acc_i=87.44 cs/acc_c=88.26 os/recall_knw=81.53 os/recall_unk=79.32 total/acc_i=78.46 total/acc_c=79.36 total/h_score=79.34\n",
      "selected:  cs/acc_i=81.83 cs/acc_c=83.68 os/recall_knw=64.41 os/recall_unk=99.70 total/acc_i=79.29 total/acc_c=68.65 total/h_score=80.21\n",
      "Loss: 2.4485580561725238\n",
      "Loss: 1.309015785237305\n",
      "Loss: 0.9918966686907615\n",
      "Loss: 0.881728391952187\n",
      "Loss: 0.8167840692833179\n",
      "Loss: 0.7553791626719119\n",
      "Loss: 0.7043588937238883\n",
      "Loss: 0.6816276234524851\n",
      "Loss: 0.6535255777016851\n",
      "Loss: 0.6383349900027268\n",
      "______\n",
      "Iteration t=3\n",
      "all:  cs/acc_i=88.12 cs/acc_c=88.85 os/recall_knw=72.13 os/recall_unk=91.03 total/acc_i=77.32 total/acc_c=72.94 total/h_score=80.42\n",
      "selected:  cs/acc_i=85.34 cs/acc_c=86.40 os/recall_knw=63.81 os/recall_unk=98.02 total/acc_i=75.80 total/acc_c=66.60 total/h_score=78.19\n",
      "Loss: 2.3725861263958783\n",
      "Loss: 1.181590338120751\n",
      "Loss: 0.9201689556935355\n",
      "Loss: 0.8147063918652073\n",
      "Loss: 0.7754252603190774\n",
      "Loss: 0.7209692135933907\n",
      "Loss: 0.6243169106890224\n",
      "Loss: 0.6353726858092893\n",
      "Loss: 0.618085304361945\n",
      "Loss: 0.5949888550893381\n",
      "______\n",
      "Iteration t=4\n",
      "all:  cs/acc_i=89.39 cs/acc_c=90.01 os/recall_knw=71.59 os/recall_unk=91.21 total/acc_i=77.08 total/acc_c=72.56 total/h_score=80.24\n",
      "selected:  cs/acc_i=88.34 cs/acc_c=88.88 os/recall_knw=67.89 os/recall_unk=94.17 total/acc_i=76.25 total/acc_c=69.70 total/h_score=79.29\n",
      "Loss: 2.2876562026580447\n",
      "Loss: 1.1055502452134272\n",
      "Loss: 0.8732470267868693\n",
      "Loss: 0.800720210368316\n",
      "Loss: 0.7181309728085384\n",
      "Loss: 0.6723167434487326\n",
      "Loss: 0.6361199245619692\n",
      "Loss: 0.6135361004404647\n",
      "Loss: 0.5673588439567911\n",
      "Loss: 0.5583420947143243\n",
      "______\n",
      "Iteration t=5\n",
      "all:  cs/acc_i=89.92 cs/acc_c=90.47 os/recall_knw=71.36 os/recall_unk=91.21 total/acc_i=76.92 total/acc_c=72.35 total/h_score=80.10\n",
      "selected:  cs/acc_i=89.48 cs/acc_c=90.03 os/recall_knw=69.49 os/recall_unk=91.64 total/acc_i=76.21 total/acc_c=71.03 total/h_score=79.37\n",
      "Loss: 2.3022231421741752\n",
      "Loss: 1.079415705790089\n",
      "Loss: 0.861377396113099\n",
      "Loss: 0.7818498220730785\n",
      "Loss: 0.7087645796828446\n",
      "Loss: 0.6550112483294114\n",
      "Loss: 0.6181047050948925\n",
      "Loss: 0.5858120620250702\n",
      "Loss: 0.5495689520518915\n",
      "Loss: 0.5300187459558149\n",
      "______\n",
      "Iteration t=6\n",
      "all:  cs/acc_i=90.01 cs/acc_c=90.66 os/recall_knw=71.36 os/recall_unk=91.27 total/acc_i=76.94 total/acc_c=72.35 total/h_score=80.12\n",
      "selected:  cs/acc_i=89.96 cs/acc_c=90.59 os/recall_knw=70.80 os/recall_unk=91.37 total/acc_i=76.78 total/acc_c=72.04 total/h_score=79.96\n",
      "Loss: 2.2800744803328263\n",
      "Loss: 1.076255626878456\n",
      "Loss: 0.8664379951200987\n",
      "Loss: 0.7558769629778046\n",
      "Loss: 0.703823471343831\n",
      "Loss: 0.6495251318831977\n",
      "Loss: 0.616307593735033\n",
      "Loss: 0.581165782666128\n",
      "Loss: 0.5551427037112022\n",
      "Loss: 0.5229271112107917\n",
      "______\n",
      "Iteration t=7\n",
      "all:  cs/acc_i=90.04 cs/acc_c=90.59 os/recall_knw=71.30 os/recall_unk=91.27 total/acc_i=76.90 total/acc_c=72.30 total/h_score=80.09\n",
      "selected:  cs/acc_i=90.02 cs/acc_c=90.58 os/recall_knw=71.26 os/recall_unk=91.27 total/acc_i=76.88 total/acc_c=72.28 total/h_score=80.07\n",
      "Loss: 2.251016205237582\n",
      "Loss: 1.0727034601705525\n",
      "Loss: 0.8417285661292232\n",
      "Loss: 0.7518836645519033\n",
      "Loss: 0.686622366309166\n",
      "Loss: 0.6380634785575026\n",
      "Loss: 0.5965643307449771\n",
      "Loss: 0.5670333333751735\n",
      "Loss: 0.5382667368923137\n",
      "Loss: 0.5213767772211748\n",
      "______\n",
      "Iteration t=8\n",
      "all:  cs/acc_i=89.98 cs/acc_c=90.54 os/recall_knw=71.30 os/recall_unk=91.27 total/acc_i=76.90 total/acc_c=72.30 total/h_score=80.09\n",
      "selected:  cs/acc_i=89.98 cs/acc_c=90.54 os/recall_knw=71.30 os/recall_unk=91.27 total/acc_i=76.90 total/acc_c=72.30 total/h_score=80.09\n",
      "Loss: 2.270117808790768\n",
      "Loss: 1.0596209857978074\n",
      "Loss: 0.8525358136572869\n",
      "Loss: 0.7433090589307492\n",
      "Loss: 0.6991708171523474\n",
      "Loss: 0.6514826111154619\n",
      "Loss: 0.6152026938651901\n",
      "Loss: 0.5723378802436629\n",
      "Loss: 0.5503605655790155\n",
      "Loss: 0.5234589540685703\n",
      "______\n",
      "Iteration t=9\n",
      "all:  cs/acc_i=89.98 cs/acc_c=90.63 os/recall_knw=71.30 os/recall_unk=91.27 total/acc_i=76.90 total/acc_c=72.30 total/h_score=80.09\n",
      "selected:  cs/acc_i=89.98 cs/acc_c=90.63 os/recall_knw=71.30 os/recall_unk=91.27 total/acc_i=76.90 total/acc_c=72.30 total/h_score=80.09\n",
      "tensor(0)\n",
      "all:  cs/acc_i=89.98 cs/acc_c=90.63 os/recall_knw=71.30 os/recall_unk=91.27 total/acc_i=76.90 total/acc_c=72.30 total/h_score=80.09\n",
      "sketch -> real lr= 0.001 seed= 4\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19]\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20]\n",
      "Loss: 2.6226916402842093\n",
      "Loss: 1.5942649295372247\n",
      "Loss: 1.2503794526631853\n",
      "Loss: 1.1039606177173884\n",
      "Loss: 1.0151010687108588\n",
      "Loss: 0.9477948422453045\n",
      "Loss: 0.882490443840491\n",
      "Loss: 0.8244991226006398\n",
      "Loss: 0.7885272630811793\n",
      "Loss: 0.7575360104046037\n",
      "tensor(True) tensor(True)\n",
      "______\n",
      "Iteration t=1\n",
      "all:  cs/acc_i=86.52 cs/acc_c=87.52 os/recall_knw=96.48 os/recall_unk=22.99 total/acc_i=64.77 total/acc_c=83.57 total/h_score=36.34\n",
      "selected:  cs/acc_i=86.48 cs/acc_c=87.63 os/recall_knw=82.70 os/recall_unk=99.49 total/acc_i=88.12 total/acc_c=84.17 total/h_score=90.74\n",
      "Loss: 2.544993989780301\n",
      "Loss: 1.4346657698271705\n",
      "Loss: 1.0983694833321649\n",
      "Loss: 0.9772795443652106\n",
      "Loss: 0.8884330444404336\n",
      "Loss: 0.8499459323824429\n",
      "Loss: 0.7763889314698391\n",
      "Loss: 0.761725519890668\n",
      "Loss: 0.7113190364153659\n",
      "Loss: 0.6562612348648368\n",
      "______\n",
      "Iteration t=2\n",
      "all:  cs/acc_i=87.44 cs/acc_c=88.32 os/recall_knw=82.68 os/recall_unk=77.78 total/acc_i=78.66 total/acc_c=80.23 total/h_score=79.04\n",
      "selected:  cs/acc_i=81.52 cs/acc_c=83.45 os/recall_knw=65.83 os/recall_unk=99.70 total/acc_i=80.09 total/acc_c=69.96 total/h_score=81.18\n",
      "Loss: 2.4373333686180696\n",
      "Loss: 1.2855868275838953\n",
      "Loss: 1.0001645743391896\n",
      "Loss: 0.9062280054310806\n",
      "Loss: 0.8178417785022095\n",
      "Loss: 0.7688749802249079\n",
      "Loss: 0.7380108578514507\n",
      "Loss: 0.6863196104309941\n",
      "Loss: 0.667145706656325\n",
      "Loss: 0.6327892126700351\n",
      "______\n",
      "Iteration t=3\n",
      "all:  cs/acc_i=88.56 cs/acc_c=89.27 os/recall_knw=72.01 os/recall_unk=91.74 total/acc_i=77.67 total/acc_c=72.97 total/h_score=80.70\n",
      "selected:  cs/acc_i=86.12 cs/acc_c=87.02 os/recall_knw=63.88 os/recall_unk=98.66 total/acc_i=76.36 total/acc_c=66.61 total/h_score=78.38\n",
      "Loss: 2.3599972118186265\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 1.1940433151192136\n",
      "Loss: 0.9178097230986455\n",
      "Loss: 0.8178755563006179\n",
      "Loss: 0.7687447880758607\n",
      "Loss: 0.7077579862541623\n",
      "Loss: 0.683797399630256\n",
      "Loss: 0.6433779967942118\n",
      "Loss: 0.5984911160763874\n",
      "Loss: 0.5897326781330997\n",
      "______\n",
      "Iteration t=4\n",
      "all:  cs/acc_i=89.68 cs/acc_c=90.31 os/recall_knw=71.62 os/recall_unk=91.92 total/acc_i=77.52 total/acc_c=72.68 total/h_score=80.57\n",
      "selected:  cs/acc_i=88.72 cs/acc_c=89.32 os/recall_knw=67.77 os/recall_unk=95.97 total/acc_i=77.02 total/acc_c=69.83 total/h_score=79.95\n",
      "Loss: 2.3215939388242375\n",
      "Loss: 1.1344163210940934\n",
      "Loss: 0.8878620684761362\n",
      "Loss: 0.7981507865219182\n",
      "Loss: 0.738377138460215\n",
      "Loss: 0.6904107476120552\n",
      "Loss: 0.6292507631569794\n",
      "Loss: 0.6055781296950435\n",
      "Loss: 0.5846124436847123\n",
      "Loss: 0.5505004255325114\n",
      "______\n",
      "Iteration t=5\n",
      "all:  cs/acc_i=89.92 cs/acc_c=90.43 os/recall_knw=71.56 os/recall_unk=92.04 total/acc_i=77.52 total/acc_c=72.63 total/h_score=80.58\n",
      "selected:  cs/acc_i=89.44 cs/acc_c=89.84 os/recall_knw=69.76 os/recall_unk=92.98 total/acc_i=76.95 total/acc_c=71.26 total/h_score=79.98\n",
      "Loss: 2.295291592444863\n",
      "Loss: 1.0999443764271943\n",
      "Loss: 0.8822621147967501\n",
      "Loss: 0.7728078344394531\n",
      "Loss: 0.6984007178142317\n",
      "Loss: 0.672393900993277\n",
      "Loss: 0.6029608093177196\n",
      "Loss: 0.5746479573656484\n",
      "Loss: 0.5673330355448069\n",
      "Loss: 0.5321098346275629\n",
      "______\n",
      "Iteration t=6\n",
      "all:  cs/acc_i=89.95 cs/acc_c=90.58 os/recall_knw=71.56 os/recall_unk=92.16 total/acc_i=77.56 total/acc_c=72.64 total/h_score=80.63\n",
      "selected:  cs/acc_i=89.91 cs/acc_c=90.53 os/recall_knw=71.12 os/recall_unk=92.32 total/acc_i=77.45 total/acc_c=72.42 total/h_score=80.54\n",
      "Loss: 2.293078909971212\n",
      "Loss: 1.059220003062173\n",
      "Loss: 0.8567697642076957\n",
      "Loss: 0.7645560512809377\n",
      "Loss: 0.6924168485657949\n",
      "Loss: 0.6603412776205101\n",
      "Loss: 0.6129709023884252\n",
      "Loss: 0.5816424713519058\n",
      "Loss: 0.5610653840887704\n",
      "Loss: 0.5265071077860499\n",
      "______\n",
      "Iteration t=7\n",
      "all:  cs/acc_i=89.95 cs/acc_c=90.53 os/recall_knw=71.56 os/recall_unk=92.22 total/acc_i=77.58 total/acc_c=72.64 total/h_score=80.65\n",
      "selected:  cs/acc_i=89.93 cs/acc_c=90.53 os/recall_knw=71.43 os/recall_unk=92.22 total/acc_i=77.52 total/acc_c=72.58 total/h_score=80.61\n",
      "Loss: 2.2658139697840958\n",
      "Loss: 1.0728339255833235\n",
      "Loss: 0.8411777670266198\n",
      "Loss: 0.7728462106868869\n",
      "Loss: 0.678025607789149\n",
      "Loss: 0.6550711326911801\n",
      "Loss: 0.6200537832056889\n",
      "Loss: 0.5891595494796018\n",
      "Loss: 0.561371331185591\n",
      "Loss: 0.5134011499217299\n",
      "______\n",
      "Iteration t=8\n",
      "all:  cs/acc_i=90.39 cs/acc_c=90.94 os/recall_knw=71.56 os/recall_unk=92.22 total/acc_i=77.58 total/acc_c=72.64 total/h_score=80.65\n",
      "selected:  cs/acc_i=90.39 cs/acc_c=90.94 os/recall_knw=71.56 os/recall_unk=92.22 total/acc_i=77.58 total/acc_c=72.64 total/h_score=80.65\n",
      "Loss: 2.248690655418471\n",
      "Loss: 1.0604353945434484\n",
      "Loss: 0.8644382056652331\n",
      "Loss: 0.7627136158008202\n",
      "Loss: 0.6970964085822012\n",
      "Loss: 0.6431324757586897\n",
      "Loss: 0.6184672479049053\n",
      "Loss: 0.5842595970611167\n",
      "Loss: 0.5423523509521889\n",
      "Loss: 0.5216857872270291\n",
      "______\n",
      "Iteration t=9\n",
      "all:  cs/acc_i=90.42 cs/acc_c=90.97 os/recall_knw=71.56 os/recall_unk=92.22 total/acc_i=77.58 total/acc_c=72.64 total/h_score=80.65\n",
      "selected:  cs/acc_i=90.42 cs/acc_c=90.97 os/recall_knw=71.56 os/recall_unk=92.22 total/acc_i=77.58 total/acc_c=72.64 total/h_score=80.65\n",
      "tensor(0)\n",
      "all:  cs/acc_i=90.42 cs/acc_c=90.97 os/recall_knw=71.56 os/recall_unk=92.22 total/acc_i=77.58 total/acc_c=72.64 total/h_score=80.65\n",
      "sketch -> real lr= 0.001 seed= 0\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19]\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20]\n",
      "Loss: 2.6193773377258167\n",
      "Loss: 1.6028022863696108\n",
      "Loss: 1.2605059592597252\n",
      "Loss: 1.0979131051396902\n",
      "Loss: 1.0018200986416994\n",
      "Loss: 0.9413920458966651\n",
      "Loss: 0.8828752428556965\n",
      "Loss: 0.8308296207569342\n",
      "Loss: 0.7937634969707084\n",
      "Loss: 0.7897758770041761\n",
      "tensor(True) tensor(True)\n",
      "______\n",
      "Iteration t=1\n",
      "all:  cs/acc_i=86.43 cs/acc_c=87.49 os/recall_knw=89.27 os/recall_unk=53.65 total/acc_i=72.90 total/acc_c=82.29 total/h_score=65.40\n",
      "selected:  cs/acc_i=74.87 cs/acc_c=79.84 os/recall_knw=61.18 os/recall_unk=99.78 total/acc_i=79.84 total/acc_c=68.78 total/h_score=80.33\n",
      "Loss: 2.5383045648942226\n",
      "Loss: 1.4538823309980455\n",
      "Loss: 1.1093115677110483\n",
      "Loss: 0.9819812317852115\n",
      "Loss: 0.9048288244693006\n",
      "Loss: 0.847847653217003\n",
      "Loss: 0.7897393053672352\n",
      "Loss: 0.7389640262747397\n",
      "Loss: 0.7286168093808362\n",
      "Loss: 0.705396514080587\n",
      "______\n",
      "Iteration t=2\n",
      "all:  cs/acc_i=87.05 cs/acc_c=87.85 os/recall_knw=60.21 os/recall_unk=94.71 total/acc_i=71.22 total/acc_c=62.55 total/h_score=74.17\n",
      "selected:  cs/acc_i=82.73 cs/acc_c=84.45 os/recall_knw=45.55 os/recall_unk=99.50 total/acc_i=66.47 total/acc_c=50.58 total/h_score=64.88\n",
      "Loss: 2.4477263648091383\n",
      "Loss: 1.2744409940169967\n",
      "Loss: 1.0068533237426336\n",
      "Loss: 0.8923524156326555\n",
      "Loss: 0.8424419276131928\n",
      "Loss: 0.7446749304769603\n",
      "Loss: 0.7223111735727951\n",
      "Loss: 0.6667166593420597\n",
      "Loss: 0.6535059388243515\n",
      "Loss: 0.6146095372907078\n",
      "______\n",
      "Iteration t=3\n",
      "all:  cs/acc_i=88.12 cs/acc_c=88.85 os/recall_knw=59.06 os/recall_unk=95.19 total/acc_i=70.65 total/acc_c=61.63 total/h_score=73.56\n",
      "selected:  cs/acc_i=86.47 cs/acc_c=87.43 os/recall_knw=52.81 os/recall_unk=98.65 total/acc_i=68.79 total/acc_c=56.70 total/h_score=70.29\n",
      "Loss: 2.3808175030621617\n",
      "Loss: 1.233113985711878\n",
      "Loss: 0.9643361749432303\n",
      "Loss: 0.8261197543144226\n",
      "Loss: 0.7727922514351931\n",
      "Loss: 0.7208138302239505\n",
      "Loss: 0.6840186193314466\n",
      "Loss: 0.6430590483275327\n",
      "Loss: 0.6058624749562957\n",
      "Loss: 0.5773826258832758\n",
      "______\n",
      "Iteration t=4\n",
      "all:  cs/acc_i=88.68 cs/acc_c=89.45 os/recall_knw=59.06 os/recall_unk=95.19 total/acc_i=70.65 total/acc_c=61.63 total/h_score=73.56\n",
      "selected:  cs/acc_i=88.09 cs/acc_c=88.87 os/recall_knw=56.71 os/recall_unk=96.74 total/acc_i=69.97 total/acc_c=59.73 total/h_score=72.43\n",
      "Loss: 2.3458340369479758\n",
      "Loss: 1.1858840603643739\n",
      "Loss: 0.8899270038999302\n",
      "Loss: 0.8028924214378209\n",
      "Loss: 0.7358663041197079\n",
      "Loss: 0.6956278055276669\n",
      "Loss: 0.6580678110181446\n",
      "Loss: 0.6113274106362336\n",
      "Loss: 0.6022132619375914\n",
      "Loss: 0.5755149338027121\n",
      "______\n",
      "Iteration t=5\n",
      "all:  cs/acc_i=88.44 cs/acc_c=89.19 os/recall_knw=59.06 os/recall_unk=95.19 total/acc_i=70.65 total/acc_c=61.63 total/h_score=73.56\n",
      "selected:  cs/acc_i=88.26 cs/acc_c=88.98 os/recall_knw=58.09 os/recall_unk=95.41 total/acc_i=70.30 total/acc_c=60.92 total/h_score=73.07\n",
      "Loss: 2.3419000739457285\n",
      "Loss: 1.1517029315955085\n",
      "Loss: 0.9195552988035869\n",
      "Loss: 0.8059392791099614\n",
      "Loss: 0.7561147884823459\n",
      "Loss: 0.6948918016517863\n",
      "Loss: 0.6431485008203447\n",
      "Loss: 0.598817408394236\n",
      "Loss: 0.5967012559769476\n",
      "Loss: 0.5506697037743862\n",
      "______\n",
      "Iteration t=6\n",
      "all:  cs/acc_i=89.09 cs/acc_c=89.83 os/recall_knw=59.06 os/recall_unk=95.19 total/acc_i=70.65 total/acc_c=61.63 total/h_score=73.56\n",
      "selected:  cs/acc_i=89.13 cs/acc_c=89.85 os/recall_knw=58.99 os/recall_unk=95.19 total/acc_i=70.65 total/acc_c=61.60 total/h_score=73.55\n",
      "Loss: 2.3134522835413613\n",
      "Loss: 1.1246847543110143\n",
      "Loss: 0.9038580517793439\n",
      "Loss: 0.7847857068187183\n",
      "Loss: 0.7283660051544097\n",
      "Loss: 0.6802008541179276\n",
      "Loss: 0.6356570697629574\n",
      "Loss: 0.6001738044097251\n",
      "Loss: 0.5656251480284425\n",
      "Loss: 0.5472790317232257\n",
      "______\n",
      "Iteration t=7\n",
      "all:  cs/acc_i=88.89 cs/acc_c=89.65 os/recall_knw=59.06 os/recall_unk=95.19 total/acc_i=70.65 total/acc_c=61.63 total/h_score=73.56\n",
      "selected:  cs/acc_i=88.89 cs/acc_c=89.65 os/recall_knw=59.06 os/recall_unk=95.19 total/acc_i=70.65 total/acc_c=61.63 total/h_score=73.56\n",
      "Loss: 2.319335118601822\n",
      "Loss: 1.1334544699831106\n",
      "Loss: 0.8659759593993118\n",
      "Loss: 0.7954902440002284\n",
      "Loss: 0.7272901536058315\n",
      "Loss: 0.6773146937802895\n",
      "Loss: 0.6519752458198783\n",
      "Loss: 0.5998427197081116\n",
      "Loss: 0.5755304298859691\n",
      "Loss: 0.5314292986061155\n",
      "______\n",
      "Iteration t=8\n",
      "all:  cs/acc_i=88.74 cs/acc_c=89.47 os/recall_knw=59.06 os/recall_unk=95.19 total/acc_i=70.65 total/acc_c=61.63 total/h_score=73.56\n",
      "selected:  cs/acc_i=88.74 cs/acc_c=89.47 os/recall_knw=59.06 os/recall_unk=95.19 total/acc_i=70.65 total/acc_c=61.63 total/h_score=73.56\n",
      "Loss: 2.2950436261920992\n",
      "Loss: 1.1318329205013222\n",
      "Loss: 0.8888077097864905\n",
      "Loss: 0.7971657935491542\n",
      "Loss: 0.7232228154988632\n",
      "Loss: 0.6887885534886232\n",
      "Loss: 0.6399743787406647\n",
      "Loss: 0.6058283545512104\n",
      "Loss: 0.5913840026892337\n",
      "Loss: 0.5479219824178112\n",
      "______\n",
      "Iteration t=9\n",
      "all:  cs/acc_i=89.12 cs/acc_c=89.81 os/recall_knw=59.06 os/recall_unk=95.19 total/acc_i=70.65 total/acc_c=61.63 total/h_score=73.56\n",
      "selected:  cs/acc_i=89.12 cs/acc_c=89.81 os/recall_knw=59.06 os/recall_unk=95.19 total/acc_i=70.65 total/acc_c=61.63 total/h_score=73.56\n",
      "tensor(0)\n",
      "all:  cs/acc_i=89.12 cs/acc_c=89.81 os/recall_knw=59.06 os/recall_unk=95.19 total/acc_i=70.65 total/acc_c=61.63 total/h_score=73.56\n",
      "sketch -> real lr= 0.001 seed= 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19]\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20]\n",
      "Loss: 2.6132885629096916\n",
      "Loss: 1.602845927519081\n",
      "Loss: 1.2573193665099356\n",
      "Loss: 1.0885304626637855\n",
      "Loss: 1.0431765971985538\n",
      "Loss: 0.941699801952438\n",
      "Loss: 0.8828497824415696\n",
      "Loss: 0.8141436984317493\n",
      "Loss: 0.7885075737681009\n",
      "Loss: 0.745715167406386\n",
      "tensor(True) tensor(True)\n",
      "______\n",
      "Iteration t=1\n",
      "all:  cs/acc_i=86.64 cs/acc_c=87.67 os/recall_knw=89.86 os/recall_unk=54.84 total/acc_i=73.67 total/acc_c=82.93 total/h_score=66.46\n",
      "selected:  cs/acc_i=75.25 cs/acc_c=80.06 os/recall_knw=62.43 os/recall_unk=99.89 total/acc_i=81.00 total/acc_c=70.75 total/h_score=81.82\n",
      "Loss: 2.5278713864381195\n",
      "Loss: 1.4228484689212235\n",
      "Loss: 1.1134886394758694\n",
      "Loss: 0.9339376471814562\n",
      "Loss: 0.8982574362002436\n",
      "Loss: 0.8546466302187716\n",
      "Loss: 0.8102693168110535\n",
      "Loss: 0.7578858254385776\n",
      "Loss: 0.7321903662847691\n",
      "Loss: 0.685867718741542\n",
      "______\n",
      "Iteration t=2\n",
      "all:  cs/acc_i=87.61 cs/acc_c=88.43 os/recall_knw=70.74 os/recall_unk=90.97 total/acc_i=76.53 total/acc_c=71.86 total/h_score=79.69\n",
      "selected:  cs/acc_i=81.85 cs/acc_c=83.86 os/recall_knw=53.32 os/recall_unk=99.61 total/acc_i=72.42 total/acc_c=58.93 total/h_score=72.42\n",
      "Loss: 2.4406676943065557\n",
      "Loss: 1.296521179321158\n",
      "Loss: 1.0019754020084861\n",
      "Loss: 0.8843299947849667\n",
      "Loss: 0.8068592441445999\n",
      "Loss: 0.7645820707992743\n",
      "Loss: 0.7106322993076485\n",
      "Loss: 0.6939343305603238\n",
      "Loss: 0.6696503530931837\n",
      "Loss: 0.6273964627553489\n",
      "______\n",
      "Iteration t=3\n",
      "all:  cs/acc_i=88.59 cs/acc_c=89.28 os/recall_knw=69.55 os/recall_unk=91.92 total/acc_i=76.14 total/acc_c=70.84 total/h_score=79.33\n",
      "selected:  cs/acc_i=86.24 cs/acc_c=87.21 os/recall_knw=60.97 os/recall_unk=97.97 total/acc_i=74.35 total/acc_c=64.53 total/h_score=76.58\n",
      "Loss: 2.389096472667873\n",
      "Loss: 1.2077787821903987\n",
      "Loss: 0.935005211873175\n",
      "Loss: 0.8393043371098997\n",
      "Loss: 0.7545264694664883\n",
      "Loss: 0.6960937480311101\n",
      "Loss: 0.6814078962437082\n",
      "Loss: 0.6313096433877945\n",
      "Loss: 0.6089646987321145\n",
      "Loss: 0.5925316146780008\n",
      "______\n",
      "Iteration t=4\n",
      "all:  cs/acc_i=89.45 cs/acc_c=90.08 os/recall_knw=68.93 os/recall_unk=92.51 total/acc_i=75.96 total/acc_c=70.37 total/h_score=79.22\n",
      "selected:  cs/acc_i=88.46 cs/acc_c=89.13 os/recall_knw=65.15 os/recall_unk=95.58 total/acc_i=75.13 total/acc_c=67.66 total/h_score=78.27\n",
      "Loss: 2.336232077253276\n",
      "Loss: 1.1403748430054763\n",
      "Loss: 0.8845005560537864\n",
      "Loss: 0.7930268945365117\n",
      "Loss: 0.7284914023917297\n",
      "Loss: 0.6754153475165368\n",
      "Loss: 0.6185497736108714\n",
      "Loss: 0.6207072659813124\n",
      "Loss: 0.5705025725837412\n",
      "Loss: 0.5618515605556553\n",
      "______\n",
      "Iteration t=5\n",
      "all:  cs/acc_i=90.16 cs/acc_c=90.70 os/recall_knw=68.84 os/recall_unk=92.57 total/acc_i=75.92 total/acc_c=70.30 total/h_score=79.19\n",
      "selected:  cs/acc_i=89.76 cs/acc_c=90.27 os/recall_knw=67.00 os/recall_unk=93.07 total/acc_i=75.25 total/acc_c=69.09 total/h_score=78.51\n",
      "Loss: 2.314309698564035\n",
      "Loss: 1.096168491776142\n",
      "Loss: 0.8699079701796124\n",
      "Loss: 0.7513578982164563\n",
      "Loss: 0.7069874136937587\n",
      "Loss: 0.6660172189225252\n",
      "Loss: 0.6414473565539929\n",
      "Loss: 0.5900166135043006\n",
      "Loss: 0.566832557947748\n",
      "Loss: 0.5329347662251405\n",
      "______\n",
      "Iteration t=6\n",
      "all:  cs/acc_i=90.07 cs/acc_c=90.61 os/recall_knw=68.84 os/recall_unk=92.63 total/acc_i=75.94 total/acc_c=70.30 total/h_score=79.21\n",
      "selected:  cs/acc_i=90.04 cs/acc_c=90.60 os/recall_knw=68.28 os/recall_unk=92.74 total/acc_i=75.78 total/acc_c=70.04 total/h_score=79.07\n",
      "Loss: 2.266312992057927\n",
      "Loss: 1.0779098026776235\n",
      "Loss: 0.8539895868776645\n",
      "Loss: 0.7491016105757995\n",
      "Loss: 0.6895182645103068\n",
      "Loss: 0.6582824305145447\n",
      "Loss: 0.6087951752731571\n",
      "Loss: 0.573204581053352\n",
      "Loss: 0.5611453497429623\n",
      "Loss: 0.5351198341858348\n",
      "______\n",
      "Iteration t=7\n",
      "all:  cs/acc_i=89.95 cs/acc_c=90.50 os/recall_knw=68.84 os/recall_unk=92.63 total/acc_i=75.94 total/acc_c=70.30 total/h_score=79.21\n",
      "selected:  cs/acc_i=89.90 cs/acc_c=90.47 os/recall_knw=68.68 os/recall_unk=92.69 total/acc_i=75.87 total/acc_c=70.21 total/h_score=79.17\n",
      "Loss: 2.2840807765524906\n",
      "Loss: 1.0831976678987212\n",
      "Loss: 0.8623822396559431\n",
      "Loss: 0.7580963482722541\n",
      "Loss: 0.6884558911848542\n",
      "Loss: 0.6612316398135084\n",
      "Loss: 0.6189355303514872\n",
      "Loss: 0.5820500648376957\n",
      "Loss: 0.5406378458272543\n",
      "Loss: 0.5389738517831888\n",
      "______\n",
      "Iteration t=8\n",
      "all:  cs/acc_i=90.66 cs/acc_c=91.26 os/recall_knw=68.84 os/recall_unk=92.63 total/acc_i=75.94 total/acc_c=70.30 total/h_score=79.21\n",
      "selected:  cs/acc_i=90.66 cs/acc_c=91.26 os/recall_knw=68.84 os/recall_unk=92.63 total/acc_i=75.94 total/acc_c=70.30 total/h_score=79.21\n",
      "Loss: 2.285110776180481\n",
      "Loss: 1.1015874208396812\n",
      "Loss: 0.8497838042553502\n",
      "Loss: 0.7647290417660187\n",
      "Loss: 0.7052825081466448\n",
      "Loss: 0.6463353854201415\n",
      "Loss: 0.6409192423615911\n",
      "Loss: 0.597769237046588\n",
      "Loss: 0.5622478873521188\n",
      "Loss: 0.5453267677290605\n",
      "______\n",
      "Iteration t=9\n",
      "all:  cs/acc_i=89.92 cs/acc_c=90.52 os/recall_knw=68.84 os/recall_unk=92.63 total/acc_i=75.94 total/acc_c=70.30 total/h_score=79.21\n",
      "selected:  cs/acc_i=89.92 cs/acc_c=90.52 os/recall_knw=68.84 os/recall_unk=92.63 total/acc_i=75.94 total/acc_c=70.30 total/h_score=79.21\n",
      "tensor(0)\n",
      "all:  cs/acc_i=89.92 cs/acc_c=90.52 os/recall_knw=68.84 os/recall_unk=92.63 total/acc_i=75.94 total/acc_c=70.30 total/h_score=79.21\n",
      "sketch -> real lr= 0.001 seed= 2\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19]\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20]\n",
      "Loss: 2.613226115176108\n",
      "Loss: 1.5995350369309957\n",
      "Loss: 1.246164600406073\n",
      "Loss: 1.109795923781606\n",
      "Loss: 1.0084307599911648\n",
      "Loss: 0.9220420900171837\n",
      "Loss: 0.8757551303215786\n",
      "Loss: 0.8372346559720757\n",
      "Loss: 0.7948347000421676\n",
      "Loss: 0.752290334849231\n",
      "tensor(True) tensor(True)\n",
      "______\n",
      "Iteration t=1\n",
      "all:  cs/acc_i=85.96 cs/acc_c=86.85 os/recall_knw=89.09 os/recall_unk=53.30 total/acc_i=72.25 total/acc_c=81.50 total/h_score=64.88\n",
      "selected:  cs/acc_i=75.35 cs/acc_c=79.06 os/recall_knw=60.62 os/recall_unk=99.67 total/acc_i=79.37 total/acc_c=68.05 total/h_score=79.75\n",
      "Loss: 2.539117833141421\n",
      "Loss: 1.437135773359752\n",
      "Loss: 1.1198361679667332\n",
      "Loss: 0.9818896287288822\n",
      "Loss: 0.9118826358777578\n",
      "Loss: 0.8217364771932852\n",
      "Loss: 0.7851063478432718\n",
      "Loss: 0.7609865143895149\n",
      "Loss: 0.721008547627535\n",
      "Loss: 0.6686253534232984\n",
      "______\n",
      "Iteration t=2\n",
      "all:  cs/acc_i=87.32 cs/acc_c=88.14 os/recall_knw=66.48 os/recall_unk=93.11 total/acc_i=74.65 total/acc_c=68.13 total/h_score=77.85\n",
      "selected:  cs/acc_i=81.98 cs/acc_c=83.93 os/recall_knw=49.78 os/recall_unk=99.43 total/acc_i=69.87 total/acc_c=54.97 total/h_score=68.93\n",
      "Loss: 2.4512841000811743\n",
      "Loss: 1.3202500955294107\n",
      "Loss: 1.008262941628012\n",
      "Loss: 0.879575852560633\n",
      "Loss: 0.8114211190747851\n",
      "Loss: 0.7780508776657454\n",
      "Loss: 0.7418011644186865\n",
      "Loss: 0.6795677725822871\n",
      "Loss: 0.6510402299748123\n",
      "Loss: 0.6377208835751046\n",
      "______\n",
      "Iteration t=3\n",
      "all:  cs/acc_i=88.80 cs/acc_c=89.55 os/recall_knw=64.35 os/recall_unk=94.18 total/acc_i=73.77 total/acc_c=66.42 total/h_score=76.94\n",
      "selected:  cs/acc_i=86.70 cs/acc_c=87.67 os/recall_knw=56.90 os/recall_unk=98.57 total/acc_i=71.70 total/acc_c=60.59 total/h_score=73.58\n",
      "Loss: 2.3642277209767366\n",
      "Loss: 1.2015687543562603\n",
      "Loss: 0.9422164467913149\n",
      "Loss: 0.8347312856452129\n",
      "Loss: 0.7878631615896948\n",
      "Loss: 0.7326066929725964\n",
      "Loss: 0.6816276382883534\n",
      "Loss: 0.647589124066735\n",
      "Loss: 0.616382270997612\n",
      "Loss: 0.589939366878155\n",
      "______\n",
      "Iteration t=4\n",
      "all:  cs/acc_i=89.12 cs/acc_c=89.78 os/recall_knw=63.26 os/recall_unk=94.41 total/acc_i=73.15 total/acc_c=65.54 total/h_score=76.36\n",
      "selected:  cs/acc_i=88.29 cs/acc_c=89.00 os/recall_knw=60.11 os/recall_unk=96.13 total/acc_i=72.17 total/acc_c=63.21 total/h_score=75.06\n",
      "Loss: 2.3397555168497437\n",
      "Loss: 1.1533906146208999\n",
      "Loss: 0.9287325394070522\n",
      "Loss: 0.8045181682923945\n",
      "Loss: 0.7442920003410831\n",
      "Loss: 0.6934944445767054\n",
      "Loss: 0.6425978510221954\n",
      "Loss: 0.6126814000178713\n",
      "Loss: 0.5959645410032638\n",
      "Loss: 0.5649317192491339\n",
      "______\n",
      "Iteration t=5\n",
      "all:  cs/acc_i=89.60 cs/acc_c=90.21 os/recall_knw=63.17 os/recall_unk=94.47 total/acc_i=73.11 total/acc_c=65.48 total/h_score=76.33\n",
      "selected:  cs/acc_i=89.23 cs/acc_c=89.92 os/recall_knw=61.88 os/recall_unk=94.81 total/acc_i=72.58 total/acc_c=64.61 total/h_score=75.77\n",
      "Loss: 2.3108168775088167\n",
      "Loss: 1.1167118751431164\n",
      "Loss: 0.894495501706045\n",
      "Loss: 0.8033433186068927\n",
      "Loss: 0.7335476555848774\n",
      "Loss: 0.6801934904635769\n",
      "Loss: 0.6472620064877483\n",
      "Loss: 0.5993700440309636\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.5674196930270489\n",
      "Loss: 0.5605058767769027\n",
      "______\n",
      "Iteration t=6\n",
      "all:  cs/acc_i=89.65 cs/acc_c=90.35 os/recall_knw=63.02 os/recall_unk=94.47 total/acc_i=73.02 total/acc_c=65.37 total/h_score=76.25\n",
      "selected:  cs/acc_i=89.57 cs/acc_c=90.28 os/recall_knw=62.71 os/recall_unk=94.47 total/acc_i=72.87 total/acc_c=65.18 total/h_score=76.11\n",
      "Loss: 2.308791748547958\n",
      "Loss: 1.1284825593738232\n",
      "Loss: 0.8741685433913086\n",
      "Loss: 0.7733571996628228\n",
      "Loss: 0.7134787208953146\n",
      "Loss: 0.6700479781223556\n",
      "Loss: 0.6356700488571393\n",
      "Loss: 0.5972453158790783\n",
      "Loss: 0.5635364920406019\n",
      "Loss: 0.558664475204581\n",
      "______\n",
      "Iteration t=7\n",
      "all:  cs/acc_i=89.30 cs/acc_c=89.95 os/recall_knw=63.02 os/recall_unk=94.47 total/acc_i=73.02 total/acc_c=65.37 total/h_score=76.25\n",
      "selected:  cs/acc_i=89.29 cs/acc_c=89.93 os/recall_knw=63.00 os/recall_unk=94.47 total/acc_i=73.01 total/acc_c=65.35 total/h_score=76.23\n",
      "Loss: 2.299900052515236\n",
      "Loss: 1.115274027191304\n",
      "Loss: 0.8506114300642464\n",
      "Loss: 0.7762614434232583\n",
      "Loss: 0.7384839494888847\n",
      "Loss: 0.6688707226232903\n",
      "Loss: 0.6307228476413198\n",
      "Loss: 0.5771543245661903\n",
      "Loss: 0.578632578052379\n",
      "Loss: 0.5314415585048295\n",
      "______\n",
      "Iteration t=8\n",
      "all:  cs/acc_i=89.62 cs/acc_c=90.27 os/recall_knw=63.02 os/recall_unk=94.47 total/acc_i=73.02 total/acc_c=65.37 total/h_score=76.25\n",
      "selected:  cs/acc_i=89.62 cs/acc_c=90.27 os/recall_knw=63.02 os/recall_unk=94.47 total/acc_i=73.02 total/acc_c=65.37 total/h_score=76.25\n",
      "Loss: 2.2893367631209864\n",
      "Loss: 1.1127320302499306\n",
      "Loss: 0.8720660308325613\n",
      "Loss: 0.7859479556413921\n",
      "Loss: 0.706466386598107\n",
      "Loss: 0.6796217588959513\n",
      "Loss: 0.622759232649932\n",
      "Loss: 0.5965074997999378\n",
      "Loss: 0.5676091266040867\n",
      "Loss: 0.5672367982868407\n",
      "______\n",
      "Iteration t=9\n",
      "all:  cs/acc_i=89.92 cs/acc_c=90.48 os/recall_knw=63.02 os/recall_unk=94.47 total/acc_i=73.02 total/acc_c=65.37 total/h_score=76.25\n",
      "selected:  cs/acc_i=89.92 cs/acc_c=90.48 os/recall_knw=63.02 os/recall_unk=94.47 total/acc_i=73.02 total/acc_c=65.37 total/h_score=76.25\n",
      "tensor(0)\n",
      "all:  cs/acc_i=89.92 cs/acc_c=90.48 os/recall_knw=63.02 os/recall_unk=94.47 total/acc_i=73.02 total/acc_c=65.37 total/h_score=76.25\n",
      "sketch -> real lr= 0.001 seed= 3\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19]\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20]\n",
      "Loss: 2.5999825037686173\n",
      "Loss: 1.5646559448368782\n",
      "Loss: 1.245030308191755\n",
      "Loss: 1.1046348227336344\n",
      "Loss: 1.0037795714044992\n",
      "Loss: 0.9308147409320933\n",
      "Loss: 0.8891580563730899\n",
      "Loss: 0.8249351507530803\n",
      "Loss: 0.8019514091774426\n",
      "Loss: 0.7607918748285918\n",
      "tensor(True) tensor(True)\n",
      "______\n",
      "Iteration t=1\n",
      "all:  cs/acc_i=86.25 cs/acc_c=87.21 os/recall_knw=89.54 os/recall_unk=54.19 total/acc_i=72.96 total/acc_c=82.10 total/h_score=65.72\n",
      "selected:  cs/acc_i=75.57 cs/acc_c=79.80 os/recall_knw=61.73 os/recall_unk=99.67 total/acc_i=80.27 total/acc_c=68.74 total/h_score=80.27\n",
      "Loss: 2.570282296079104\n",
      "Loss: 1.4462483459320226\n",
      "Loss: 1.0993633675770682\n",
      "Loss: 0.9849504469359507\n",
      "Loss: 0.8886749368222033\n",
      "Loss: 0.8576508342731194\n",
      "Loss: 0.7893212598855378\n",
      "Loss: 0.7581588158109149\n",
      "Loss: 0.711672234486361\n",
      "Loss: 0.6957112052401558\n",
      "______\n",
      "Iteration t=2\n",
      "all:  cs/acc_i=87.53 cs/acc_c=88.27 os/recall_knw=68.79 os/recall_unk=92.45 total/acc_i=75.82 total/acc_c=70.20 total/h_score=79.08\n",
      "selected:  cs/acc_i=82.04 cs/acc_c=83.52 os/recall_knw=51.63 os/recall_unk=99.55 total/acc_i=71.30 total/acc_c=57.05 total/h_score=70.79\n",
      "Loss: 2.4396101199943603\n",
      "Loss: 1.2782313366427676\n",
      "Loss: 0.9895758159060515\n",
      "Loss: 0.891081296988116\n",
      "Loss: 0.8028905624879226\n",
      "Loss: 0.7609980278115236\n",
      "Loss: 0.7426045217359339\n",
      "Loss: 0.6699369314290186\n",
      "Loss: 0.6513223451853708\n",
      "Loss: 0.6481164311634675\n",
      "______\n",
      "Iteration t=3\n",
      "all:  cs/acc_i=88.71 cs/acc_c=89.35 os/recall_knw=65.95 os/recall_unk=93.05 total/acc_i=74.32 total/acc_c=67.72 total/h_score=77.53\n",
      "selected:  cs/acc_i=86.55 cs/acc_c=87.43 os/recall_knw=58.35 os/recall_unk=97.88 total/acc_i=72.33 total/acc_c=61.68 total/h_score=74.29\n",
      "Loss: 2.3724389252045173\n",
      "Loss: 1.202883909503333\n",
      "Loss: 0.9267458868541306\n",
      "Loss: 0.816667356829849\n",
      "Loss: 0.7421894440119216\n",
      "Loss: 0.7234092574539802\n",
      "Loss: 0.6587087640659415\n",
      "Loss: 0.6424246407348475\n",
      "Loss: 0.6369143683168528\n",
      "Loss: 0.5808838032346835\n",
      "______\n",
      "Iteration t=4\n",
      "all:  cs/acc_i=89.03 cs/acc_c=89.70 os/recall_knw=65.27 os/recall_unk=93.17 total/acc_i=73.96 total/acc_c=67.20 total/h_score=77.19\n",
      "selected:  cs/acc_i=88.03 cs/acc_c=88.63 os/recall_knw=61.69 os/recall_unk=95.38 total/acc_i=72.91 total/acc_c=64.34 total/h_score=75.73\n",
      "Loss: 2.3401438660091824\n",
      "Loss: 1.1393229828940497\n",
      "Loss: 0.9053555655603608\n",
      "Loss: 0.8057957758299179\n",
      "Loss: 0.7235283386997051\n",
      "Loss: 0.6804326430170072\n",
      "Loss: 0.6528474513648285\n",
      "Loss: 0.6230251926204396\n",
      "Loss: 0.5734949727646179\n",
      "Loss: 0.5728683814199435\n",
      "______\n",
      "Iteration t=5\n",
      "all:  cs/acc_i=89.36 cs/acc_c=89.98 os/recall_knw=65.24 os/recall_unk=93.23 total/acc_i=73.96 total/acc_c=67.18 total/h_score=77.20\n",
      "selected:  cs/acc_i=89.03 cs/acc_c=89.58 os/recall_knw=63.85 os/recall_unk=93.62 total/acc_i=73.44 total/acc_c=66.11 total/h_score=76.54\n",
      "Loss: 2.3062244061710073\n",
      "Loss: 1.117285136057406\n",
      "Loss: 0.8587097979727245\n",
      "Loss: 0.7892503554926438\n",
      "Loss: 0.7156546083944184\n",
      "Loss: 0.6796519884041378\n",
      "Loss: 0.6591556501023623\n",
      "Loss: 0.6004561217767852\n",
      "Loss: 0.5707040452430038\n",
      "Loss: 0.5475914531013593\n",
      "______\n",
      "Iteration t=6\n",
      "all:  cs/acc_i=89.51 cs/acc_c=90.12 os/recall_knw=65.24 os/recall_unk=93.23 total/acc_i=73.96 total/acc_c=67.18 total/h_score=77.20\n",
      "selected:  cs/acc_i=89.45 cs/acc_c=90.02 os/recall_knw=64.94 os/recall_unk=93.39 total/acc_i=73.88 total/acc_c=66.96 total/h_score=77.09\n",
      "Loss: 2.2836100891132483\n",
      "Loss: 1.0810455501879621\n",
      "Loss: 0.8725001903988371\n",
      "Loss: 0.7701579541367972\n",
      "Loss: 0.7252326975732841\n",
      "Loss: 0.658761795835207\n",
      "Loss: 0.6310118513319316\n",
      "Loss: 0.6058698172037233\n",
      "Loss: 0.5581116489816031\n",
      "Loss: 0.5469395073518257\n",
      "______\n",
      "Iteration t=7\n",
      "all:  cs/acc_i=89.51 cs/acc_c=90.10 os/recall_knw=65.24 os/recall_unk=93.23 total/acc_i=73.96 total/acc_c=67.18 total/h_score=77.20\n",
      "selected:  cs/acc_i=89.51 cs/acc_c=90.10 os/recall_knw=65.24 os/recall_unk=93.28 total/acc_i=73.98 total/acc_c=67.18 total/h_score=77.22\n",
      "Loss: 2.273098946016369\n",
      "Loss: 1.0886762481070682\n",
      "Loss: 0.8522883503134036\n",
      "Loss: 0.7818596888346018\n",
      "Loss: 0.7152663577460127\n",
      "Loss: 0.6895651335899646\n",
      "Loss: 0.6144703166141956\n",
      "Loss: 0.5869884181481141\n",
      "Loss: 0.5620764582153148\n",
      "Loss: 0.5421533099185663\n",
      "______\n",
      "Iteration t=8\n",
      "all:  cs/acc_i=89.45 cs/acc_c=90.05 os/recall_knw=65.24 os/recall_unk=93.23 total/acc_i=73.96 total/acc_c=67.18 total/h_score=77.20\n",
      "selected:  cs/acc_i=89.45 cs/acc_c=90.05 os/recall_knw=65.24 os/recall_unk=93.23 total/acc_i=73.96 total/acc_c=67.18 total/h_score=77.20\n",
      "Loss: 2.284645175854099\n",
      "Loss: 1.09355108474808\n",
      "Loss: 0.8605209751472027\n",
      "Loss: 0.7927229096458908\n",
      "Loss: 0.706044279861211\n",
      "Loss: 0.6519857458147317\n",
      "Loss: 0.6467660902734584\n",
      "Loss: 0.6008151097839891\n",
      "Loss: 0.5619179110064554\n",
      "Loss: 0.5183568298318314\n",
      "______\n",
      "Iteration t=9\n",
      "all:  cs/acc_i=89.30 cs/acc_c=89.95 os/recall_knw=65.24 os/recall_unk=93.23 total/acc_i=73.96 total/acc_c=67.18 total/h_score=77.20\n",
      "selected:  cs/acc_i=89.30 cs/acc_c=89.95 os/recall_knw=65.24 os/recall_unk=93.23 total/acc_i=73.96 total/acc_c=67.18 total/h_score=77.20\n",
      "tensor(0)\n",
      "all:  cs/acc_i=89.30 cs/acc_c=89.95 os/recall_knw=65.24 os/recall_unk=93.23 total/acc_i=73.96 total/acc_c=67.18 total/h_score=77.20\n",
      "sketch -> real lr= 0.001 seed= 4\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19]\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20]\n",
      "Loss: 2.6217339260388264\n",
      "Loss: 1.5900569088691103\n",
      "Loss: 1.2472330236856917\n",
      "Loss: 1.1015502720807506\n",
      "Loss: 1.0134334118492836\n",
      "Loss: 0.9458468851789964\n",
      "Loss: 0.8817198702455622\n",
      "Loss: 0.8235887114980579\n",
      "Loss: 0.787381440928552\n",
      "Loss: 0.7569376309361078\n",
      "tensor(True) tensor(True)\n",
      "______\n",
      "Iteration t=1\n",
      "all:  cs/acc_i=86.40 cs/acc_c=87.38 os/recall_knw=89.60 os/recall_unk=54.31 total/acc_i=73.19 total/acc_c=82.37 total/h_score=65.90\n",
      "selected:  cs/acc_i=75.16 cs/acc_c=80.80 os/recall_knw=61.82 os/recall_unk=99.78 total/acc_i=80.41 total/acc_c=70.27 total/h_score=81.44\n",
      "Loss: 2.532476998254901\n",
      "Loss: 1.4354767095847207\n",
      "Loss: 1.100429914769579\n",
      "Loss: 0.986250747422703\n",
      "Loss: 0.8943929324140314\n",
      "Loss: 0.8322050551899144\n",
      "Loss: 0.7837212507109172\n",
      "Loss: 0.7601694782249263\n",
      "Loss: 0.6914010664722958\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.6771081441738567\n",
      "______\n",
      "Iteration t=2\n",
      "all:  cs/acc_i=87.82 cs/acc_c=88.55 os/recall_knw=76.85 os/recall_unk=86.22 total/acc_i=78.41 total/acc_c=76.28 total/h_score=80.67\n",
      "selected:  cs/acc_i=81.98 cs/acc_c=83.62 os/recall_knw=59.11 os/recall_unk=99.79 total/acc_i=76.31 total/acc_c=63.78 total/h_score=76.47\n",
      "Loss: 2.458570875284326\n",
      "Loss: 1.27233593245499\n",
      "Loss: 1.0130810420249254\n",
      "Loss: 0.8729153437013845\n",
      "Loss: 0.8090384451260093\n",
      "Loss: 0.8024231676609461\n",
      "Loss: 0.7107120640860259\n",
      "Loss: 0.6885600202638684\n",
      "Loss: 0.6454622761438821\n",
      "Loss: 0.6232306391910742\n",
      "______\n",
      "Iteration t=3\n",
      "all:  cs/acc_i=88.29 cs/acc_c=89.03 os/recall_knw=73.16 os/recall_unk=90.14 total/acc_i=77.69 total/acc_c=73.69 total/h_score=80.59\n",
      "selected:  cs/acc_i=85.88 cs/acc_c=86.90 os/recall_knw=64.57 os/recall_unk=98.51 total/acc_i=76.77 total/acc_c=67.64 total/h_score=79.11\n",
      "Loss: 2.376684944262214\n",
      "Loss: 1.1805418088871946\n",
      "Loss: 0.9139735788427373\n",
      "Loss: 0.8207057978303629\n",
      "Loss: 0.7594200328900396\n",
      "Loss: 0.7087877502791771\n",
      "Loss: 0.6687654007933901\n",
      "Loss: 0.6397447199377108\n",
      "Loss: 0.6048730232061879\n",
      "Loss: 0.5845284285724804\n",
      "______\n",
      "Iteration t=4\n",
      "all:  cs/acc_i=89.86 cs/acc_c=90.41 os/recall_knw=72.36 os/recall_unk=90.67 total/acc_i=77.48 total/acc_c=73.13 total/h_score=80.42\n",
      "selected:  cs/acc_i=88.87 cs/acc_c=89.47 os/recall_knw=68.48 os/recall_unk=95.61 total/acc_i=77.18 total/acc_c=70.38 total/h_score=80.24\n",
      "Loss: 2.326320215855559\n",
      "Loss: 1.1370656461748359\n",
      "Loss: 0.8960963505996417\n",
      "Loss: 0.7858191939351493\n",
      "Loss: 0.7238160337079061\n",
      "Loss: 0.6790100142665921\n",
      "Loss: 0.6403843456343429\n",
      "Loss: 0.6118975656285678\n",
      "Loss: 0.5892486031333061\n",
      "Loss: 0.5640192233944592\n",
      "______\n",
      "Iteration t=5\n",
      "all:  cs/acc_i=89.74 cs/acc_c=90.28 os/recall_knw=71.86 os/recall_unk=90.79 total/acc_i=77.22 total/acc_c=72.76 total/h_score=80.23\n",
      "selected:  cs/acc_i=89.26 cs/acc_c=89.90 os/recall_knw=70.19 os/recall_unk=91.88 total/acc_i=76.73 total/acc_c=71.66 total/h_score=79.88\n",
      "Loss: 2.2883422271410625\n",
      "Loss: 1.109002605477969\n",
      "Loss: 0.8758126738667488\n",
      "Loss: 0.7520150443414847\n",
      "Loss: 0.6862386526664098\n",
      "Loss: 0.6535116336743036\n",
      "Loss: 0.6267825568219026\n",
      "Loss: 0.6128895230094592\n",
      "Loss: 0.5627418493727843\n",
      "Loss: 0.5252903743584951\n",
      "______\n",
      "Iteration t=6\n",
      "all:  cs/acc_i=89.89 cs/acc_c=90.38 os/recall_knw=71.86 os/recall_unk=90.79 total/acc_i=77.22 total/acc_c=72.76 total/h_score=80.23\n",
      "selected:  cs/acc_i=89.70 cs/acc_c=90.25 os/recall_knw=71.25 os/recall_unk=91.01 total/acc_i=76.97 total/acc_c=72.42 total/h_score=80.08\n",
      "Loss: 2.2762915015220644\n",
      "Loss: 1.080041579340325\n",
      "Loss: 0.8396155730622714\n",
      "Loss: 0.7779302607794277\n",
      "Loss: 0.6801255693201159\n",
      "Loss: 0.6410908073675438\n",
      "Loss: 0.617309421105463\n",
      "Loss: 0.5681326774300122\n",
      "Loss: 0.5678689548226653\n",
      "Loss: 0.5113017254188412\n",
      "______\n",
      "Iteration t=7\n",
      "all:  cs/acc_i=90.13 cs/acc_c=90.67 os/recall_knw=71.83 os/recall_unk=90.85 total/acc_i=77.22 total/acc_c=72.74 total/h_score=80.23\n",
      "selected:  cs/acc_i=90.09 cs/acc_c=90.66 os/recall_knw=71.74 os/recall_unk=90.85 total/acc_i=77.17 total/acc_c=72.70 total/h_score=80.20\n",
      "Loss: 2.2577778799914383\n",
      "Loss: 1.0811536535378\n",
      "Loss: 0.8512881845721204\n",
      "Loss: 0.7595706285016933\n",
      "Loss: 0.6914119219061606\n",
      "Loss: 0.6593243163746421\n",
      "Loss: 0.6228314270219896\n",
      "Loss: 0.5787124776490736\n",
      "Loss: 0.5481332061442179\n",
      "Loss: 0.5371863981314513\n",
      "______\n",
      "Iteration t=8\n",
      "all:  cs/acc_i=90.19 cs/acc_c=90.75 os/recall_knw=71.83 os/recall_unk=90.85 total/acc_i=77.22 total/acc_c=72.74 total/h_score=80.23\n",
      "selected:  cs/acc_i=90.19 cs/acc_c=90.75 os/recall_knw=71.83 os/recall_unk=90.85 total/acc_i=77.22 total/acc_c=72.74 total/h_score=80.23\n",
      "Loss: 2.2603556931212982\n",
      "Loss: 1.0666865065742392\n",
      "Loss: 0.8517506960354722\n",
      "Loss: 0.7472665135169262\n",
      "Loss: 0.6999887839590687\n",
      "Loss: 0.6436784517396157\n",
      "Loss: 0.6225697969477806\n",
      "Loss: 0.5712249245045627\n",
      "Loss: 0.5547907018020798\n",
      "Loss: 0.5156979150220703\n",
      "______\n",
      "Iteration t=9\n",
      "all:  cs/acc_i=89.65 cs/acc_c=90.24 os/recall_knw=71.83 os/recall_unk=90.85 total/acc_i=77.22 total/acc_c=72.74 total/h_score=80.23\n",
      "selected:  cs/acc_i=89.65 cs/acc_c=90.24 os/recall_knw=71.83 os/recall_unk=90.85 total/acc_i=77.22 total/acc_c=72.74 total/h_score=80.23\n",
      "tensor(0)\n",
      "all:  cs/acc_i=89.65 cs/acc_c=90.24 os/recall_knw=71.83 os/recall_unk=90.85 total/acc_i=77.22 total/acc_c=72.74 total/h_score=80.23\n",
      "sketch -> real lr= 0.001 seed= 0\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19]\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20]\n",
      "Loss: 2.619562912831264\n",
      "Loss: 1.6028424195483721\n",
      "Loss: 1.2593147609613637\n",
      "Loss: 1.0974391429825168\n",
      "Loss: 1.0016341378203535\n",
      "Loss: 0.9401589204779769\n",
      "Loss: 0.8834164316675305\n",
      "Loss: 0.8297714560696509\n",
      "Loss: 0.7929217489683522\n",
      "Loss: 0.7902048944899466\n",
      "tensor(True) tensor(True)\n",
      "______\n",
      "Iteration t=1\n",
      "all:  cs/acc_i=86.73 cs/acc_c=87.70 os/recall_knw=88.94 os/recall_unk=53.00 total/acc_i=72.52 total/acc_c=82.02 total/h_score=64.83\n",
      "selected:  cs/acc_i=75.77 cs/acc_c=79.71 os/recall_knw=60.26 os/recall_unk=99.78 total/acc_i=79.18 total/acc_c=67.86 total/h_score=79.64\n",
      "Loss: 2.539988570037435\n",
      "Loss: 1.4349066849614753\n",
      "Loss: 1.0934768778378847\n",
      "Loss: 0.9844623105447801\n",
      "Loss: 0.8881618981478644\n",
      "Loss: 0.8353854894149498\n",
      "Loss: 0.7961987318074117\n",
      "Loss: 0.7437276448138425\n",
      "Loss: 0.7197904767560177\n",
      "Loss: 0.679702416795199\n",
      "______\n",
      "Iteration t=2\n",
      "all:  cs/acc_i=87.82 cs/acc_c=88.53 os/recall_knw=62.52 os/recall_unk=94.06 total/acc_i=72.40 total/acc_c=64.63 total/h_score=75.58\n",
      "selected:  cs/acc_i=83.51 cs/acc_c=84.89 os/recall_knw=46.95 os/recall_unk=99.31 total/acc_i=67.60 total/acc_c=52.00 total/h_score=66.19\n",
      "Loss: 2.4459573226120637\n",
      "Loss: 1.2949522599464154\n",
      "Loss: 1.0029847053171115\n",
      "Loss: 0.8849241698288736\n",
      "Loss: 0.8262462681941404\n",
      "Loss: 0.755232767863128\n",
      "Loss: 0.7426704639241896\n",
      "Loss: 0.688318936083153\n",
      "Loss: 0.6495112210284663\n",
      "Loss: 0.6456069197249776\n",
      "______\n",
      "Iteration t=3\n",
      "all:  cs/acc_i=88.65 cs/acc_c=89.32 os/recall_knw=61.45 os/recall_unk=95.25 total/acc_i=72.23 total/acc_c=63.90 total/h_score=75.35\n",
      "selected:  cs/acc_i=86.77 cs/acc_c=87.50 os/recall_knw=54.47 os/recall_unk=98.71 total/acc_i=70.08 total/acc_c=58.21 total/h_score=71.61\n",
      "Loss: 2.38260624287785\n",
      "Loss: 1.2289904893740364\n",
      "Loss: 0.947653576515723\n",
      "Loss: 0.8509288262845813\n",
      "Loss: 0.7707606703042984\n",
      "Loss: 0.7007216722636983\n",
      "Loss: 0.6771186603692131\n",
      "Loss: 0.636025059050408\n",
      "Loss: 0.6108275303158207\n",
      "Loss: 0.5658767531099527\n",
      "______\n",
      "Iteration t=4\n",
      "all:  cs/acc_i=88.97 cs/acc_c=89.60 os/recall_knw=61.42 os/recall_unk=95.42 total/acc_i=72.27 total/acc_c=63.88 total/h_score=75.39\n",
      "selected:  cs/acc_i=88.28 cs/acc_c=88.91 os/recall_knw=58.65 os/recall_unk=96.86 total/acc_i=71.40 total/acc_c=61.69 total/h_score=74.04\n",
      "Loss: 2.332092672378033\n",
      "Loss: 1.149523278216382\n",
      "Loss: 0.8969022537861671\n",
      "Loss: 0.7946579917952731\n",
      "Loss: 0.7598746485643454\n",
      "Loss: 0.6905810407825284\n",
      "Loss: 0.6841310706588771\n",
      "Loss: 0.613104036846361\n",
      "Loss: 0.6027682232377413\n",
      "Loss: 0.5677764705427877\n",
      "______\n",
      "Iteration t=5\n",
      "all:  cs/acc_i=89.30 cs/acc_c=89.96 os/recall_knw=61.34 os/recall_unk=95.42 total/acc_i=72.21 total/acc_c=63.81 total/h_score=75.33\n",
      "selected:  cs/acc_i=89.16 cs/acc_c=89.79 os/recall_knw=60.39 os/recall_unk=95.42 total/acc_i=71.84 total/acc_c=63.12 total/h_score=74.80\n",
      "Loss: 2.3329175018362984\n",
      "Loss: 1.1383359416858436\n",
      "Loss: 0.9080063986409571\n",
      "Loss: 0.7775670993573887\n",
      "Loss: 0.7362195103848513\n",
      "Loss: 0.6843436485303637\n",
      "Loss: 0.6423826112165484\n",
      "Loss: 0.6088930002807342\n",
      "Loss: 0.5660726027083152\n",
      "Loss: 0.551896571549763\n",
      "______\n",
      "Iteration t=6\n",
      "all:  cs/acc_i=89.12 cs/acc_c=89.71 os/recall_knw=61.31 os/recall_unk=95.42 total/acc_i=72.21 total/acc_c=63.81 total/h_score=75.33\n",
      "selected:  cs/acc_i=89.11 cs/acc_c=89.67 os/recall_knw=61.16 os/recall_unk=95.42 total/acc_i=72.16 total/acc_c=63.70 total/h_score=75.24\n",
      "Loss: 2.317639158447448\n",
      "Loss: 1.1195620402134319\n",
      "Loss: 0.8805634437364116\n",
      "Loss: 0.7897847298876011\n",
      "Loss: 0.7063431342103782\n",
      "Loss: 0.6584310755896486\n",
      "Loss: 0.6330455641036554\n",
      "Loss: 0.601282033700585\n",
      "Loss: 0.5616673480833757\n",
      "Loss: 0.5454233169250521\n",
      "______\n",
      "Iteration t=7\n",
      "all:  cs/acc_i=88.94 cs/acc_c=89.58 os/recall_knw=61.31 os/recall_unk=95.42 total/acc_i=72.21 total/acc_c=63.81 total/h_score=75.33\n",
      "selected:  cs/acc_i=88.94 cs/acc_c=89.58 os/recall_knw=61.31 os/recall_unk=95.42 total/acc_i=72.21 total/acc_c=63.81 total/h_score=75.33\n",
      "Loss: 2.3074184851434856\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 1.1246891727626527\n",
      "Loss: 0.8758174504436324\n",
      "Loss: 0.7815395794020578\n",
      "Loss: 0.7273073013833765\n",
      "Loss: 0.6667418718948299\n",
      "Loss: 0.6387859110946135\n",
      "Loss: 0.6088925803480701\n",
      "Loss: 0.5590610270207246\n",
      "Loss: 0.541037758462665\n",
      "______\n",
      "Iteration t=8\n",
      "all:  cs/acc_i=89.42 cs/acc_c=90.01 os/recall_knw=61.31 os/recall_unk=95.42 total/acc_i=72.21 total/acc_c=63.81 total/h_score=75.33\n",
      "selected:  cs/acc_i=89.42 cs/acc_c=90.01 os/recall_knw=61.31 os/recall_unk=95.42 total/acc_i=72.21 total/acc_c=63.81 total/h_score=75.33\n",
      "Loss: 2.3141568174948057\n",
      "Loss: 1.1332226151492408\n",
      "Loss: 0.8907176149379679\n",
      "Loss: 0.790416743568186\n",
      "Loss: 0.7128650554211067\n",
      "Loss: 0.6932735000657547\n",
      "Loss: 0.64631991622391\n",
      "Loss: 0.5949056156666206\n",
      "Loss: 0.575998205984005\n",
      "Loss: 0.5540186570569516\n",
      "______\n",
      "Iteration t=9\n",
      "all:  cs/acc_i=89.27 cs/acc_c=89.95 os/recall_knw=61.31 os/recall_unk=95.42 total/acc_i=72.21 total/acc_c=63.81 total/h_score=75.33\n",
      "selected:  cs/acc_i=89.27 cs/acc_c=89.95 os/recall_knw=61.31 os/recall_unk=95.42 total/acc_i=72.21 total/acc_c=63.81 total/h_score=75.33\n",
      "tensor(0)\n",
      "all:  cs/acc_i=89.27 cs/acc_c=89.95 os/recall_knw=61.31 os/recall_unk=95.42 total/acc_i=72.21 total/acc_c=63.81 total/h_score=75.33\n",
      "sketch -> real lr= 0.001 seed= 1\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19]\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20]\n",
      "Loss: 2.6135761342217436\n",
      "Loss: 1.603218064107726\n",
      "Loss: 1.2573891163399789\n",
      "Loss: 1.0886403512110752\n",
      "Loss: 1.0428604736792302\n",
      "Loss: 0.9419432867944768\n",
      "Loss: 0.8832968619808687\n",
      "Loss: 0.8145946132398285\n",
      "Loss: 0.7894338625194752\n",
      "Loss: 0.7467041768595181\n",
      "tensor(True) tensor(True)\n",
      "______\n",
      "Iteration t=1\n",
      "all:  cs/acc_i=86.43 cs/acc_c=87.47 os/recall_knw=89.51 os/recall_unk=54.13 total/acc_i=73.21 total/acc_c=82.56 total/h_score=65.83\n",
      "selected:  cs/acc_i=74.73 cs/acc_c=79.70 os/recall_knw=61.66 os/recall_unk=99.89 total/acc_i=80.36 total/acc_c=69.61 total/h_score=80.99\n",
      "Loss: 2.5339225970330785\n",
      "Loss: 1.4264198812793514\n",
      "Loss: 1.1079628680084572\n",
      "Loss: 0.9453114738962689\n",
      "Loss: 0.9040884654052922\n",
      "Loss: 0.8549534145925866\n",
      "Loss: 0.7938949033373692\n",
      "Loss: 0.7678682998311325\n",
      "Loss: 0.723445970076518\n",
      "Loss: 0.6865740208352198\n",
      "______\n",
      "Iteration t=2\n",
      "all:  cs/acc_i=87.56 cs/acc_c=88.35 os/recall_knw=72.24 os/recall_unk=89.36 total/acc_i=76.73 total/acc_c=72.68 total/h_score=79.65\n",
      "selected:  cs/acc_i=81.94 cs/acc_c=83.77 os/recall_knw=54.53 os/recall_unk=99.60 total/acc_i=73.20 total/acc_c=59.73 total/h_score=73.10\n",
      "Loss: 2.4455081375165917\n",
      "Loss: 1.3232008127417145\n",
      "Loss: 0.9733406659287055\n",
      "Loss: 0.905909299165353\n",
      "Loss: 0.7973825797952455\n",
      "Loss: 0.7802461359464345\n",
      "Loss: 0.7084618773725297\n",
      "Loss: 0.6985155686564829\n",
      "Loss: 0.6516392329186772\n",
      "Loss: 0.6530215928609344\n",
      "______\n",
      "Iteration t=3\n",
      "all:  cs/acc_i=88.41 cs/acc_c=89.14 os/recall_knw=68.46 os/recall_unk=92.51 total/acc_i=75.74 total/acc_c=70.09 total/h_score=79.03\n",
      "selected:  cs/acc_i=85.98 cs/acc_c=86.95 os/recall_knw=60.64 os/recall_unk=98.05 total/acc_i=73.90 total/acc_c=63.98 total/h_score=76.17\n",
      "Loss: 2.375106457754862\n",
      "Loss: 1.1809117067203247\n",
      "Loss: 0.9261237029120218\n",
      "Loss: 0.8418021749892681\n",
      "Loss: 0.7570860480233063\n",
      "Loss: 0.727771666946171\n",
      "Loss: 0.67457325928074\n",
      "Loss: 0.6281322558685173\n",
      "Loss: 0.6174092824510533\n",
      "Loss: 0.5699587811132987\n",
      "______\n",
      "Iteration t=4\n",
      "all:  cs/acc_i=89.33 cs/acc_c=89.86 os/recall_knw=67.96 os/recall_unk=93.64 total/acc_i=75.82 total/acc_c=69.70 total/h_score=79.12\n",
      "selected:  cs/acc_i=88.28 cs/acc_c=88.83 os/recall_knw=64.31 os/recall_unk=96.21 total/acc_i=74.87 total/acc_c=66.89 total/h_score=77.88\n",
      "Loss: 2.333540443318113\n",
      "Loss: 1.1235407916732314\n",
      "Loss: 0.8865188246779788\n",
      "Loss: 0.7937995060298683\n",
      "Loss: 0.7296786468128019\n",
      "Loss: 0.6878109571224266\n",
      "Loss: 0.6439245490673091\n",
      "Loss: 0.6138234250891993\n",
      "Loss: 0.5789950286331473\n",
      "Loss: 0.5789282629749767\n",
      "______\n",
      "Iteration t=5\n",
      "all:  cs/acc_i=89.54 cs/acc_c=90.14 os/recall_knw=67.93 os/recall_unk=93.64 total/acc_i=75.80 total/acc_c=69.68 total/h_score=79.11\n",
      "selected:  cs/acc_i=89.12 cs/acc_c=89.69 os/recall_knw=66.27 os/recall_unk=93.81 total/acc_i=75.11 total/acc_c=68.52 total/h_score=78.34\n",
      "Loss: 2.2977769431230186\n",
      "Loss: 1.1025763689666181\n",
      "Loss: 0.8784189278612266\n",
      "Loss: 0.7580834299930044\n",
      "Loss: 0.7032034864296784\n",
      "Loss: 0.651964276072544\n",
      "Loss: 0.6417326901007343\n",
      "Loss: 0.5695285494565159\n",
      "Loss: 0.5877275461884769\n",
      "Loss: 0.5235323484080869\n",
      "______\n",
      "Iteration t=6\n",
      "all:  cs/acc_i=89.71 cs/acc_c=90.33 os/recall_knw=67.81 os/recall_unk=93.64 total/acc_i=75.74 total/acc_c=69.60 total/h_score=79.06\n",
      "selected:  cs/acc_i=89.63 cs/acc_c=90.21 os/recall_knw=67.45 os/recall_unk=93.64 total/acc_i=75.58 total/acc_c=69.34 total/h_score=78.87\n",
      "Loss: 2.2813740773995717\n",
      "Loss: 1.0976981451114018\n",
      "Loss: 0.8522305500507354\n",
      "Loss: 0.7524106350541114\n",
      "Loss: 0.7033360236883164\n",
      "Loss: 0.648623077571392\n",
      "Loss: 0.6369807747254769\n",
      "Loss: 0.5926560363173485\n",
      "Loss: 0.5591214968264103\n",
      "Loss: 0.5289766479531924\n",
      "______\n",
      "Iteration t=7\n",
      "all:  cs/acc_i=89.68 cs/acc_c=90.31 os/recall_knw=67.81 os/recall_unk=93.64 total/acc_i=75.74 total/acc_c=69.60 total/h_score=79.06\n",
      "selected:  cs/acc_i=89.68 cs/acc_c=90.30 os/recall_knw=67.80 os/recall_unk=93.64 total/acc_i=75.74 total/acc_c=69.59 total/h_score=79.05\n",
      "Loss: 2.294718126125906\n",
      "Loss: 1.1113116145133972\n",
      "Loss: 0.8840953236402467\n",
      "Loss: 0.7652980377804798\n",
      "Loss: 0.6985978847524257\n",
      "Loss: 0.6699836394715547\n",
      "Loss: 0.6181748700498346\n",
      "Loss: 0.5797926777125989\n",
      "Loss: 0.5439678694916722\n",
      "Loss: 0.5532502295863985\n",
      "______\n",
      "Iteration t=8\n",
      "all:  cs/acc_i=89.71 cs/acc_c=90.37 os/recall_knw=67.81 os/recall_unk=93.64 total/acc_i=75.74 total/acc_c=69.60 total/h_score=79.06\n",
      "selected:  cs/acc_i=89.71 cs/acc_c=90.37 os/recall_knw=67.81 os/recall_unk=93.64 total/acc_i=75.74 total/acc_c=69.60 total/h_score=79.06\n",
      "Loss: 2.2876639029512376\n",
      "Loss: 1.0879048661536157\n",
      "Loss: 0.8382094783640384\n",
      "Loss: 0.7794231502122657\n",
      "Loss: 0.6896062040348782\n",
      "Loss: 0.6477669369045682\n",
      "Loss: 0.634483914042628\n",
      "Loss: 0.5976961828842512\n",
      "Loss: 0.5608384530013582\n",
      "Loss: 0.525606982310943\n",
      "______\n",
      "Iteration t=9\n",
      "all:  cs/acc_i=89.86 cs/acc_c=90.47 os/recall_knw=67.81 os/recall_unk=93.64 total/acc_i=75.74 total/acc_c=69.60 total/h_score=79.06\n",
      "selected:  cs/acc_i=89.86 cs/acc_c=90.47 os/recall_knw=67.81 os/recall_unk=93.64 total/acc_i=75.74 total/acc_c=69.60 total/h_score=79.06\n",
      "tensor(0)\n",
      "all:  cs/acc_i=89.86 cs/acc_c=90.47 os/recall_knw=67.81 os/recall_unk=93.64 total/acc_i=75.74 total/acc_c=69.60 total/h_score=79.06\n",
      "sketch -> real lr= 0.001 seed= 2\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19]\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20]\n",
      "Loss: 2.611847136400442\n",
      "Loss: 1.5989960743262706\n",
      "Loss: 1.2456736351008963\n",
      "Loss: 1.1096321310089752\n",
      "Loss: 1.008172787659991\n",
      "Loss: 0.922012020528844\n",
      "Loss: 0.8760386431111699\n",
      "Loss: 0.8372019870882541\n",
      "Loss: 0.7949087230768879\n",
      "Loss: 0.7524672067534607\n",
      "tensor(True) tensor(True)\n",
      "______\n",
      "Iteration t=1\n",
      "all:  cs/acc_i=85.72 cs/acc_c=86.62 os/recall_knw=89.00 os/recall_unk=53.12 total/acc_i=72.19 total/acc_c=81.50 total/h_score=64.76\n",
      "selected:  cs/acc_i=74.36 cs/acc_c=78.20 os/recall_knw=60.59 os/recall_unk=99.78 total/acc_i=79.29 total/acc_c=67.79 total/h_score=79.58\n",
      "Loss: 2.535562873863783\n",
      "Loss: 1.4384174332266948\n",
      "Loss: 1.0985158862637692\n",
      "Loss: 0.9779238016878973\n",
      "Loss: 0.9006110344265328\n",
      "Loss: 0.8439790979027748\n",
      "Loss: 0.7856871364790885\n",
      "Loss: 0.7645934478181308\n",
      "Loss: 0.7039158926879774\n",
      "Loss: 0.6779393192197456\n",
      "______\n",
      "Iteration t=2\n",
      "all:  cs/acc_i=86.99 cs/acc_c=87.85 os/recall_knw=68.49 os/recall_unk=93.23 total/acc_i=75.98 total/acc_c=69.90 total/h_score=79.12\n",
      "selected:  cs/acc_i=81.11 cs/acc_c=83.06 os/recall_knw=51.37 os/recall_unk=99.56 total/acc_i=71.23 total/acc_c=56.72 total/h_score=70.50\n",
      "Loss: 2.4425590679845737\n",
      "Loss: 1.3217150462037734\n",
      "Loss: 1.0016913268402332\n",
      "Loss: 0.9027443665812034\n",
      "Loss: 0.8260252036666142\n",
      "Loss: 0.7947201658296221\n",
      "Loss: 0.7214483842822431\n",
      "Loss: 0.7025258701493722\n",
      "Loss: 0.6486278964590481\n",
      "Loss: 0.6393559022259167\n",
      "______\n",
      "Iteration t=3\n",
      "all:  cs/acc_i=88.80 cs/acc_c=89.44 os/recall_knw=65.83 os/recall_unk=94.12 total/acc_i=74.69 total/acc_c=67.82 total/h_score=77.94\n",
      "selected:  cs/acc_i=86.70 cs/acc_c=87.52 os/recall_knw=58.57 os/recall_unk=98.63 total/acc_i=72.77 total/acc_c=62.17 total/h_score=74.88\n",
      "Loss: 2.3726245675155586\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 1.2069489889436489\n",
      "Loss: 0.9340085179256878\n",
      "Loss: 0.8393702300118028\n",
      "Loss: 0.7816978947078581\n",
      "Loss: 0.7179964812968275\n",
      "Loss: 0.6667990450807613\n",
      "Loss: 0.6361225381386366\n",
      "Loss: 0.5945418913372986\n",
      "Loss: 0.568343593651871\n",
      "______\n",
      "Iteration t=4\n",
      "all:  cs/acc_i=89.03 cs/acc_c=89.66 os/recall_knw=65.15 os/recall_unk=94.41 total/acc_i=74.36 total/acc_c=67.20 total/h_score=77.58\n",
      "selected:  cs/acc_i=88.12 cs/acc_c=88.67 os/recall_knw=61.82 os/recall_unk=96.42 total/acc_i=73.40 total/acc_c=64.63 total/h_score=76.24\n",
      "Loss: 2.342197513414754\n",
      "Loss: 1.1367156404174037\n",
      "Loss: 0.9087089535055889\n",
      "Loss: 0.8112184537781609\n",
      "Loss: 0.742280289116833\n",
      "Loss: 0.6664839164457388\n",
      "Loss: 0.6421437957324088\n",
      "Loss: 0.6020434787496924\n",
      "Loss: 0.5889863861310813\n",
      "Loss: 0.5791383577096794\n",
      "______\n",
      "Iteration t=5\n",
      "all:  cs/acc_i=89.21 cs/acc_c=89.82 os/recall_knw=64.71 os/recall_unk=94.41 total/acc_i=74.10 total/acc_c=66.90 total/h_score=77.36\n",
      "selected:  cs/acc_i=88.77 cs/acc_c=89.36 os/recall_knw=63.26 os/recall_unk=94.70 total/acc_i=73.48 total/acc_c=65.82 total/h_score=76.65\n",
      "Loss: 2.2937011722818577\n",
      "Loss: 1.0976392108018895\n",
      "Loss: 0.8711110439927098\n",
      "Loss: 0.788522153685931\n",
      "Loss: 0.7261197096048362\n",
      "Loss: 0.6696577584784186\n",
      "Loss: 0.647067789077352\n",
      "Loss: 0.5974797603416768\n",
      "Loss: 0.5743999922641715\n",
      "Loss: 0.5501229537225014\n",
      "______\n",
      "Iteration t=6\n",
      "all:  cs/acc_i=89.89 cs/acc_c=90.40 os/recall_knw=64.68 os/recall_unk=94.41 total/acc_i=74.08 total/acc_c=66.88 total/h_score=77.34\n",
      "selected:  cs/acc_i=89.81 cs/acc_c=90.36 os/recall_knw=64.39 os/recall_unk=94.41 total/acc_i=73.94 total/acc_c=66.73 total/h_score=77.23\n",
      "Loss: 2.297080256320812\n",
      "Loss: 1.100314990237907\n",
      "Loss: 0.8789922001987996\n",
      "Loss: 0.7718359910779529\n",
      "Loss: 0.754719640269424\n",
      "Loss: 0.6585213734646036\n",
      "Loss: 0.6317821027403728\n",
      "Loss: 0.599316250996959\n",
      "Loss: 0.5895525515079498\n",
      "Loss: 0.5507220579718901\n",
      "______\n",
      "Iteration t=7\n",
      "all:  cs/acc_i=89.33 cs/acc_c=89.91 os/recall_knw=64.68 os/recall_unk=94.41 total/acc_i=74.08 total/acc_c=66.88 total/h_score=77.34\n",
      "selected:  cs/acc_i=89.33 cs/acc_c=89.91 os/recall_knw=64.68 os/recall_unk=94.41 total/acc_i=74.08 total/acc_c=66.88 total/h_score=77.34\n",
      "Loss: 2.3145269372246484\n",
      "Loss: 1.1054804453544744\n",
      "Loss: 0.8622262004248622\n",
      "Loss: 0.7686626429509635\n",
      "Loss: 0.7220712296589457\n",
      "Loss: 0.6606961741591945\n",
      "Loss: 0.6237955443084441\n",
      "Loss: 0.5894913134049085\n",
      "Loss: 0.5539115298075307\n",
      "Loss: 0.5346582761717966\n",
      "______\n",
      "Iteration t=8\n",
      "all:  cs/acc_i=90.10 cs/acc_c=90.67 os/recall_knw=64.68 os/recall_unk=94.41 total/acc_i=74.08 total/acc_c=66.88 total/h_score=77.34\n",
      "selected:  cs/acc_i=90.10 cs/acc_c=90.67 os/recall_knw=64.68 os/recall_unk=94.41 total/acc_i=74.08 total/acc_c=66.88 total/h_score=77.34\n",
      "Loss: 2.314594020345797\n",
      "Loss: 1.0953724947240617\n",
      "Loss: 0.8445950037100499\n",
      "Loss: 0.7823265135689617\n",
      "Loss: 0.7081763893867583\n",
      "Loss: 0.6691920328822601\n",
      "Loss: 0.6164177731933819\n",
      "Loss: 0.586054878202753\n",
      "Loss: 0.5477770043141914\n",
      "Loss: 0.5309851265415199\n",
      "______\n",
      "Iteration t=9\n",
      "all:  cs/acc_i=90.01 cs/acc_c=90.50 os/recall_knw=64.68 os/recall_unk=94.41 total/acc_i=74.08 total/acc_c=66.88 total/h_score=77.34\n",
      "selected:  cs/acc_i=90.01 cs/acc_c=90.50 os/recall_knw=64.68 os/recall_unk=94.41 total/acc_i=74.08 total/acc_c=66.88 total/h_score=77.34\n",
      "tensor(0)\n",
      "all:  cs/acc_i=90.01 cs/acc_c=90.50 os/recall_knw=64.68 os/recall_unk=94.41 total/acc_i=74.08 total/acc_c=66.88 total/h_score=77.34\n",
      "sketch -> real lr= 0.001 seed= 3\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19]\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20]\n",
      "Loss: 2.6001662000090673\n",
      "Loss: 1.5649565616540149\n",
      "Loss: 1.2455595452173622\n",
      "Loss: 1.1037551958476548\n",
      "Loss: 1.002430981766861\n",
      "Loss: 0.9293257201139906\n",
      "Loss: 0.8868063851795366\n",
      "Loss: 0.8232357214509913\n",
      "Loss: 0.8004633438798179\n",
      "Loss: 0.7585929400098007\n",
      "tensor(True) tensor(True)\n",
      "______\n",
      "Iteration t=1\n",
      "all:  cs/acc_i=86.43 cs/acc_c=87.37 os/recall_knw=89.42 os/recall_unk=53.95 total/acc_i=72.88 total/acc_c=82.04 total/h_score=65.53\n",
      "selected:  cs/acc_i=75.84 cs/acc_c=80.09 os/recall_knw=61.38 os/recall_unk=99.67 total/acc_i=80.03 total/acc_c=68.32 total/h_score=79.96\n",
      "Loss: 2.569919280341414\n",
      "Loss: 1.455783547680886\n",
      "Loss: 1.1229129917308933\n",
      "Loss: 0.9897174049840599\n",
      "Loss: 0.8891306657527314\n",
      "Loss: 0.8368698099597556\n",
      "Loss: 0.7735310161455733\n",
      "Loss: 0.7586930000879726\n",
      "Loss: 0.7127487179441531\n",
      "Loss: 0.7005521515842343\n",
      "______\n",
      "Iteration t=2\n",
      "all:  cs/acc_i=87.41 cs/acc_c=88.25 os/recall_knw=70.91 os/recall_unk=91.50 total/acc_i=76.65 total/acc_c=71.83 total/h_score=79.86\n",
      "selected:  cs/acc_i=81.94 cs/acc_c=83.68 os/recall_knw=53.36 os/recall_unk=99.55 total/acc_i=72.60 total/acc_c=58.62 total/h_score=72.14\n",
      "Loss: 2.4501141582736534\n",
      "Loss: 1.2886797849458593\n",
      "Loss: 0.9949858786950585\n",
      "Loss: 0.8968388680510848\n",
      "Loss: 0.8072134258637902\n",
      "Loss: 0.7534736980691211\n",
      "Loss: 0.740859710760699\n",
      "Loss: 0.6918116826137514\n",
      "Loss: 0.6674716238870876\n",
      "Loss: 0.6256373973406908\n",
      "______\n",
      "Iteration t=3\n",
      "all:  cs/acc_i=88.68 cs/acc_c=89.35 os/recall_knw=68.67 os/recall_unk=92.87 total/acc_i=75.82 total/acc_c=70.03 total/h_score=79.10\n",
      "selected:  cs/acc_i=86.58 cs/acc_c=87.43 os/recall_knw=60.80 os/recall_unk=98.43 total/acc_i=74.14 total/acc_c=64.36 total/h_score=76.57\n",
      "Loss: 2.379037571896752\n",
      "Loss: 1.1863780193191638\n",
      "Loss: 0.932305610008377\n",
      "Loss: 0.8184310092771654\n",
      "Loss: 0.7561775278702056\n",
      "Loss: 0.7215176598845626\n",
      "Loss: 0.6662154784091086\n",
      "Loss: 0.6288741513979521\n",
      "Loss: 0.6066595282164409\n",
      "Loss: 0.5702939579973547\n",
      "______\n",
      "Iteration t=4\n",
      "all:  cs/acc_i=89.30 cs/acc_c=89.87 os/recall_knw=68.46 os/recall_unk=93.17 total/acc_i=75.80 total/acc_c=69.89 total/h_score=79.10\n",
      "selected:  cs/acc_i=88.44 cs/acc_c=88.97 os/recall_knw=64.86 os/recall_unk=96.08 total/acc_i=75.06 total/acc_c=67.37 total/h_score=78.20\n",
      "Loss: 2.3154285726876096\n",
      "Loss: 1.1646521962922194\n",
      "Loss: 0.8656610222726032\n",
      "Loss: 0.7935846256798711\n",
      "Loss: 0.7149125991710301\n",
      "Loss: 0.6847048783610608\n",
      "Loss: 0.6468043347371035\n",
      "Loss: 0.6090365294238617\n",
      "Loss: 0.5691644274982913\n",
      "Loss: 0.5718323148530106\n",
      "______\n",
      "Iteration t=5\n",
      "all:  cs/acc_i=89.45 cs/acc_c=90.07 os/recall_knw=68.37 os/recall_unk=93.29 total/acc_i=75.78 total/acc_c=69.81 total/h_score=79.09\n",
      "selected:  cs/acc_i=89.07 cs/acc_c=89.68 os/recall_knw=66.68 os/recall_unk=93.96 total/acc_i=75.24 total/acc_c=68.72 total/h_score=78.53\n",
      "Loss: 2.3102535992055326\n",
      "Loss: 1.0881670914791726\n",
      "Loss: 0.8694702263015348\n",
      "Loss: 0.7848238858419496\n",
      "Loss: 0.73520473400886\n",
      "Loss: 0.6504917649199834\n",
      "Loss: 0.6342061973755827\n",
      "Loss: 0.5847785275026753\n",
      "Loss: 0.5784895015830124\n",
      "Loss: 0.5369519531928204\n",
      "______\n",
      "Iteration t=6\n",
      "all:  cs/acc_i=89.80 cs/acc_c=90.41 os/recall_knw=68.31 os/recall_unk=93.29 total/acc_i=75.76 total/acc_c=69.78 total/h_score=79.06\n",
      "selected:  cs/acc_i=89.71 cs/acc_c=90.33 os/recall_knw=67.75 os/recall_unk=93.51 total/acc_i=75.59 total/acc_c=69.47 total/h_score=78.92\n",
      "Loss: 2.283332861264547\n",
      "Loss: 1.0835740357637405\n",
      "Loss: 0.8719221356511117\n",
      "Loss: 0.7657701840003331\n",
      "Loss: 0.6912736400961876\n",
      "Loss: 0.6835354248682658\n",
      "Loss: 0.6245956056813399\n",
      "Loss: 0.5785591971377532\n",
      "Loss: 0.5627890854080518\n",
      "Loss: 0.5523716482520103\n",
      "______\n",
      "Iteration t=7\n",
      "all:  cs/acc_i=90.07 cs/acc_c=90.65 os/recall_knw=68.28 os/recall_unk=93.29 total/acc_i=75.74 total/acc_c=69.75 total/h_score=79.04\n",
      "selected:  cs/acc_i=90.09 cs/acc_c=90.67 os/recall_knw=68.25 os/recall_unk=93.29 total/acc_i=75.75 total/acc_c=69.75 total/h_score=79.05\n",
      "Loss: 2.28964412093952\n",
      "Loss: 1.0797206039065557\n",
      "Loss: 0.8497512329690504\n",
      "Loss: 0.771754524368324\n",
      "Loss: 0.7200089347678305\n",
      "Loss: 0.6548545433097328\n",
      "Loss: 0.6127459533167201\n",
      "Loss: 0.5813744780144944\n",
      "Loss: 0.551798833768494\n",
      "Loss: 0.5218353587270572\n",
      "______\n",
      "Iteration t=8\n",
      "all:  cs/acc_i=90.48 cs/acc_c=90.98 os/recall_knw=68.28 os/recall_unk=93.29 total/acc_i=75.74 total/acc_c=69.75 total/h_score=79.04\n",
      "selected:  cs/acc_i=90.48 cs/acc_c=90.98 os/recall_knw=68.28 os/recall_unk=93.29 total/acc_i=75.74 total/acc_c=69.75 total/h_score=79.04\n",
      "Loss: 2.279825023073234\n",
      "Loss: 1.1062811740384197\n",
      "Loss: 0.8431541350306264\n",
      "Loss: 0.7670003665204079\n",
      "Loss: 0.692556380978878\n",
      "Loss: 0.6547587578067716\n",
      "Loss: 0.6356367150580646\n",
      "Loss: 0.5954154981485266\n",
      "Loss: 0.5483436219344865\n",
      "Loss: 0.5395132841554698\n",
      "______\n",
      "Iteration t=9\n",
      "all:  cs/acc_i=89.89 cs/acc_c=90.54 os/recall_knw=68.28 os/recall_unk=93.29 total/acc_i=75.74 total/acc_c=69.75 total/h_score=79.04\n",
      "selected:  cs/acc_i=89.89 cs/acc_c=90.54 os/recall_knw=68.28 os/recall_unk=93.29 total/acc_i=75.74 total/acc_c=69.75 total/h_score=79.04\n",
      "tensor(0)\n",
      "all:  cs/acc_i=89.89 cs/acc_c=90.54 os/recall_knw=68.28 os/recall_unk=93.29 total/acc_i=75.74 total/acc_c=69.75 total/h_score=79.04\n",
      "sketch -> real lr= 0.001 seed= 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19]\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20]\n",
      "Loss: 2.6203276604677725\n",
      "Loss: 1.5919631508599341\n",
      "Loss: 1.2495304625646202\n",
      "Loss: 1.1023333433982545\n",
      "Loss: 1.013199003396836\n",
      "Loss: 0.9458240949738342\n",
      "Loss: 0.881077845539667\n",
      "Loss: 0.8221635958262249\n",
      "Loss: 0.7866165386100786\n",
      "Loss: 0.7556474829933285\n",
      "tensor(True) tensor(True)\n",
      "______\n",
      "Iteration t=1\n",
      "all:  cs/acc_i=86.52 cs/acc_c=87.46 os/recall_knw=89.27 os/recall_unk=53.65 total/acc_i=72.68 total/acc_c=81.90 total/h_score=65.27\n",
      "selected:  cs/acc_i=76.34 cs/acc_c=81.54 os/recall_knw=61.13 os/recall_unk=99.78 total/acc_i=79.83 total/acc_c=69.41 total/h_score=80.80\n",
      "Loss: 2.5353006368777793\n",
      "Loss: 1.4061945767187682\n",
      "Loss: 1.0929912399561679\n",
      "Loss: 0.9802919011868414\n",
      "Loss: 0.8790267009715564\n",
      "Loss: 0.8356233152454017\n",
      "Loss: 0.771526545164038\n",
      "Loss: 0.725707122292675\n",
      "Loss: 0.7028992745231409\n",
      "Loss: 0.6775779385791451\n",
      "______\n",
      "Iteration t=2\n",
      "all:  cs/acc_i=87.61 cs/acc_c=88.40 os/recall_knw=70.26 os/recall_unk=90.43 total/acc_i=76.02 total/acc_c=71.22 total/h_score=79.08\n",
      "selected:  cs/acc_i=82.12 cs/acc_c=84.12 os/recall_knw=52.90 os/recall_unk=99.61 total/acc_i=72.08 total/acc_c=58.13 total/h_score=71.74\n",
      "Loss: 2.4500115950598973\n",
      "Loss: 1.277100966631911\n",
      "Loss: 0.9941089319363805\n",
      "Loss: 0.8839054852724075\n",
      "Loss: 0.8058453993942901\n",
      "Loss: 0.7606359214045619\n",
      "Loss: 0.7404401348974868\n",
      "Loss: 0.6915221128982442\n",
      "Loss: 0.643375453546302\n",
      "Loss: 0.637115454514518\n",
      "______\n",
      "Iteration t=3\n",
      "all:  cs/acc_i=88.77 cs/acc_c=89.42 os/recall_knw=69.82 os/recall_unk=91.33 total/acc_i=76.08 total/acc_c=70.92 total/h_score=79.19\n",
      "selected:  cs/acc_i=86.46 cs/acc_c=87.42 os/recall_knw=61.28 os/recall_unk=98.02 total/acc_i=74.46 total/acc_c=64.72 total/h_score=76.74\n",
      "Loss: 2.3804682686174514\n",
      "Loss: 1.1886436124499753\n",
      "Loss: 0.9348518561116226\n",
      "Loss: 0.8325083453020603\n",
      "Loss: 0.7527869785432335\n",
      "Loss: 0.6997195083460361\n",
      "Loss: 0.6851717684980777\n",
      "Loss: 0.6379026982852881\n",
      "Loss: 0.6140678719007712\n",
      "Loss: 0.5950380196031049\n",
      "______\n",
      "Iteration t=4\n",
      "all:  cs/acc_i=89.18 cs/acc_c=89.74 os/recall_knw=68.99 os/recall_unk=91.80 total/acc_i=75.78 total/acc_c=70.31 total/h_score=78.94\n",
      "selected:  cs/acc_i=88.24 cs/acc_c=88.78 os/recall_knw=65.15 os/recall_unk=95.14 total/acc_i=75.05 total/acc_c=67.56 total/h_score=78.06\n",
      "Loss: 2.327355069949709\n",
      "Loss: 1.1580023726512645\n",
      "Loss: 0.9113047633705468\n",
      "Loss: 0.7996760721864371\n",
      "Loss: 0.7460105738763152\n",
      "Loss: 0.6732999394166058\n",
      "Loss: 0.6448820525716091\n",
      "Loss: 0.6112302929676813\n",
      "Loss: 0.5905188808153415\n",
      "Loss: 0.5492761822610066\n",
      "______\n",
      "Iteration t=5\n",
      "all:  cs/acc_i=89.09 cs/acc_c=89.70 os/recall_knw=68.87 os/recall_unk=91.80 total/acc_i=75.72 total/acc_c=70.24 total/h_score=78.89\n",
      "selected:  cs/acc_i=88.65 cs/acc_c=89.31 os/recall_knw=67.06 os/recall_unk=92.57 total/acc_i=75.13 total/acc_c=69.06 total/h_score=78.33\n",
      "Loss: 2.3003006093831173\n",
      "Loss: 1.1030944019857079\n",
      "Loss: 0.8622955267477517\n",
      "Loss: 0.792595814675193\n",
      "Loss: 0.7063950674000011\n",
      "Loss: 0.6723570041483902\n",
      "Loss: 0.6214325918693735\n",
      "Loss: 0.5864898939225007\n",
      "Loss: 0.5643341563366078\n",
      "Loss: 0.5445447854873308\n",
      "______\n",
      "Iteration t=6\n",
      "all:  cs/acc_i=89.86 cs/acc_c=90.47 os/recall_knw=68.81 os/recall_unk=91.80 total/acc_i=75.70 total/acc_c=70.22 total/h_score=78.88\n",
      "selected:  cs/acc_i=89.85 cs/acc_c=90.51 os/recall_knw=68.32 os/recall_unk=92.02 total/acc_i=75.60 total/acc_c=70.03 total/h_score=78.82\n",
      "Loss: 2.2798061446098\n",
      "Loss: 1.076471063187748\n",
      "Loss: 0.8721979984215328\n",
      "Loss: 0.7483522278129856\n",
      "Loss: 0.7149749008128017\n",
      "Loss: 0.6645864815609004\n",
      "Loss: 0.6144976090652206\n",
      "Loss: 0.5809341176007673\n",
      "Loss: 0.543494719603529\n",
      "Loss: 0.5418337353836262\n",
      "______\n",
      "Iteration t=7\n",
      "all:  cs/acc_i=89.65 cs/acc_c=90.27 os/recall_knw=68.81 os/recall_unk=91.80 total/acc_i=75.70 total/acc_c=70.22 total/h_score=78.88\n",
      "selected:  cs/acc_i=89.68 cs/acc_c=90.30 os/recall_knw=68.80 os/recall_unk=91.80 total/acc_i=75.71 total/acc_c=70.24 total/h_score=78.89\n",
      "Loss: 2.281279996676807\n",
      "Loss: 1.0877137054311168\n",
      "Loss: 0.8431662679111996\n",
      "Loss: 0.7682252786930638\n",
      "Loss: 0.6942707136912708\n",
      "Loss: 0.639345664789181\n",
      "Loss: 0.6025036891596546\n",
      "Loss: 0.5837282628411113\n",
      "Loss: 0.5494698610636267\n",
      "Loss: 0.5309338498331926\n",
      "______\n",
      "Iteration t=8\n",
      "all:  cs/acc_i=90.01 cs/acc_c=90.63 os/recall_knw=68.81 os/recall_unk=91.80 total/acc_i=75.70 total/acc_c=70.22 total/h_score=78.88\n",
      "selected:  cs/acc_i=90.01 cs/acc_c=90.63 os/recall_knw=68.81 os/recall_unk=91.80 total/acc_i=75.70 total/acc_c=70.22 total/h_score=78.88\n",
      "Loss: 2.2525742986414694\n",
      "Loss: 1.0539127171236295\n",
      "Loss: 0.8536416965939424\n",
      "Loss: 0.7706364008656429\n",
      "Loss: 0.7002569166543854\n",
      "Loss: 0.6393604581505552\n",
      "Loss: 0.6276128206020928\n",
      "Loss: 0.5798469116487125\n",
      "Loss: 0.5705157696413915\n",
      "Loss: 0.5379289176696205\n",
      "______\n",
      "Iteration t=9\n",
      "all:  cs/acc_i=90.10 cs/acc_c=90.66 os/recall_knw=68.81 os/recall_unk=91.80 total/acc_i=75.70 total/acc_c=70.22 total/h_score=78.88\n",
      "selected:  cs/acc_i=90.10 cs/acc_c=90.66 os/recall_knw=68.81 os/recall_unk=91.80 total/acc_i=75.70 total/acc_c=70.22 total/h_score=78.88\n",
      "tensor(0)\n",
      "all:  cs/acc_i=90.10 cs/acc_c=90.66 os/recall_knw=68.81 os/recall_unk=91.80 total/acc_i=75.70 total/acc_c=70.22 total/h_score=78.88\n",
      "sketch -> real lr= 0.001 seed= 0\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19]\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20]\n",
      "Loss: 2.6175921121529773\n",
      "Loss: 1.6013941123949742\n",
      "Loss: 1.2602262987499744\n",
      "Loss: 1.0986553620448154\n",
      "Loss: 1.0026553561993405\n",
      "Loss: 0.9416032862083047\n",
      "Loss: 0.8845067038736513\n",
      "Loss: 0.8312141628919449\n",
      "Loss: 0.7944873428977697\n",
      "Loss: 0.7906646066534836\n",
      "tensor(True) tensor(True)\n",
      "______\n",
      "Iteration t=1\n",
      "all:  cs/acc_i=86.37 cs/acc_c=87.36 os/recall_knw=89.39 os/recall_unk=53.89 total/acc_i=73.06 total/acc_c=82.45 total/h_score=65.62\n",
      "selected:  cs/acc_i=74.46 cs/acc_c=78.69 os/recall_knw=61.31 os/recall_unk=99.67 total/acc_i=79.98 total/acc_c=69.05 total/h_score=80.51\n",
      "Loss: 2.5453266833649306\n",
      "Loss: 1.4404682106659061\n",
      "Loss: 1.113252076946321\n",
      "Loss: 0.9861835952176422\n",
      "Loss: 0.9058870758678093\n",
      "Loss: 0.8530694860659662\n",
      "Loss: 0.80108436111544\n",
      "Loss: 0.7379075094568924\n",
      "Loss: 0.6919031777098531\n",
      "Loss: 0.6923224719577148\n",
      "______\n",
      "Iteration t=2\n",
      "all:  cs/acc_i=87.97 cs/acc_c=88.70 os/recall_knw=66.18 os/recall_unk=92.63 total/acc_i=74.36 total/acc_c=68.01 total/h_score=77.61\n",
      "selected:  cs/acc_i=82.84 cs/acc_c=84.41 os/recall_knw=49.54 os/recall_unk=99.30 total/acc_i=69.56 total/acc_c=54.30 total/h_score=68.30\n",
      "Loss: 2.447183047542135\n",
      "Loss: 1.3002887090653863\n",
      "Loss: 1.0021170664379615\n",
      "Loss: 0.8772220467110626\n",
      "Loss: 0.8314246481839027\n",
      "Loss: 0.762238250206445\n",
      "Loss: 0.7404040635087108\n",
      "Loss: 0.6883729549537179\n",
      "Loss: 0.6526176144603555\n",
      "Loss: 0.6252406345296452\n",
      "______\n",
      "Iteration t=3\n",
      "all:  cs/acc_i=88.18 cs/acc_c=88.85 os/recall_knw=64.82 os/recall_unk=93.52 total/acc_i=73.86 total/acc_c=66.94 total/h_score=77.12\n",
      "selected:  cs/acc_i=85.97 cs/acc_c=86.87 os/recall_knw=57.52 os/recall_unk=98.19 total/acc_i=71.91 total/acc_c=61.03 total/h_score=73.84\n",
      "Loss: 2.3756065131955197\n",
      "Loss: 1.2045762158042688\n",
      "Loss: 0.9425876338559368\n",
      "Loss: 0.8150099943045674\n",
      "Loss: 0.7713477109098262\n",
      "Loss: 0.7025040521518419\n",
      "Loss: 0.6745834749743396\n",
      "Loss: 0.6285619322573666\n",
      "Loss: 0.6051436863328575\n",
      "Loss: 0.5820839720835325\n",
      "______\n",
      "Iteration t=4\n",
      "all:  cs/acc_i=89.12 cs/acc_c=89.69 os/recall_knw=64.65 os/recall_unk=93.58 total/acc_i=73.79 total/acc_c=66.82 total/h_score=77.05\n",
      "selected:  cs/acc_i=88.34 cs/acc_c=88.89 os/recall_knw=61.80 os/recall_unk=95.57 total/acc_i=73.01 total/acc_c=64.51 total/h_score=75.91\n",
      "Loss: 2.323929667885328\n",
      "Loss: 1.1185612045357385\n",
      "Loss: 0.8756223802541779\n",
      "Loss: 0.7876781379887802\n",
      "Loss: 0.7289776767001432\n",
      "Loss: 0.7036450453695542\n",
      "Loss: 0.6415164496453163\n",
      "Loss: 0.6157619354531014\n",
      "Loss: 0.5959942164511829\n",
      "Loss: 0.5543545026680178\n",
      "______\n",
      "Iteration t=5\n",
      "all:  cs/acc_i=89.42 cs/acc_c=90.00 os/recall_knw=64.65 os/recall_unk=93.58 total/acc_i=73.79 total/acc_c=66.82 total/h_score=77.05\n",
      "selected:  cs/acc_i=89.07 cs/acc_c=89.70 os/recall_knw=63.27 os/recall_unk=93.69 total/acc_i=73.18 total/acc_c=65.85 total/h_score=76.37\n",
      "Loss: 2.3272767302130357\n",
      "Loss: 1.1157863291145182\n",
      "Loss: 0.8806001324029196\n",
      "Loss: 0.7778290587217629\n",
      "Loss: 0.7283046229356\n",
      "Loss: 0.6794734673232449\n",
      "Loss: 0.6260113229050117\n",
      "Loss: 0.5906448222341991\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.5731841471730447\n",
      "Loss: 0.5427217522547358\n",
      "______\n",
      "Iteration t=6\n",
      "all:  cs/acc_i=90.16 cs/acc_c=90.79 os/recall_knw=64.59 os/recall_unk=93.58 total/acc_i=73.75 total/acc_c=66.78 total/h_score=77.02\n",
      "selected:  cs/acc_i=90.12 cs/acc_c=90.74 os/recall_knw=64.36 os/recall_unk=93.64 total/acc_i=73.67 total/acc_c=66.60 total/h_score=76.91\n",
      "Loss: 2.29743206099629\n",
      "Loss: 1.0907355188721357\n",
      "Loss: 0.8891056361623886\n",
      "Loss: 0.7866359457423792\n",
      "Loss: 0.7047009120886575\n",
      "Loss: 0.6751032668833781\n",
      "Loss: 0.6150772658863453\n",
      "Loss: 0.5927509481357003\n",
      "Loss: 0.5716097053855357\n",
      "Loss: 0.5356005004259071\n",
      "______\n",
      "Iteration t=7\n",
      "all:  cs/acc_i=89.77 cs/acc_c=90.39 os/recall_knw=64.59 os/recall_unk=93.64 total/acc_i=73.77 total/acc_c=66.78 total/h_score=77.04\n",
      "selected:  cs/acc_i=89.77 cs/acc_c=90.37 os/recall_knw=64.57 os/recall_unk=93.64 total/acc_i=73.76 total/acc_c=66.75 total/h_score=77.02\n",
      "Loss: 2.307759350978288\n",
      "Loss: 1.1100507438582863\n",
      "Loss: 0.8541389385725828\n",
      "Loss: 0.785689485553127\n",
      "Loss: 0.7257744098869746\n",
      "Loss: 0.6778391047112093\n",
      "Loss: 0.6381879210872138\n",
      "Loss: 0.5983165203024877\n",
      "Loss: 0.5716700713906512\n",
      "Loss: 0.5495846416526193\n",
      "______\n",
      "Iteration t=8\n",
      "all:  cs/acc_i=89.77 cs/acc_c=90.43 os/recall_knw=64.59 os/recall_unk=93.64 total/acc_i=73.77 total/acc_c=66.78 total/h_score=77.04\n",
      "selected:  cs/acc_i=89.77 cs/acc_c=90.43 os/recall_knw=64.59 os/recall_unk=93.64 total/acc_i=73.77 total/acc_c=66.78 total/h_score=77.04\n",
      "Loss: 2.3079249266810065\n",
      "Loss: 1.0950446834900236\n",
      "Loss: 0.8673609009125088\n",
      "Loss: 0.7556099588138945\n",
      "Loss: 0.7154161984088437\n",
      "Loss: 0.6659146821338858\n",
      "Loss: 0.6275110282753938\n",
      "Loss: 0.5986890208801167\n",
      "Loss: 0.5568062261547018\n",
      "Loss: 0.530511504651716\n",
      "______\n",
      "Iteration t=9\n",
      "all:  cs/acc_i=89.39 cs/acc_c=89.98 os/recall_knw=64.59 os/recall_unk=93.64 total/acc_i=73.77 total/acc_c=66.78 total/h_score=77.04\n",
      "selected:  cs/acc_i=89.39 cs/acc_c=89.98 os/recall_knw=64.59 os/recall_unk=93.64 total/acc_i=73.77 total/acc_c=66.78 total/h_score=77.04\n",
      "tensor(0)\n",
      "all:  cs/acc_i=89.39 cs/acc_c=89.98 os/recall_knw=64.59 os/recall_unk=93.64 total/acc_i=73.77 total/acc_c=66.78 total/h_score=77.04\n",
      "sketch -> real lr= 0.001 seed= 1\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19]\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20]\n",
      "Loss: 2.613240904512659\n",
      "Loss: 1.603020871107557\n",
      "Loss: 1.2583571005184038\n",
      "Loss: 1.0899239480495453\n",
      "Loss: 1.0432245462341647\n",
      "Loss: 0.9427372524432377\n",
      "Loss: 0.8845870960338981\n",
      "Loss: 0.8156714178292097\n",
      "Loss: 0.7909021541080644\n",
      "Loss: 0.7463864549598863\n",
      "tensor(True) tensor(True)\n",
      "______\n",
      "Iteration t=1\n",
      "all:  cs/acc_i=86.55 cs/acc_c=87.60 os/recall_knw=89.98 os/recall_unk=55.08 total/acc_i=73.65 total/acc_c=82.77 total/h_score=66.58\n",
      "selected:  cs/acc_i=75.82 cs/acc_c=80.44 os/recall_knw=62.75 os/recall_unk=99.89 total/acc_i=81.23 total/acc_c=70.45 total/h_score=81.61\n",
      "Loss: 2.5295409203552808\n",
      "Loss: 1.412741493983347\n",
      "Loss: 1.116744055366907\n",
      "Loss: 0.9495218413286521\n",
      "Loss: 0.9134712180153268\n",
      "Loss: 0.8658110885346522\n",
      "Loss: 0.7990486670712955\n",
      "Loss: 0.7676506755781956\n",
      "Loss: 0.7419544944509131\n",
      "Loss: 0.6774455311356998\n",
      "______\n",
      "Iteration t=2\n",
      "all:  cs/acc_i=87.82 cs/acc_c=88.67 os/recall_knw=64.20 os/recall_unk=94.12 total/acc_i=73.59 total/acc_c=66.45 total/h_score=76.94\n",
      "selected:  cs/acc_i=83.02 cs/acc_c=84.92 os/recall_knw=48.20 os/recall_unk=99.56 total/acc_i=68.67 total/acc_c=53.78 total/h_score=67.88\n",
      "Loss: 2.443021734252231\n",
      "Loss: 1.3094931686197528\n",
      "Loss: 1.01141291310769\n",
      "Loss: 0.8979475491374503\n",
      "Loss: 0.7994874420056817\n",
      "Loss: 0.7550359449086298\n",
      "Loss: 0.6942972273544501\n",
      "Loss: 0.6795593328375853\n",
      "Loss: 0.671478946359103\n",
      "Loss: 0.6139790597194024\n",
      "______\n",
      "Iteration t=3\n",
      "all:  cs/acc_i=88.35 cs/acc_c=89.07 os/recall_knw=63.49 os/recall_unk=94.77 total/acc_i=73.43 total/acc_c=65.94 total/h_score=76.76\n",
      "selected:  cs/acc_i=86.23 cs/acc_c=87.23 os/recall_knw=55.81 os/recall_unk=98.58 total/acc_i=71.18 total/acc_c=60.11 total/h_score=73.18\n",
      "Loss: 2.401451441688814\n",
      "Loss: 1.20935871095761\n",
      "Loss: 0.9593177059854286\n",
      "Loss: 0.8307091763270074\n",
      "Loss: 0.7606378950286603\n",
      "Loss: 0.7291683157285055\n",
      "Loss: 0.6613226377445719\n",
      "Loss: 0.6530097208485224\n",
      "Loss: 0.6230469221870104\n",
      "Loss: 0.5931108487580997\n",
      "______\n",
      "Iteration t=4\n",
      "all:  cs/acc_i=88.92 cs/acc_c=89.56 os/recall_knw=63.29 os/recall_unk=94.89 total/acc_i=73.39 total/acc_c=65.84 total/h_score=76.72\n",
      "selected:  cs/acc_i=88.07 cs/acc_c=88.75 os/recall_knw=60.28 os/recall_unk=96.96 total/acc_i=72.56 total/acc_c=63.65 total/h_score=75.63\n",
      "Loss: 2.337463068214443\n",
      "Loss: 1.1549982893757704\n",
      "Loss: 0.9086077946403716\n",
      "Loss: 0.8046827650651699\n",
      "Loss: 0.7460256361172174\n",
      "Loss: 0.6913345795682914\n",
      "Loss: 0.6439144192360835\n",
      "Loss: 0.625539604950865\n",
      "Loss: 0.5874401543302403\n",
      "Loss: 0.5662135904466649\n",
      "______\n",
      "Iteration t=5\n",
      "all:  cs/acc_i=89.39 cs/acc_c=90.08 os/recall_knw=62.96 os/recall_unk=94.95 total/acc_i=73.19 total/acc_c=65.58 total/h_score=76.54\n",
      "selected:  cs/acc_i=89.10 cs/acc_c=89.79 os/recall_knw=61.73 os/recall_unk=95.18 total/acc_i=72.70 total/acc_c=64.77 total/h_score=75.99\n",
      "Loss: 2.3143844743297524\n",
      "Loss: 1.1340837366368672\n",
      "Loss: 0.8848557665127598\n",
      "Loss: 0.7822043674245273\n",
      "Loss: 0.7236734850153531\n",
      "Loss: 0.6611418232627927\n",
      "Loss: 0.6433447096751977\n",
      "Loss: 0.6135371465695231\n",
      "Loss: 0.5760367928098326\n",
      "Loss: 0.5413120029213494\n",
      "______\n",
      "Iteration t=6\n",
      "all:  cs/acc_i=89.33 cs/acc_c=89.97 os/recall_knw=62.96 os/recall_unk=94.95 total/acc_i=73.19 total/acc_c=65.58 total/h_score=76.54\n",
      "selected:  cs/acc_i=89.28 cs/acc_c=89.89 os/recall_knw=62.77 os/recall_unk=94.95 total/acc_i=73.10 total/acc_c=65.42 total/h_score=76.42\n",
      "Loss: 2.30448382668576\n",
      "Loss: 1.1309321607573557\n",
      "Loss: 0.8760893527734077\n",
      "Loss: 0.7730888123229399\n",
      "Loss: 0.7403651728468427\n",
      "Loss: 0.6697572032273826\n",
      "Loss: 0.6300990494125981\n",
      "Loss: 0.5930435748676123\n",
      "Loss: 0.5658672936892105\n",
      "Loss: 0.5467243654243017\n",
      "______\n",
      "Iteration t=7\n",
      "all:  cs/acc_i=89.65 cs/acc_c=90.35 os/recall_knw=62.96 os/recall_unk=94.95 total/acc_i=73.19 total/acc_c=65.58 total/h_score=76.54\n",
      "selected:  cs/acc_i=89.65 cs/acc_c=90.35 os/recall_knw=62.96 os/recall_unk=94.95 total/acc_i=73.19 total/acc_c=65.58 total/h_score=76.54\n",
      "Loss: 2.3186121981022723\n",
      "Loss: 1.1103068449739681\n",
      "Loss: 0.8869621900178618\n",
      "Loss: 0.7923247664661731\n",
      "Loss: 0.7127887206562494\n",
      "Loss: 0.6779880821704865\n",
      "Loss: 0.6379624164205486\n",
      "Loss: 0.6046049826225992\n",
      "Loss: 0.5894842804488489\n",
      "Loss: 0.5459742799148721\n",
      "______\n",
      "Iteration t=8\n",
      "all:  cs/acc_i=89.48 cs/acc_c=90.17 os/recall_knw=62.96 os/recall_unk=94.95 total/acc_i=73.19 total/acc_c=65.58 total/h_score=76.54\n",
      "selected:  cs/acc_i=89.48 cs/acc_c=90.17 os/recall_knw=62.96 os/recall_unk=94.95 total/acc_i=73.19 total/acc_c=65.58 total/h_score=76.54\n",
      "Loss: 2.3027580665329754\n",
      "Loss: 1.1312953015505258\n",
      "Loss: 0.8782542585316351\n",
      "Loss: 0.780173951084331\n",
      "Loss: 0.7133195504293603\n",
      "Loss: 0.6498562718346967\n",
      "Loss: 0.6240659634693194\n",
      "Loss: 0.5808187874697023\n",
      "Loss: 0.5840957067275452\n",
      "Loss: 0.5537018048056102\n",
      "______\n",
      "Iteration t=9\n",
      "all:  cs/acc_i=88.97 cs/acc_c=89.70 os/recall_knw=62.96 os/recall_unk=94.95 total/acc_i=73.19 total/acc_c=65.58 total/h_score=76.54\n",
      "selected:  cs/acc_i=88.97 cs/acc_c=89.70 os/recall_knw=62.96 os/recall_unk=94.95 total/acc_i=73.19 total/acc_c=65.58 total/h_score=76.54\n",
      "tensor(0)\n",
      "all:  cs/acc_i=88.97 cs/acc_c=89.70 os/recall_knw=62.96 os/recall_unk=94.95 total/acc_i=73.19 total/acc_c=65.58 total/h_score=76.54\n",
      "sketch -> real lr= 0.001 seed= 2\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19]\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20]\n",
      "Loss: 2.6125502607463735\n",
      "Loss: 1.602078642465372\n",
      "Loss: 1.2468896357886559\n",
      "Loss: 1.1101202585000907\n",
      "Loss: 1.0084486904397476\n",
      "Loss: 0.921417772769928\n",
      "Loss: 0.8760327216798225\n",
      "Loss: 0.8365487842696958\n",
      "Loss: 0.7949959540789107\n",
      "Loss: 0.752037405703975\n",
      "tensor(True) tensor(True)\n",
      "______\n",
      "Iteration t=1\n",
      "all:  cs/acc_i=85.81 cs/acc_c=86.75 os/recall_knw=88.97 os/recall_unk=53.06 total/acc_i=72.19 total/acc_c=81.50 total/h_score=64.71\n",
      "selected:  cs/acc_i=74.50 cs/acc_c=78.29 os/recall_knw=60.36 os/recall_unk=99.78 total/acc_i=79.25 total/acc_c=67.49 total/h_score=79.36\n",
      "Loss: 2.5414072255619238\n",
      "Loss: 1.4272710360953065\n",
      "Loss: 1.1169722087559153\n",
      "Loss: 1.0008809329544912\n",
      "Loss: 0.8929996894764118\n",
      "Loss: 0.8313435322192849\n",
      "Loss: 0.7860020264738896\n",
      "Loss: 0.7684571964086079\n",
      "Loss: 0.7336196717424471\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.6776759942046932\n",
      "______\n",
      "Iteration t=2\n",
      "all:  cs/acc_i=86.96 cs/acc_c=87.88 os/recall_knw=62.87 os/recall_unk=95.25 total/acc_i=73.15 total/acc_c=65.07 total/h_score=76.25\n",
      "selected:  cs/acc_i=82.05 cs/acc_c=84.14 os/recall_knw=47.20 os/recall_unk=99.32 total/acc_i=68.02 total/acc_c=52.58 total/h_score=66.73\n",
      "Loss: 2.44482149377124\n",
      "Loss: 1.3142700070188245\n",
      "Loss: 1.007351800458122\n",
      "Loss: 0.8871849802614168\n",
      "Loss: 0.8076779668340246\n",
      "Loss: 0.7817870832354058\n",
      "Loss: 0.7281746289316025\n",
      "Loss: 0.6997066820964558\n",
      "Loss: 0.6263774391121537\n",
      "Loss: 0.6379296916700502\n",
      "______\n",
      "Iteration t=3\n",
      "all:  cs/acc_i=88.32 cs/acc_c=89.09 os/recall_knw=61.87 os/recall_unk=95.31 total/acc_i=72.54 total/acc_c=64.24 total/h_score=75.63\n",
      "selected:  cs/acc_i=86.38 cs/acc_c=87.44 os/recall_knw=54.61 os/recall_unk=98.47 total/acc_i=70.28 total/acc_c=58.75 total/h_score=72.01\n",
      "Loss: 2.3728632233359597\n",
      "Loss: 1.2189509439468384\n",
      "Loss: 0.9455380371483889\n",
      "Loss: 0.8498679804801941\n",
      "Loss: 0.7975429555502804\n",
      "Loss: 0.7012889517437328\n",
      "Loss: 0.6819226969372142\n",
      "Loss: 0.6597597627477212\n",
      "Loss: 0.6161675763672049\n",
      "Loss: 0.5798412665453824\n",
      "______\n",
      "Iteration t=4\n",
      "all:  cs/acc_i=89.39 cs/acc_c=89.99 os/recall_knw=61.42 os/recall_unk=95.37 total/acc_i=72.33 total/acc_c=63.87 total/h_score=75.36\n",
      "selected:  cs/acc_i=88.69 cs/acc_c=89.38 os/recall_knw=58.53 os/recall_unk=96.05 total/acc_i=71.21 total/acc_c=61.78 total/h_score=73.91\n",
      "Loss: 2.341210565783761\n",
      "Loss: 1.1571277926018189\n",
      "Loss: 0.91392753653593\n",
      "Loss: 0.8105118236133269\n",
      "Loss: 0.743617716785911\n",
      "Loss: 0.6752041705942654\n",
      "Loss: 0.6634533184391636\n",
      "Loss: 0.6265857727169157\n",
      "Loss: 0.5957193004709858\n",
      "Loss: 0.565311865789907\n",
      "______\n",
      "Iteration t=5\n",
      "all:  cs/acc_i=88.65 cs/acc_c=89.42 os/recall_knw=61.37 os/recall_unk=95.37 total/acc_i=72.29 total/acc_c=63.83 total/h_score=75.33\n",
      "selected:  cs/acc_i=88.41 cs/acc_c=89.20 os/recall_knw=60.23 os/recall_unk=95.65 total/acc_i=71.88 total/acc_c=63.12 total/h_score=74.86\n",
      "Loss: 2.3334815099321564\n",
      "Loss: 1.1320262705457622\n",
      "Loss: 0.9036486413972131\n",
      "Loss: 0.7939785526744251\n",
      "Loss: 0.7343551328983801\n",
      "Loss: 0.6836451010457401\n",
      "Loss: 0.627293175767208\n",
      "Loss: 0.6069197872075541\n",
      "Loss: 0.5937230747321557\n",
      "Loss: 0.5765939542445643\n",
      "______\n",
      "Iteration t=6\n",
      "all:  cs/acc_i=89.27 cs/acc_c=89.95 os/recall_knw=61.31 os/recall_unk=95.37 total/acc_i=72.25 total/acc_c=63.79 total/h_score=75.30\n",
      "selected:  cs/acc_i=89.20 cs/acc_c=89.93 os/recall_knw=61.06 os/recall_unk=95.37 total/acc_i=72.13 total/acc_c=63.69 total/h_score=75.22\n",
      "Loss: 2.29914889319358\n",
      "Loss: 1.1187509503787696\n",
      "Loss: 0.8778344497542332\n",
      "Loss: 0.7970037843790477\n",
      "Loss: 0.7219557242385356\n",
      "Loss: 0.6682324664788034\n",
      "Loss: 0.6407034885354417\n",
      "Loss: 0.6047795757193615\n",
      "Loss: 0.5900135792461272\n",
      "Loss: 0.5576853939290747\n",
      "______\n",
      "Iteration t=7\n",
      "all:  cs/acc_i=89.24 cs/acc_c=89.94 os/recall_knw=61.31 os/recall_unk=95.37 total/acc_i=72.25 total/acc_c=63.79 total/h_score=75.30\n",
      "selected:  cs/acc_i=89.24 cs/acc_c=89.94 os/recall_knw=61.31 os/recall_unk=95.37 total/acc_i=72.25 total/acc_c=63.79 total/h_score=75.30\n",
      "Loss: 2.3233537258955397\n",
      "Loss: 1.1471642914892464\n",
      "Loss: 0.8586251129469367\n",
      "Loss: 0.7833568075411149\n",
      "Loss: 0.7266280866727081\n",
      "Loss: 0.6714889106083242\n",
      "Loss: 0.6459561843717464\n",
      "Loss: 0.6092425547921617\n",
      "Loss: 0.5848212146006346\n",
      "Loss: 0.5499759666850542\n",
      "______\n",
      "Iteration t=8\n",
      "all:  cs/acc_i=89.30 cs/acc_c=89.98 os/recall_knw=61.31 os/recall_unk=95.37 total/acc_i=72.25 total/acc_c=63.79 total/h_score=75.30\n",
      "selected:  cs/acc_i=89.30 cs/acc_c=89.98 os/recall_knw=61.31 os/recall_unk=95.37 total/acc_i=72.25 total/acc_c=63.79 total/h_score=75.30\n",
      "Loss: 2.322834378623311\n",
      "Loss: 1.1306637828667416\n",
      "Loss: 0.8794651267471574\n",
      "Loss: 0.7811384751324768\n",
      "Loss: 0.733363033459862\n",
      "Loss: 0.6759802880140702\n",
      "Loss: 0.6435522496598572\n",
      "Loss: 0.6034215213699146\n",
      "Loss: 0.5735626756229498\n",
      "Loss: 0.5302708533945344\n",
      "______\n",
      "Iteration t=9\n",
      "all:  cs/acc_i=89.27 cs/acc_c=89.89 os/recall_knw=61.31 os/recall_unk=95.37 total/acc_i=72.25 total/acc_c=63.79 total/h_score=75.30\n",
      "selected:  cs/acc_i=89.27 cs/acc_c=89.89 os/recall_knw=61.31 os/recall_unk=95.37 total/acc_i=72.25 total/acc_c=63.79 total/h_score=75.30\n",
      "tensor(0)\n",
      "all:  cs/acc_i=89.27 cs/acc_c=89.89 os/recall_knw=61.31 os/recall_unk=95.37 total/acc_i=72.25 total/acc_c=63.79 total/h_score=75.30\n",
      "sketch -> real lr= 0.001 seed= 3\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19]\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20]\n",
      "Loss: 2.6011673032709983\n",
      "Loss: 1.5653558943123944\n",
      "Loss: 1.2440088441414117\n",
      "Loss: 1.1033495501079391\n",
      "Loss: 1.0013534128665924\n",
      "Loss: 0.9286206296059938\n",
      "Loss: 0.8851786046165281\n",
      "Loss: 0.821966434870146\n",
      "Loss: 0.7995961578810109\n",
      "Loss: 0.7583029263578684\n",
      "tensor(True) tensor(True)\n",
      "______\n",
      "Iteration t=1\n",
      "all:  cs/acc_i=86.61 cs/acc_c=87.55 os/recall_knw=89.54 os/recall_unk=54.19 total/acc_i=73.04 total/acc_c=82.15 total/h_score=65.74\n",
      "selected:  cs/acc_i=76.36 cs/acc_c=80.56 os/recall_knw=61.61 os/recall_unk=99.67 total/acc_i=80.24 total/acc_c=68.91 total/h_score=80.40\n",
      "Loss: 2.566484251960379\n",
      "Loss: 1.4497237444901077\n",
      "Loss: 1.1071727253863068\n",
      "Loss: 0.9951596602064664\n",
      "Loss: 0.8984655073431672\n",
      "Loss: 0.8277776762843132\n",
      "Loss: 0.7728447396247113\n",
      "Loss: 0.7579966961848931\n",
      "Loss: 0.718201859258726\n",
      "Loss: 0.6958551725647488\n",
      "______\n",
      "Iteration t=2\n",
      "all:  cs/acc_i=87.47 cs/acc_c=88.22 os/recall_knw=68.11 os/recall_unk=90.61 total/acc_i=74.81 total/acc_c=69.55 total/h_score=78.02\n",
      "selected:  cs/acc_i=82.06 cs/acc_c=83.68 os/recall_knw=51.11 os/recall_unk=99.54 total/acc_i=70.66 total/acc_c=56.14 total/h_score=69.99\n",
      "Loss: 2.4512109278722574\n",
      "Loss: 1.2908484815186216\n",
      "Loss: 0.9958611035164986\n",
      "Loss: 0.9013070483471601\n",
      "Loss: 0.8306151245159047\n",
      "Loss: 0.7552072027029882\n",
      "Loss: 0.7348959366328843\n",
      "Loss: 0.69605711716732\n",
      "Loss: 0.6433713725049988\n",
      "Loss: 0.6340892519659669\n",
      "______\n",
      "Iteration t=3\n",
      "all:  cs/acc_i=88.62 cs/acc_c=89.27 os/recall_knw=66.12 os/recall_unk=93.40 total/acc_i=74.65 total/acc_c=68.11 total/h_score=77.92\n",
      "selected:  cs/acc_i=86.33 cs/acc_c=87.26 os/recall_knw=58.66 os/recall_unk=98.25 total/acc_i=72.67 total/acc_c=62.19 total/h_score=74.80\n",
      "Loss: 2.3727933751593393\n",
      "Loss: 1.1959593980003604\n",
      "Loss: 0.915641464453807\n",
      "Loss: 0.8193477141342574\n",
      "Loss: 0.7662281100269702\n",
      "Loss: 0.7075930726613929\n",
      "Loss: 0.6851382374549083\n",
      "Loss: 0.6185814799915115\n",
      "Loss: 0.6260538025618457\n",
      "Loss: 0.5678629900375716\n",
      "______\n",
      "Iteration t=4\n",
      "all:  cs/acc_i=89.09 cs/acc_c=89.70 os/recall_knw=65.77 os/recall_unk=93.52 total/acc_i=74.50 total/acc_c=67.86 total/h_score=77.78\n",
      "selected:  cs/acc_i=88.05 cs/acc_c=88.60 os/recall_knw=62.28 os/recall_unk=95.74 total/acc_i=73.46 total/acc_c=65.12 total/h_score=76.42\n",
      "Loss: 2.3354305107560425\n",
      "Loss: 1.1483412124216557\n",
      "Loss: 0.8943103155535128\n",
      "Loss: 0.8202420572439829\n",
      "Loss: 0.7376255938369367\n",
      "Loss: 0.6947490812486244\n",
      "Loss: 0.641312424507406\n",
      "Loss: 0.6082680640845664\n",
      "Loss: 0.5922111193132069\n",
      "Loss: 0.5722394175310102\n",
      "______\n",
      "Iteration t=5\n",
      "all:  cs/acc_i=89.92 cs/acc_c=90.44 os/recall_knw=65.65 os/recall_unk=93.52 total/acc_i=74.42 total/acc_c=67.76 total/h_score=77.71\n",
      "selected:  cs/acc_i=89.51 cs/acc_c=89.99 os/recall_knw=64.16 os/recall_unk=93.86 total/acc_i=73.80 total/acc_c=66.60 total/h_score=76.97\n",
      "Loss: 2.3133200484068217\n",
      "Loss: 1.1273784842215429\n",
      "Loss: 0.8853349605587875\n",
      "Loss: 0.7745876728880162\n",
      "Loss: 0.7060778938791379\n",
      "Loss: 0.6695278518307372\n",
      "Loss: 0.6436277177869058\n",
      "Loss: 0.5974493705395127\n",
      "Loss: 0.5716627560505251\n",
      "Loss: 0.5487681192909779\n",
      "______\n",
      "Iteration t=6\n",
      "all:  cs/acc_i=89.80 cs/acc_c=90.42 os/recall_knw=65.65 os/recall_unk=93.52 total/acc_i=74.42 total/acc_c=67.76 total/h_score=77.71\n",
      "selected:  cs/acc_i=89.73 cs/acc_c=90.30 os/recall_knw=65.32 os/recall_unk=93.52 total/acc_i=74.27 total/acc_c=67.50 total/h_score=77.53\n",
      "Loss: 2.2873687216099476\n",
      "Loss: 1.1026549688321632\n",
      "Loss: 0.8676680050440283\n",
      "Loss: 0.7638987799818884\n",
      "Loss: 0.7073812801765915\n",
      "Loss: 0.6640505958223503\n",
      "Loss: 0.6341483506980359\n",
      "Loss: 0.6162093366252496\n",
      "Loss: 0.554025912694883\n",
      "Loss: 0.534539532891456\n",
      "______\n",
      "Iteration t=7\n",
      "all:  cs/acc_i=89.77 cs/acc_c=90.43 os/recall_knw=65.65 os/recall_unk=93.52 total/acc_i=74.42 total/acc_c=67.76 total/h_score=77.71\n",
      "selected:  cs/acc_i=89.77 cs/acc_c=90.42 os/recall_knw=65.63 os/recall_unk=93.52 total/acc_i=74.41 total/acc_c=67.74 total/h_score=77.70\n",
      "Loss: 2.2915688956461624\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 1.0830449888538756\n",
      "Loss: 0.844283587856835\n",
      "Loss: 0.7726841768293476\n",
      "Loss: 0.7148191148421438\n",
      "Loss: 0.6606985975468039\n",
      "Loss: 0.6307971623529958\n",
      "Loss: 0.595136059865505\n",
      "Loss: 0.5632450384240485\n",
      "Loss: 0.5433233940730924\n",
      "______\n",
      "Iteration t=8\n",
      "all:  cs/acc_i=89.86 cs/acc_c=90.44 os/recall_knw=65.65 os/recall_unk=93.52 total/acc_i=74.42 total/acc_c=67.76 total/h_score=77.71\n",
      "selected:  cs/acc_i=89.86 cs/acc_c=90.44 os/recall_knw=65.65 os/recall_unk=93.52 total/acc_i=74.42 total/acc_c=67.76 total/h_score=77.71\n",
      "Loss: 2.2935461790665337\n",
      "Loss: 1.0934443341250404\n",
      "Loss: 0.835631962105582\n",
      "Loss: 0.7793156659124687\n",
      "Loss: 0.6841337977843142\n",
      "Loss: 0.6512896182345707\n",
      "Loss: 0.6473875691659474\n",
      "Loss: 0.5779995343158875\n",
      "Loss: 0.5531198862304656\n",
      "Loss: 0.524639711431835\n",
      "______\n",
      "Iteration t=9\n",
      "all:  cs/acc_i=89.12 cs/acc_c=89.72 os/recall_knw=65.65 os/recall_unk=93.52 total/acc_i=74.42 total/acc_c=67.76 total/h_score=77.71\n",
      "selected:  cs/acc_i=89.12 cs/acc_c=89.72 os/recall_knw=65.65 os/recall_unk=93.52 total/acc_i=74.42 total/acc_c=67.76 total/h_score=77.71\n",
      "tensor(0)\n",
      "all:  cs/acc_i=89.12 cs/acc_c=89.72 os/recall_knw=65.65 os/recall_unk=93.52 total/acc_i=74.42 total/acc_c=67.76 total/h_score=77.71\n",
      "sketch -> real lr= 0.001 seed= 4\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19]\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20]\n",
      "Loss: 2.621026869368764\n",
      "Loss: 1.589253206959868\n",
      "Loss: 1.2479018750971398\n",
      "Loss: 1.1025105216334352\n",
      "Loss: 1.014116098791097\n",
      "Loss: 0.9464851103525246\n",
      "Loss: 0.8826393941334919\n",
      "Loss: 0.8246301937419757\n",
      "Loss: 0.7897779121335629\n",
      "Loss: 0.7581604377622098\n",
      "tensor(True) tensor(True)\n",
      "______\n",
      "Iteration t=1\n",
      "all:  cs/acc_i=86.28 cs/acc_c=87.30 os/recall_knw=89.71 os/recall_unk=54.55 total/acc_i=73.33 total/acc_c=82.44 total/h_score=66.09\n",
      "selected:  cs/acc_i=74.73 cs/acc_c=80.60 os/recall_knw=62.09 os/recall_unk=99.78 total/acc_i=80.63 total/acc_c=70.25 total/h_score=81.43\n",
      "Loss: 2.5399750915707133\n",
      "Loss: 1.4232198605771924\n",
      "Loss: 1.102983218480329\n",
      "Loss: 0.9614061053659095\n",
      "Loss: 0.8962412695171403\n",
      "Loss: 0.8300944644896711\n",
      "Loss: 0.7744212072403704\n",
      "Loss: 0.7287572218624295\n",
      "Loss: 0.708704485756452\n",
      "Loss: 0.6601007485487422\n",
      "______\n",
      "Iteration t=2\n",
      "all:  cs/acc_i=87.70 cs/acc_c=88.48 os/recall_knw=74.02 os/recall_unk=86.87 total/acc_i=77.06 total/acc_c=74.13 total/h_score=79.62\n",
      "selected:  cs/acc_i=81.89 cs/acc_c=83.91 os/recall_knw=56.27 os/recall_unk=99.66 total/acc_i=74.29 total/acc_c=61.13 total/h_score=74.28\n",
      "Loss: 2.449159382863809\n",
      "Loss: 1.2952006798209126\n",
      "Loss: 1.0008174068372668\n",
      "Loss: 0.8800663415712254\n",
      "Loss: 0.8087317403263719\n",
      "Loss: 0.7543945968833589\n",
      "Loss: 0.7315210409974324\n",
      "Loss: 0.6811942641289179\n",
      "Loss: 0.6574414735873237\n",
      "Loss: 0.6460873200238206\n",
      "______\n",
      "Iteration t=3\n",
      "all:  cs/acc_i=88.53 cs/acc_c=89.23 os/recall_knw=69.49 os/recall_unk=92.10 total/acc_i=76.17 total/acc_c=70.64 total/h_score=79.26\n",
      "selected:  cs/acc_i=86.10 cs/acc_c=87.07 os/recall_knw=61.43 os/recall_unk=98.29 total/acc_i=74.49 total/acc_c=64.29 total/h_score=76.48\n",
      "Loss: 2.379767516105295\n",
      "Loss: 1.1795695803577093\n",
      "Loss: 0.9338848987500444\n",
      "Loss: 0.825183082077143\n",
      "Loss: 0.7662101287207157\n",
      "Loss: 0.7274963610785471\n",
      "Loss: 0.6810481725193613\n",
      "Loss: 0.6422168889062868\n",
      "Loss: 0.6164008531210233\n",
      "Loss: 0.5784022555076819\n",
      "______\n",
      "Iteration t=4\n",
      "all:  cs/acc_i=89.06 cs/acc_c=89.69 os/recall_knw=69.29 os/recall_unk=92.28 total/acc_i=76.12 total/acc_c=70.45 total/h_score=79.19\n",
      "selected:  cs/acc_i=88.15 cs/acc_c=88.70 os/recall_knw=65.70 os/recall_unk=95.10 total/acc_i=75.35 total/acc_c=67.69 total/h_score=78.15\n",
      "Loss: 2.332489054227613\n",
      "Loss: 1.1476006133040202\n",
      "Loss: 0.9035086900098217\n",
      "Loss: 0.805213719503986\n",
      "Loss: 0.725365814115993\n",
      "Loss: 0.674491363548741\n",
      "Loss: 0.6485125056861603\n",
      "Loss: 0.6042002861442435\n",
      "Loss: 0.5801853468942478\n",
      "Loss: 0.5609157645620432\n",
      "______\n",
      "Iteration t=5\n",
      "all:  cs/acc_i=89.62 cs/acc_c=90.22 os/recall_knw=69.23 os/recall_unk=92.45 total/acc_i=76.15 total/acc_c=70.43 total/h_score=79.24\n",
      "selected:  cs/acc_i=89.25 cs/acc_c=89.89 os/recall_knw=67.66 os/recall_unk=92.95 total/acc_i=75.60 total/acc_c=69.35 total/h_score=78.65\n",
      "Loss: 2.2943855852088673\n",
      "Loss: 1.1040445132143546\n",
      "Loss: 0.873883902426534\n",
      "Loss: 0.7606435623144944\n",
      "Loss: 0.7136981249255622\n",
      "Loss: 0.6675943931277166\n",
      "Loss: 0.6208102522080376\n",
      "Loss: 0.6007376575729991\n",
      "Loss: 0.5667503040108904\n",
      "Loss: 0.5332280029386482\n",
      "______\n",
      "Iteration t=6\n",
      "all:  cs/acc_i=90.01 cs/acc_c=90.60 os/recall_knw=69.17 os/recall_unk=92.45 total/acc_i=76.12 total/acc_c=70.39 total/h_score=79.21\n",
      "selected:  cs/acc_i=89.87 cs/acc_c=90.49 os/recall_knw=68.46 os/recall_unk=92.51 total/acc_i=75.83 total/acc_c=69.99 total/h_score=78.96\n",
      "Loss: 2.287250913258803\n",
      "Loss: 1.0843990205530312\n",
      "Loss: 0.8688527346647459\n",
      "Loss: 0.7767027648184387\n",
      "Loss: 0.7028678214530216\n",
      "Loss: 0.667413954570444\n",
      "Loss: 0.6293496292492876\n",
      "Loss: 0.5935161723151952\n",
      "Loss: 0.5625549356307699\n",
      "Loss: 0.525474416704669\n",
      "______\n",
      "Iteration t=7\n",
      "all:  cs/acc_i=89.80 cs/acc_c=90.41 os/recall_knw=69.17 os/recall_unk=92.45 total/acc_i=76.12 total/acc_c=70.39 total/h_score=79.21\n",
      "selected:  cs/acc_i=89.82 cs/acc_c=90.43 os/recall_knw=69.14 os/recall_unk=92.45 total/acc_i=76.12 total/acc_c=70.40 total/h_score=79.22\n",
      "Loss: 2.276687001631205\n",
      "Loss: 1.0658529903432323\n",
      "Loss: 0.8480675261799652\n",
      "Loss: 0.749227353940309\n",
      "Loss: 0.710262542608941\n",
      "Loss: 0.654326587423633\n",
      "Loss: 0.629344595590047\n",
      "Loss: 0.5756604203296574\n",
      "Loss: 0.5567997670409703\n",
      "Loss: 0.5213157810983878\n",
      "______\n",
      "Iteration t=8\n",
      "all:  cs/acc_i=89.68 cs/acc_c=90.31 os/recall_knw=69.17 os/recall_unk=92.45 total/acc_i=76.12 total/acc_c=70.39 total/h_score=79.21\n",
      "selected:  cs/acc_i=89.68 cs/acc_c=90.31 os/recall_knw=69.17 os/recall_unk=92.45 total/acc_i=76.12 total/acc_c=70.39 total/h_score=79.21\n",
      "Loss: 2.258405596509625\n",
      "Loss: 1.0768197896850384\n",
      "Loss: 0.8622717662612991\n",
      "Loss: 0.7742660832483776\n",
      "Loss: 0.7091156600332102\n",
      "Loss: 0.6636106792849676\n",
      "Loss: 0.6183413234677645\n",
      "Loss: 0.5884267348464173\n",
      "Loss: 0.5526667965127297\n",
      "Loss: 0.5306676007044984\n",
      "______\n",
      "Iteration t=9\n",
      "all:  cs/acc_i=89.95 cs/acc_c=90.52 os/recall_knw=69.17 os/recall_unk=92.45 total/acc_i=76.12 total/acc_c=70.39 total/h_score=79.21\n",
      "selected:  cs/acc_i=89.95 cs/acc_c=90.52 os/recall_knw=69.17 os/recall_unk=92.45 total/acc_i=76.12 total/acc_c=70.39 total/h_score=79.21\n",
      "tensor(0)\n",
      "all:  cs/acc_i=89.95 cs/acc_c=90.52 os/recall_knw=69.17 os/recall_unk=92.45 total/acc_i=76.12 total/acc_c=70.39 total/h_score=79.21\n",
      "sketch -> real lr= 0.001 seed= 0\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19]\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20]\n",
      "Loss: 2.6184245954572627\n",
      "Loss: 1.6017555088068531\n",
      "Loss: 1.2603877827657008\n",
      "Loss: 1.098684320407631\n",
      "Loss: 1.0025335129647128\n",
      "Loss: 0.9420822406500842\n",
      "Loss: 0.8844871037038027\n",
      "Loss: 0.8310855732554883\n",
      "Loss: 0.7944667548996157\n",
      "Loss: 0.7905726465767464\n",
      "tensor(True) tensor(True)\n",
      "______\n",
      "Iteration t=1\n",
      "all:  cs/acc_i=86.67 cs/acc_c=87.67 os/recall_knw=89.77 os/recall_unk=54.66 total/acc_i=73.41 total/acc_c=82.63 total/h_score=66.24\n",
      "selected:  cs/acc_i=76.12 cs/acc_c=80.72 os/recall_knw=62.27 os/recall_unk=99.78 total/acc_i=80.75 total/acc_c=70.39 total/h_score=81.53\n",
      "Loss: 2.539314334998365\n",
      "Loss: 1.433546149095551\n",
      "Loss: 1.1166097736749492\n",
      "Loss: 0.9737817888132861\n",
      "Loss: 0.8833241939056115\n",
      "Loss: 0.8515704275398958\n",
      "Loss: 0.7976208872726707\n",
      "Loss: 0.7473170285830733\n",
      "Loss: 0.7060585174648488\n",
      "Loss: 0.6836376160871788\n",
      "______\n",
      "Iteration t=2\n",
      "all:  cs/acc_i=87.41 cs/acc_c=88.19 os/recall_knw=63.46 os/recall_unk=94.30 total/acc_i=73.17 total/acc_c=65.68 total/h_score=76.42\n",
      "selected:  cs/acc_i=82.64 cs/acc_c=84.40 os/recall_knw=47.67 os/recall_unk=99.50 total/acc_i=68.28 total/acc_c=53.03 total/h_score=67.18\n",
      "Loss: 2.442266993395245\n",
      "Loss: 1.277122858598942\n",
      "Loss: 1.0051087641534004\n",
      "Loss: 0.8827099339425108\n",
      "Loss: 0.8214141508095137\n",
      "Loss: 0.7588945825136345\n",
      "Loss: 0.7142617884483046\n",
      "Loss: 0.6673324862281784\n",
      "Loss: 0.6562175887800356\n",
      "Loss: 0.6299853630307066\n",
      "______\n",
      "Iteration t=3\n",
      "all:  cs/acc_i=88.47 cs/acc_c=89.26 os/recall_knw=62.25 os/recall_unk=95.13 total/acc_i=72.72 total/acc_c=64.67 total/h_score=75.90\n",
      "selected:  cs/acc_i=86.51 cs/acc_c=87.63 os/recall_knw=55.27 os/recall_unk=98.64 total/acc_i=70.59 total/acc_c=59.24 total/h_score=72.46\n",
      "Loss: 2.3934650896252068\n",
      "Loss: 1.2338838309481523\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.9489986132020536\n",
      "Loss: 0.8322313733506894\n",
      "Loss: 0.7602365159470102\n",
      "Loss: 0.7125244377639847\n",
      "Loss: 0.6675966060787871\n",
      "Loss: 0.6208064959964891\n",
      "Loss: 0.6188735364247924\n",
      "Loss: 0.5876413219324921\n",
      "______\n",
      "Iteration t=4\n",
      "all:  cs/acc_i=88.62 cs/acc_c=89.37 os/recall_knw=62.22 os/recall_unk=95.13 total/acc_i=72.70 total/acc_c=64.63 total/h_score=75.88\n",
      "selected:  cs/acc_i=87.78 cs/acc_c=88.65 os/recall_knw=59.21 os/recall_unk=96.39 total/acc_i=71.65 total/acc_c=62.31 total/h_score=74.42\n",
      "Loss: 2.3413875052978943\n",
      "Loss: 1.1627668457014577\n",
      "Loss: 0.9109242560563388\n",
      "Loss: 0.8004561161453073\n",
      "Loss: 0.7400076529988042\n",
      "Loss: 0.6937208610189545\n",
      "Loss: 0.659494026453345\n",
      "Loss: 0.6285922499178173\n",
      "Loss: 0.5814627725761253\n",
      "Loss: 0.5506282282042336\n",
      "______\n",
      "Iteration t=5\n",
      "all:  cs/acc_i=89.09 cs/acc_c=89.87 os/recall_knw=62.16 os/recall_unk=95.25 total/acc_i=72.70 total/acc_c=64.59 total/h_score=75.88\n",
      "selected:  cs/acc_i=88.80 cs/acc_c=89.58 os/recall_knw=61.15 os/recall_unk=95.42 total/acc_i=72.26 total/acc_c=63.82 total/h_score=75.34\n",
      "Loss: 2.3286618461313937\n",
      "Loss: 1.113393115423799\n",
      "Loss: 0.9021940710618324\n",
      "Loss: 0.8057722323334094\n",
      "Loss: 0.7237045814081565\n",
      "Loss: 0.6901493937903663\n",
      "Loss: 0.6343607420671437\n",
      "Loss: 0.5990493542857186\n",
      "Loss: 0.5910639416208792\n",
      "Loss: 0.5443828889901695\n",
      "______\n",
      "Iteration t=6\n",
      "all:  cs/acc_i=89.30 cs/acc_c=89.97 os/recall_knw=62.10 os/recall_unk=95.31 total/acc_i=72.68 total/acc_c=64.55 total/h_score=75.86\n",
      "selected:  cs/acc_i=89.22 cs/acc_c=89.91 os/recall_knw=61.82 os/recall_unk=95.31 total/acc_i=72.55 total/acc_c=64.37 total/h_score=75.73\n",
      "Loss: 2.3197045661890465\n",
      "Loss: 1.118816141585848\n",
      "Loss: 0.8959318301783487\n",
      "Loss: 0.7934146891681815\n",
      "Loss: 0.7509390849098817\n",
      "Loss: 0.6551949903114664\n",
      "Loss: 0.628551874805636\n",
      "Loss: 0.585118480916723\n",
      "Loss: 0.5805811173069599\n",
      "Loss: 0.5486373812367078\n",
      "______\n",
      "Iteration t=7\n",
      "all:  cs/acc_i=89.21 cs/acc_c=89.85 os/recall_knw=62.08 os/recall_unk=95.31 total/acc_i=72.66 total/acc_c=64.53 total/h_score=75.85\n",
      "selected:  cs/acc_i=89.21 cs/acc_c=89.85 os/recall_knw=62.08 os/recall_unk=95.31 total/acc_i=72.66 total/acc_c=64.53 total/h_score=75.85\n",
      "Loss: 2.3126103427945353\n",
      "Loss: 1.1349123312907965\n",
      "Loss: 0.8688892987715143\n",
      "Loss: 0.7893222609953005\n",
      "Loss: 0.7294237326805283\n",
      "Loss: 0.6550718248904157\n",
      "Loss: 0.641099001071891\n",
      "Loss: 0.6253011947383686\n",
      "Loss: 0.5804438265103872\n",
      "Loss: 0.5639827060354811\n",
      "______\n",
      "Iteration t=8\n",
      "all:  cs/acc_i=88.74 cs/acc_c=89.48 os/recall_knw=62.08 os/recall_unk=95.31 total/acc_i=72.66 total/acc_c=64.53 total/h_score=75.85\n",
      "selected:  cs/acc_i=88.74 cs/acc_c=89.48 os/recall_knw=62.08 os/recall_unk=95.31 total/acc_i=72.66 total/acc_c=64.53 total/h_score=75.85\n",
      "Loss: 2.305468812280772\n",
      "Loss: 1.131317298631279\n",
      "Loss: 0.8953771806087624\n",
      "Loss: 0.7953558079644937\n",
      "Loss: 0.717229483281674\n",
      "Loss: 0.6714505007883318\n",
      "Loss: 0.6402292037192656\n",
      "Loss: 0.6071004451943093\n",
      "Loss: 0.5583891008480065\n",
      "Loss: 0.5518969454276724\n",
      "______\n",
      "Iteration t=9\n",
      "all:  cs/acc_i=88.65 cs/acc_c=89.35 os/recall_knw=62.08 os/recall_unk=95.31 total/acc_i=72.66 total/acc_c=64.53 total/h_score=75.85\n",
      "selected:  cs/acc_i=88.65 cs/acc_c=89.35 os/recall_knw=62.08 os/recall_unk=95.31 total/acc_i=72.66 total/acc_c=64.53 total/h_score=75.85\n",
      "tensor(0)\n",
      "all:  cs/acc_i=88.65 cs/acc_c=89.35 os/recall_knw=62.08 os/recall_unk=95.31 total/acc_i=72.66 total/acc_c=64.53 total/h_score=75.85\n",
      "sketch -> real lr= 0.001 seed= 1\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19]\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20]\n",
      "Loss: 2.6136020221541414\n",
      "Loss: 1.6033060669371513\n",
      "Loss: 1.257722368018817\n",
      "Loss: 1.0892756560207468\n",
      "Loss: 1.0420736694230444\n",
      "Loss: 0.9412848510309658\n",
      "Loss: 0.8821370413081836\n",
      "Loss: 0.8137180457072976\n",
      "Loss: 0.7876929222746233\n",
      "Loss: 0.7455765947831415\n",
      "tensor(True) tensor(True)\n",
      "______\n",
      "Iteration t=1\n",
      "all:  cs/acc_i=86.85 cs/acc_c=87.82 os/recall_knw=90.22 os/recall_unk=55.56 total/acc_i=74.00 total/acc_c=83.07 total/h_score=67.02\n",
      "selected:  cs/acc_i=76.39 cs/acc_c=80.52 os/recall_knw=63.30 os/recall_unk=99.89 total/acc_i=81.61 total/acc_c=70.81 total/h_score=81.87\n",
      "Loss: 2.530350101287248\n",
      "Loss: 1.4265582385610363\n",
      "Loss: 1.1123123061461526\n",
      "Loss: 0.9704907088250411\n",
      "Loss: 0.9012492220909869\n",
      "Loss: 0.8614399679860131\n",
      "Loss: 0.8077314977274567\n",
      "Loss: 0.7605048348424864\n",
      "Loss: 0.7240376277658783\n",
      "Loss: 0.6815560273215419\n",
      "______\n",
      "Iteration t=2\n",
      "all:  cs/acc_i=87.88 cs/acc_c=88.75 os/recall_knw=70.88 os/recall_unk=91.27 total/acc_i=76.55 total/acc_c=71.73 total/h_score=79.71\n",
      "selected:  cs/acc_i=82.62 cs/acc_c=84.54 os/recall_knw=53.36 os/recall_unk=99.48 total/acc_i=72.48 total/acc_c=58.60 total/h_score=72.12\n",
      "Loss: 2.4420890284858587\n",
      "Loss: 1.2915084298330408\n",
      "Loss: 1.008084476676606\n",
      "Loss: 0.8953371013848836\n",
      "Loss: 0.809848593732783\n",
      "Loss: 0.7637374034819712\n",
      "Loss: 0.7079886782715339\n",
      "Loss: 0.6848262760020395\n",
      "Loss: 0.6672254349780447\n",
      "Loss: 0.6367156826357805\n",
      "______\n",
      "Iteration t=3\n",
      "all:  cs/acc_i=88.24 cs/acc_c=88.96 os/recall_knw=67.60 os/recall_unk=93.40 total/acc_i=75.37 total/acc_c=69.11 total/h_score=78.63\n",
      "selected:  cs/acc_i=85.89 cs/acc_c=86.73 os/recall_knw=59.74 os/recall_unk=98.56 total/acc_i=73.45 total/acc_c=62.90 total/h_score=75.45\n",
      "Loss: 2.387704147280549\n",
      "Loss: 1.2149866094692148\n",
      "Loss: 0.95380103866831\n",
      "Loss: 0.8307222562084953\n",
      "Loss: 0.7415712109143785\n",
      "Loss: 0.722985728824739\n",
      "Loss: 0.6890392055292781\n",
      "Loss: 0.6362442047797519\n",
      "Loss: 0.6199395554207212\n",
      "Loss: 0.5791449131939909\n",
      "______\n",
      "Iteration t=4\n",
      "all:  cs/acc_i=89.12 cs/acc_c=89.75 os/recall_knw=66.24 os/recall_unk=93.88 total/acc_i=74.67 total/acc_c=68.00 total/h_score=77.99\n",
      "selected:  cs/acc_i=88.25 cs/acc_c=88.82 os/recall_knw=63.03 os/recall_unk=95.93 total/acc_i=73.78 total/acc_c=65.43 total/h_score=76.71\n",
      "Loss: 2.334032739322491\n",
      "Loss: 1.1380489497448747\n",
      "Loss: 0.877004900708743\n",
      "Loss: 0.7878655615974876\n",
      "Loss: 0.7373592359590695\n",
      "Loss: 0.6641537425427289\n",
      "Loss: 0.6511106641647313\n",
      "Loss: 0.6038691287531572\n",
      "Loss: 0.5926216107029403\n",
      "Loss: 0.5592742283864005\n",
      "______\n",
      "Iteration t=5\n",
      "all:  cs/acc_i=89.42 cs/acc_c=90.03 os/recall_knw=66.01 os/recall_unk=93.94 total/acc_i=74.56 total/acc_c=67.83 total/h_score=77.89\n",
      "selected:  cs/acc_i=89.15 cs/acc_c=89.73 os/recall_knw=64.76 os/recall_unk=94.22 total/acc_i=74.09 total/acc_c=66.89 total/h_score=77.30\n",
      "Loss: 2.3228590783426317\n",
      "Loss: 1.129024392063335\n",
      "Loss: 0.8766428547390437\n",
      "Loss: 0.7431719070774013\n",
      "Loss: 0.6991724246639316\n",
      "Loss: 0.6623404697846558\n",
      "Loss: 0.6283400980092712\n",
      "Loss: 0.6000046368372642\n",
      "Loss: 0.5552514390420106\n",
      "Loss: 0.5436772056555343\n",
      "______\n",
      "Iteration t=6\n",
      "all:  cs/acc_i=89.42 cs/acc_c=90.00 os/recall_knw=66.01 os/recall_unk=93.94 total/acc_i=74.56 total/acc_c=67.83 total/h_score=77.89\n",
      "selected:  cs/acc_i=89.42 cs/acc_c=89.98 os/recall_knw=65.73 os/recall_unk=93.94 total/acc_i=74.48 total/acc_c=67.67 total/h_score=77.78\n",
      "Loss: 2.298204590410194\n",
      "Loss: 1.0911878369398564\n",
      "Loss: 0.855244481523565\n",
      "Loss: 0.7542720008016432\n",
      "Loss: 0.7269357729878202\n",
      "Loss: 0.6538818818610787\n",
      "Loss: 0.6196710267322976\n",
      "Loss: 0.589589027300377\n",
      "Loss: 0.587899470089266\n",
      "Loss: 0.5472169454465776\n",
      "______\n",
      "Iteration t=7\n",
      "all:  cs/acc_i=89.80 cs/acc_c=90.40 os/recall_knw=66.01 os/recall_unk=93.94 total/acc_i=74.56 total/acc_c=67.83 total/h_score=77.89\n",
      "selected:  cs/acc_i=89.80 cs/acc_c=90.39 os/recall_knw=65.99 os/recall_unk=93.94 total/acc_i=74.55 total/acc_c=67.81 total/h_score=77.87\n",
      "Loss: 2.2905375801998638\n",
      "Loss: 1.1152555324560822\n",
      "Loss: 0.878012787936922\n",
      "Loss: 0.7835718187998768\n",
      "Loss: 0.6930738497139219\n",
      "Loss: 0.6736493999244377\n",
      "Loss: 0.6213816802537561\n",
      "Loss: 0.5813755191688155\n",
      "Loss: 0.5656196643975268\n",
      "Loss: 0.5416777570012421\n",
      "______\n",
      "Iteration t=8\n",
      "all:  cs/acc_i=89.95 cs/acc_c=90.51 os/recall_knw=66.01 os/recall_unk=93.94 total/acc_i=74.56 total/acc_c=67.83 total/h_score=77.89\n",
      "selected:  cs/acc_i=89.95 cs/acc_c=90.51 os/recall_knw=66.01 os/recall_unk=93.94 total/acc_i=74.56 total/acc_c=67.83 total/h_score=77.89\n",
      "Loss: 2.293355334163908\n",
      "Loss: 1.0917302999010055\n",
      "Loss: 0.8471584212421175\n",
      "Loss: 0.776773409002202\n",
      "Loss: 0.6837950165455158\n",
      "Loss: 0.6514919584610789\n",
      "Loss: 0.6250161016764848\n",
      "Loss: 0.6114999230290735\n",
      "Loss: 0.5606469459408103\n",
      "Loss: 0.5431870366617987\n",
      "______\n",
      "Iteration t=9\n",
      "all:  cs/acc_i=89.57 cs/acc_c=90.22 os/recall_knw=66.01 os/recall_unk=93.94 total/acc_i=74.56 total/acc_c=67.83 total/h_score=77.89\n",
      "selected:  cs/acc_i=89.57 cs/acc_c=90.22 os/recall_knw=66.01 os/recall_unk=93.94 total/acc_i=74.56 total/acc_c=67.83 total/h_score=77.89\n",
      "tensor(0)\n",
      "all:  cs/acc_i=89.57 cs/acc_c=90.22 os/recall_knw=66.01 os/recall_unk=93.94 total/acc_i=74.56 total/acc_c=67.83 total/h_score=77.89\n",
      "sketch -> real lr= 0.001 seed= 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19]\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20]\n",
      "Loss: 2.6116374393480015\n",
      "Loss: 1.599215095549558\n",
      "Loss: 1.2461059887324815\n",
      "Loss: 1.1102193580792012\n",
      "Loss: 1.0092081794169097\n",
      "Loss: 0.9216799190086601\n",
      "Loss: 0.8757593867789327\n",
      "Loss: 0.8372786747934544\n",
      "Loss: 0.7949569523334503\n",
      "Loss: 0.7517861193787735\n",
      "tensor(True) tensor(True)\n",
      "______\n",
      "Iteration t=1\n",
      "all:  cs/acc_i=85.75 cs/acc_c=86.70 os/recall_knw=89.39 os/recall_unk=53.89 total/acc_i=72.66 total/acc_c=81.85 total/h_score=65.43\n",
      "selected:  cs/acc_i=74.30 cs/acc_c=78.87 os/recall_knw=61.40 os/recall_unk=99.78 total/acc_i=79.99 total/acc_c=69.15 total/h_score=80.61\n",
      "Loss: 2.551292240131097\n",
      "Loss: 1.4466237489317284\n",
      "Loss: 1.1008403775144795\n",
      "Loss: 0.9975105504520604\n",
      "Loss: 0.9027535032297744\n",
      "Loss: 0.8161359049501966\n",
      "Loss: 0.7673828742298924\n",
      "Loss: 0.7501231835025256\n",
      "Loss: 0.719707434172513\n",
      "Loss: 0.6642296783259658\n",
      "______\n",
      "Iteration t=2\n",
      "all:  cs/acc_i=87.35 cs/acc_c=88.17 os/recall_knw=71.77 os/recall_unk=90.31 total/acc_i=76.94 total/acc_c=72.60 total/h_score=79.94\n",
      "selected:  cs/acc_i=81.31 cs/acc_c=83.31 os/recall_knw=54.11 os/recall_unk=99.54 total/acc_i=73.03 total/acc_c=59.44 total/h_score=72.84\n",
      "Loss: 2.448792344286242\n",
      "Loss: 1.330178891656963\n",
      "Loss: 1.0280244275358796\n",
      "Loss: 0.8803338120684369\n",
      "Loss: 0.8162722940208348\n",
      "Loss: 0.7898606470295491\n",
      "Loss: 0.7158901537875183\n",
      "Loss: 0.7143642020817021\n",
      "Loss: 0.6390253794557266\n",
      "Loss: 0.6187410585525381\n",
      "______\n",
      "Iteration t=3\n",
      "all:  cs/acc_i=88.32 cs/acc_c=89.01 os/recall_knw=68.05 os/recall_unk=93.17 total/acc_i=75.66 total/acc_c=69.67 total/h_score=78.95\n",
      "selected:  cs/acc_i=85.93 cs/acc_c=86.80 os/recall_knw=60.39 os/recall_unk=98.31 total/acc_i=73.77 total/acc_c=63.63 total/h_score=75.96\n",
      "Loss: 2.361277159598234\n",
      "Loss: 1.214184630045788\n",
      "Loss: 0.9161635418590024\n",
      "Loss: 0.8275727038975242\n",
      "Loss: 0.7692936522711953\n",
      "Loss: 0.7094847478990932\n",
      "Loss: 0.6641792158107106\n",
      "Loss: 0.658304115958351\n",
      "Loss: 0.5762607763461072\n",
      "Loss: 0.590847636673519\n",
      "______\n",
      "Iteration t=4\n",
      "all:  cs/acc_i=89.42 cs/acc_c=90.12 os/recall_knw=67.99 os/recall_unk=93.17 total/acc_i=75.62 total/acc_c=69.61 total/h_score=78.91\n",
      "selected:  cs/acc_i=88.51 cs/acc_c=89.21 os/recall_knw=64.46 os/recall_unk=95.61 total/acc_i=74.74 total/acc_c=67.10 total/h_score=77.86\n",
      "Loss: 2.3313460793988456\n",
      "Loss: 1.1416670928741324\n",
      "Loss: 0.8855834864850702\n",
      "Loss: 0.8016326308250428\n",
      "Loss: 0.7241244300686079\n",
      "Loss: 0.6810602292932313\n",
      "Loss: 0.6403001966147587\n",
      "Loss: 0.6043934888366995\n",
      "Loss: 0.5750656496861886\n",
      "Loss: 0.5596468378243775\n",
      "______\n",
      "Iteration t=5\n",
      "all:  cs/acc_i=89.74 cs/acc_c=90.32 os/recall_knw=67.93 os/recall_unk=93.17 total/acc_i=75.60 total/acc_c=69.58 total/h_score=78.88\n",
      "selected:  cs/acc_i=89.45 cs/acc_c=89.99 os/recall_knw=66.52 os/recall_unk=93.50 total/acc_i=75.09 total/acc_c=68.61 total/h_score=78.31\n",
      "Loss: 2.2965580229004625\n",
      "Loss: 1.1102496744807722\n",
      "Loss: 0.8609883900644001\n",
      "Loss: 0.7797016370978821\n",
      "Loss: 0.7047875488446618\n",
      "Loss: 0.659062929526724\n",
      "Loss: 0.6346611812560246\n",
      "Loss: 0.6086204653035109\n",
      "Loss: 0.5803730710588321\n",
      "Loss: 0.5437620506443158\n",
      "______\n",
      "Iteration t=6\n",
      "all:  cs/acc_i=89.62 cs/acc_c=90.27 os/recall_knw=67.93 os/recall_unk=93.29 total/acc_i=75.64 total/acc_c=69.58 total/h_score=78.93\n",
      "selected:  cs/acc_i=89.58 cs/acc_c=90.19 os/recall_knw=67.41 os/recall_unk=93.45 total/acc_i=75.50 total/acc_c=69.29 total/h_score=78.78\n",
      "Loss: 2.2768392368157704\n",
      "Loss: 1.1089282502730688\n",
      "Loss: 0.8501940372586251\n",
      "Loss: 0.7626925327380498\n",
      "Loss: 0.7065416229764621\n",
      "Loss: 0.6763419119517008\n",
      "Loss: 0.6299333963294824\n",
      "Loss: 0.5869110805044572\n",
      "Loss: 0.558193430925409\n",
      "Loss: 0.5344924142956734\n",
      "______\n",
      "Iteration t=7\n",
      "all:  cs/acc_i=89.86 cs/acc_c=90.50 os/recall_knw=67.93 os/recall_unk=93.29 total/acc_i=75.64 total/acc_c=69.58 total/h_score=78.93\n",
      "selected:  cs/acc_i=89.86 cs/acc_c=90.49 os/recall_knw=67.92 os/recall_unk=93.34 total/acc_i=75.65 total/acc_c=69.58 total/h_score=78.94\n",
      "Loss: 2.2948470325565022\n",
      "Loss: 1.1000056019257074\n",
      "Loss: 0.8512253650399142\n",
      "Loss: 0.7726034019575563\n",
      "Loss: 0.6901656531812345\n",
      "Loss: 0.6527169978994863\n",
      "Loss: 0.62209762266506\n",
      "Loss: 0.5956212712383746\n",
      "Loss: 0.5654897571996201\n",
      "Loss: 0.5298617809416843\n",
      "______\n",
      "Iteration t=8\n",
      "all:  cs/acc_i=89.33 cs/acc_c=89.98 os/recall_knw=67.93 os/recall_unk=93.29 total/acc_i=75.64 total/acc_c=69.58 total/h_score=78.93\n",
      "selected:  cs/acc_i=89.33 cs/acc_c=89.98 os/recall_knw=67.93 os/recall_unk=93.29 total/acc_i=75.64 total/acc_c=69.58 total/h_score=78.93\n",
      "Loss: 2.2785901540141564\n",
      "Loss: 1.1050562015007501\n",
      "Loss: 0.8469723616525581\n",
      "Loss: 0.7758972500249793\n",
      "Loss: 0.6939576821667808\n",
      "Loss: 0.6420695773786881\n",
      "Loss: 0.6157762149837722\n",
      "Loss: 0.5760091641218559\n",
      "Loss: 0.5501179738694251\n",
      "Loss: 0.5363425698094194\n",
      "______\n",
      "Iteration t=9\n",
      "all:  cs/acc_i=89.77 cs/acc_c=90.42 os/recall_knw=67.93 os/recall_unk=93.29 total/acc_i=75.64 total/acc_c=69.58 total/h_score=78.93\n",
      "selected:  cs/acc_i=89.77 cs/acc_c=90.42 os/recall_knw=67.93 os/recall_unk=93.29 total/acc_i=75.64 total/acc_c=69.58 total/h_score=78.93\n",
      "tensor(0)\n",
      "all:  cs/acc_i=89.77 cs/acc_c=90.42 os/recall_knw=67.93 os/recall_unk=93.29 total/acc_i=75.64 total/acc_c=69.58 total/h_score=78.93\n",
      "sketch -> real lr= 0.001 seed= 3\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19]\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20]\n",
      "Loss: 2.5997840181916163\n",
      "Loss: 1.5643544526754227\n",
      "Loss: 1.2449032772431332\n",
      "Loss: 1.103743972767771\n",
      "Loss: 1.0027597359323923\n",
      "Loss: 0.9298079325034555\n",
      "Loss: 0.8880949565003403\n",
      "Loss: 0.8228735710139823\n",
      "Loss: 0.8019405906706785\n",
      "Loss: 0.7603074033967162\n",
      "tensor(True) tensor(True)\n",
      "______\n",
      "Iteration t=1\n",
      "all:  cs/acc_i=86.64 cs/acc_c=87.57 os/recall_knw=89.80 os/recall_unk=54.72 total/acc_i=73.33 total/acc_c=82.40 total/h_score=66.21\n",
      "selected:  cs/acc_i=76.61 cs/acc_c=81.36 os/recall_knw=62.30 os/recall_unk=99.68 total/acc_i=80.75 total/acc_c=70.12 total/h_score=81.30\n",
      "Loss: 2.5685622144917972\n",
      "Loss: 1.4527581302357502\n",
      "Loss: 1.1006758567251143\n",
      "Loss: 0.9876758001866888\n",
      "Loss: 0.8955819018062998\n",
      "Loss: 0.838409812724004\n",
      "Loss: 0.7848721372543789\n",
      "Loss: 0.745521249707605\n",
      "Loss: 0.7114444648633238\n",
      "Loss: 0.6989463436432549\n",
      "______\n",
      "Iteration t=2\n",
      "all:  cs/acc_i=88.03 cs/acc_c=88.78 os/recall_knw=75.14 os/recall_unk=89.13 total/acc_i=78.52 total/acc_c=75.40 total/h_score=81.29\n",
      "selected:  cs/acc_i=82.08 cs/acc_c=83.65 os/recall_knw=57.31 os/recall_unk=99.67 total/acc_i=75.31 total/acc_c=62.32 total/h_score=75.26\n",
      "Loss: 2.4429767982650348\n",
      "Loss: 1.2877550960042095\n",
      "Loss: 0.9709862015629542\n",
      "Loss: 0.9021967443573566\n",
      "Loss: 0.7895488001918065\n",
      "Loss: 0.7847934403947292\n",
      "Loss: 0.7302601882292115\n",
      "Loss: 0.6909126851508636\n",
      "Loss: 0.6696456183345263\n",
      "Loss: 0.6467838861787593\n",
      "______\n",
      "Iteration t=3\n",
      "all:  cs/acc_i=87.97 cs/acc_c=88.64 os/recall_knw=70.97 os/recall_unk=91.86 total/acc_i=76.94 total/acc_c=72.01 total/h_score=80.11\n",
      "selected:  cs/acc_i=85.23 cs/acc_c=86.08 os/recall_knw=62.80 os/recall_unk=97.91 total/acc_i=75.18 total/acc_c=65.58 total/h_score=77.37\n",
      "Loss: 2.3594164955145995\n",
      "Loss: 1.1732591843519586\n",
      "Loss: 0.8920387055284233\n",
      "Loss: 0.8193386392567747\n",
      "Loss: 0.762621871673078\n",
      "Loss: 0.7184588708330654\n",
      "Loss: 0.661428573257607\n",
      "Loss: 0.6211368742275409\n",
      "Loss: 0.603142358603016\n",
      "Loss: 0.5813846502145986\n",
      "______\n",
      "Iteration t=4\n",
      "all:  cs/acc_i=89.54 cs/acc_c=90.18 os/recall_knw=70.47 os/recall_unk=92.22 total/acc_i=76.79 total/acc_c=71.65 total/h_score=79.99\n",
      "selected:  cs/acc_i=88.56 cs/acc_c=89.26 os/recall_knw=66.88 os/recall_unk=94.81 total/acc_i=75.91 total/acc_c=69.02 total/h_score=79.02\n",
      "Loss: 2.3189040348954397\n",
      "Loss: 1.1126721859590647\n",
      "Loss: 0.8936845917407781\n",
      "Loss: 0.7553621843865473\n",
      "Loss: 0.7223464714950079\n",
      "Loss: 0.6684857542077972\n",
      "Loss: 0.6236066367630273\n",
      "Loss: 0.6202390923687856\n",
      "Loss: 0.5687241799721162\n",
      "Loss: 0.5468221233315664\n",
      "______\n",
      "Iteration t=5\n",
      "all:  cs/acc_i=89.98 cs/acc_c=90.57 os/recall_knw=70.44 os/recall_unk=92.34 total/acc_i=76.81 total/acc_c=71.63 total/h_score=80.01\n",
      "selected:  cs/acc_i=89.51 cs/acc_c=90.12 os/recall_knw=68.59 os/recall_unk=92.78 total/acc_i=76.09 total/acc_c=70.35 total/h_score=79.29\n",
      "Loss: 2.298255736795848\n",
      "Loss: 1.1060649760617505\n",
      "Loss: 0.8680398091173812\n",
      "Loss: 0.7580728308866488\n",
      "Loss: 0.7173126500924961\n",
      "Loss: 0.6602478735898966\n",
      "Loss: 0.630882528654281\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.579819230825309\n",
      "Loss: 0.5715583827871604\n",
      "Loss: 0.5410725145331965\n",
      "______\n",
      "Iteration t=6\n",
      "all:  cs/acc_i=89.92 cs/acc_c=90.54 os/recall_knw=70.44 os/recall_unk=92.34 total/acc_i=76.81 total/acc_c=71.63 total/h_score=80.01\n",
      "selected:  cs/acc_i=89.82 cs/acc_c=90.46 os/recall_knw=69.71 os/recall_unk=92.44 total/acc_i=76.56 total/acc_c=71.26 total/h_score=79.80\n",
      "Loss: 2.2710193020618514\n",
      "Loss: 1.0714450660130836\n",
      "Loss: 0.8552883166745798\n",
      "Loss: 0.7674412522094929\n",
      "Loss: 0.7090586139666324\n",
      "Loss: 0.6646496912600189\n",
      "Loss: 0.6136070986259852\n",
      "Loss: 0.5906404817341179\n",
      "Loss: 0.5634024032693825\n",
      "Loss: 0.5459231244807212\n",
      "______\n",
      "Iteration t=7\n",
      "all:  cs/acc_i=89.48 cs/acc_c=90.09 os/recall_knw=70.44 os/recall_unk=92.34 total/acc_i=76.81 total/acc_c=71.63 total/h_score=80.01\n",
      "selected:  cs/acc_i=89.47 cs/acc_c=90.08 os/recall_knw=70.43 os/recall_unk=92.34 total/acc_i=76.80 total/acc_c=71.62 total/h_score=80.01\n",
      "Loss: 2.2665856193323606\n",
      "Loss: 1.0650543955505871\n",
      "Loss: 0.8455782462338932\n",
      "Loss: 0.7431119501590728\n",
      "Loss: 0.6828349686059796\n",
      "Loss: 0.6434121094277647\n",
      "Loss: 0.6011054934536825\n",
      "Loss: 0.5670445808621704\n",
      "Loss: 0.549408706289823\n",
      "Loss: 0.5314572989452081\n",
      "______\n",
      "Iteration t=8\n",
      "all:  cs/acc_i=89.89 cs/acc_c=90.53 os/recall_knw=70.44 os/recall_unk=92.34 total/acc_i=76.81 total/acc_c=71.63 total/h_score=80.01\n",
      "selected:  cs/acc_i=89.89 cs/acc_c=90.53 os/recall_knw=70.44 os/recall_unk=92.34 total/acc_i=76.81 total/acc_c=71.63 total/h_score=80.01\n",
      "Loss: 2.278872513771057\n",
      "Loss: 1.0851883511074254\n",
      "Loss: 0.836200769318909\n",
      "Loss: 0.7652406485354314\n",
      "Loss: 0.6999118130715167\n",
      "Loss: 0.6601903283205188\n",
      "Loss: 0.6196700827508677\n",
      "Loss: 0.6020863546211211\n",
      "Loss: 0.5463235602515643\n",
      "Loss: 0.5352296705617279\n",
      "______\n",
      "Iteration t=9\n",
      "all:  cs/acc_i=89.89 cs/acc_c=90.51 os/recall_knw=70.44 os/recall_unk=92.34 total/acc_i=76.81 total/acc_c=71.63 total/h_score=80.01\n",
      "selected:  cs/acc_i=89.89 cs/acc_c=90.51 os/recall_knw=70.44 os/recall_unk=92.34 total/acc_i=76.81 total/acc_c=71.63 total/h_score=80.01\n",
      "tensor(0)\n",
      "all:  cs/acc_i=89.89 cs/acc_c=90.51 os/recall_knw=70.44 os/recall_unk=92.34 total/acc_i=76.81 total/acc_c=71.63 total/h_score=80.01\n",
      "sketch -> real lr= 0.001 seed= 4\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19]\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20]\n",
      "Loss: 2.6217792260963306\n",
      "Loss: 1.5893216763449982\n",
      "Loss: 1.2469858925426955\n",
      "Loss: 1.1013592130842462\n",
      "Loss: 1.0131918743120885\n",
      "Loss: 0.9460976624910811\n",
      "Loss: 0.8810420896099732\n",
      "Loss: 0.8217333905992255\n",
      "Loss: 0.7869297818536252\n",
      "Loss: 0.7556043236920263\n",
      "tensor(True) tensor(True)\n",
      "______\n",
      "Iteration t=1\n",
      "all:  cs/acc_i=86.23 cs/acc_c=87.21 os/recall_knw=89.51 os/recall_unk=54.13 total/acc_i=73.02 total/acc_c=82.22 total/h_score=65.72\n",
      "selected:  cs/acc_i=74.86 cs/acc_c=80.45 os/recall_knw=61.54 os/recall_unk=99.78 total/acc_i=80.23 total/acc_c=70.01 total/h_score=81.25\n",
      "Loss: 2.5429589982892646\n",
      "Loss: 1.4265667608038324\n",
      "Loss: 1.0940928122059244\n",
      "Loss: 0.9747319228825022\n",
      "Loss: 0.8975024201342316\n",
      "Loss: 0.8507882762150686\n",
      "Loss: 0.7735376963849927\n",
      "Loss: 0.7511555479808909\n",
      "Loss: 0.7042167893931514\n",
      "Loss: 0.677179466016957\n",
      "______\n",
      "Iteration t=2\n",
      "all:  cs/acc_i=87.58 cs/acc_c=88.33 os/recall_knw=72.13 os/recall_unk=89.36 total/acc_i=76.77 total/acc_c=72.76 total/h_score=79.70\n",
      "selected:  cs/acc_i=81.81 cs/acc_c=83.38 os/recall_knw=54.49 os/recall_unk=99.67 total/acc_i=73.19 total/acc_c=59.21 total/h_score=72.67\n",
      "Loss: 2.4482266184027868\n",
      "Loss: 1.2819953779227862\n",
      "Loss: 1.0143234124620453\n",
      "Loss: 0.9026999173273567\n",
      "Loss: 0.8219318269318296\n",
      "Loss: 0.7530636831776787\n",
      "Loss: 0.7209693955556127\n",
      "Loss: 0.6963056090451379\n",
      "Loss: 0.6558452655795877\n",
      "Loss: 0.616081735105005\n",
      "______\n",
      "Iteration t=3\n",
      "all:  cs/acc_i=88.68 cs/acc_c=89.34 os/recall_knw=69.05 os/recall_unk=92.39 total/acc_i=76.12 total/acc_c=70.48 total/h_score=79.26\n",
      "selected:  cs/acc_i=86.24 cs/acc_c=87.11 os/recall_knw=61.16 os/recall_unk=98.36 total/acc_i=74.37 total/acc_c=64.28 total/h_score=76.49\n",
      "Loss: 2.373102025591212\n",
      "Loss: 1.19194263369917\n",
      "Loss: 0.925269389860064\n",
      "Loss: 0.8285561533068582\n",
      "Loss: 0.750986584978138\n",
      "Loss: 0.7030242486394567\n",
      "Loss: 0.6824561806677056\n",
      "Loss: 0.6338246234779735\n",
      "Loss: 0.6185316238150322\n",
      "Loss: 0.5655520738457605\n",
      "______\n",
      "Iteration t=4\n",
      "all:  cs/acc_i=89.57 cs/acc_c=90.09 os/recall_knw=68.70 os/recall_unk=92.63 total/acc_i=76.00 total/acc_c=70.22 total/h_score=79.15\n",
      "selected:  cs/acc_i=88.45 cs/acc_c=88.90 os/recall_knw=64.96 os/recall_unk=95.12 total/acc_i=74.94 total/acc_c=67.22 total/h_score=77.80\n",
      "Loss: 2.33235619273679\n",
      "Loss: 1.1441016877519674\n",
      "Loss: 0.8913599970011875\n",
      "Loss: 0.7885915327688743\n",
      "Loss: 0.7427552862413999\n",
      "Loss: 0.6902773233323262\n",
      "Loss: 0.6327301303374356\n",
      "Loss: 0.5754670865576843\n",
      "Loss: 0.5854010384144455\n",
      "Loss: 0.5533014437247967\n",
      "______\n",
      "Iteration t=5\n",
      "all:  cs/acc_i=89.71 cs/acc_c=90.30 os/recall_knw=68.70 os/recall_unk=92.63 total/acc_i=76.00 total/acc_c=70.22 total/h_score=79.15\n",
      "selected:  cs/acc_i=89.22 cs/acc_c=89.79 os/recall_knw=67.02 os/recall_unk=93.35 total/acc_i=75.39 total/acc_c=68.96 total/h_score=78.51\n",
      "Loss: 2.3011648261587228\n",
      "Loss: 1.1035057598292226\n",
      "Loss: 0.8818358719750286\n",
      "Loss: 0.7842351742063709\n",
      "Loss: 0.7203355987465342\n",
      "Loss: 0.6505899888397467\n",
      "Loss: 0.6500193014088704\n",
      "Loss: 0.5895381554810688\n",
      "Loss: 0.5621591203842902\n",
      "Loss: 0.5508499339172735\n",
      "______\n",
      "Iteration t=6\n",
      "all:  cs/acc_i=89.57 cs/acc_c=90.18 os/recall_knw=68.55 os/recall_unk=92.69 total/acc_i=75.92 total/acc_c=70.11 total/h_score=79.10\n",
      "selected:  cs/acc_i=89.45 cs/acc_c=90.05 os/recall_knw=68.11 os/recall_unk=92.80 total/acc_i=75.74 total/acc_c=69.82 total/h_score=78.93\n",
      "Loss: 2.2727413268580388\n",
      "Loss: 1.0646532391788952\n",
      "Loss: 0.853057882417476\n",
      "Loss: 0.7654821098444866\n",
      "Loss: 0.6935655702388168\n",
      "Loss: 0.6784131959625257\n",
      "Loss: 0.6316310021271341\n",
      "Loss: 0.6052096495992717\n",
      "Loss: 0.5591465229805918\n",
      "Loss: 0.5279268169422878\n",
      "______\n",
      "Iteration t=7\n",
      "all:  cs/acc_i=89.71 cs/acc_c=90.38 os/recall_knw=68.52 os/recall_unk=92.75 total/acc_i=75.92 total/acc_c=70.09 total/h_score=79.10\n",
      "selected:  cs/acc_i=89.71 cs/acc_c=90.37 os/recall_knw=68.50 os/recall_unk=92.75 total/acc_i=75.91 total/acc_c=70.06 total/h_score=79.09\n",
      "Loss: 2.280615283953433\n",
      "Loss: 1.0856517894773294\n",
      "Loss: 0.8554889538035487\n",
      "Loss: 0.7715388100273561\n",
      "Loss: 0.7110561266640164\n",
      "Loss: 0.6460428539885591\n",
      "Loss: 0.6125696011331697\n",
      "Loss: 0.5866665966956821\n",
      "Loss: 0.5552012206900199\n",
      "Loss: 0.5241672261217177\n",
      "______\n",
      "Iteration t=8\n",
      "all:  cs/acc_i=89.68 cs/acc_c=90.32 os/recall_knw=68.52 os/recall_unk=92.75 total/acc_i=75.92 total/acc_c=70.09 total/h_score=79.10\n",
      "selected:  cs/acc_i=89.68 cs/acc_c=90.32 os/recall_knw=68.52 os/recall_unk=92.75 total/acc_i=75.92 total/acc_c=70.09 total/h_score=79.10\n",
      "Loss: 2.269546815101674\n",
      "Loss: 1.071116593105114\n",
      "Loss: 0.8598732569359786\n",
      "Loss: 0.769145037559484\n",
      "Loss: 0.7009442081514573\n",
      "Loss: 0.6583213066028444\n",
      "Loss: 0.6328283009051487\n",
      "Loss: 0.5834088329447816\n",
      "Loss: 0.5555210428818173\n",
      "Loss: 0.5329935863021983\n",
      "______\n",
      "Iteration t=9\n",
      "all:  cs/acc_i=90.04 cs/acc_c=90.55 os/recall_knw=68.52 os/recall_unk=92.75 total/acc_i=75.92 total/acc_c=70.09 total/h_score=79.10\n",
      "selected:  cs/acc_i=90.04 cs/acc_c=90.55 os/recall_knw=68.52 os/recall_unk=92.75 total/acc_i=75.92 total/acc_c=70.09 total/h_score=79.10\n",
      "tensor(0)\n",
      "all:  cs/acc_i=90.04 cs/acc_c=90.55 os/recall_knw=68.52 os/recall_unk=92.75 total/acc_i=75.92 total/acc_c=70.09 total/h_score=79.10\n",
      "sketch -> painting lr= 0.001 seed= 0\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19]\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20]\n",
      "Loss: 2.6840221734391045\n",
      "Loss: 1.6281390549595822\n",
      "Loss: 1.1324772549044226\n",
      "Loss: 0.924191589668854\n",
      "Loss: 0.8256666655700231\n",
      "Loss: 0.7526799750696752\n",
      "Loss: 0.7163646239595315\n",
      "Loss: 0.6498848196771956\n",
      "Loss: 0.6392454246884769\n",
      "Loss: 0.5936314467455923\n",
      "tensor(True) tensor(True)\n",
      "______\n",
      "Iteration t=1\n",
      "all:  cs/acc_i=65.56 cs/acc_c=66.11 os/recall_knw=92.91 os/recall_unk=16.11 total/acc_i=48.72 total/acc_c=62.36 total/h_score=25.80\n",
      "selected:  cs/acc_i=72.99 cs/acc_c=72.93 os/recall_knw=69.63 os/recall_unk=94.63 total/acc_i=73.91 total/acc_c=68.28 total/h_score=78.43\n",
      "Loss: 2.6219476225295506\n",
      "Loss: 1.454609399544444\n",
      "Loss: 1.0010971625645955\n",
      "Loss: 0.8586702401511335\n",
      "Loss: 0.7716775681949468\n",
      "Loss: 0.6882401760937511\n",
      "Loss: 0.6526078689789426\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.576024830053394\n",
      "Loss: 0.5896296799902755\n",
      "Loss: 0.5371893999225276\n",
      "______\n",
      "Iteration t=2\n",
      "all:  cs/acc_i=67.16 cs/acc_c=67.53 os/recall_knw=62.46 os/recall_unk=73.84 total/acc_i=60.44 total/acc_c=55.81 total/h_score=62.98\n",
      "selected:  cs/acc_i=60.91 cs/acc_c=62.17 os/recall_knw=45.01 os/recall_unk=94.17 total/acc_i=60.20 total/acc_c=46.26 total/h_score=59.85\n",
      "Loss: 2.5814192831516265\n",
      "Loss: 1.3770412908359007\n",
      "Loss: 0.9414748760786924\n",
      "Loss: 0.7917327879504724\n",
      "Loss: 0.7175926509905945\n",
      "Loss: 0.6462869771502234\n",
      "Loss: 0.6014158047735692\n",
      "Loss: 0.565918792039156\n",
      "Loss: 0.518677525899627\n",
      "Loss: 0.4836188775233247\n",
      "______\n",
      "Iteration t=3\n",
      "all:  cs/acc_i=67.05 cs/acc_c=67.29 os/recall_knw=58.50 os/recall_unk=78.32 total/acc_i=60.46 total/acc_c=54.07 total/h_score=63.12\n",
      "selected:  cs/acc_i=63.24 cs/acc_c=64.12 os/recall_knw=50.02 os/recall_unk=89.72 total/acc_i=59.94 total/acc_c=48.89 total/h_score=61.56\n",
      "Loss: 2.52968917152156\n",
      "Loss: 1.287207707633143\n",
      "Loss: 0.8802513950544855\n",
      "Loss: 0.729514490780623\n",
      "Loss: 0.6506537885769553\n",
      "Loss: 0.6074068338326786\n",
      "Loss: 0.5855736652794091\n",
      "Loss: 0.5104842363492302\n",
      "Loss: 0.4873980893712977\n",
      "Loss: 0.4631230245465818\n",
      "______\n",
      "Iteration t=4\n",
      "all:  cs/acc_i=67.32 cs/acc_c=67.69 os/recall_knw=57.56 os/recall_unk=79.90 total/acc_i=60.54 total/acc_c=53.48 total/h_score=63.11\n",
      "selected:  cs/acc_i=65.79 cs/acc_c=66.57 os/recall_knw=53.91 os/recall_unk=85.13 total/acc_i=60.40 total/acc_c=51.42 total/h_score=62.79\n",
      "Loss: 2.5276340690117998\n",
      "Loss: 1.2345247465696294\n",
      "Loss: 0.8744067496086264\n",
      "Loss: 0.7216282858509399\n",
      "Loss: 0.6347821282542401\n",
      "Loss: 0.5894290896514469\n",
      "Loss: 0.5460639619054156\n",
      "Loss: 0.5072705023084225\n",
      "Loss: 0.4812874957046249\n",
      "Loss: 0.459635983451141\n",
      "______\n",
      "Iteration t=5\n",
      "all:  cs/acc_i=68.61 cs/acc_c=68.93 os/recall_knw=57.13 os/recall_unk=80.40 total/acc_i=60.49 total/acc_c=53.20 total/h_score=63.04\n",
      "selected:  cs/acc_i=68.20 cs/acc_c=68.68 os/recall_knw=55.96 os/recall_unk=82.45 total/acc_i=60.55 total/acc_c=52.66 total/h_score=63.15\n",
      "Loss: 2.4716517265702858\n",
      "Loss: 1.2217195581217282\n",
      "Loss: 0.8376560665544917\n",
      "Loss: 0.7133250659117933\n",
      "Loss: 0.6241797308941357\n",
      "Loss: 0.5767098544318168\n",
      "Loss: 0.5257383980101249\n",
      "Loss: 0.5033236911795178\n",
      "Loss: 0.46288621993582757\n",
      "Loss: 0.4549063549178546\n",
      "______\n",
      "Iteration t=6\n",
      "all:  cs/acc_i=67.75 cs/acc_c=68.32 os/recall_knw=57.09 os/recall_unk=80.40 total/acc_i=60.49 total/acc_c=53.20 total/h_score=63.04\n",
      "selected:  cs/acc_i=67.60 cs/acc_c=68.26 os/recall_knw=56.84 os/recall_unk=80.87 total/acc_i=60.47 total/acc_c=53.09 total/h_score=63.07\n",
      "Loss: 2.5008997655496366\n",
      "Loss: 1.2383584828396155\n",
      "Loss: 0.8445413296784812\n",
      "Loss: 0.6976999640464783\n",
      "Loss: 0.6350459232926369\n",
      "Loss: 0.578091224155775\n",
      "Loss: 0.5316453057576002\n",
      "Loss: 0.4954409526615608\n",
      "Loss: 0.46716015846506365\n",
      "Loss: 0.43010324285161206\n",
      "______\n",
      "Iteration t=7\n",
      "all:  cs/acc_i=68.77 cs/acc_c=69.03 os/recall_knw=57.09 os/recall_unk=80.40 total/acc_i=60.49 total/acc_c=53.20 total/h_score=63.04\n",
      "selected:  cs/acc_i=68.75 cs/acc_c=69.01 os/recall_knw=57.06 os/recall_unk=80.40 total/acc_i=60.47 total/acc_c=53.18 total/h_score=63.02\n",
      "Loss: 2.4848182297911237\n",
      "Loss: 1.2054663370495382\n",
      "Loss: 0.8587331865963183\n",
      "Loss: 0.7042568556451605\n",
      "Loss: 0.604813282125392\n",
      "Loss: 0.5542444337596778\n",
      "Loss: 0.5201034668365471\n",
      "Loss: 0.4996247877355529\n",
      "Loss: 0.47106781233901435\n",
      "Loss: 0.44964969496012697\n",
      "______\n",
      "Iteration t=8\n",
      "all:  cs/acc_i=68.10 cs/acc_c=68.72 os/recall_knw=57.09 os/recall_unk=80.40 total/acc_i=60.49 total/acc_c=53.20 total/h_score=63.04\n",
      "selected:  cs/acc_i=68.10 cs/acc_c=68.72 os/recall_knw=57.09 os/recall_unk=80.40 total/acc_i=60.49 total/acc_c=53.20 total/h_score=63.04\n",
      "Loss: 2.4928902566191637\n",
      "Loss: 1.2380322051434383\n",
      "Loss: 0.8404572270659783\n",
      "Loss: 0.718021589493462\n",
      "Loss: 0.6448888174797359\n",
      "Loss: 0.5836504893867593\n",
      "Loss: 0.5420890971113314\n",
      "Loss: 0.48680721503882274\n",
      "Loss: 0.4609389372079479\n",
      "Loss: 0.46445654592050717\n",
      "______\n",
      "Iteration t=9\n",
      "all:  cs/acc_i=68.65 cs/acc_c=69.03 os/recall_knw=57.09 os/recall_unk=80.40 total/acc_i=60.49 total/acc_c=53.20 total/h_score=63.04\n",
      "selected:  cs/acc_i=68.65 cs/acc_c=69.03 os/recall_knw=57.09 os/recall_unk=80.40 total/acc_i=60.49 total/acc_c=53.20 total/h_score=63.04\n",
      "tensor(0)\n",
      "all:  cs/acc_i=68.65 cs/acc_c=69.03 os/recall_knw=57.09 os/recall_unk=80.40 total/acc_i=60.49 total/acc_c=53.20 total/h_score=63.04\n",
      "sketch -> painting lr= 0.001 seed= 1\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19]\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20]\n",
      "Loss: 2.677957374410531\n",
      "Loss: 1.5970686557366676\n",
      "Loss: 1.1331196759164948\n",
      "Loss: 0.9466246781275445\n",
      "Loss: 0.8453145080927721\n",
      "Loss: 0.7640833575086495\n",
      "Loss: 0.7041603309899261\n",
      "Loss: 0.671329298891972\n",
      "Loss: 0.6299913781359023\n",
      "Loss: 0.6089185367232746\n",
      "tensor(True) tensor(True)\n",
      "______\n",
      "Iteration t=1\n",
      "all:  cs/acc_i=64.93 cs/acc_c=65.29 os/recall_knw=92.95 os/recall_unk=16.20 total/acc_i=48.54 total/acc_c=61.89 total/h_score=25.86\n",
      "selected:  cs/acc_i=70.87 cs/acc_c=71.44 os/recall_knw=69.34 os/recall_unk=91.55 total/acc_i=72.75 total/acc_c=68.00 total/h_score=77.26\n",
      "Loss: 2.6320860598974183\n",
      "Loss: 1.4569655173066733\n",
      "Loss: 1.0111320683921592\n",
      "Loss: 0.8644814033439194\n",
      "Loss: 0.7458961483649009\n",
      "Loss: 0.6891634098573584\n",
      "Loss: 0.6392869700988134\n",
      "Loss: 0.6076600197432698\n",
      "Loss: 0.5686513101997007\n",
      "Loss: 0.5361101819553237\n",
      "______\n",
      "Iteration t=2\n",
      "all:  cs/acc_i=65.71 cs/acc_c=66.21 os/recall_knw=63.87 os/recall_unk=71.68 total/acc_i=60.09 total/acc_c=56.11 total/h_score=62.45\n",
      "selected:  cs/acc_i=58.91 cs/acc_c=60.61 os/recall_knw=45.80 os/recall_unk=93.40 total/acc_i=60.27 total/acc_c=46.70 total/h_score=60.15\n",
      "Loss: 2.5904497168280862\n",
      "Loss: 1.367385468157855\n",
      "Loss: 0.939554420790889\n",
      "Loss: 0.8090535578402606\n",
      "Loss: 0.7147342324256897\n",
      "Loss: 0.637486612864516\n",
      "Loss: 0.5930872212756764\n",
      "Loss: 0.5527215705676513\n",
      "Loss: 0.5155143322592431\n",
      "Loss: 0.47875555685975335\n",
      "______\n",
      "Iteration t=3\n",
      "all:  cs/acc_i=66.50 cs/acc_c=67.02 os/recall_knw=56.82 os/recall_unk=80.90 total/acc_i=60.30 total/acc_c=52.70 total/h_score=62.78\n",
      "selected:  cs/acc_i=63.06 cs/acc_c=64.41 os/recall_knw=49.05 os/recall_unk=89.94 total/acc_i=59.52 total/acc_c=48.04 total/h_score=60.82\n",
      "Loss: 2.5446560382843018\n",
      "Loss: 1.3109317246453587\n",
      "Loss: 0.9001973906120697\n",
      "Loss: 0.773378837547261\n",
      "Loss: 0.6692036576085276\n",
      "Loss: 0.6031890000615802\n",
      "Loss: 0.5757062635767511\n",
      "Loss: 0.5570854660107459\n",
      "Loss: 0.501457210033487\n",
      "Loss: 0.47433185064560407\n",
      "______\n",
      "Iteration t=4\n",
      "all:  cs/acc_i=67.20 cs/acc_c=67.70 os/recall_knw=55.13 os/recall_unk=82.89 total/acc_i=60.17 total/acc_c=51.75 total/h_score=62.52\n",
      "selected:  cs/acc_i=65.95 cs/acc_c=67.00 os/recall_knw=51.93 os/recall_unk=87.01 total/acc_i=59.96 total/acc_c=50.19 total/h_score=62.16\n",
      "Loss: 2.508894438482035\n",
      "Loss: 1.2701188255462967\n",
      "Loss: 0.8875006516522999\n",
      "Loss: 0.7266512753339759\n",
      "Loss: 0.6575136275231084\n",
      "Loss: 0.5972203794033718\n",
      "Loss: 0.5549595198173564\n",
      "Loss: 0.5151914267600337\n",
      "Loss: 0.47122003751087793\n",
      "Loss: 0.4379037510808007\n",
      "______\n",
      "Iteration t=5\n",
      "all:  cs/acc_i=68.10 cs/acc_c=68.40 os/recall_knw=55.09 os/recall_unk=83.06 total/acc_i=60.22 total/acc_c=51.76 total/h_score=62.57\n",
      "selected:  cs/acc_i=67.83 cs/acc_c=68.36 os/recall_knw=53.86 os/recall_unk=84.96 total/acc_i=60.34 total/acc_c=51.38 total/h_score=62.71\n",
      "Loss: 2.4927826986273294\n",
      "Loss: 1.2411424705596386\n",
      "Loss: 0.8497227458785679\n",
      "Loss: 0.7330809631906604\n",
      "Loss: 0.6596779632865146\n",
      "Loss: 0.5832358831191953\n",
      "Loss: 0.5390517026556972\n",
      "Loss: 0.5225213622032854\n",
      "Loss: 0.47037811957577946\n",
      "Loss: 0.4401798173476057\n",
      "______\n",
      "Iteration t=6\n",
      "all:  cs/acc_i=68.14 cs/acc_c=68.59 os/recall_knw=55.09 os/recall_unk=83.06 total/acc_i=60.22 total/acc_c=51.76 total/h_score=62.57\n",
      "selected:  cs/acc_i=68.16 cs/acc_c=68.67 os/recall_knw=54.85 os/recall_unk=83.89 total/acc_i=60.40 total/acc_c=51.79 total/h_score=62.80\n",
      "Loss: 2.492654578675949\n",
      "Loss: 1.2315533659095137\n",
      "Loss: 0.8503328787446512\n",
      "Loss: 0.7113947761647496\n",
      "Loss: 0.6382357873666433\n",
      "Loss: 0.5724608671272733\n",
      "Loss: 0.5427673372589512\n",
      "Loss: 0.503173238793273\n",
      "Loss: 0.48371701083556123\n",
      "Loss: 0.4386946993722837\n",
      "______\n",
      "Iteration t=7\n",
      "all:  cs/acc_i=67.79 cs/acc_c=68.03 os/recall_knw=55.05 os/recall_unk=83.06 total/acc_i=60.22 total/acc_c=51.76 total/h_score=62.57\n",
      "selected:  cs/acc_i=67.79 cs/acc_c=68.03 os/recall_knw=55.05 os/recall_unk=83.06 total/acc_i=60.22 total/acc_c=51.76 total/h_score=62.57\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 2.5041547012133676\n",
      "Loss: 1.2393273068744628\n",
      "Loss: 0.8523178747931465\n",
      "Loss: 0.7079648600249994\n",
      "Loss: 0.6308511719107628\n",
      "Loss: 0.5993444364456857\n",
      "Loss: 0.5429140226152099\n",
      "Loss: 0.5056910817740393\n",
      "Loss: 0.480516467609855\n",
      "Loss: 0.4492673646109026\n",
      "______\n",
      "Iteration t=8\n",
      "all:  cs/acc_i=68.18 cs/acc_c=68.60 os/recall_knw=55.05 os/recall_unk=83.06 total/acc_i=60.22 total/acc_c=51.76 total/h_score=62.57\n",
      "selected:  cs/acc_i=68.18 cs/acc_c=68.60 os/recall_knw=55.05 os/recall_unk=83.06 total/acc_i=60.22 total/acc_c=51.76 total/h_score=62.57\n",
      "Loss: 2.4953712659781098\n",
      "Loss: 1.2318085830231182\n",
      "Loss: 0.8426947906369069\n",
      "Loss: 0.7244206745116437\n",
      "Loss: 0.6336342270989888\n",
      "Loss: 0.5830857549778751\n",
      "Loss: 0.5340643203893646\n",
      "Loss: 0.4981338046185794\n",
      "Loss: 0.4610401179763626\n",
      "Loss: 0.45669772598098535\n",
      "______\n",
      "Iteration t=9\n",
      "all:  cs/acc_i=68.89 cs/acc_c=69.32 os/recall_knw=55.05 os/recall_unk=83.06 total/acc_i=60.22 total/acc_c=51.76 total/h_score=62.57\n",
      "selected:  cs/acc_i=68.89 cs/acc_c=69.32 os/recall_knw=55.05 os/recall_unk=83.06 total/acc_i=60.22 total/acc_c=51.76 total/h_score=62.57\n",
      "tensor(0)\n",
      "all:  cs/acc_i=68.89 cs/acc_c=69.32 os/recall_knw=55.05 os/recall_unk=83.06 total/acc_i=60.22 total/acc_c=51.76 total/h_score=62.57\n",
      "sketch -> painting lr= 0.001 seed= 2\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19]\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20]\n",
      "Loss: 2.6798956412629984\n",
      "Loss: 1.5892054801134718\n",
      "Loss: 1.136032055640958\n",
      "Loss: 0.959412701043886\n",
      "Loss: 0.8074563844609506\n",
      "Loss: 0.7593788668974158\n",
      "Loss: 0.698358450968241\n",
      "Loss: 0.6530595973287661\n",
      "Loss: 0.6449257471819514\n",
      "Loss: 0.596458290348348\n",
      "tensor(True) tensor(True)\n",
      "______\n",
      "Iteration t=1\n",
      "all:  cs/acc_i=65.28 cs/acc_c=65.97 os/recall_knw=92.91 os/recall_unk=16.11 total/acc_i=48.72 total/acc_c=62.52 total/h_score=25.81\n",
      "selected:  cs/acc_i=71.14 cs/acc_c=70.98 os/recall_knw=69.27 os/recall_unk=91.94 total/acc_i=72.88 total/acc_c=67.54 total/h_score=77.06\n",
      "Loss: 2.6228067345089383\n",
      "Loss: 1.4710190261619678\n",
      "Loss: 1.0215707424182248\n",
      "Loss: 0.8864996878133304\n",
      "Loss: 0.7661052912041761\n",
      "Loss: 0.7061560192833776\n",
      "Loss: 0.6568980409903227\n",
      "Loss: 0.6120477598070523\n",
      "Loss: 0.5631587411038541\n",
      "Loss: 0.5485895407804544\n",
      "______\n",
      "Iteration t=2\n",
      "all:  cs/acc_i=67.24 cs/acc_c=67.57 os/recall_knw=65.87 os/recall_unk=67.44 total/acc_i=59.48 total/acc_c=56.86 total/h_score=61.39\n",
      "selected:  cs/acc_i=61.97 cs/acc_c=63.12 os/recall_knw=47.59 os/recall_unk=94.31 total/acc_i=61.36 total/acc_c=48.21 total/h_score=61.75\n",
      "Loss: 2.5588442114266483\n",
      "Loss: 1.3434274860403754\n",
      "Loss: 0.9421346629207784\n",
      "Loss: 0.804014157707041\n",
      "Loss: 0.7027628228068352\n",
      "Loss: 0.6534192621707916\n",
      "Loss: 0.6114450336857276\n",
      "Loss: 0.5423973897641355\n",
      "Loss: 0.5453070555898276\n",
      "Loss: 0.49976652935147287\n",
      "______\n",
      "Iteration t=3\n",
      "all:  cs/acc_i=67.12 cs/acc_c=67.48 os/recall_knw=59.13 os/recall_unk=78.82 total/acc_i=61.05 total/acc_c=54.45 total/h_score=63.55\n",
      "selected:  cs/acc_i=63.63 cs/acc_c=64.68 os/recall_knw=50.73 os/recall_unk=91.43 total/acc_i=61.08 total/acc_c=49.72 total/h_score=62.63\n",
      "Loss: 2.5428780089253964\n",
      "Loss: 1.2973336310490318\n",
      "Loss: 0.9104036836520485\n",
      "Loss: 0.7611478293719499\n",
      "Loss: 0.6729015526564225\n",
      "Loss: 0.6204316670479981\n",
      "Loss: 0.5737726698427097\n",
      "Loss: 0.5348767243001772\n",
      "Loss: 0.4913261948072392\n",
      "Loss: 0.4672200714116511\n",
      "______\n",
      "Iteration t=4\n",
      "all:  cs/acc_i=67.95 cs/acc_c=68.22 os/recall_knw=58.39 os/recall_unk=79.73 total/acc_i=61.05 total/acc_c=54.09 total/h_score=63.54\n",
      "selected:  cs/acc_i=66.32 cs/acc_c=66.99 os/recall_knw=54.50 os/recall_unk=85.94 total/acc_i=61.05 total/acc_c=51.96 total/h_score=63.43\n",
      "Loss: 2.5230802048200345\n",
      "Loss: 1.2455139222504206\n",
      "Loss: 0.8870921703562078\n",
      "Loss: 0.7254901402415591\n",
      "Loss: 0.647246212640068\n",
      "Loss: 0.5785449777562249\n",
      "Loss: 0.536221705221232\n",
      "Loss: 0.515125478878929\n",
      "Loss: 0.4785058802017108\n",
      "Loss: 0.44713612306068135\n",
      "______\n",
      "Iteration t=5\n",
      "all:  cs/acc_i=68.14 cs/acc_c=68.60 os/recall_knw=58.27 os/recall_unk=80.15 total/acc_i=61.16 total/acc_c=54.07 total/h_score=63.64\n",
      "selected:  cs/acc_i=67.53 cs/acc_c=68.26 os/recall_knw=56.44 os/recall_unk=82.62 total/acc_i=61.14 total/acc_c=53.33 total/h_score=63.73\n",
      "Loss: 2.4860013306386186\n",
      "Loss: 1.2062601003136655\n",
      "Loss: 0.8710949338757943\n",
      "Loss: 0.7002896438410253\n",
      "Loss: 0.661594493766871\n",
      "Loss: 0.5820497466948787\n",
      "Loss: 0.5523607590438898\n",
      "Loss: 0.5035556289884779\n",
      "Loss: 0.47686651575957795\n",
      "Loss: 0.4297076005626608\n",
      "______\n",
      "Iteration t=6\n",
      "all:  cs/acc_i=68.61 cs/acc_c=69.00 os/recall_knw=58.07 os/recall_unk=80.32 total/acc_i=61.13 total/acc_c=53.97 total/h_score=63.60\n",
      "selected:  cs/acc_i=68.56 cs/acc_c=69.01 os/recall_knw=57.74 os/recall_unk=80.92 total/acc_i=61.20 total/acc_c=53.92 total/h_score=63.73\n",
      "Loss: 2.4880581732220977\n",
      "Loss: 1.2221049118621146\n",
      "Loss: 0.8361346074926709\n",
      "Loss: 0.7147205245157002\n",
      "Loss: 0.6261896998414144\n",
      "Loss: 0.5644092673835485\n",
      "Loss: 0.5310667605414564\n",
      "Loss: 0.492377002772532\n",
      "Loss: 0.47077917093448796\n",
      "Loss: 0.4511339021959768\n",
      "______\n",
      "Iteration t=7\n",
      "all:  cs/acc_i=68.73 cs/acc_c=69.05 os/recall_knw=58.07 os/recall_unk=80.32 total/acc_i=61.13 total/acc_c=53.97 total/h_score=63.60\n",
      "selected:  cs/acc_i=68.73 cs/acc_c=69.07 os/recall_knw=58.02 os/recall_unk=80.45 total/acc_i=61.16 total/acc_c=53.97 total/h_score=63.64\n",
      "Loss: 2.4911501378782335\n",
      "Loss: 1.2209009045074064\n",
      "Loss: 0.8549738350895143\n",
      "Loss: 0.7214763630782405\n",
      "Loss: 0.6429378676318354\n",
      "Loss: 0.5744455590723984\n",
      "Loss: 0.5289781083382906\n",
      "Loss: 0.49219643312596506\n",
      "Loss: 0.4591745013491281\n",
      "Loss: 0.43186478250690047\n",
      "______\n",
      "Iteration t=8\n",
      "all:  cs/acc_i=68.93 cs/acc_c=69.10 os/recall_knw=58.07 os/recall_unk=80.32 total/acc_i=61.13 total/acc_c=53.97 total/h_score=63.60\n",
      "selected:  cs/acc_i=68.93 cs/acc_c=69.10 os/recall_knw=58.07 os/recall_unk=80.32 total/acc_i=61.13 total/acc_c=53.97 total/h_score=63.60\n",
      "Loss: 2.4751667976379395\n",
      "Loss: 1.2010527519929795\n",
      "Loss: 0.8377063834378796\n",
      "Loss: 0.7039904487469504\n",
      "Loss: 0.6126786020974959\n",
      "Loss: 0.5754812379638033\n",
      "Loss: 0.5023393578106358\n",
      "Loss: 0.4964965431981029\n",
      "Loss: 0.46417023337656454\n",
      "Loss: 0.4379509517682656\n",
      "______\n",
      "Iteration t=9\n",
      "all:  cs/acc_i=68.89 cs/acc_c=69.23 os/recall_knw=58.07 os/recall_unk=80.32 total/acc_i=61.13 total/acc_c=53.97 total/h_score=63.60\n",
      "selected:  cs/acc_i=68.89 cs/acc_c=69.23 os/recall_knw=58.07 os/recall_unk=80.32 total/acc_i=61.13 total/acc_c=53.97 total/h_score=63.60\n",
      "tensor(0)\n",
      "all:  cs/acc_i=68.89 cs/acc_c=69.23 os/recall_knw=58.07 os/recall_unk=80.32 total/acc_i=61.13 total/acc_c=53.97 total/h_score=63.60\n",
      "sketch -> painting lr= 0.001 seed= 3\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19]\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20]\n",
      "Loss: 2.6870289776743075\n",
      "Loss: 1.6012606381141032\n",
      "Loss: 1.1051189493887204\n",
      "Loss: 0.9473465730234519\n",
      "Loss: 0.8292071114188617\n",
      "Loss: 0.7426205801287877\n",
      "Loss: 0.7071096510002294\n",
      "Loss: 0.6543484259512007\n",
      "Loss: 0.6391112207598293\n",
      "Loss: 0.5866768621292311\n",
      "tensor(True) tensor(True)\n",
      "______\n",
      "Iteration t=1\n",
      "all:  cs/acc_i=64.46 cs/acc_c=65.10 os/recall_knw=93.06 os/recall_unk=16.45 total/acc_i=48.32 total/acc_c=61.80 total/h_score=26.17\n",
      "selected:  cs/acc_i=70.65 cs/acc_c=70.87 os/recall_knw=69.80 os/recall_unk=91.67 total/acc_i=72.82 total/acc_c=67.33 total/h_score=76.82\n",
      "Loss: 2.62342525737873\n",
      "Loss: 1.4578021085204709\n",
      "Loss: 1.0328444438280115\n",
      "Loss: 0.8813148535392135\n",
      "Loss: 0.7490208048175498\n",
      "Loss: 0.6958904267797148\n",
      "Loss: 0.6516987505742318\n",
      "Loss: 0.6343751654820742\n",
      "Loss: 0.5543176125789034\n",
      "Loss: 0.5403804494706905\n",
      "______\n",
      "Iteration t=2\n",
      "all:  cs/acc_i=65.44 cs/acc_c=65.86 os/recall_knw=61.83 os/recall_unk=72.51 total/acc_i=59.05 total/acc_c=54.38 total/h_score=61.55\n",
      "selected:  cs/acc_i=58.85 cs/acc_c=60.09 os/recall_knw=44.56 os/recall_unk=93.57 total/acc_i=58.81 total/acc_c=44.48 total/h_score=58.00\n",
      "Loss: 2.5757157396186483\n",
      "Loss: 1.3728681512854315\n",
      "Loss: 0.931058606640859\n",
      "Loss: 0.795017008618875\n",
      "Loss: 0.7042085684158585\n",
      "Loss: 0.6518816664137623\n",
      "Loss: 0.5942427652803335\n",
      "Loss: 0.5533349064263431\n",
      "Loss: 0.5092716459523547\n",
      "Loss: 0.4780766875906424\n",
      "______\n",
      "Iteration t=3\n",
      "all:  cs/acc_i=65.75 cs/acc_c=65.87 os/recall_knw=56.23 os/recall_unk=80.73 total/acc_i=59.77 total/acc_c=51.96 total/h_score=62.15\n",
      "selected:  cs/acc_i=62.34 cs/acc_c=63.29 os/recall_knw=48.38 os/recall_unk=90.42 total/acc_i=59.15 total/acc_c=47.39 total/h_score=60.30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 2.5327650609223737\n",
      "Loss: 1.2768613846405692\n",
      "Loss: 0.8981023539667544\n",
      "Loss: 0.7387835129447605\n",
      "Loss: 0.6500922559396081\n",
      "Loss: 0.6151486768670704\n",
      "Loss: 0.5683801606297493\n",
      "Loss: 0.5354946401456128\n",
      "Loss: 0.4646228460514027\n",
      "Loss: 0.4645761715329212\n",
      "______\n",
      "Iteration t=4\n",
      "all:  cs/acc_i=66.81 cs/acc_c=67.02 os/recall_knw=55.92 os/recall_unk=81.64 total/acc_i=59.96 total/acc_c=51.86 total/h_score=62.31\n",
      "selected:  cs/acc_i=65.24 cs/acc_c=65.99 os/recall_knw=52.43 os/recall_unk=86.46 total/acc_i=59.68 total/acc_c=50.00 total/h_score=61.87\n",
      "Loss: 2.5298052284897876\n",
      "Loss: 1.2566889406753188\n",
      "Loss: 0.8490398721534664\n",
      "Loss: 0.7304385253110853\n",
      "Loss: 0.6442496256918466\n",
      "Loss: 0.5739672592207163\n",
      "Loss: 0.5422933152368089\n",
      "Loss: 0.526627165742782\n",
      "Loss: 0.4845059675579311\n",
      "Loss: 0.45277948139094504\n",
      "______\n",
      "Iteration t=5\n",
      "all:  cs/acc_i=67.52 cs/acc_c=67.82 os/recall_knw=55.68 os/recall_unk=81.98 total/acc_i=60.04 total/acc_c=51.83 total/h_score=62.36\n",
      "selected:  cs/acc_i=67.01 cs/acc_c=67.58 os/recall_knw=54.56 os/recall_unk=83.86 total/acc_i=60.01 total/acc_c=51.32 total/h_score=62.40\n",
      "Loss: 2.50235553122749\n",
      "Loss: 1.2610741452244687\n",
      "Loss: 0.8571799040333299\n",
      "Loss: 0.729132174706656\n",
      "Loss: 0.6401033578209641\n",
      "Loss: 0.583736425712089\n",
      "Loss: 0.5363237846119344\n",
      "Loss: 0.5069470842761442\n",
      "Loss: 0.47350185173602144\n",
      "Loss: 0.4509429418104739\n",
      "______\n",
      "Iteration t=6\n",
      "all:  cs/acc_i=67.40 cs/acc_c=67.81 os/recall_knw=55.60 os/recall_unk=81.98 total/acc_i=59.98 total/acc_c=51.73 total/h_score=62.28\n",
      "selected:  cs/acc_i=67.31 cs/acc_c=67.77 os/recall_knw=55.43 os/recall_unk=82.46 total/acc_i=60.02 total/acc_c=51.66 total/h_score=62.35\n",
      "Loss: 2.491083111568373\n",
      "Loss: 1.223935626234327\n",
      "Loss: 0.8719153986901653\n",
      "Loss: 0.7121988008216936\n",
      "Loss: 0.6628603532606242\n",
      "Loss: 0.5794061755039254\n",
      "Loss: 0.5287753173283168\n",
      "Loss: 0.48667260493550984\n",
      "Loss: 0.4694065089432561\n",
      "Loss: 0.4249253422021866\n",
      "______\n",
      "Iteration t=7\n",
      "all:  cs/acc_i=67.87 cs/acc_c=68.07 os/recall_knw=55.60 os/recall_unk=82.06 total/acc_i=60.01 total/acc_c=51.74 total/h_score=62.31\n",
      "selected:  cs/acc_i=67.86 cs/acc_c=68.06 os/recall_knw=55.59 os/recall_unk=82.06 total/acc_i=60.00 total/acc_c=51.72 total/h_score=62.30\n",
      "Loss: 2.491368927761\n",
      "Loss: 1.2215608205114092\n",
      "Loss: 0.8593972163540976\n",
      "Loss: 0.7312314539539571\n",
      "Loss: 0.6368463316742254\n",
      "Loss: 0.5813179222296695\n",
      "Loss: 0.5457248257130992\n",
      "Loss: 0.4999561028821128\n",
      "Loss: 0.47188580960643534\n",
      "Loss: 0.43345838210412435\n",
      "______\n",
      "Iteration t=8\n",
      "all:  cs/acc_i=68.10 cs/acc_c=68.38 os/recall_knw=55.60 os/recall_unk=82.06 total/acc_i=60.01 total/acc_c=51.74 total/h_score=62.31\n",
      "selected:  cs/acc_i=68.10 cs/acc_c=68.38 os/recall_knw=55.60 os/recall_unk=82.06 total/acc_i=60.01 total/acc_c=51.74 total/h_score=62.31\n",
      "Loss: 2.50149792943682\n",
      "Loss: 1.2046578587317953\n",
      "Loss: 0.8587841267488441\n",
      "Loss: 0.7040774767496147\n",
      "Loss: 0.655849608353206\n",
      "Loss: 0.5908723865236555\n",
      "Loss: 0.5408308488982064\n",
      "Loss: 0.4840806821171118\n",
      "Loss: 0.47373604336563424\n",
      "Loss: 0.441778301280372\n",
      "______\n",
      "Iteration t=9\n",
      "all:  cs/acc_i=68.10 cs/acc_c=68.51 os/recall_knw=55.60 os/recall_unk=82.06 total/acc_i=60.01 total/acc_c=51.74 total/h_score=62.31\n",
      "selected:  cs/acc_i=68.10 cs/acc_c=68.51 os/recall_knw=55.60 os/recall_unk=82.06 total/acc_i=60.01 total/acc_c=51.74 total/h_score=62.31\n",
      "tensor(0)\n",
      "all:  cs/acc_i=68.10 cs/acc_c=68.51 os/recall_knw=55.60 os/recall_unk=82.06 total/acc_i=60.01 total/acc_c=51.74 total/h_score=62.31\n",
      "sketch -> painting lr= 0.001 seed= 4\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19]\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20]\n",
      "Loss: 2.670063559541997\n",
      "Loss: 1.5760588722745168\n",
      "Loss: 1.1192332401718061\n",
      "Loss: 0.9268013352585822\n",
      "Loss: 0.8608073538418898\n",
      "Loss: 0.7823310130342995\n",
      "Loss: 0.7109093979461906\n",
      "Loss: 0.6942255934796382\n",
      "Loss: 0.6193395253155649\n",
      "Loss: 0.6076776089588392\n",
      "tensor(True) tensor(True)\n",
      "______\n",
      "Iteration t=1\n",
      "all:  cs/acc_i=64.62 cs/acc_c=65.37 os/recall_knw=92.44 os/recall_unk=15.12 total/acc_i=47.47 total/acc_c=61.20 total/h_score=24.42\n",
      "selected:  cs/acc_i=72.77 cs/acc_c=73.99 os/recall_knw=68.15 os/recall_unk=92.86 total/acc_i=71.70 total/acc_c=67.51 total/h_score=77.33\n",
      "Loss: 2.6228628135533723\n",
      "Loss: 1.454152792836157\n",
      "Loss: 1.0226945047793181\n",
      "Loss: 0.8502223533420747\n",
      "Loss: 0.758769893127939\n",
      "Loss: 0.6942197147774811\n",
      "Loss: 0.6498089982691594\n",
      "Loss: 0.616250956548009\n",
      "Loss: 0.578200420535705\n",
      "Loss: 0.5363977165613774\n",
      "______\n",
      "Iteration t=2\n",
      "all:  cs/acc_i=66.50 cs/acc_c=66.78 os/recall_knw=64.07 os/recall_unk=71.76 total/acc_i=59.82 total/acc_c=55.61 total/h_score=62.15\n",
      "selected:  cs/acc_i=60.74 cs/acc_c=61.82 os/recall_knw=46.34 os/recall_unk=94.53 total/acc_i=60.54 total/acc_c=46.28 total/h_score=59.92\n",
      "Loss: 2.5805962990630755\n",
      "Loss: 1.384971802884882\n",
      "Loss: 0.9317047037861564\n",
      "Loss: 0.7813743641430682\n",
      "Loss: 0.7083489258180965\n",
      "Loss: 0.6467079648917372\n",
      "Loss: 0.6014928135682236\n",
      "Loss: 0.5601483625444499\n",
      "Loss: 0.5273692803626711\n",
      "Loss: 0.510300456800244\n",
      "______\n",
      "Iteration t=3\n",
      "all:  cs/acc_i=67.08 cs/acc_c=67.45 os/recall_knw=58.62 os/recall_unk=78.57 total/acc_i=60.36 total/acc_c=53.58 total/h_score=62.82\n",
      "selected:  cs/acc_i=63.73 cs/acc_c=64.89 os/recall_knw=50.52 os/recall_unk=90.35 total/acc_i=60.20 total/acc_c=48.91 total/h_score=61.69\n",
      "Loss: 2.5428595862863386\n",
      "Loss: 1.2906111984541921\n",
      "Loss: 0.9204444076333728\n",
      "Loss: 0.7521958179546125\n",
      "Loss: 0.6693346715850748\n",
      "Loss: 0.6044588742447106\n",
      "Loss: 0.5619125594566394\n",
      "Loss: 0.5303553039635415\n",
      "Loss: 0.4882084575050321\n",
      "Loss: 0.4407848768355526\n",
      "______\n",
      "Iteration t=4\n",
      "all:  cs/acc_i=67.16 cs/acc_c=67.46 os/recall_knw=58.31 os/recall_unk=80.07 total/acc_i=60.73 total/acc_c=53.51 total/h_score=63.19\n",
      "selected:  cs/acc_i=65.84 cs/acc_c=66.78 os/recall_knw=54.74 os/recall_unk=85.69 total/acc_i=60.85 total/acc_c=51.92 total/h_score=63.33\n",
      "Loss: 2.48336988512941\n",
      "Loss: 1.2209636479242076\n",
      "Loss: 0.8675479265436468\n",
      "Loss: 0.7325900172089932\n",
      "Loss: 0.6324043644896112\n",
      "Loss: 0.6097656986578738\n",
      "Loss: 0.5440795551907567\n",
      "Loss: 0.5179824642681178\n",
      "Loss: 0.46739224540888014\n",
      "Loss: 0.4658043236475609\n",
      "______\n",
      "Iteration t=5\n",
      "all:  cs/acc_i=68.06 cs/acc_c=68.23 os/recall_knw=57.88 os/recall_unk=80.40 total/acc_i=60.68 total/acc_c=53.27 total/h_score=63.09\n",
      "selected:  cs/acc_i=67.49 cs/acc_c=67.91 os/recall_knw=56.48 os/recall_unk=83.02 total/acc_i=60.75 total/acc_c=52.68 total/h_score=63.31\n",
      "Loss: 2.475668069280562\n",
      "Loss: 1.2172537526634872\n",
      "Loss: 0.8580608493724807\n",
      "Loss: 0.7370644835907905\n",
      "Loss: 0.6129334837686821\n",
      "Loss: 0.5684619223485228\n",
      "Loss: 0.5387422803361885\n",
      "Loss: 0.49163306608307555\n",
      "Loss: 0.45733338667721046\n",
      "Loss: 0.45950824187182987\n",
      "______\n",
      "Iteration t=6\n",
      "all:  cs/acc_i=68.18 cs/acc_c=68.36 os/recall_knw=57.84 os/recall_unk=80.40 total/acc_i=60.68 total/acc_c=53.27 total/h_score=63.09\n",
      "selected:  cs/acc_i=68.07 cs/acc_c=68.29 os/recall_knw=57.59 os/recall_unk=81.00 total/acc_i=60.72 total/acc_c=53.15 total/h_score=63.16\n",
      "Loss: 2.483980771018426\n",
      "Loss: 1.2169443298930582\n",
      "Loss: 0.828447396697303\n",
      "Loss: 0.7157581565592454\n",
      "Loss: 0.6147608500622544\n",
      "Loss: 0.5691339537983964\n",
      "Loss: 0.5253290574439624\n",
      "Loss: 0.47518540279344024\n",
      "Loss: 0.46268783135694047\n",
      "Loss: 0.43362023651237913\n",
      "______\n",
      "Iteration t=7\n",
      "all:  cs/acc_i=68.53 cs/acc_c=68.82 os/recall_knw=57.80 os/recall_unk=80.40 total/acc_i=60.65 total/acc_c=53.23 total/h_score=63.06\n",
      "selected:  cs/acc_i=68.52 cs/acc_c=68.81 os/recall_knw=57.78 os/recall_unk=80.47 total/acc_i=60.66 total/acc_c=53.22 total/h_score=63.07\n",
      "Loss: 2.477574958975016\n",
      "Loss: 1.21998314674084\n",
      "Loss: 0.8384615949049652\n",
      "Loss: 0.7081555623998527\n",
      "Loss: 0.6094794305953902\n",
      "Loss: 0.5749745339396511\n",
      "Loss: 0.5168631481014283\n",
      "Loss: 0.48187420538321196\n",
      "Loss: 0.4790106629915083\n",
      "Loss: 0.4564545026674927\n",
      "______\n",
      "Iteration t=8\n",
      "all:  cs/acc_i=68.57 cs/acc_c=68.94 os/recall_knw=57.80 os/recall_unk=80.40 total/acc_i=60.65 total/acc_c=53.23 total/h_score=63.06\n",
      "selected:  cs/acc_i=68.57 cs/acc_c=68.94 os/recall_knw=57.80 os/recall_unk=80.40 total/acc_i=60.65 total/acc_c=53.23 total/h_score=63.06\n",
      "Loss: 2.469893269210692\n",
      "Loss: 1.216402273187753\n",
      "Loss: 0.8268146606592032\n",
      "Loss: 0.7157870888227393\n",
      "Loss: 0.624815431442338\n",
      "Loss: 0.5820337360204473\n",
      "Loss: 0.535982055220044\n",
      "Loss: 0.5004592367753327\n",
      "Loss: 0.4647479294403362\n",
      "Loss: 0.4425775897406373\n",
      "______\n",
      "Iteration t=9\n",
      "all:  cs/acc_i=68.57 cs/acc_c=69.21 os/recall_knw=57.80 os/recall_unk=80.40 total/acc_i=60.65 total/acc_c=53.23 total/h_score=63.06\n",
      "selected:  cs/acc_i=68.57 cs/acc_c=69.21 os/recall_knw=57.80 os/recall_unk=80.40 total/acc_i=60.65 total/acc_c=53.23 total/h_score=63.06\n",
      "tensor(0)\n",
      "all:  cs/acc_i=68.57 cs/acc_c=69.21 os/recall_knw=57.80 os/recall_unk=80.40 total/acc_i=60.65 total/acc_c=53.23 total/h_score=63.06\n",
      "sketch -> painting lr= 0.001 seed= 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19]\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20]\n",
      "Loss: 2.6823856726135173\n",
      "Loss: 1.6253691530719245\n",
      "Loss: 1.1303753554821014\n",
      "Loss: 0.922690865151661\n",
      "Loss: 0.8246334950948498\n",
      "Loss: 0.7517246232204831\n",
      "Loss: 0.7153757074751805\n",
      "Loss: 0.6501572159762236\n",
      "Loss: 0.6396885892165076\n",
      "Loss: 0.5937853974779856\n",
      "tensor(True) tensor(True)\n",
      "______\n",
      "Iteration t=1\n",
      "all:  cs/acc_i=65.87 cs/acc_c=66.51 os/recall_knw=92.71 os/recall_unk=15.70 total/acc_i=48.62 total/acc_c=62.47 total/h_score=25.27\n",
      "selected:  cs/acc_i=73.04 cs/acc_c=73.63 os/recall_knw=69.05 os/recall_unk=94.50 total/acc_i=72.91 total/acc_c=67.78 total/h_score=78.03\n",
      "Loss: 2.624084560191574\n",
      "Loss: 1.4748763450677844\n",
      "Loss: 0.9984651803970337\n",
      "Loss: 0.8677556943778254\n",
      "Loss: 0.7570211657003504\n",
      "Loss: 0.7160785044161018\n",
      "Loss: 0.649908568404147\n",
      "Loss: 0.5989454204333577\n",
      "Loss: 0.59327340176428\n",
      "Loss: 0.5686368645677244\n",
      "______\n",
      "Iteration t=2\n",
      "all:  cs/acc_i=67.01 cs/acc_c=67.34 os/recall_knw=62.58 os/recall_unk=73.34 total/acc_i=60.04 total/acc_c=55.30 total/h_score=62.47\n",
      "selected:  cs/acc_i=60.98 cs/acc_c=62.20 os/recall_knw=45.37 os/recall_unk=94.74 total/acc_i=60.11 total/acc_c=45.66 total/h_score=59.35\n",
      "Loss: 2.587076084722172\n",
      "Loss: 1.3714432621544057\n",
      "Loss: 0.9305950858376243\n",
      "Loss: 0.7978237164291468\n",
      "Loss: 0.6984827651218934\n",
      "Loss: 0.6393291287124157\n",
      "Loss: 0.6039414495229721\n",
      "Loss: 0.5548518773506989\n",
      "Loss: 0.5438513041897254\n",
      "Loss: 0.4978034381839362\n",
      "______\n",
      "Iteration t=3\n",
      "all:  cs/acc_i=67.16 cs/acc_c=67.33 os/recall_knw=59.01 os/recall_unk=78.49 total/acc_i=60.54 total/acc_c=53.90 total/h_score=63.04\n",
      "selected:  cs/acc_i=63.91 cs/acc_c=64.77 os/recall_knw=50.59 os/recall_unk=89.74 total/acc_i=60.35 total/acc_c=49.18 total/h_score=61.82\n",
      "Loss: 2.529324930467647\n",
      "Loss: 1.2750392723909187\n",
      "Loss: 0.9081447959204256\n",
      "Loss: 0.735874554811618\n",
      "Loss: 0.6572436588409143\n",
      "Loss: 0.6133379650451404\n",
      "Loss: 0.5675959976720604\n",
      "Loss: 0.5103953978070965\n",
      "Loss: 0.5100113984310266\n",
      "Loss: 0.4805171520679028\n",
      "______\n",
      "Iteration t=4\n",
      "all:  cs/acc_i=66.65 cs/acc_c=67.10 os/recall_knw=58.07 os/recall_unk=79.40 total/acc_i=60.44 total/acc_c=53.39 total/h_score=62.91\n",
      "selected:  cs/acc_i=65.00 cs/acc_c=65.98 os/recall_knw=54.21 os/recall_unk=85.51 total/acc_i=60.43 total/acc_c=51.38 total/h_score=62.84\n",
      "Loss: 2.514160045520032\n",
      "Loss: 1.2396623217909906\n",
      "Loss: 0.8707945712191291\n",
      "Loss: 0.7063797313299139\n",
      "Loss: 0.6612085111470402\n",
      "Loss: 0.5994432326640046\n",
      "Loss: 0.5410314866314373\n",
      "Loss: 0.5105934495020611\n",
      "Loss: 0.50473504136297\n",
      "Loss: 0.4619448419395351\n",
      "______\n",
      "Iteration t=5\n",
      "all:  cs/acc_i=68.18 cs/acc_c=68.51 os/recall_knw=58.03 os/recall_unk=79.65 total/acc_i=60.52 total/acc_c=53.41 total/h_score=62.99\n",
      "selected:  cs/acc_i=67.61 cs/acc_c=68.28 os/recall_knw=56.64 os/recall_unk=82.11 total/acc_i=60.56 total/acc_c=52.86 total/h_score=63.22\n",
      "Loss: 2.4922880413102324\n",
      "Loss: 1.251621460572618\n",
      "Loss: 0.8585056875084267\n",
      "Loss: 0.7298075082849284\n",
      "Loss: 0.6303421034187567\n",
      "Loss: 0.5782299864365429\n",
      "Loss: 0.5277798682695529\n",
      "Loss: 0.49810490409126046\n",
      "Loss: 0.46781304051152994\n",
      "Loss: 0.4383706662987099\n",
      "______\n",
      "Iteration t=6\n",
      "all:  cs/acc_i=68.42 cs/acc_c=68.65 os/recall_knw=57.95 os/recall_unk=79.65 total/acc_i=60.49 total/acc_c=53.37 total/h_score=62.97\n",
      "selected:  cs/acc_i=68.30 cs/acc_c=68.61 os/recall_knw=57.59 os/recall_unk=80.66 total/acc_i=60.61 total/acc_c=53.27 total/h_score=63.16\n",
      "Loss: 2.4800723549808086\n",
      "Loss: 1.2139888492673032\n",
      "Loss: 0.8099803251293507\n",
      "Loss: 0.7054994341574217\n",
      "Loss: 0.6298103460416138\n",
      "Loss: 0.5616627173867785\n",
      "Loss: 0.537739659248576\n",
      "Loss: 0.47246828156444226\n",
      "Loss: 0.4642560904928547\n",
      "Loss: 0.4316270505851097\n",
      "______\n",
      "Iteration t=7\n",
      "all:  cs/acc_i=68.65 cs/acc_c=69.05 os/recall_knw=57.95 os/recall_unk=79.65 total/acc_i=60.49 total/acc_c=53.37 total/h_score=62.97\n",
      "selected:  cs/acc_i=68.65 cs/acc_c=69.07 os/recall_knw=57.91 os/recall_unk=79.72 total/acc_i=60.50 total/acc_c=53.37 total/h_score=62.98\n",
      "Loss: 2.491211714763795\n",
      "Loss: 1.210445954915016\n",
      "Loss: 0.8279591476724993\n",
      "Loss: 0.7111093973921191\n",
      "Loss: 0.6030395211231324\n",
      "Loss: 0.5699462117326837\n",
      "Loss: 0.5171522134614568\n",
      "Loss: 0.48086777599828856\n",
      "Loss: 0.4650089410283873\n",
      "Loss: 0.4385883450027435\n",
      "______\n",
      "Iteration t=8\n",
      "all:  cs/acc_i=69.32 cs/acc_c=69.59 os/recall_knw=57.95 os/recall_unk=79.65 total/acc_i=60.49 total/acc_c=53.37 total/h_score=62.97\n",
      "selected:  cs/acc_i=69.32 cs/acc_c=69.59 os/recall_knw=57.95 os/recall_unk=79.65 total/acc_i=60.49 total/acc_c=53.37 total/h_score=62.97\n",
      "Loss: 2.4932512679407672\n",
      "Loss: 1.2201194561296893\n",
      "Loss: 0.8484872550733628\n",
      "Loss: 0.7249054706865742\n",
      "Loss: 0.6207727912452913\n",
      "Loss: 0.5850103048066939\n",
      "Loss: 0.5219711694385736\n",
      "Loss: 0.49342910873313106\n",
      "Loss: 0.4676881078630686\n",
      "Loss: 0.4221467768713351\n",
      "______\n",
      "Iteration t=9\n",
      "all:  cs/acc_i=68.22 cs/acc_c=68.79 os/recall_knw=57.95 os/recall_unk=79.65 total/acc_i=60.49 total/acc_c=53.37 total/h_score=62.97\n",
      "selected:  cs/acc_i=68.22 cs/acc_c=68.79 os/recall_knw=57.95 os/recall_unk=79.65 total/acc_i=60.49 total/acc_c=53.37 total/h_score=62.97\n",
      "tensor(0)\n",
      "all:  cs/acc_i=68.22 cs/acc_c=68.79 os/recall_knw=57.95 os/recall_unk=79.65 total/acc_i=60.49 total/acc_c=53.37 total/h_score=62.97\n",
      "sketch -> painting lr= 0.001 seed= 1\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19]\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20]\n",
      "Loss: 2.6779043533138394\n",
      "Loss: 1.5997198451425612\n",
      "Loss: 1.133991527495925\n",
      "Loss: 0.9467436065993358\n",
      "Loss: 0.8442183302849838\n",
      "Loss: 0.7645602980532598\n",
      "Loss: 0.7034567884870411\n",
      "Loss: 0.6709255142924712\n",
      "Loss: 0.6309315132111618\n",
      "Loss: 0.6091324801451152\n",
      "tensor(True) tensor(True)\n",
      "______\n",
      "Iteration t=1\n",
      "all:  cs/acc_i=65.36 cs/acc_c=65.71 os/recall_knw=92.63 os/recall_unk=15.53 total/acc_i=48.40 total/acc_c=61.91 total/h_score=25.01\n",
      "selected:  cs/acc_i=70.73 cs/acc_c=72.02 os/recall_knw=68.19 os/recall_unk=89.47 total/acc_i=71.00 total/acc_c=67.09 total/h_score=75.94\n",
      "Loss: 2.6300890727895467\n",
      "Loss: 1.4589046447173408\n",
      "Loss: 1.022213550005558\n",
      "Loss: 0.844824104493367\n",
      "Loss: 0.7770991205881184\n",
      "Loss: 0.7010776298345575\n",
      "Loss: 0.6459360233539544\n",
      "Loss: 0.6215730574395921\n",
      "Loss: 0.5773161869262151\n",
      "Loss: 0.5225592973295617\n",
      "______\n",
      "Iteration t=2\n",
      "all:  cs/acc_i=66.14 cs/acc_c=66.39 os/recall_knw=63.21 os/recall_unk=71.51 total/acc_i=59.77 total/acc_c=55.61 total/h_score=62.06\n",
      "selected:  cs/acc_i=59.67 cs/acc_c=61.13 os/recall_knw=45.44 os/recall_unk=93.89 total/acc_i=60.05 total/acc_c=46.27 total/h_score=59.82\n",
      "Loss: 2.5868268755349244\n",
      "Loss: 1.3659638360142707\n",
      "Loss: 0.9624863917177374\n",
      "Loss: 0.7773340188644149\n",
      "Loss: 0.6962436944246292\n",
      "Loss: 0.6546485415913842\n",
      "Loss: 0.5854959388348189\n",
      "Loss: 0.5499224728481336\n",
      "Loss: 0.5262936006892811\n",
      "Loss: 0.4845938337120143\n",
      "______\n",
      "Iteration t=3\n",
      "all:  cs/acc_i=66.03 cs/acc_c=66.46 os/recall_knw=58.66 os/recall_unk=78.07 total/acc_i=60.30 total/acc_c=53.74 total/h_score=62.80\n",
      "selected:  cs/acc_i=62.00 cs/acc_c=63.23 os/recall_knw=49.57 os/recall_unk=89.52 total/acc_i=59.74 total/acc_c=48.57 total/h_score=61.23\n",
      "Loss: 2.538636917653291\n",
      "Loss: 1.3394801064677861\n",
      "Loss: 0.9152180763690368\n",
      "Loss: 0.7353297753826432\n",
      "Loss: 0.6771776086610296\n",
      "Loss: 0.6156334369078926\n",
      "Loss: 0.5753379628062248\n",
      "Loss: 0.5196470931820247\n",
      "Loss: 0.5047801502696846\n",
      "Loss: 0.47348334510689194\n",
      "______\n",
      "Iteration t=4\n",
      "all:  cs/acc_i=67.44 cs/acc_c=67.77 os/recall_knw=57.48 os/recall_unk=79.32 total/acc_i=60.25 total/acc_c=53.26 total/h_score=62.79\n",
      "selected:  cs/acc_i=65.87 cs/acc_c=66.71 os/recall_knw=53.59 os/recall_unk=84.66 total/acc_i=60.07 total/acc_c=51.29 total/h_score=62.57\n",
      "Loss: 2.4860030462552314\n",
      "Loss: 1.2538318469434602\n",
      "Loss: 0.8697427978824871\n",
      "Loss: 0.7465380188311493\n",
      "Loss: 0.6451152667216177\n",
      "Loss: 0.581615596635571\n",
      "Loss: 0.5404419170139225\n",
      "Loss: 0.5124862859937437\n",
      "Loss: 0.5012852420492651\n",
      "Loss: 0.45863015862438966\n",
      "______\n",
      "Iteration t=5\n",
      "all:  cs/acc_i=68.38 cs/acc_c=68.77 os/recall_knw=57.29 os/recall_unk=79.65 total/acc_i=60.30 total/acc_c=53.21 total/h_score=62.84\n",
      "selected:  cs/acc_i=67.95 cs/acc_c=68.63 os/recall_knw=55.67 os/recall_unk=81.76 total/acc_i=60.32 total/acc_c=52.65 total/h_score=62.97\n",
      "Loss: 2.489901249791369\n",
      "Loss: 1.2187228376973314\n",
      "Loss: 0.8569448798772239\n",
      "Loss: 0.7214664148450388\n",
      "Loss: 0.6344092332531885\n",
      "Loss: 0.617186380389296\n",
      "Loss: 0.5411661597804277\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.4922517005798748\n",
      "Loss: 0.46650006125370663\n",
      "Loss: 0.44076336705635605\n",
      "______\n",
      "Iteration t=6\n",
      "all:  cs/acc_i=69.20 cs/acc_c=69.54 os/recall_knw=57.17 os/recall_unk=79.73 total/acc_i=60.30 total/acc_c=53.17 total/h_score=62.83\n",
      "selected:  cs/acc_i=69.15 cs/acc_c=69.58 os/recall_knw=56.71 os/recall_unk=80.47 total/acc_i=60.38 total/acc_c=53.11 total/h_score=62.98\n",
      "Loss: 2.480270645967344\n",
      "Loss: 1.2113703552300368\n",
      "Loss: 0.8334857241167286\n",
      "Loss: 0.6953623722481533\n",
      "Loss: 0.6225220012834402\n",
      "Loss: 0.5703274047350496\n",
      "Loss: 0.5395370570988189\n",
      "Loss: 0.49211742283730975\n",
      "Loss: 0.4550223943542659\n",
      "Loss: 0.45276303843754095\n",
      "______\n",
      "Iteration t=7\n",
      "all:  cs/acc_i=68.18 cs/acc_c=68.50 os/recall_knw=57.17 os/recall_unk=79.73 total/acc_i=60.30 total/acc_c=53.17 total/h_score=62.83\n",
      "selected:  cs/acc_i=68.21 cs/acc_c=68.52 os/recall_knw=57.15 os/recall_unk=79.73 total/acc_i=60.32 total/acc_c=53.19 total/h_score=62.85\n",
      "Loss: 2.490204306749197\n",
      "Loss: 1.2434626231309374\n",
      "Loss: 0.845010456527293\n",
      "Loss: 0.702419032090106\n",
      "Loss: 0.6394280355106964\n",
      "Loss: 0.5676178355448642\n",
      "Loss: 0.5249440176525579\n",
      "Loss: 0.4865022713114858\n",
      "Loss: 0.46139703431592777\n",
      "Loss: 0.4424050095894559\n",
      "______\n",
      "Iteration t=8\n",
      "all:  cs/acc_i=68.18 cs/acc_c=68.68 os/recall_knw=57.17 os/recall_unk=79.73 total/acc_i=60.30 total/acc_c=53.17 total/h_score=62.83\n",
      "selected:  cs/acc_i=68.18 cs/acc_c=68.68 os/recall_knw=57.17 os/recall_unk=79.73 total/acc_i=60.30 total/acc_c=53.17 total/h_score=62.83\n",
      "Loss: 2.494393216453583\n",
      "Loss: 1.2391349950782684\n",
      "Loss: 0.8281878193139065\n",
      "Loss: 0.704154532930629\n",
      "Loss: 0.6325488094134852\n",
      "Loss: 0.5870536129001663\n",
      "Loss: 0.5207483005306499\n",
      "Loss: 0.4914416862040879\n",
      "Loss: 0.4481370433984015\n",
      "Loss: 0.4368231726682138\n",
      "______\n",
      "Iteration t=9\n",
      "all:  cs/acc_i=68.22 cs/acc_c=68.77 os/recall_knw=57.17 os/recall_unk=79.73 total/acc_i=60.30 total/acc_c=53.17 total/h_score=62.83\n",
      "selected:  cs/acc_i=68.22 cs/acc_c=68.77 os/recall_knw=57.17 os/recall_unk=79.73 total/acc_i=60.30 total/acc_c=53.17 total/h_score=62.83\n",
      "tensor(0)\n",
      "all:  cs/acc_i=68.22 cs/acc_c=68.77 os/recall_knw=57.17 os/recall_unk=79.73 total/acc_i=60.30 total/acc_c=53.17 total/h_score=62.83\n",
      "sketch -> painting lr= 0.001 seed= 2\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19]\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20]\n",
      "Loss: 2.6810460133650866\n",
      "Loss: 1.5900454330690128\n",
      "Loss: 1.1371932819332045\n",
      "Loss: 0.9615041888558987\n",
      "Loss: 0.8090525596719427\n",
      "Loss: 0.760808019140332\n",
      "Loss: 0.6998027607644957\n",
      "Loss: 0.654428164215432\n",
      "Loss: 0.6464370540583256\n",
      "Loss: 0.5982459038496017\n",
      "tensor(True) tensor(True)\n",
      "______\n",
      "Iteration t=1\n",
      "all:  cs/acc_i=65.20 cs/acc_c=65.91 os/recall_knw=92.75 os/recall_unk=15.78 total/acc_i=48.56 total/acc_c=62.39 total/h_score=25.37\n",
      "selected:  cs/acc_i=70.66 cs/acc_c=71.21 os/recall_knw=68.80 os/recall_unk=91.79 total/acc_i=72.38 total/acc_c=67.86 total/h_score=77.23\n",
      "Loss: 2.6173809317574985\n",
      "Loss: 1.4697885101544108\n",
      "Loss: 1.0434732333473538\n",
      "Loss: 0.8619905288380701\n",
      "Loss: 0.7746907059409193\n",
      "Loss: 0.7065064051157035\n",
      "Loss: 0.6440032940843831\n",
      "Loss: 0.6197036290226351\n",
      "Loss: 0.5934593551544751\n",
      "Loss: 0.5376532449958406\n",
      "______\n",
      "Iteration t=2\n",
      "all:  cs/acc_i=66.38 cs/acc_c=66.84 os/recall_knw=63.71 os/recall_unk=71.26 total/acc_i=59.61 total/acc_c=55.74 total/h_score=62.06\n",
      "selected:  cs/acc_i=60.85 cs/acc_c=62.11 os/recall_knw=45.97 os/recall_unk=94.08 total/acc_i=60.47 total/acc_c=47.09 total/h_score=60.64\n",
      "Loss: 2.5663869749416004\n",
      "Loss: 1.356950270858678\n",
      "Loss: 0.9318765155293725\n",
      "Loss: 0.7968262177976695\n",
      "Loss: 0.7006008207798005\n",
      "Loss: 0.6707469635389068\n",
      "Loss: 0.6014279013330286\n",
      "Loss: 0.5578425026752732\n",
      "Loss: 0.5433363768187436\n",
      "Loss: 0.4906872422180393\n",
      "______\n",
      "Iteration t=3\n",
      "all:  cs/acc_i=67.01 cs/acc_c=67.36 os/recall_knw=58.07 os/recall_unk=77.99 total/acc_i=59.96 total/acc_c=53.46 total/h_score=62.56\n",
      "selected:  cs/acc_i=63.55 cs/acc_c=64.43 os/recall_knw=49.48 os/recall_unk=89.60 total/acc_i=59.63 total/acc_c=48.37 total/h_score=61.06\n",
      "Loss: 2.5390307400537573\n",
      "Loss: 1.2958593617314877\n",
      "Loss: 0.8785898961450742\n",
      "Loss: 0.7863005658854609\n",
      "Loss: 0.6767301476520041\n",
      "Loss: 0.6173972583335379\n",
      "Loss: 0.5959651283595873\n",
      "Loss: 0.5526290723811025\n",
      "Loss: 0.509469210712806\n",
      "Loss: 0.47342950850725174\n",
      "______\n",
      "Iteration t=4\n",
      "all:  cs/acc_i=67.32 cs/acc_c=67.75 os/recall_knw=57.48 os/recall_unk=78.65 total/acc_i=59.96 total/acc_c=53.20 total/h_score=62.55\n",
      "selected:  cs/acc_i=65.79 cs/acc_c=66.72 os/recall_knw=53.31 os/recall_unk=85.09 total/acc_i=60.02 total/acc_c=51.13 total/h_score=62.53\n",
      "Loss: 2.516423052098571\n",
      "Loss: 1.2413873058908127\n",
      "Loss: 0.8809675858551714\n",
      "Loss: 0.7544606940335586\n",
      "Loss: 0.6568874766220566\n",
      "Loss: 0.5775778914700035\n",
      "Loss: 0.549105959717466\n",
      "Loss: 0.515921711107763\n",
      "Loss: 0.4806149302660918\n",
      "Loss: 0.4571397563739985\n",
      "______\n",
      "Iteration t=5\n",
      "all:  cs/acc_i=67.99 cs/acc_c=68.45 os/recall_knw=57.33 os/recall_unk=78.82 total/acc_i=59.98 total/acc_c=53.16 total/h_score=62.57\n",
      "selected:  cs/acc_i=67.55 cs/acc_c=68.22 os/recall_knw=55.82 os/recall_unk=81.81 total/acc_i=60.22 total/acc_c=52.56 total/h_score=62.91\n",
      "Loss: 2.5069612093636247\n",
      "Loss: 1.2029623144962749\n",
      "Loss: 0.8468751810857507\n",
      "Loss: 0.7077647282085457\n",
      "Loss: 0.6390876162980423\n",
      "Loss: 0.6032183811557098\n",
      "Loss: 0.5438243920807956\n",
      "Loss: 0.5285686740621192\n",
      "Loss: 0.46913702101981053\n",
      "Loss: 0.4489100780643401\n",
      "______\n",
      "Iteration t=6\n",
      "all:  cs/acc_i=68.46 cs/acc_c=68.84 os/recall_knw=57.29 os/recall_unk=78.99 total/acc_i=60.01 total/acc_c=53.13 total/h_score=62.60\n",
      "selected:  cs/acc_i=68.48 cs/acc_c=68.87 os/recall_knw=57.00 os/recall_unk=80.05 total/acc_i=60.25 total/acc_c=53.11 total/h_score=62.87\n",
      "Loss: 2.4776426022834626\n",
      "Loss: 1.2145733770571256\n",
      "Loss: 0.82878540414065\n",
      "Loss: 0.7221214982420809\n",
      "Loss: 0.6351034625580436\n",
      "Loss: 0.5594289746844334\n",
      "Loss: 0.5323611350073988\n",
      "Loss: 0.5028576110056054\n",
      "Loss: 0.45131283727010735\n",
      "Loss: 0.4341314102896312\n",
      "______\n",
      "Iteration t=7\n",
      "all:  cs/acc_i=68.53 cs/acc_c=68.92 os/recall_knw=57.13 os/recall_unk=78.99 total/acc_i=59.96 total/acc_c=53.06 total/h_score=62.54\n",
      "selected:  cs/acc_i=68.53 cs/acc_c=68.92 os/recall_knw=57.13 os/recall_unk=78.99 total/acc_i=59.96 total/acc_c=53.06 total/h_score=62.54\n",
      "Loss: 2.478744197470939\n",
      "Loss: 1.22976878200948\n",
      "Loss: 0.8380792204908997\n",
      "Loss: 0.7061766009581717\n",
      "Loss: 0.6442388083167404\n",
      "Loss: 0.567885490805514\n",
      "Loss: 0.5249339266103289\n",
      "Loss: 0.5073866827888527\n",
      "Loss: 0.47273400045840847\n",
      "Loss: 0.4347592616370815\n",
      "______\n",
      "Iteration t=8\n",
      "all:  cs/acc_i=68.61 cs/acc_c=68.90 os/recall_knw=57.13 os/recall_unk=78.99 total/acc_i=59.96 total/acc_c=53.06 total/h_score=62.54\n",
      "selected:  cs/acc_i=68.61 cs/acc_c=68.90 os/recall_knw=57.13 os/recall_unk=78.99 total/acc_i=59.96 total/acc_c=53.06 total/h_score=62.54\n",
      "Loss: 2.487523976607844\n",
      "Loss: 1.1975555320982991\n",
      "Loss: 0.8532181826197667\n",
      "Loss: 0.7336077552575332\n",
      "Loss: 0.6161974627479367\n",
      "Loss: 0.5832569803062239\n",
      "Loss: 0.5223551013691705\n",
      "Loss: 0.5232159064607582\n",
      "Loss: 0.47091580767501223\n",
      "Loss: 0.4245439820625039\n",
      "______\n",
      "Iteration t=9\n",
      "all:  cs/acc_i=68.57 cs/acc_c=68.92 os/recall_knw=57.13 os/recall_unk=78.99 total/acc_i=59.96 total/acc_c=53.06 total/h_score=62.54\n",
      "selected:  cs/acc_i=68.57 cs/acc_c=68.92 os/recall_knw=57.13 os/recall_unk=78.99 total/acc_i=59.96 total/acc_c=53.06 total/h_score=62.54\n",
      "tensor(0)\n",
      "all:  cs/acc_i=68.57 cs/acc_c=68.92 os/recall_knw=57.13 os/recall_unk=78.99 total/acc_i=59.96 total/acc_c=53.06 total/h_score=62.54\n",
      "sketch -> painting lr= 0.001 seed= 3\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19]\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20]\n",
      "Loss: 2.688019739598343\n",
      "Loss: 1.6023879008194835\n",
      "Loss: 1.1060588832983036\n",
      "Loss: 0.9480994537319105\n",
      "Loss: 0.8299348117764463\n",
      "Loss: 0.7434662833963472\n",
      "Loss: 0.7079304235497701\n",
      "Loss: 0.654585514793691\n",
      "Loss: 0.6399991957797218\n",
      "Loss: 0.5863570034811177\n",
      "tensor(True) tensor(True)\n",
      "______\n",
      "Iteration t=1\n",
      "all:  cs/acc_i=64.66 cs/acc_c=65.32 os/recall_knw=93.03 os/recall_unk=16.36 total/acc_i=48.43 total/acc_c=61.97 total/h_score=26.08\n",
      "selected:  cs/acc_i=70.31 cs/acc_c=71.38 os/recall_knw=69.62 os/recall_unk=91.63 total/acc_i=72.53 total/acc_c=68.20 total/h_score=77.42\n",
      "Loss: 2.6252247360017567\n",
      "Loss: 1.4661106251288152\n",
      "Loss: 1.0206674999660916\n",
      "Loss: 0.8670980777717443\n",
      "Loss: 0.7795257644664838\n",
      "Loss: 0.6938603639890606\n",
      "Loss: 0.6608818069748257\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.6081807737189214\n",
      "Loss: 0.5475680931034871\n",
      "Loss: 0.5283059029331529\n",
      "______\n",
      "Iteration t=2\n",
      "all:  cs/acc_i=65.67 cs/acc_c=66.20 os/recall_knw=61.32 os/recall_unk=73.01 total/acc_i=59.40 total/acc_c=54.52 total/h_score=61.81\n",
      "selected:  cs/acc_i=58.49 cs/acc_c=59.85 os/recall_knw=44.11 os/recall_unk=93.61 total/acc_i=58.71 total/acc_c=44.30 total/h_score=57.83\n",
      "Loss: 2.5925579764626243\n",
      "Loss: 1.3820266609842127\n",
      "Loss: 0.9453804748979482\n",
      "Loss: 0.801500740647316\n",
      "Loss: 0.7099015754732219\n",
      "Loss: 0.6510796509005806\n",
      "Loss: 0.5827227961610664\n",
      "Loss: 0.5599748841063543\n",
      "Loss: 0.5274252215569669\n",
      "Loss: 0.520548065751791\n",
      "______\n",
      "Iteration t=3\n",
      "all:  cs/acc_i=65.87 cs/acc_c=66.25 os/recall_knw=56.58 os/recall_unk=78.99 total/acc_i=59.32 total/acc_c=52.05 total/h_score=61.76\n",
      "selected:  cs/acc_i=62.32 cs/acc_c=63.50 os/recall_knw=48.58 os/recall_unk=89.13 total/acc_i=58.66 total/acc_c=47.25 total/h_score=59.94\n",
      "Loss: 2.5255635033483093\n",
      "Loss: 1.294455549509629\n",
      "Loss: 0.8892257544009582\n",
      "Loss: 0.7748529644116111\n",
      "Loss: 0.6678240987269775\n",
      "Loss: 0.6263125862764276\n",
      "Loss: 0.5544899731226589\n",
      "Loss: 0.5244933049315992\n",
      "Loss: 0.4809230551123619\n",
      "Loss: 0.4795045980940694\n",
      "______\n",
      "Iteration t=4\n",
      "all:  cs/acc_i=67.08 cs/acc_c=67.40 os/recall_knw=56.31 os/recall_unk=79.40 total/acc_i=59.35 total/acc_c=51.93 total/h_score=61.78\n",
      "selected:  cs/acc_i=65.56 cs/acc_c=66.38 os/recall_knw=52.53 os/recall_unk=84.83 total/acc_i=59.18 total/acc_c=49.93 total/h_score=61.46\n",
      "Loss: 2.530312145457548\n",
      "Loss: 1.238189486395411\n",
      "Loss: 0.8768468301336304\n",
      "Loss: 0.7293535836604463\n",
      "Loss: 0.6584828711983537\n",
      "Loss: 0.6037212979017186\n",
      "Loss: 0.5384415611937767\n",
      "Loss: 0.5243910369502396\n",
      "Loss: 0.4799980163699439\n",
      "Loss: 0.44298870830225345\n",
      "______\n",
      "Iteration t=5\n",
      "all:  cs/acc_i=67.55 cs/acc_c=67.92 os/recall_knw=55.76 os/recall_unk=80.07 total/acc_i=59.37 total/acc_c=51.67 total/h_score=61.75\n",
      "selected:  cs/acc_i=66.96 cs/acc_c=67.51 os/recall_knw=54.46 os/recall_unk=82.11 total/acc_i=59.29 total/acc_c=50.97 total/h_score=61.70\n",
      "Loss: 2.4964123517888073\n",
      "Loss: 1.2356764105121785\n",
      "Loss: 0.8395747473701037\n",
      "Loss: 0.7182359913739648\n",
      "Loss: 0.6423199465613306\n",
      "Loss: 0.5868511871116642\n",
      "Loss: 0.5534069560805466\n",
      "Loss: 0.5011405342645606\n",
      "Loss: 0.45705109227586677\n",
      "Loss: 0.4551759250308751\n",
      "______\n",
      "Iteration t=6\n",
      "all:  cs/acc_i=67.52 cs/acc_c=67.92 os/recall_knw=55.72 os/recall_unk=80.07 total/acc_i=59.35 total/acc_c=51.64 total/h_score=61.72\n",
      "selected:  cs/acc_i=67.39 cs/acc_c=67.86 os/recall_knw=55.39 os/recall_unk=81.01 total/acc_i=59.44 total/acc_c=51.51 total/h_score=61.86\n",
      "Loss: 2.4791450349652036\n",
      "Loss: 1.2028323297597925\n",
      "Loss: 0.8642559924904181\n",
      "Loss: 0.7136159382304367\n",
      "Loss: 0.6280885672082707\n",
      "Loss: 0.5666491610055067\n",
      "Loss: 0.5503773961140185\n",
      "Loss: 0.5083522610518397\n",
      "Loss: 0.43986206206740164\n",
      "Loss: 0.4399780757573186\n",
      "______\n",
      "Iteration t=7\n",
      "all:  cs/acc_i=68.42 cs/acc_c=68.67 os/recall_knw=55.72 os/recall_unk=80.07 total/acc_i=59.35 total/acc_c=51.64 total/h_score=61.72\n",
      "selected:  cs/acc_i=68.42 cs/acc_c=68.67 os/recall_knw=55.72 os/recall_unk=80.07 total/acc_i=59.35 total/acc_c=51.64 total/h_score=61.72\n",
      "Loss: 2.4715036216790116\n",
      "Loss: 1.2002639007277605\n",
      "Loss: 0.8629949610165464\n",
      "Loss: 0.7126145411313065\n",
      "Loss: 0.635852648414732\n",
      "Loss: 0.5689103533703137\n",
      "Loss: 0.5334842815631773\n",
      "Loss: 0.49598193986386785\n",
      "Loss: 0.477146348030102\n",
      "Loss: 0.434116324758142\n",
      "______\n",
      "Iteration t=8\n",
      "all:  cs/acc_i=67.91 cs/acc_c=68.57 os/recall_knw=55.72 os/recall_unk=80.07 total/acc_i=59.35 total/acc_c=51.64 total/h_score=61.72\n",
      "selected:  cs/acc_i=67.91 cs/acc_c=68.57 os/recall_knw=55.72 os/recall_unk=80.07 total/acc_i=59.35 total/acc_c=51.64 total/h_score=61.72\n",
      "Loss: 2.4900374039401854\n",
      "Loss: 1.1932236283290676\n",
      "Loss: 0.8450170928627495\n",
      "Loss: 0.6986036525993813\n",
      "Loss: 0.6370785365380892\n",
      "Loss: 0.5828014712750427\n",
      "Loss: 0.5478830192147232\n",
      "Loss: 0.5031450543461776\n",
      "Loss: 0.45894257494104584\n",
      "Loss: 0.43683376817441566\n",
      "______\n",
      "Iteration t=9\n",
      "all:  cs/acc_i=67.55 cs/acc_c=67.96 os/recall_knw=55.72 os/recall_unk=80.07 total/acc_i=59.35 total/acc_c=51.64 total/h_score=61.72\n",
      "selected:  cs/acc_i=67.55 cs/acc_c=67.96 os/recall_knw=55.72 os/recall_unk=80.07 total/acc_i=59.35 total/acc_c=51.64 total/h_score=61.72\n",
      "tensor(0)\n",
      "all:  cs/acc_i=67.55 cs/acc_c=67.96 os/recall_knw=55.72 os/recall_unk=80.07 total/acc_i=59.35 total/acc_c=51.64 total/h_score=61.72\n",
      "sketch -> painting lr= 0.001 seed= 4\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19]\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20]\n",
      "Loss: 2.669394431040459\n",
      "Loss: 1.577528848783257\n",
      "Loss: 1.1198024878796844\n",
      "Loss: 0.9276936484366348\n",
      "Loss: 0.8603955052562595\n",
      "Loss: 0.7830821251131824\n",
      "Loss: 0.7113867159356776\n",
      "Loss: 0.6956146325647217\n",
      "Loss: 0.6199037698433572\n",
      "Loss: 0.6076203297401211\n",
      "tensor(True) tensor(True)\n",
      "______\n",
      "Iteration t=1\n",
      "all:  cs/acc_i=64.58 cs/acc_c=65.37 os/recall_knw=92.59 os/recall_unk=15.45 total/acc_i=47.60 total/acc_c=61.36 total/h_score=24.86\n",
      "selected:  cs/acc_i=73.34 cs/acc_c=74.18 os/recall_knw=68.71 os/recall_unk=93.94 total/acc_i=72.69 total/acc_c=68.49 total/h_score=78.36\n",
      "Loss: 2.62417539479076\n",
      "Loss: 1.4382963986788395\n",
      "Loss: 1.0113230917764746\n",
      "Loss: 0.8594142421720109\n",
      "Loss: 0.7726148089061037\n",
      "Loss: 0.6828717309351705\n",
      "Loss: 0.6572513140486058\n",
      "Loss: 0.6052789801848684\n",
      "Loss: 0.5538175700655306\n",
      "Loss: 0.5398936934661174\n",
      "______\n",
      "Iteration t=2\n",
      "all:  cs/acc_i=66.58 cs/acc_c=66.95 os/recall_knw=62.50 os/recall_unk=72.26 total/acc_i=59.58 total/acc_c=55.21 total/h_score=62.05\n",
      "selected:  cs/acc_i=60.17 cs/acc_c=61.05 os/recall_knw=45.00 os/recall_unk=94.26 total/acc_i=59.56 total/acc_c=45.16 total/h_score=58.78\n",
      "Loss: 2.58358568278226\n",
      "Loss: 1.3804012992165304\n",
      "Loss: 0.9465268238024278\n",
      "Loss: 0.8050529337742112\n",
      "Loss: 0.721919532391158\n",
      "Loss: 0.6317855567417362\n",
      "Loss: 0.6060318554666909\n",
      "Loss: 0.5725393165241588\n",
      "Loss: 0.5412270605564118\n",
      "Loss: 0.520882943814451\n",
      "______\n",
      "Iteration t=3\n",
      "all:  cs/acc_i=65.48 cs/acc_c=65.68 os/recall_knw=57.76 os/recall_unk=79.49 total/acc_i=60.20 total/acc_c=52.94 total/h_score=62.59\n",
      "selected:  cs/acc_i=61.16 cs/acc_c=62.10 os/recall_knw=49.13 os/recall_unk=90.28 total/acc_i=59.33 total/acc_c=47.37 total/h_score=60.26\n",
      "Loss: 2.55836660861969\n",
      "Loss: 1.2989235603291056\n",
      "Loss: 0.9042071243991022\n",
      "Loss: 0.7619702190160751\n",
      "Loss: 0.6710483210242313\n",
      "Loss: 0.5921300855343756\n",
      "Loss: 0.581379685194596\n",
      "Loss: 0.5253866139961325\n",
      "Loss: 0.4974211198156295\n",
      "Loss: 0.45957980492840644\n",
      "______\n",
      "Iteration t=4\n",
      "all:  cs/acc_i=67.24 cs/acc_c=67.42 os/recall_knw=56.35 os/recall_unk=82.06 total/acc_i=60.52 total/acc_c=52.39 total/h_score=62.83\n",
      "selected:  cs/acc_i=65.70 cs/acc_c=66.30 os/recall_knw=53.29 os/recall_unk=85.99 total/acc_i=60.10 total/acc_c=50.53 total/h_score=62.23\n",
      "Loss: 2.4883262088608045\n",
      "Loss: 1.2450835460399483\n",
      "Loss: 0.8830131323517117\n",
      "Loss: 0.7175063084358949\n",
      "Loss: 0.646303175321184\n",
      "Loss: 0.5873545329066999\n",
      "Loss: 0.5419860964165572\n",
      "Loss: 0.49605087087992344\n",
      "Loss: 0.47913169386995386\n",
      "Loss: 0.46698937518327305\n",
      "______\n",
      "Iteration t=5\n",
      "all:  cs/acc_i=67.16 cs/acc_c=67.33 os/recall_knw=56.03 os/recall_unk=82.14 total/acc_i=60.38 total/acc_c=52.15 total/h_score=62.66\n",
      "selected:  cs/acc_i=66.63 cs/acc_c=66.92 os/recall_knw=54.83 os/recall_unk=83.96 total/acc_i=60.32 total/acc_c=51.51 total/h_score=62.58\n",
      "Loss: 2.5005671352394354\n",
      "Loss: 1.2268200730981906\n",
      "Loss: 0.848566670802014\n",
      "Loss: 0.725457468062393\n",
      "Loss: 0.6256771209565076\n",
      "Loss: 0.5719010262819361\n",
      "Loss: 0.563116484313957\n",
      "Loss: 0.4962490370327776\n",
      "Loss: 0.47309486777329246\n",
      "Loss: 0.4510557181086422\n",
      "______\n",
      "Iteration t=6\n",
      "all:  cs/acc_i=67.16 cs/acc_c=67.77 os/recall_knw=55.96 os/recall_unk=82.23 total/acc_i=60.38 total/acc_c=52.10 total/h_score=62.64\n",
      "selected:  cs/acc_i=66.96 cs/acc_c=67.61 os/recall_knw=55.57 os/recall_unk=82.64 total/acc_i=60.30 total/acc_c=51.85 total/h_score=62.55\n",
      "Loss: 2.5128477215766907\n",
      "Loss: 1.2545217710440275\n",
      "Loss: 0.8566895635401617\n",
      "Loss: 0.7202312021714742\n",
      "Loss: 0.6289446146273222\n",
      "Loss: 0.5843871969912873\n",
      "Loss: 0.5367003782179023\n",
      "Loss: 0.51169617632862\n",
      "Loss: 0.4616406487270457\n",
      "Loss: 0.44266904218763603\n",
      "______\n",
      "Iteration t=7\n",
      "all:  cs/acc_i=68.53 cs/acc_c=68.89 os/recall_knw=55.96 os/recall_unk=82.23 total/acc_i=60.38 total/acc_c=52.10 total/h_score=62.64\n",
      "selected:  cs/acc_i=68.52 cs/acc_c=68.87 os/recall_knw=55.94 os/recall_unk=82.29 total/acc_i=60.39 total/acc_c=52.08 total/h_score=62.65\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 2.497056234612757\n",
      "Loss: 1.2182597371996666\n",
      "Loss: 0.8468533590131876\n",
      "Loss: 0.7146755441110961\n",
      "Loss: 0.630837680977218\n",
      "Loss: 0.5775230080497508\n",
      "Loss: 0.5302930681681146\n",
      "Loss: 0.491772046411524\n",
      "Loss: 0.4837164827147309\n",
      "Loss: 0.4582362020502285\n",
      "______\n",
      "Iteration t=8\n",
      "all:  cs/acc_i=68.03 cs/acc_c=68.51 os/recall_knw=55.96 os/recall_unk=82.23 total/acc_i=60.38 total/acc_c=52.10 total/h_score=62.64\n",
      "selected:  cs/acc_i=68.03 cs/acc_c=68.51 os/recall_knw=55.96 os/recall_unk=82.23 total/acc_i=60.38 total/acc_c=52.10 total/h_score=62.64\n",
      "Loss: 2.4995555571147374\n",
      "Loss: 1.251219772927615\n",
      "Loss: 0.8486784211226872\n",
      "Loss: 0.7085875945431845\n",
      "Loss: 0.6473041918812966\n",
      "Loss: 0.58635381356794\n",
      "Loss: 0.547045691402591\n",
      "Loss: 0.5014156086712468\n",
      "Loss: 0.45919758595374166\n",
      "Loss: 0.4509012257566257\n",
      "______\n",
      "Iteration t=9\n",
      "all:  cs/acc_i=67.71 cs/acc_c=68.27 os/recall_knw=55.96 os/recall_unk=82.23 total/acc_i=60.38 total/acc_c=52.10 total/h_score=62.64\n",
      "selected:  cs/acc_i=67.71 cs/acc_c=68.27 os/recall_knw=55.96 os/recall_unk=82.23 total/acc_i=60.38 total/acc_c=52.10 total/h_score=62.64\n",
      "tensor(0)\n",
      "all:  cs/acc_i=67.71 cs/acc_c=68.27 os/recall_knw=55.96 os/recall_unk=82.23 total/acc_i=60.38 total/acc_c=52.10 total/h_score=62.64\n",
      "sketch -> painting lr= 0.001 seed= 0\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19]\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20]\n",
      "Loss: 2.682792648212197\n",
      "Loss: 1.627247852148469\n",
      "Loss: 1.1320973152352363\n",
      "Loss: 0.9240660028359324\n",
      "Loss: 0.825833017678605\n",
      "Loss: 0.7527351748083055\n",
      "Loss: 0.7162050786092109\n",
      "Loss: 0.6488779731018027\n",
      "Loss: 0.638110433887575\n",
      "Loss: 0.593212634709078\n",
      "tensor(True) tensor(True)\n",
      "______\n",
      "Iteration t=1\n",
      "all:  cs/acc_i=65.40 cs/acc_c=66.06 os/recall_knw=93.06 os/recall_unk=16.45 total/acc_i=48.91 total/acc_c=62.60 total/h_score=26.24\n",
      "selected:  cs/acc_i=72.03 cs/acc_c=72.07 os/recall_knw=70.00 os/recall_unk=94.74 total/acc_i=74.22 total/acc_c=68.32 total/h_score=78.49\n",
      "Loss: 2.6270524724094186\n",
      "Loss: 1.471551729861089\n",
      "Loss: 1.0270969673343326\n",
      "Loss: 0.870607781957313\n",
      "Loss: 0.7509316609101595\n",
      "Loss: 0.6804360299582642\n",
      "Loss: 0.6470429013316757\n",
      "Loss: 0.6019684544220063\n",
      "Loss: 0.5684529089409373\n",
      "Loss: 0.546919488100614\n",
      "______\n",
      "Iteration t=2\n",
      "all:  cs/acc_i=67.24 cs/acc_c=67.82 os/recall_knw=62.11 os/recall_unk=73.01 total/acc_i=59.88 total/acc_c=55.35 total/h_score=62.39\n",
      "selected:  cs/acc_i=61.17 cs/acc_c=63.37 os/recall_knw=45.03 os/recall_unk=94.52 total/acc_i=59.84 total/acc_c=46.19 total/h_score=59.84\n",
      "Loss: 2.573253735628995\n",
      "Loss: 1.374736523628235\n",
      "Loss: 0.9720297714526003\n",
      "Loss: 0.8001288680867715\n",
      "Loss: 0.7323291212320328\n",
      "Loss: 0.6567555915902962\n",
      "Loss: 0.6257834933020852\n",
      "Loss: 0.545329383422028\n",
      "Loss: 0.5259889148853042\n",
      "Loss: 0.4989659932526675\n",
      "______\n",
      "Iteration t=3\n",
      "all:  cs/acc_i=66.97 cs/acc_c=67.22 os/recall_knw=57.64 os/recall_unk=78.41 total/acc_i=59.98 total/acc_c=53.28 total/h_score=62.54\n",
      "selected:  cs/acc_i=63.54 cs/acc_c=64.77 os/recall_knw=49.60 os/recall_unk=88.89 total/acc_i=59.46 total/acc_c=48.78 total/h_score=61.29\n",
      "Loss: 2.5337624157662\n",
      "Loss: 1.2787848349773523\n",
      "Loss: 0.9211257910315609\n",
      "Loss: 0.7377898340875452\n",
      "Loss: 0.6692305602036513\n",
      "Loss: 0.6187102855283977\n",
      "Loss: 0.5717471019401179\n",
      "Loss: 0.5264902847347321\n",
      "Loss: 0.502237128746974\n",
      "Loss: 0.47545461505006403\n",
      "______\n",
      "Iteration t=4\n",
      "all:  cs/acc_i=67.12 cs/acc_c=67.50 os/recall_knw=56.74 os/recall_unk=79.82 total/acc_i=60.01 total/acc_c=52.75 total/h_score=62.53\n",
      "selected:  cs/acc_i=65.81 cs/acc_c=66.78 os/recall_knw=53.22 os/recall_unk=85.35 total/acc_i=60.07 total/acc_c=51.23 total/h_score=62.68\n",
      "Loss: 2.51120581045872\n",
      "Loss: 1.2278773454057068\n",
      "Loss: 0.8649145828074768\n",
      "Loss: 0.7189836341793797\n",
      "Loss: 0.6534865364557555\n",
      "Loss: 0.5882412553334436\n",
      "Loss: 0.5580595486930439\n",
      "Loss: 0.4994157178311789\n",
      "Loss: 0.4705665594890338\n",
      "Loss: 0.44153141205300805\n",
      "______\n",
      "Iteration t=5\n",
      "all:  cs/acc_i=67.79 cs/acc_c=68.11 os/recall_knw=56.54 os/recall_unk=80.15 total/acc_i=60.04 total/acc_c=52.65 total/h_score=62.54\n",
      "selected:  cs/acc_i=67.23 cs/acc_c=67.81 os/recall_knw=55.03 os/recall_unk=82.13 total/acc_i=59.96 total/acc_c=52.06 total/h_score=62.58\n",
      "Loss: 2.478210508087535\n",
      "Loss: 1.2486439246699643\n",
      "Loss: 0.8565224453254983\n",
      "Loss: 0.7192777428362105\n",
      "Loss: 0.6414600088272566\n",
      "Loss: 0.5886129404536982\n",
      "Loss: 0.5341385472335933\n",
      "Loss: 0.5207687626772948\n",
      "Loss: 0.4676514209665879\n",
      "Loss: 0.4480885454595334\n",
      "______\n",
      "Iteration t=6\n",
      "all:  cs/acc_i=67.99 cs/acc_c=68.38 os/recall_knw=56.47 os/recall_unk=80.15 total/acc_i=60.01 total/acc_c=52.60 total/h_score=62.50\n",
      "selected:  cs/acc_i=67.80 cs/acc_c=68.29 os/recall_knw=56.21 os/recall_unk=80.75 total/acc_i=59.99 total/acc_c=52.48 total/h_score=62.56\n",
      "Loss: 2.476282165302494\n",
      "Loss: 1.225499816299454\n",
      "Loss: 0.8407710016500659\n",
      "Loss: 0.703120349262788\n",
      "Loss: 0.6188221564137839\n",
      "Loss: 0.5740476350595312\n",
      "Loss: 0.5395543338443206\n",
      "Loss: 0.49581359853831736\n",
      "Loss: 0.47073660427477304\n",
      "Loss: 0.4429067548334114\n",
      "______\n",
      "Iteration t=7\n",
      "all:  cs/acc_i=68.46 cs/acc_c=68.96 os/recall_knw=56.47 os/recall_unk=80.15 total/acc_i=60.01 total/acc_c=52.60 total/h_score=62.50\n",
      "selected:  cs/acc_i=68.43 cs/acc_c=68.94 os/recall_knw=56.43 os/recall_unk=80.22 total/acc_i=60.01 total/acc_c=52.58 total/h_score=62.51\n",
      "Loss: 2.471607440855445\n",
      "Loss: 1.225677981366956\n",
      "Loss: 0.8411562675383033\n",
      "Loss: 0.7227431212256594\n",
      "Loss: 0.6280369002644609\n",
      "Loss: 0.5771494126174508\n",
      "Loss: 0.5438236910395506\n",
      "Loss: 0.5067371830828791\n",
      "Loss: 0.46072367012379617\n",
      "Loss: 0.4452630068228497\n",
      "______\n",
      "Iteration t=8\n",
      "all:  cs/acc_i=68.14 cs/acc_c=68.50 os/recall_knw=56.47 os/recall_unk=80.15 total/acc_i=60.01 total/acc_c=52.60 total/h_score=62.50\n",
      "selected:  cs/acc_i=68.14 cs/acc_c=68.50 os/recall_knw=56.47 os/recall_unk=80.15 total/acc_i=60.01 total/acc_c=52.60 total/h_score=62.50\n",
      "Loss: 2.4971555907551837\n",
      "Loss: 1.243170676919503\n",
      "Loss: 0.8477809042707691\n",
      "Loss: 0.7263951706207865\n",
      "Loss: 0.6312396682617141\n",
      "Loss: 0.572969466144961\n",
      "Loss: 0.5392045961405204\n",
      "Loss: 0.4875958429240599\n",
      "Loss: 0.47537954157687784\n",
      "Loss: 0.43469703542750054\n",
      "______\n",
      "Iteration t=9\n",
      "all:  cs/acc_i=68.10 cs/acc_c=68.91 os/recall_knw=56.47 os/recall_unk=80.15 total/acc_i=60.01 total/acc_c=52.60 total/h_score=62.50\n",
      "selected:  cs/acc_i=68.10 cs/acc_c=68.91 os/recall_knw=56.47 os/recall_unk=80.15 total/acc_i=60.01 total/acc_c=52.60 total/h_score=62.50\n",
      "tensor(0)\n",
      "all:  cs/acc_i=68.10 cs/acc_c=68.91 os/recall_knw=56.47 os/recall_unk=80.15 total/acc_i=60.01 total/acc_c=52.60 total/h_score=62.50\n",
      "sketch -> painting lr= 0.001 seed= 1\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19]\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20]\n",
      "Loss: 2.6777599214278545\n",
      "Loss: 1.5997190131354577\n",
      "Loss: 1.1338534431973684\n",
      "Loss: 0.9465434660309369\n",
      "Loss: 0.8440142475145379\n",
      "Loss: 0.7642097688212837\n",
      "Loss: 0.7028081099089888\n",
      "Loss: 0.669610744745461\n",
      "Loss: 0.6289398313797626\n",
      "Loss: 0.608724562547256\n",
      "tensor(True) tensor(True)\n",
      "______\n",
      "Iteration t=1\n",
      "all:  cs/acc_i=65.16 cs/acc_c=65.57 os/recall_knw=93.10 os/recall_unk=16.53 total/acc_i=48.86 total/acc_c=62.24 total/h_score=26.32\n",
      "selected:  cs/acc_i=70.99 cs/acc_c=71.97 os/recall_knw=69.97 os/recall_unk=91.71 total/acc_i=73.23 total/acc_c=68.83 total/h_score=77.88\n",
      "Loss: 2.638987566537903\n",
      "Loss: 1.4710411636725715\n",
      "Loss: 1.0161485336540979\n",
      "Loss: 0.8475263982579329\n",
      "Loss: 0.754552746164626\n",
      "Loss: 0.6826954960535114\n",
      "Loss: 0.6542556016629445\n",
      "Loss: 0.6176354163798733\n",
      "Loss: 0.588076831350004\n",
      "Loss: 0.5181910675648905\n",
      "______\n",
      "Iteration t=2\n",
      "all:  cs/acc_i=66.81 cs/acc_c=67.10 os/recall_knw=63.05 os/recall_unk=72.18 total/acc_i=59.74 total/acc_c=55.43 total/h_score=62.16\n",
      "selected:  cs/acc_i=61.41 cs/acc_c=62.61 os/recall_knw=45.68 os/recall_unk=94.35 total/acc_i=60.41 total/acc_c=46.73 total/h_score=60.33\n",
      "Loss: 2.5967187280004675\n",
      "Loss: 1.3561251423575662\n",
      "Loss: 0.9326344137842005\n",
      "Loss: 0.7958007548343051\n",
      "Loss: 0.6836260103366592\n",
      "Loss: 0.6435632199726321\n",
      "Loss: 0.5985389330170371\n",
      "Loss: 0.5662821374156258\n",
      "Loss: 0.5049251799556342\n",
      "Loss: 0.49447782371531834\n",
      "______\n",
      "Iteration t=3\n",
      "all:  cs/acc_i=66.58 cs/acc_c=66.86 os/recall_knw=56.07 os/recall_unk=80.98 total/acc_i=60.17 total/acc_c=52.41 total/h_score=62.57\n",
      "selected:  cs/acc_i=63.26 cs/acc_c=64.39 os/recall_knw=48.13 os/recall_unk=90.45 total/acc_i=59.52 total/acc_c=47.85 total/h_score=60.74\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 2.526205173264379\n",
      "Loss: 1.300543996302978\n",
      "Loss: 0.9264039335043533\n",
      "Loss: 0.7817454839530198\n",
      "Loss: 0.7011286311823389\n",
      "Loss: 0.6190551116414692\n",
      "Loss: 0.5800635815314624\n",
      "Loss: 0.5389366853496302\n",
      "Loss: 0.5059392859754355\n",
      "Loss: 0.46469884809592493\n",
      "______\n",
      "Iteration t=4\n",
      "all:  cs/acc_i=66.89 cs/acc_c=67.34 os/recall_knw=55.09 os/recall_unk=81.89 total/acc_i=60.06 total/acc_c=51.93 total/h_score=62.42\n",
      "selected:  cs/acc_i=65.46 cs/acc_c=66.40 os/recall_knw=51.79 os/recall_unk=86.72 total/acc_i=59.90 total/acc_c=50.19 total/h_score=62.10\n",
      "Loss: 2.5096009064324294\n",
      "Loss: 1.270495039752767\n",
      "Loss: 0.90338899038009\n",
      "Loss: 0.7312890704925553\n",
      "Loss: 0.6667818178104449\n",
      "Loss: 0.6124121532912998\n",
      "Loss: 0.5276577993913039\n",
      "Loss: 0.5185968835645587\n",
      "Loss: 0.49413680388957637\n",
      "Loss: 0.4534966824929925\n",
      "______\n",
      "Iteration t=5\n",
      "all:  cs/acc_i=67.67 cs/acc_c=67.92 os/recall_knw=54.86 os/recall_unk=82.06 total/acc_i=60.01 total/acc_c=51.77 total/h_score=62.34\n",
      "selected:  cs/acc_i=67.24 cs/acc_c=67.75 os/recall_knw=53.86 os/recall_unk=83.80 total/acc_i=60.01 total/acc_c=51.38 total/h_score=62.44\n",
      "Loss: 2.4850190794172367\n",
      "Loss: 1.220624538246265\n",
      "Loss: 0.8730955816004887\n",
      "Loss: 0.7340666847534416\n",
      "Loss: 0.6455687405156695\n",
      "Loss: 0.6035869040272452\n",
      "Loss: 0.5452945017494446\n",
      "Loss: 0.5137072238794043\n",
      "Loss: 0.47520279878180877\n",
      "Loss: 0.44612185225999057\n",
      "______\n",
      "Iteration t=6\n",
      "all:  cs/acc_i=68.06 cs/acc_c=68.42 os/recall_knw=54.86 os/recall_unk=82.06 total/acc_i=60.01 total/acc_c=51.77 total/h_score=62.34\n",
      "selected:  cs/acc_i=68.00 cs/acc_c=68.43 os/recall_knw=54.72 os/recall_unk=82.33 total/acc_i=60.02 total/acc_c=51.75 total/h_score=62.39\n",
      "Loss: 2.4890792892604576\n",
      "Loss: 1.225192357526451\n",
      "Loss: 0.8336183752437107\n",
      "Loss: 0.6877871183220481\n",
      "Loss: 0.6440377162738902\n",
      "Loss: 0.5738830584116646\n",
      "Loss: 0.5569593521659492\n",
      "Loss: 0.4959421419217938\n",
      "Loss: 0.48822254021881056\n",
      "Loss: 0.45019866220775195\n",
      "______\n",
      "Iteration t=7\n",
      "all:  cs/acc_i=68.65 cs/acc_c=68.91 os/recall_knw=54.86 os/recall_unk=82.06 total/acc_i=60.01 total/acc_c=51.77 total/h_score=62.34\n",
      "selected:  cs/acc_i=68.65 cs/acc_c=68.91 os/recall_knw=54.86 os/recall_unk=82.06 total/acc_i=60.01 total/acc_c=51.77 total/h_score=62.34\n",
      "Loss: 2.4873649458416174\n",
      "Loss: 1.2276180650367112\n",
      "Loss: 0.8386772875903082\n",
      "Loss: 0.7284088046824346\n",
      "Loss: 0.6393048997785225\n",
      "Loss: 0.5971951137800686\n",
      "Loss: 0.5434502565347757\n",
      "Loss: 0.4946379325062525\n",
      "Loss: 0.4780083801292005\n",
      "Loss: 0.4441367479987809\n",
      "______\n",
      "Iteration t=8\n",
      "all:  cs/acc_i=68.73 cs/acc_c=69.00 os/recall_knw=54.86 os/recall_unk=82.06 total/acc_i=60.01 total/acc_c=51.77 total/h_score=62.34\n",
      "selected:  cs/acc_i=68.73 cs/acc_c=69.00 os/recall_knw=54.86 os/recall_unk=82.06 total/acc_i=60.01 total/acc_c=51.77 total/h_score=62.34\n",
      "Loss: 2.4883821127844636\n",
      "Loss: 1.233840039519013\n",
      "Loss: 0.8498983728836794\n",
      "Loss: 0.7242756165930482\n",
      "Loss: 0.6399227661676095\n",
      "Loss: 0.6023591506432314\n",
      "Loss: 0.5413105457899023\n",
      "Loss: 0.5004107040948556\n",
      "Loss: 0.4597947034435194\n",
      "Loss: 0.4413632803642359\n",
      "______\n",
      "Iteration t=9\n",
      "all:  cs/acc_i=68.73 cs/acc_c=68.94 os/recall_knw=54.86 os/recall_unk=82.06 total/acc_i=60.01 total/acc_c=51.77 total/h_score=62.34\n",
      "selected:  cs/acc_i=68.73 cs/acc_c=68.94 os/recall_knw=54.86 os/recall_unk=82.06 total/acc_i=60.01 total/acc_c=51.77 total/h_score=62.34\n",
      "tensor(0)\n",
      "all:  cs/acc_i=68.73 cs/acc_c=68.94 os/recall_knw=54.86 os/recall_unk=82.06 total/acc_i=60.01 total/acc_c=51.77 total/h_score=62.34\n",
      "sketch -> painting lr= 0.001 seed= 2\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19]\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20]\n",
      "Loss: 2.6814632956514655\n",
      "Loss: 1.5918643265655361\n",
      "Loss: 1.1371455379982585\n",
      "Loss: 0.9608876030776918\n",
      "Loss: 0.8091702298405244\n",
      "Loss: 0.7600597201548901\n",
      "Loss: 0.7000275513867742\n",
      "Loss: 0.6556374158748647\n",
      "Loss: 0.6453036574512413\n",
      "Loss: 0.5980278858818959\n",
      "tensor(True) tensor(True)\n",
      "______\n",
      "Iteration t=1\n",
      "all:  cs/acc_i=65.36 cs/acc_c=66.06 os/recall_knw=92.48 os/recall_unk=15.20 total/acc_i=48.35 total/acc_c=62.35 total/h_score=24.62\n",
      "selected:  cs/acc_i=70.67 cs/acc_c=71.64 os/recall_knw=68.00 os/recall_unk=91.50 total/acc_i=71.50 total/acc_c=67.32 total/h_score=76.76\n",
      "Loss: 2.6233714208510763\n",
      "Loss: 1.4757162695345671\n",
      "Loss: 1.0503642324376221\n",
      "Loss: 0.8778175065194928\n",
      "Loss: 0.7721006219513751\n",
      "Loss: 0.6749548251214235\n",
      "Loss: 0.6703831395089338\n",
      "Loss: 0.6234959251638772\n",
      "Loss: 0.5706473888406431\n",
      "Loss: 0.54266842364689\n",
      "______\n",
      "Iteration t=2\n",
      "all:  cs/acc_i=66.81 cs/acc_c=67.21 os/recall_knw=64.34 os/recall_unk=71.26 total/acc_i=60.28 total/acc_c=56.67 total/h_score=62.68\n",
      "selected:  cs/acc_i=60.69 cs/acc_c=61.84 os/recall_knw=46.53 os/recall_unk=94.60 total/acc_i=61.02 total/acc_c=47.47 total/h_score=61.10\n",
      "Loss: 2.555734707550569\n",
      "Loss: 1.342597894506021\n",
      "Loss: 0.9299735123460943\n",
      "Loss: 0.7818128278309648\n",
      "Loss: 0.6937750488519668\n",
      "Loss: 0.6484839397397908\n",
      "Loss: 0.5907239272513173\n",
      "Loss: 0.5539110292765227\n",
      "Loss: 0.5332914472303607\n",
      "Loss: 0.49309429919177833\n",
      "______\n",
      "Iteration t=3\n",
      "all:  cs/acc_i=67.44 cs/acc_c=67.70 os/recall_knw=59.25 os/recall_unk=77.74 total/acc_i=60.86 total/acc_c=54.78 total/h_score=63.48\n",
      "selected:  cs/acc_i=63.98 cs/acc_c=65.03 os/recall_knw=50.78 os/recall_unk=90.70 total/acc_i=60.95 total/acc_c=50.12 total/h_score=62.85\n",
      "Loss: 2.522364079178154\n",
      "Loss: 1.3069978573105552\n",
      "Loss: 0.8823012686395025\n",
      "Loss: 0.7609031110098867\n",
      "Loss: 0.6628969363319925\n",
      "Loss: 0.6157439665876941\n",
      "Loss: 0.598047514885535\n",
      "Loss: 0.5453322319499342\n",
      "Loss: 0.5084533330811051\n",
      "Loss: 0.49226825036011734\n",
      "______\n",
      "Iteration t=4\n",
      "all:  cs/acc_i=67.24 cs/acc_c=67.76 os/recall_knw=58.82 os/recall_unk=78.49 total/acc_i=60.94 total/acc_c=54.59 total/h_score=63.55\n",
      "selected:  cs/acc_i=65.54 cs/acc_c=66.66 os/recall_knw=55.01 os/recall_unk=85.37 total/acc_i=61.11 total/acc_c=52.70 total/h_score=63.91\n",
      "Loss: 2.4968651692737596\n",
      "Loss: 1.237132968014753\n",
      "Loss: 0.8712604037139207\n",
      "Loss: 0.7389657920125139\n",
      "Loss: 0.6436171913870209\n",
      "Loss: 0.5855177377806547\n",
      "Loss: 0.5593997236325651\n",
      "Loss: 0.5163013690685129\n",
      "Loss: 0.4849832124041713\n",
      "Loss: 0.47265158518837086\n",
      "______\n",
      "Iteration t=5\n",
      "all:  cs/acc_i=67.67 cs/acc_c=68.01 os/recall_knw=58.27 os/recall_unk=78.99 total/acc_i=60.89 total/acc_c=54.27 total/h_score=63.46\n",
      "selected:  cs/acc_i=66.83 cs/acc_c=67.49 os/recall_knw=56.76 os/recall_unk=81.98 total/acc_i=60.89 total/acc_c=53.50 total/h_score=63.69\n",
      "Loss: 2.485124187879875\n",
      "Loss: 1.1956587169991164\n",
      "Loss: 0.8624994214929518\n",
      "Loss: 0.7288031319125754\n",
      "Loss: 0.6259543152495486\n",
      "Loss: 0.5837222736512051\n",
      "Loss: 0.558711902772794\n",
      "Loss: 0.5004151340146534\n",
      "Loss: 0.4692460512895076\n",
      "Loss: 0.42213093981024674\n",
      "______\n",
      "Iteration t=6\n",
      "all:  cs/acc_i=68.30 cs/acc_c=68.82 os/recall_knw=58.19 os/recall_unk=79.15 total/acc_i=60.92 total/acc_c=54.24 total/h_score=63.49\n",
      "selected:  cs/acc_i=68.14 cs/acc_c=68.72 os/recall_knw=57.93 os/recall_unk=80.29 total/acc_i=61.05 total/acc_c=54.13 total/h_score=63.72\n",
      "Loss: 2.485321396758199\n",
      "Loss: 1.228033874681604\n",
      "Loss: 0.8519879419070023\n",
      "Loss: 0.7194879918928571\n",
      "Loss: 0.6078034231537267\n",
      "Loss: 0.5758784742731797\n",
      "Loss: 0.5440967474811473\n",
      "Loss: 0.4970546795530358\n",
      "Loss: 0.4642879904402412\n",
      "Loss: 0.4359717099410802\n",
      "______\n",
      "Iteration t=7\n",
      "all:  cs/acc_i=69.04 cs/acc_c=69.43 os/recall_knw=58.15 os/recall_unk=79.32 total/acc_i=60.94 total/acc_c=54.22 total/h_score=63.51\n",
      "selected:  cs/acc_i=69.04 cs/acc_c=69.43 os/recall_knw=58.15 os/recall_unk=79.32 total/acc_i=60.94 total/acc_c=54.22 total/h_score=63.51\n",
      "Loss: 2.4830742257256664\n",
      "Loss: 1.200849667672188\n",
      "Loss: 0.8546819618392375\n",
      "Loss: 0.7102669727417731\n",
      "Loss: 0.638835332927204\n",
      "Loss: 0.5717998382545286\n",
      "Loss: 0.5247237259942678\n",
      "Loss: 0.4968997570535829\n",
      "Loss: 0.46278386857480774\n",
      "Loss: 0.440617571975435\n",
      "______\n",
      "Iteration t=8\n",
      "all:  cs/acc_i=68.34 cs/acc_c=68.85 os/recall_knw=58.15 os/recall_unk=79.32 total/acc_i=60.94 total/acc_c=54.22 total/h_score=63.51\n",
      "selected:  cs/acc_i=68.34 cs/acc_c=68.85 os/recall_knw=58.15 os/recall_unk=79.32 total/acc_i=60.94 total/acc_c=54.22 total/h_score=63.51\n",
      "Loss: 2.4868517095042812\n",
      "Loss: 1.2085748137004915\n",
      "Loss: 0.8495400426608901\n",
      "Loss: 0.7122687637325256\n",
      "Loss: 0.6274305116385221\n",
      "Loss: 0.5629080189692397\n",
      "Loss: 0.5310319433769872\n",
      "Loss: 0.487123352325251\n",
      "Loss: 0.4579302747283251\n",
      "Loss: 0.44553969100478197\n",
      "______\n",
      "Iteration t=9\n",
      "all:  cs/acc_i=68.85 cs/acc_c=69.12 os/recall_knw=58.15 os/recall_unk=79.32 total/acc_i=60.94 total/acc_c=54.22 total/h_score=63.51\n",
      "selected:  cs/acc_i=68.85 cs/acc_c=69.12 os/recall_knw=58.15 os/recall_unk=79.32 total/acc_i=60.94 total/acc_c=54.22 total/h_score=63.51\n",
      "tensor(0)\n",
      "all:  cs/acc_i=68.85 cs/acc_c=69.12 os/recall_knw=58.15 os/recall_unk=79.32 total/acc_i=60.94 total/acc_c=54.22 total/h_score=63.51\n",
      "sketch -> painting lr= 0.001 seed= 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19]\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20]\n",
      "Loss: 2.687912252145944\n",
      "Loss: 1.603115466759377\n",
      "Loss: 1.106402909940051\n",
      "Loss: 0.9474530942046765\n",
      "Loss: 0.8297852784702459\n",
      "Loss: 0.7436415327271235\n",
      "Loss: 0.7085674621702469\n",
      "Loss: 0.6560185433355803\n",
      "Loss: 0.6398289168311149\n",
      "Loss: 0.5866522733698186\n",
      "tensor(True) tensor(True)\n",
      "______\n",
      "Iteration t=1\n",
      "all:  cs/acc_i=64.34 cs/acc_c=64.96 os/recall_knw=93.06 os/recall_unk=16.45 total/acc_i=48.16 total/acc_c=61.52 total/h_score=26.15\n",
      "selected:  cs/acc_i=70.70 cs/acc_c=71.47 os/recall_knw=69.85 os/recall_unk=91.67 total/acc_i=72.48 total/acc_c=67.51 total/h_score=76.95\n",
      "Loss: 2.6312242009213582\n",
      "Loss: 1.4515777616109249\n",
      "Loss: 1.0027688712889447\n",
      "Loss: 0.8820821216716859\n",
      "Loss: 0.775987162106279\n",
      "Loss: 0.6891510342630212\n",
      "Loss: 0.6587574640333941\n",
      "Loss: 0.5997206363557042\n",
      "Loss: 0.5776583680496123\n",
      "Loss: 0.5359168825806051\n",
      "______\n",
      "Iteration t=2\n",
      "all:  cs/acc_i=65.20 cs/acc_c=65.76 os/recall_knw=63.09 os/recall_unk=71.01 total/acc_i=59.08 total/acc_c=54.97 total/h_score=61.45\n",
      "selected:  cs/acc_i=58.63 cs/acc_c=60.12 os/recall_knw=45.42 os/recall_unk=93.14 total/acc_i=59.27 total/acc_c=45.70 total/h_score=59.14\n",
      "Loss: 2.5749014507640493\n",
      "Loss: 1.367359621687369\n",
      "Loss: 0.9465542633425106\n",
      "Loss: 0.7564754525368864\n",
      "Loss: 0.691110696033998\n",
      "Loss: 0.6723499150438742\n",
      "Loss: 0.6003972075202249\n",
      "Loss: 0.5545770304446871\n",
      "Loss: 0.5329041335393082\n",
      "Loss: 0.5052623016590422\n",
      "______\n",
      "Iteration t=3\n",
      "all:  cs/acc_i=65.95 cs/acc_c=66.22 os/recall_knw=56.78 os/recall_unk=79.07 total/acc_i=59.58 total/acc_c=52.34 total/h_score=62.01\n",
      "selected:  cs/acc_i=62.54 cs/acc_c=63.53 os/recall_knw=48.29 os/recall_unk=88.81 total/acc_i=58.94 total/acc_c=47.54 total/h_score=60.15\n",
      "Loss: 2.5379343115765116\n",
      "Loss: 1.305811379007671\n",
      "Loss: 0.9147554047729658\n",
      "Loss: 0.7681336599847545\n",
      "Loss: 0.6629815158636674\n",
      "Loss: 0.635420332784238\n",
      "Loss: 0.5747468474118606\n",
      "Loss: 0.5347857711755711\n",
      "Loss: 0.4927803101099056\n",
      "Loss: 0.4881511432969052\n",
      "______\n",
      "Iteration t=4\n",
      "all:  cs/acc_i=67.01 cs/acc_c=67.47 os/recall_knw=56.23 os/recall_unk=80.15 total/acc_i=59.69 total/acc_c=52.11 total/h_score=62.11\n",
      "selected:  cs/acc_i=65.54 cs/acc_c=66.55 os/recall_knw=52.65 os/recall_unk=85.32 total/acc_i=59.54 total/acc_c=50.37 total/h_score=61.94\n",
      "Loss: 2.5151942687876083\n",
      "Loss: 1.2575215907657848\n",
      "Loss: 0.8590048223483462\n",
      "Loss: 0.7016039074969893\n",
      "Loss: 0.6689129861212578\n",
      "Loss: 0.5957840448167143\n",
      "Loss: 0.5636428562658173\n",
      "Loss: 0.5188286023981431\n",
      "Loss: 0.4913473499923193\n",
      "Loss: 0.4431476741403091\n",
      "______\n",
      "Iteration t=5\n",
      "all:  cs/acc_i=66.93 cs/acc_c=67.38 os/recall_knw=56.03 os/recall_unk=80.23 total/acc_i=59.69 total/acc_c=52.08 total/h_score=62.12\n",
      "selected:  cs/acc_i=66.25 cs/acc_c=66.93 os/recall_knw=54.54 os/recall_unk=82.99 total/acc_i=59.72 total/acc_c=51.42 total/h_score=62.28\n",
      "Loss: 2.5220204650863143\n",
      "Loss: 1.2343140781418351\n",
      "Loss: 0.841869667295582\n",
      "Loss: 0.7171619783255679\n",
      "Loss: 0.6357480520305555\n",
      "Loss: 0.5776779411499166\n",
      "Loss: 0.5397742417725649\n",
      "Loss: 0.5083201613184835\n",
      "Loss: 0.48020226071196154\n",
      "Loss: 0.45932640067555686\n",
      "______\n",
      "Iteration t=6\n",
      "all:  cs/acc_i=66.97 cs/acc_c=67.45 os/recall_knw=56.00 os/recall_unk=80.40 total/acc_i=59.74 total/acc_c=52.09 total/h_score=62.16\n",
      "selected:  cs/acc_i=66.88 cs/acc_c=67.40 os/recall_knw=55.72 os/recall_unk=81.21 total/acc_i=59.84 total/acc_c=52.00 total/h_score=62.30\n",
      "Loss: 2.4944205785284237\n",
      "Loss: 1.200338940717736\n",
      "Loss: 0.8671790416143379\n",
      "Loss: 0.7310510679167144\n",
      "Loss: 0.641380095968441\n",
      "Loss: 0.5714811251479752\n",
      "Loss: 0.5203652348445387\n",
      "Loss: 0.4927071751988664\n",
      "Loss: 0.46555398504952994\n",
      "Loss: 0.4549552308053387\n",
      "______\n",
      "Iteration t=7\n",
      "all:  cs/acc_i=67.71 cs/acc_c=68.10 os/recall_knw=55.92 os/recall_unk=80.40 total/acc_i=59.74 total/acc_c=52.09 total/h_score=62.16\n",
      "selected:  cs/acc_i=67.70 cs/acc_c=68.09 os/recall_knw=55.90 os/recall_unk=80.40 total/acc_i=59.73 total/acc_c=52.08 total/h_score=62.15\n",
      "Loss: 2.4833032716580523\n",
      "Loss: 1.2305238644282024\n",
      "Loss: 0.8478540226938279\n",
      "Loss: 0.716652575910576\n",
      "Loss: 0.6462228210960946\n",
      "Loss: 0.5738217071667919\n",
      "Loss: 0.5257870938962068\n",
      "Loss: 0.4931111259431374\n",
      "Loss: 0.47765287902297043\n",
      "Loss: 0.42890410821854585\n",
      "______\n",
      "Iteration t=8\n",
      "all:  cs/acc_i=67.75 cs/acc_c=68.25 os/recall_knw=55.92 os/recall_unk=80.40 total/acc_i=59.74 total/acc_c=52.09 total/h_score=62.16\n",
      "selected:  cs/acc_i=67.75 cs/acc_c=68.25 os/recall_knw=55.92 os/recall_unk=80.40 total/acc_i=59.74 total/acc_c=52.09 total/h_score=62.16\n",
      "Loss: 2.4990954588099226\n",
      "Loss: 1.2220832000418407\n",
      "Loss: 0.8428369692670621\n",
      "Loss: 0.7108317192007856\n",
      "Loss: 0.6436728886593648\n",
      "Loss: 0.5767643398385707\n",
      "Loss: 0.5442247001257369\n",
      "Loss: 0.4948939148003493\n",
      "Loss: 0.4655087261604584\n",
      "Loss: 0.4393732537462459\n",
      "______\n",
      "Iteration t=9\n",
      "all:  cs/acc_i=67.52 cs/acc_c=67.77 os/recall_knw=55.92 os/recall_unk=80.40 total/acc_i=59.74 total/acc_c=52.09 total/h_score=62.16\n",
      "selected:  cs/acc_i=67.52 cs/acc_c=67.77 os/recall_knw=55.92 os/recall_unk=80.40 total/acc_i=59.74 total/acc_c=52.09 total/h_score=62.16\n",
      "tensor(0)\n",
      "all:  cs/acc_i=67.52 cs/acc_c=67.77 os/recall_knw=55.92 os/recall_unk=80.40 total/acc_i=59.74 total/acc_c=52.09 total/h_score=62.16\n",
      "sketch -> painting lr= 0.001 seed= 4\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19]\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20]\n",
      "Loss: 2.6699343735409764\n",
      "Loss: 1.5762643294850576\n",
      "Loss: 1.1183734554605387\n",
      "Loss: 0.9269092851078388\n",
      "Loss: 0.8602956287639657\n",
      "Loss: 0.7820617333822644\n",
      "Loss: 0.7107577422230514\n",
      "Loss: 0.6939948453116662\n",
      "Loss: 0.619300785906536\n",
      "Loss: 0.6070181695149117\n",
      "tensor(True) tensor(True)\n",
      "______\n",
      "Iteration t=1\n",
      "all:  cs/acc_i=64.46 cs/acc_c=65.18 os/recall_knw=92.59 os/recall_unk=15.45 total/acc_i=47.60 total/acc_c=61.23 total/h_score=24.85\n",
      "selected:  cs/acc_i=72.52 cs/acc_c=72.78 os/recall_knw=68.71 os/recall_unk=93.47 total/acc_i=72.35 total/acc_c=67.19 total/h_score=77.29\n",
      "Loss: 2.6247211890520106\n",
      "Loss: 1.4423902855403181\n",
      "Loss: 1.0165496972448007\n",
      "Loss: 0.8556413477745609\n",
      "Loss: 0.7713335732331023\n",
      "Loss: 0.6846506859081379\n",
      "Loss: 0.6579248556768261\n",
      "Loss: 0.6077841144541035\n",
      "Loss: 0.5505518252434938\n",
      "Loss: 0.5389401860859083\n",
      "______\n",
      "Iteration t=2\n",
      "all:  cs/acc_i=66.30 cs/acc_c=66.67 os/recall_knw=61.76 os/recall_unk=73.34 total/acc_i=59.42 total/acc_c=54.40 total/h_score=61.83\n",
      "selected:  cs/acc_i=59.77 cs/acc_c=60.85 os/recall_knw=44.70 os/recall_unk=94.44 total/acc_i=59.07 total/acc_c=44.30 total/h_score=57.95\n",
      "Loss: 2.586500743302432\n",
      "Loss: 1.3740929679437117\n",
      "Loss: 0.9372160071676428\n",
      "Loss: 0.7970550734888423\n",
      "Loss: 0.7046822791072456\n",
      "Loss: 0.6316941680555994\n",
      "Loss: 0.6083469348197633\n",
      "Loss: 0.5708883401345123\n",
      "Loss: 0.5197496851736849\n",
      "Loss: 0.5269897707483985\n",
      "______\n",
      "Iteration t=3\n",
      "all:  cs/acc_i=65.63 cs/acc_c=65.99 os/recall_knw=57.60 os/recall_unk=79.24 total/acc_i=59.80 total/acc_c=52.57 total/h_score=62.23\n",
      "selected:  cs/acc_i=61.66 cs/acc_c=62.63 os/recall_knw=49.03 os/recall_unk=89.92 total/acc_i=59.05 total/acc_c=47.13 total/h_score=59.98\n",
      "Loss: 2.543396750740383\n",
      "Loss: 1.29749737330105\n",
      "Loss: 0.8956679030604985\n",
      "Loss: 0.7546787624773772\n",
      "Loss: 0.6787404380414797\n",
      "Loss: 0.5921752439244934\n",
      "Loss: 0.5736673355750416\n",
      "Loss: 0.5237374399667201\n",
      "Loss: 0.506553308924903\n",
      "Loss: 0.45625170806179877\n",
      "______\n",
      "Iteration t=4\n",
      "all:  cs/acc_i=65.87 cs/acc_c=66.40 os/recall_knw=57.01 os/recall_unk=79.73 total/acc_i=59.69 total/acc_c=52.22 total/h_score=62.09\n",
      "selected:  cs/acc_i=64.41 cs/acc_c=65.41 os/recall_knw=53.63 os/recall_unk=84.96 total/acc_i=59.64 total/acc_c=50.39 total/h_score=61.88\n",
      "Loss: 2.4925886751717603\n",
      "Loss: 1.2506354338953185\n",
      "Loss: 0.8693269028573855\n",
      "Loss: 0.7277127990662802\n",
      "Loss: 0.6322584542519877\n",
      "Loss: 0.5879654747172879\n",
      "Loss: 0.545433362595207\n",
      "Loss: 0.5103148970145062\n",
      "Loss: 0.48835311412312493\n",
      "Loss: 0.44982742243855567\n",
      "______\n",
      "Iteration t=5\n",
      "all:  cs/acc_i=68.18 cs/acc_c=68.63 os/recall_knw=56.82 os/recall_unk=79.82 total/acc_i=59.66 total/acc_c=52.12 total/h_score=62.04\n",
      "selected:  cs/acc_i=67.77 cs/acc_c=68.41 os/recall_knw=55.71 os/recall_unk=82.00 total/acc_i=59.75 total/acc_c=51.63 total/h_score=62.21\n",
      "Loss: 2.489624061056825\n",
      "Loss: 1.2331232809629598\n",
      "Loss: 0.8669334284839083\n",
      "Loss: 0.7362639083236945\n",
      "Loss: 0.6207790066961383\n",
      "Loss: 0.5855208307382513\n",
      "Loss: 0.5465960669957224\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.501978019893658\n",
      "Loss: 0.4517777985969528\n",
      "Loss: 0.46242019906640053\n",
      "______\n",
      "Iteration t=6\n",
      "all:  cs/acc_i=68.03 cs/acc_c=68.31 os/recall_knw=56.74 os/recall_unk=79.82 total/acc_i=59.61 total/acc_c=52.03 total/h_score=61.97\n",
      "selected:  cs/acc_i=67.96 cs/acc_c=68.28 os/recall_knw=56.65 os/recall_unk=80.76 total/acc_i=59.78 total/acc_c=52.03 total/h_score=62.21\n",
      "Loss: 2.469140663379576\n",
      "Loss: 1.2153992279758299\n",
      "Loss: 0.8457011581678701\n",
      "Loss: 0.7211980516833019\n",
      "Loss: 0.6365963562232692\n",
      "Loss: 0.5552504363098765\n",
      "Loss: 0.5264314780148064\n",
      "Loss: 0.48332825515086086\n",
      "Loss: 0.4646662828641209\n",
      "Loss: 0.432703867070074\n",
      "______\n",
      "Iteration t=7\n",
      "all:  cs/acc_i=67.83 cs/acc_c=68.27 os/recall_knw=56.70 os/recall_unk=79.82 total/acc_i=59.58 total/acc_c=52.00 total/h_score=61.94\n",
      "selected:  cs/acc_i=67.83 cs/acc_c=68.27 os/recall_knw=56.70 os/recall_unk=79.88 total/acc_i=59.60 total/acc_c=52.00 total/h_score=61.96\n",
      "Loss: 2.474639162360898\n",
      "Loss: 1.2097656673748\n",
      "Loss: 0.8539267076171844\n",
      "Loss: 0.6907562543506082\n",
      "Loss: 0.6335446122686873\n",
      "Loss: 0.5761260909710818\n",
      "Loss: 0.529917771215381\n",
      "Loss: 0.5118199889717797\n",
      "Loss: 0.45257698500204663\n",
      "Loss: 0.44005576189350987\n",
      "______\n",
      "Iteration t=8\n",
      "all:  cs/acc_i=67.63 cs/acc_c=68.11 os/recall_knw=56.70 os/recall_unk=79.82 total/acc_i=59.58 total/acc_c=52.00 total/h_score=61.94\n",
      "selected:  cs/acc_i=67.63 cs/acc_c=68.11 os/recall_knw=56.70 os/recall_unk=79.82 total/acc_i=59.58 total/acc_c=52.00 total/h_score=61.94\n",
      "Loss: 2.484970803202888\n",
      "Loss: 1.1932824584636612\n",
      "Loss: 0.8379446947381564\n",
      "Loss: 0.7027236208741964\n",
      "Loss: 0.6292086364889917\n",
      "Loss: 0.5704264405526613\n",
      "Loss: 0.5453419847044385\n",
      "Loss: 0.47510210572466677\n",
      "Loss: 0.4856842187372779\n",
      "Loss: 0.4516088203018011\n",
      "______\n",
      "Iteration t=9\n",
      "all:  cs/acc_i=67.32 cs/acc_c=67.45 os/recall_knw=56.70 os/recall_unk=79.82 total/acc_i=59.58 total/acc_c=52.00 total/h_score=61.94\n",
      "selected:  cs/acc_i=67.32 cs/acc_c=67.45 os/recall_knw=56.70 os/recall_unk=79.82 total/acc_i=59.58 total/acc_c=52.00 total/h_score=61.94\n",
      "tensor(0)\n",
      "all:  cs/acc_i=67.32 cs/acc_c=67.45 os/recall_knw=56.70 os/recall_unk=79.82 total/acc_i=59.58 total/acc_c=52.00 total/h_score=61.94\n",
      "sketch -> painting lr= 0.001 seed= 0\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19]\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20]\n",
      "Loss: 2.683256307213577\n",
      "Loss: 1.6280650729985582\n",
      "Loss: 1.1316685547533722\n",
      "Loss: 0.9231887598013141\n",
      "Loss: 0.8252413590851518\n",
      "Loss: 0.7520798566107897\n",
      "Loss: 0.7159862828623388\n",
      "Loss: 0.6490156418576682\n",
      "Loss: 0.6379818069873396\n",
      "Loss: 0.5941701175779411\n",
      "tensor(True) tensor(True)\n",
      "______\n",
      "Iteration t=1\n",
      "all:  cs/acc_i=65.63 cs/acc_c=66.24 os/recall_knw=92.67 os/recall_unk=15.61 total/acc_i=48.59 total/acc_c=62.50 total/h_score=25.17\n",
      "selected:  cs/acc_i=71.91 cs/acc_c=71.91 os/recall_knw=68.73 os/recall_unk=94.00 total/acc_i=72.68 total/acc_c=67.31 total/h_score=77.53\n",
      "Loss: 2.631519397099813\n",
      "Loss: 1.473187778019099\n",
      "Loss: 0.9951504949786237\n",
      "Loss: 0.862746167442073\n",
      "Loss: 0.7595368504236286\n",
      "Loss: 0.6838427998737436\n",
      "Loss: 0.648885978448794\n",
      "Loss: 0.6105120272740073\n",
      "Loss: 0.5895005709307205\n",
      "Loss: 0.5557907779435605\n",
      "______\n",
      "Iteration t=2\n",
      "all:  cs/acc_i=67.05 cs/acc_c=67.48 os/recall_knw=62.50 os/recall_unk=74.25 total/acc_i=60.62 total/acc_c=55.84 total/h_score=63.14\n",
      "selected:  cs/acc_i=60.76 cs/acc_c=62.45 os/recall_knw=45.50 os/recall_unk=95.41 total/acc_i=60.64 total/acc_c=46.47 total/h_score=60.24\n",
      "Loss: 2.56016297286207\n",
      "Loss: 1.3631877557797865\n",
      "Loss: 0.9535494089126587\n",
      "Loss: 0.793765875697136\n",
      "Loss: 0.7179266691207886\n",
      "Loss: 0.6567530423402786\n",
      "Loss: 0.6096890021454204\n",
      "Loss: 0.5704789351333271\n",
      "Loss: 0.5516701119189913\n",
      "Loss: 0.4997025561603633\n",
      "______\n",
      "Iteration t=3\n",
      "all:  cs/acc_i=66.34 cs/acc_c=66.79 os/recall_knw=58.62 os/recall_unk=79.15 total/acc_i=60.81 total/acc_c=54.08 total/h_score=63.36\n",
      "selected:  cs/acc_i=62.36 cs/acc_c=63.64 os/recall_knw=50.38 os/recall_unk=89.65 total/acc_i=60.11 total/acc_c=49.00 total/h_score=61.64\n",
      "Loss: 2.5330536912530017\n",
      "Loss: 1.268294782091529\n",
      "Loss: 0.8991061280042062\n",
      "Loss: 0.7660742511738946\n",
      "Loss: 0.6535474588344623\n",
      "Loss: 0.6085727359309341\n",
      "Loss: 0.5917077018714054\n",
      "Loss: 0.5323291440288742\n",
      "Loss: 0.49907839878813015\n",
      "Loss: 0.4708527233693507\n",
      "______\n",
      "Iteration t=4\n",
      "all:  cs/acc_i=67.32 cs/acc_c=67.76 os/recall_knw=57.88 os/recall_unk=80.23 total/acc_i=60.86 total/acc_c=53.70 total/h_score=63.38\n",
      "selected:  cs/acc_i=65.62 cs/acc_c=66.68 os/recall_knw=53.80 os/recall_unk=85.64 total/acc_i=60.64 total/acc_c=51.62 total/h_score=63.07\n",
      "Loss: 2.5241872828547693\n",
      "Loss: 1.2574205128084712\n",
      "Loss: 0.8753926609994984\n",
      "Loss: 0.7335653358898243\n",
      "Loss: 0.6577600805448884\n",
      "Loss: 0.5773664695375106\n",
      "Loss: 0.5405798382243189\n",
      "Loss: 0.5005217410561418\n",
      "Loss: 0.47274394402233494\n",
      "Loss: 0.44476871483591424\n",
      "______\n",
      "Iteration t=5\n",
      "all:  cs/acc_i=67.40 cs/acc_c=67.63 os/recall_knw=57.25 os/recall_unk=80.90 total/acc_i=60.76 total/acc_c=53.32 total/h_score=63.27\n",
      "selected:  cs/acc_i=66.86 cs/acc_c=67.37 os/recall_knw=55.74 os/recall_unk=83.25 total/acc_i=60.80 total/acc_c=52.71 total/h_score=63.39\n",
      "Loss: 2.4835801100044095\n",
      "Loss: 1.25301665263902\n",
      "Loss: 0.8495395461963527\n",
      "Loss: 0.7252025750193576\n",
      "Loss: 0.6408660805519716\n",
      "Loss: 0.598915123522527\n",
      "Loss: 0.5410456283347597\n",
      "Loss: 0.48775184497911744\n",
      "Loss: 0.47230040521165473\n",
      "Loss: 0.4555118090699239\n",
      "______\n",
      "Iteration t=6\n",
      "all:  cs/acc_i=68.22 cs/acc_c=68.76 os/recall_knw=57.17 os/recall_unk=80.98 total/acc_i=60.76 total/acc_c=53.30 total/h_score=63.27\n",
      "selected:  cs/acc_i=68.14 cs/acc_c=68.71 os/recall_knw=57.00 os/recall_unk=81.52 total/acc_i=60.81 total/acc_c=53.22 total/h_score=63.35\n",
      "Loss: 2.491521362366715\n",
      "Loss: 1.2236036634057519\n",
      "Loss: 0.8338792865596166\n",
      "Loss: 0.7036867904953841\n",
      "Loss: 0.6339423619513589\n",
      "Loss: 0.5574141339800223\n",
      "Loss: 0.5570886093305378\n",
      "Loss: 0.4761649855389828\n",
      "Loss: 0.4538673759112513\n",
      "Loss: 0.4380083793425948\n",
      "______\n",
      "Iteration t=7\n",
      "all:  cs/acc_i=68.57 cs/acc_c=68.94 os/recall_knw=57.17 os/recall_unk=80.98 total/acc_i=60.76 total/acc_c=53.30 total/h_score=63.27\n",
      "selected:  cs/acc_i=68.58 cs/acc_c=68.95 os/recall_knw=57.12 os/recall_unk=81.05 total/acc_i=60.77 total/acc_c=53.30 total/h_score=63.29\n",
      "Loss: 2.480398669899234\n",
      "Loss: 1.2059250459497275\n",
      "Loss: 0.8281350605159636\n",
      "Loss: 0.7269095579380931\n",
      "Loss: 0.638836986864144\n",
      "Loss: 0.5872806396923567\n",
      "Loss: 0.5243330376471586\n",
      "Loss: 0.48941492069105386\n",
      "Loss: 0.4767413678680837\n",
      "Loss: 0.45054804584999314\n",
      "______\n",
      "Iteration t=8\n",
      "all:  cs/acc_i=69.00 cs/acc_c=69.20 os/recall_knw=57.17 os/recall_unk=80.98 total/acc_i=60.76 total/acc_c=53.30 total/h_score=63.27\n",
      "selected:  cs/acc_i=69.00 cs/acc_c=69.20 os/recall_knw=57.17 os/recall_unk=80.98 total/acc_i=60.76 total/acc_c=53.30 total/h_score=63.27\n",
      "Loss: 2.4762448617803905\n",
      "Loss: 1.217880826247366\n",
      "Loss: 0.8445628620834968\n",
      "Loss: 0.7282158592451922\n",
      "Loss: 0.6375394994430696\n",
      "Loss: 0.5734528734495765\n",
      "Loss: 0.5223733689862224\n",
      "Loss: 0.5045078546412078\n",
      "Loss: 0.5028874534465041\n",
      "Loss: 0.44554637662070967\n",
      "______\n",
      "Iteration t=9\n",
      "all:  cs/acc_i=67.99 cs/acc_c=68.43 os/recall_knw=57.17 os/recall_unk=80.98 total/acc_i=60.76 total/acc_c=53.30 total/h_score=63.27\n",
      "selected:  cs/acc_i=67.99 cs/acc_c=68.43 os/recall_knw=57.17 os/recall_unk=80.98 total/acc_i=60.76 total/acc_c=53.30 total/h_score=63.27\n",
      "tensor(0)\n",
      "all:  cs/acc_i=67.99 cs/acc_c=68.43 os/recall_knw=57.17 os/recall_unk=80.98 total/acc_i=60.76 total/acc_c=53.30 total/h_score=63.27\n",
      "sketch -> painting lr= 0.001 seed= 1\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19]\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20]\n",
      "Loss: 2.6760922111186787\n",
      "Loss: 1.5955239515943624\n",
      "Loss: 1.1337892809479506\n",
      "Loss: 0.9471946834903402\n",
      "Loss: 0.8450500098700376\n",
      "Loss: 0.7652730410246505\n",
      "Loss: 0.7048490231799096\n",
      "Loss: 0.670812416015212\n",
      "Loss: 0.6311426409280178\n",
      "Loss: 0.6099208148637998\n",
      "tensor(True) tensor(True)\n",
      "______\n",
      "Iteration t=1\n",
      "all:  cs/acc_i=65.36 cs/acc_c=65.68 os/recall_knw=93.10 os/recall_unk=16.53 total/acc_i=48.88 total/acc_c=62.21 total/h_score=26.31\n",
      "selected:  cs/acc_i=71.65 cs/acc_c=72.44 os/recall_knw=69.76 os/recall_unk=90.87 total/acc_i=73.03 total/acc_c=68.82 total/h_score=77.60\n",
      "Loss: 2.6349959678695973\n",
      "Loss: 1.4484629556176742\n",
      "Loss: 1.0012936759110234\n",
      "Loss: 0.8701080042095\n",
      "Loss: 0.7818937688921961\n",
      "Loss: 0.6940721437550973\n",
      "Loss: 0.645750740012109\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.613626285235663\n",
      "Loss: 0.5708659023478411\n",
      "Loss: 0.5281764146498436\n",
      "______\n",
      "Iteration t=2\n",
      "all:  cs/acc_i=66.26 cs/acc_c=66.62 os/recall_knw=67.24 os/recall_unk=65.78 total/acc_i=59.29 total/acc_c=57.26 total/h_score=60.98\n",
      "selected:  cs/acc_i=60.81 cs/acc_c=62.04 os/recall_knw=48.49 os/recall_unk=93.51 total/acc_i=61.66 total/acc_c=49.13 total/h_score=62.48\n",
      "Loss: 2.575393624197353\n",
      "Loss: 1.334672986106439\n",
      "Loss: 0.9300526824864475\n",
      "Loss: 0.7818258891051466\n",
      "Loss: 0.6852161677046256\n",
      "Loss: 0.6557168510827152\n",
      "Loss: 0.5795245779508894\n",
      "Loss: 0.5915575286204164\n",
      "Loss: 0.5163940201428804\n",
      "Loss: 0.504380311478268\n",
      "______\n",
      "Iteration t=3\n",
      "all:  cs/acc_i=66.38 cs/acc_c=66.52 os/recall_knw=59.40 os/recall_unk=75.58 total/acc_i=59.98 total/acc_c=54.22 total/h_score=62.41\n",
      "selected:  cs/acc_i=62.42 cs/acc_c=63.17 os/recall_knw=50.02 os/recall_unk=89.57 total/acc_i=59.99 total/acc_c=49.02 total/h_score=61.64\n",
      "Loss: 2.533298413131548\n",
      "Loss: 1.3040215639964394\n",
      "Loss: 0.9177458675011344\n",
      "Loss: 0.7644819013450457\n",
      "Loss: 0.6726289119409479\n",
      "Loss: 0.6248640377884326\n",
      "Loss: 0.5662750767624897\n",
      "Loss: 0.5350487391585889\n",
      "Loss: 0.4921225676070089\n",
      "Loss: 0.4806135259244753\n",
      "______\n",
      "Iteration t=4\n",
      "all:  cs/acc_i=66.81 cs/acc_c=67.01 os/recall_knw=57.25 os/recall_unk=78.57 total/acc_i=60.01 total/acc_c=53.03 total/h_score=62.41\n",
      "selected:  cs/acc_i=65.11 cs/acc_c=65.88 os/recall_knw=53.57 os/recall_unk=84.46 total/acc_i=59.91 total/acc_c=51.08 total/h_score=62.35\n",
      "Loss: 2.502617054404574\n",
      "Loss: 1.2378471990010729\n",
      "Loss: 0.8829400404726611\n",
      "Loss: 0.74718154150073\n",
      "Loss: 0.6619763931719329\n",
      "Loss: 0.6082617116149001\n",
      "Loss: 0.5459830010909914\n",
      "Loss: 0.5150425037579557\n",
      "Loss: 0.4658970390154228\n",
      "Loss: 0.4446076802192373\n",
      "______\n",
      "Iteration t=5\n",
      "all:  cs/acc_i=68.85 cs/acc_c=68.90 os/recall_knw=57.25 os/recall_unk=78.74 total/acc_i=60.06 total/acc_c=53.04 total/h_score=62.46\n",
      "selected:  cs/acc_i=68.42 cs/acc_c=68.71 os/recall_knw=55.83 os/recall_unk=81.65 total/acc_i=60.29 total/acc_c=52.60 total/h_score=62.90\n",
      "Loss: 2.485727653151653\n",
      "Loss: 1.2206243027429111\n",
      "Loss: 0.8480818666151313\n",
      "Loss: 0.7000317411100279\n",
      "Loss: 0.6287731141096256\n",
      "Loss: 0.6008111656811393\n",
      "Loss: 0.5362747674960582\n",
      "Loss: 0.5154972451387859\n",
      "Loss: 0.45978808006057975\n",
      "Loss: 0.4397928205425622\n",
      "______\n",
      "Iteration t=6\n",
      "all:  cs/acc_i=68.46 cs/acc_c=68.65 os/recall_knw=57.21 os/recall_unk=79.15 total/acc_i=60.20 total/acc_c=53.06 total/h_score=62.59\n",
      "selected:  cs/acc_i=68.38 cs/acc_c=68.66 os/recall_knw=56.89 os/recall_unk=79.68 total/acc_i=60.23 total/acc_c=53.01 total/h_score=62.69\n",
      "Loss: 2.477816340411723\n",
      "Loss: 1.2186341259160989\n",
      "Loss: 0.8487775304056855\n",
      "Loss: 0.7181372206944686\n",
      "Loss: 0.6374639833745687\n",
      "Loss: 0.5705052033851021\n",
      "Loss: 0.5272854471254927\n",
      "Loss: 0.479584774326699\n",
      "Loss: 0.47058824338169714\n",
      "Loss: 0.450099918041152\n",
      "______\n",
      "Iteration t=7\n",
      "all:  cs/acc_i=67.87 cs/acc_c=68.14 os/recall_knw=57.21 os/recall_unk=79.15 total/acc_i=60.20 total/acc_c=53.06 total/h_score=62.59\n",
      "selected:  cs/acc_i=67.86 cs/acc_c=68.14 os/recall_knw=57.19 os/recall_unk=79.22 total/acc_i=60.20 total/acc_c=53.06 total/h_score=62.60\n",
      "Loss: 2.483452892979147\n",
      "Loss: 1.200571694837408\n",
      "Loss: 0.8549816526382076\n",
      "Loss: 0.7171563600239\n",
      "Loss: 0.6310352696942897\n",
      "Loss: 0.5816514247100846\n",
      "Loss: 0.5341632559835187\n",
      "Loss: 0.4961481430390586\n",
      "Loss: 0.4686026994274695\n",
      "Loss: 0.4386125078447435\n",
      "______\n",
      "Iteration t=8\n",
      "all:  cs/acc_i=68.50 cs/acc_c=68.86 os/recall_knw=57.17 os/recall_unk=79.15 total/acc_i=60.17 total/acc_c=53.02 total/h_score=62.56\n",
      "selected:  cs/acc_i=68.50 cs/acc_c=68.86 os/recall_knw=57.17 os/recall_unk=79.15 total/acc_i=60.17 total/acc_c=53.02 total/h_score=62.56\n",
      "Loss: 2.490287866669628\n",
      "Loss: 1.2233592882330118\n",
      "Loss: 0.8397751532585515\n",
      "Loss: 0.713332872641714\n",
      "Loss: 0.6233194349748403\n",
      "Loss: 0.5838076212869482\n",
      "Loss: 0.5191864459379482\n",
      "Loss: 0.46659350485695517\n",
      "Loss: 0.46934207827456087\n",
      "Loss: 0.4080350289520947\n",
      "______\n",
      "Iteration t=9\n",
      "all:  cs/acc_i=68.57 cs/acc_c=68.83 os/recall_knw=57.17 os/recall_unk=79.15 total/acc_i=60.17 total/acc_c=53.02 total/h_score=62.56\n",
      "selected:  cs/acc_i=68.57 cs/acc_c=68.83 os/recall_knw=57.17 os/recall_unk=79.15 total/acc_i=60.17 total/acc_c=53.02 total/h_score=62.56\n",
      "tensor(0)\n",
      "all:  cs/acc_i=68.57 cs/acc_c=68.83 os/recall_knw=57.17 os/recall_unk=79.15 total/acc_i=60.17 total/acc_c=53.02 total/h_score=62.56\n",
      "sketch -> painting lr= 0.001 seed= 2\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19]\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20]\n",
      "Loss: 2.6806488227598444\n",
      "Loss: 1.5871408876684523\n",
      "Loss: 1.1352388115273309\n",
      "Loss: 0.959662312392107\n",
      "Loss: 0.8081189278782028\n",
      "Loss: 0.7592375817679867\n",
      "Loss: 0.6987464815070948\n",
      "Loss: 0.6532106691414548\n",
      "Loss: 0.6448414548463428\n",
      "Loss: 0.5966301512779649\n",
      "tensor(True) tensor(True)\n",
      "______\n",
      "Iteration t=1\n",
      "all:  cs/acc_i=65.13 cs/acc_c=65.87 os/recall_knw=92.91 os/recall_unk=16.11 total/acc_i=48.64 total/acc_c=62.38 total/h_score=25.80\n",
      "selected:  cs/acc_i=71.19 cs/acc_c=71.76 os/recall_knw=69.32 os/recall_unk=92.38 total/acc_i=73.12 total/acc_c=68.20 total/h_score=77.66\n",
      "Loss: 2.614269811750034\n",
      "Loss: 1.4740133069563603\n",
      "Loss: 1.0348472793896992\n",
      "Loss: 0.8577778594217439\n",
      "Loss: 0.7555483933808147\n",
      "Loss: 0.6991955963309836\n",
      "Loss: 0.652015280176476\n",
      "Loss: 0.6262819676295571\n",
      "Loss: 0.583292353556352\n",
      "Loss: 0.5343814325217463\n",
      "______\n",
      "Iteration t=2\n",
      "all:  cs/acc_i=66.85 cs/acc_c=67.22 os/recall_knw=65.24 os/recall_unk=68.69 total/acc_i=59.80 total/acc_c=56.91 total/h_score=61.89\n",
      "selected:  cs/acc_i=60.97 cs/acc_c=62.24 os/recall_knw=47.14 os/recall_unk=93.98 total/acc_i=61.10 total/acc_c=48.00 total/h_score=61.50\n",
      "Loss: 2.555814511125738\n",
      "Loss: 1.358862272717736\n",
      "Loss: 0.9374504522843794\n",
      "Loss: 0.7895939843221145\n",
      "Loss: 0.6928942116824064\n",
      "Loss: 0.668317396600138\n",
      "Loss: 0.5769932748919183\n",
      "Loss: 0.5597227071496573\n",
      "Loss: 0.5233227553692731\n",
      "Loss: 0.514982194588943\n",
      "______\n",
      "Iteration t=3\n",
      "all:  cs/acc_i=67.12 cs/acc_c=67.60 os/recall_knw=62.11 os/recall_unk=72.76 total/acc_i=60.28 total/acc_c=55.83 total/h_score=62.64\n",
      "selected:  cs/acc_i=63.78 cs/acc_c=65.05 os/recall_knw=52.67 os/recall_unk=88.22 total/acc_i=61.07 total/acc_c=51.32 total/h_score=63.40\n",
      "Loss: 2.5371434776297894\n",
      "Loss: 1.2988918568148757\n",
      "Loss: 0.8891329316349773\n",
      "Loss: 0.7717129410087288\n",
      "Loss: 0.6521639024024402\n",
      "Loss: 0.614829309123419\n",
      "Loss: 0.579788115439993\n",
      "Loss: 0.5242345638540916\n",
      "Loss: 0.508104100049316\n",
      "Loss: 0.46063903241833565\n",
      "______\n",
      "Iteration t=4\n",
      "all:  cs/acc_i=67.52 cs/acc_c=67.89 os/recall_knw=59.91 os/recall_unk=75.75 total/acc_i=60.44 total/acc_c=54.88 total/h_score=62.94\n",
      "selected:  cs/acc_i=65.89 cs/acc_c=66.73 os/recall_knw=55.71 os/recall_unk=82.68 total/acc_i=60.62 total/acc_c=52.86 total/h_score=63.37\n",
      "Loss: 2.5039045532544453\n",
      "Loss: 1.229868832975626\n",
      "Loss: 0.8515837661921978\n",
      "Loss: 0.7259058612088363\n",
      "Loss: 0.6336561755587657\n",
      "Loss: 0.5852836357429624\n",
      "Loss: 0.5456669903670748\n",
      "Loss: 0.5065555990984042\n",
      "Loss: 0.48278717330346504\n",
      "Loss: 0.43951366848001877\n",
      "______\n",
      "Iteration t=5\n",
      "all:  cs/acc_i=67.87 cs/acc_c=68.54 os/recall_knw=59.21 os/recall_unk=76.58 total/acc_i=60.46 total/acc_c=54.63 total/h_score=63.01\n",
      "selected:  cs/acc_i=67.22 cs/acc_c=68.13 os/recall_knw=57.67 os/recall_unk=79.41 total/acc_i=60.55 total/acc_c=53.95 total/h_score=63.34\n",
      "Loss: 2.4835216640456905\n",
      "Loss: 1.2093046244567003\n",
      "Loss: 0.8556335957312002\n",
      "Loss: 0.7095395725190154\n",
      "Loss: 0.6310069561610377\n",
      "Loss: 0.6068650664595084\n",
      "Loss: 0.5440779665742463\n",
      "Loss: 0.4971498378772077\n",
      "Loss: 0.4711598633992963\n",
      "Loss: 0.42509878584282185\n",
      "______\n",
      "Iteration t=6\n",
      "all:  cs/acc_i=68.42 cs/acc_c=69.04 os/recall_knw=59.01 os/recall_unk=76.83 total/acc_i=60.41 total/acc_c=54.44 total/h_score=62.95\n",
      "selected:  cs/acc_i=68.25 cs/acc_c=68.93 os/recall_knw=58.69 os/recall_unk=77.60 total/acc_i=60.45 total/acc_c=54.29 total/h_score=63.07\n",
      "Loss: 2.4672843232212296\n",
      "Loss: 1.1902693146203895\n",
      "Loss: 0.8156597451512594\n",
      "Loss: 0.7110003835585222\n",
      "Loss: 0.6227124126321341\n",
      "Loss: 0.5562038349219595\n",
      "Loss: 0.5382119347771488\n",
      "Loss: 0.49376762703240634\n",
      "Loss: 0.4335927644886645\n",
      "Loss: 0.43203886942451736\n",
      "______\n",
      "Iteration t=7\n",
      "all:  cs/acc_i=68.30 cs/acc_c=68.92 os/recall_knw=59.01 os/recall_unk=76.83 total/acc_i=60.41 total/acc_c=54.44 total/h_score=62.95\n",
      "selected:  cs/acc_i=68.29 cs/acc_c=68.91 os/recall_knw=59.00 os/recall_unk=77.02 total/acc_i=60.45 total/acc_c=54.44 total/h_score=63.01\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 2.484321943759918\n",
      "Loss: 1.1825245053768159\n",
      "Loss: 0.8419200979471206\n",
      "Loss: 0.6809034578800202\n",
      "Loss: 0.6345776549577713\n",
      "Loss: 0.5649374477267265\n",
      "Loss: 0.5245363231301308\n",
      "Loss: 0.49658902251720427\n",
      "Loss: 0.45144034999608995\n",
      "Loss: 0.4530038810968399\n",
      "______\n",
      "Iteration t=8\n",
      "all:  cs/acc_i=68.50 cs/acc_c=69.06 os/recall_knw=59.01 os/recall_unk=76.83 total/acc_i=60.41 total/acc_c=54.44 total/h_score=62.95\n",
      "selected:  cs/acc_i=68.50 cs/acc_c=69.06 os/recall_knw=59.01 os/recall_unk=76.83 total/acc_i=60.41 total/acc_c=54.44 total/h_score=62.95\n",
      "Loss: 2.466368984222412\n",
      "Loss: 1.1778775615692139\n",
      "Loss: 0.8140800330638885\n",
      "Loss: 0.6928330960273743\n",
      "Loss: 0.631597443163395\n",
      "Loss: 0.5663032661676407\n",
      "Loss: 0.558027377486229\n",
      "Loss: 0.48941148072481155\n",
      "Loss: 0.4510568988919258\n",
      "Loss: 0.43829555466771125\n",
      "______\n",
      "Iteration t=9\n",
      "all:  cs/acc_i=69.20 cs/acc_c=69.60 os/recall_knw=59.01 os/recall_unk=76.83 total/acc_i=60.41 total/acc_c=54.44 total/h_score=62.95\n",
      "selected:  cs/acc_i=69.20 cs/acc_c=69.60 os/recall_knw=59.01 os/recall_unk=76.83 total/acc_i=60.41 total/acc_c=54.44 total/h_score=62.95\n",
      "tensor(0)\n",
      "all:  cs/acc_i=69.20 cs/acc_c=69.60 os/recall_knw=59.01 os/recall_unk=76.83 total/acc_i=60.41 total/acc_c=54.44 total/h_score=62.95\n",
      "sketch -> painting lr= 0.001 seed= 3\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19]\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20]\n",
      "Loss: 2.688228161679101\n",
      "Loss: 1.6004748541055267\n",
      "Loss: 1.1047646089927436\n",
      "Loss: 0.9469215716283346\n",
      "Loss: 0.8297381336541519\n",
      "Loss: 0.7434643725144494\n",
      "Loss: 0.7073162933907557\n",
      "Loss: 0.6557710749894073\n",
      "Loss: 0.6391228036474936\n",
      "Loss: 0.5872229672584337\n",
      "tensor(True) tensor(True)\n",
      "______\n",
      "Iteration t=1\n",
      "all:  cs/acc_i=64.42 cs/acc_c=65.05 os/recall_knw=93.50 os/recall_unk=17.36 total/acc_i=48.54 total/acc_c=61.69 total/h_score=27.30\n",
      "selected:  cs/acc_i=72.13 cs/acc_c=72.61 os/recall_knw=71.08 os/recall_unk=91.67 total/acc_i=73.94 total/acc_c=68.75 total/h_score=77.82\n",
      "Loss: 2.6215226298944962\n",
      "Loss: 1.4669596817758348\n",
      "Loss: 1.0303806718708812\n",
      "Loss: 0.8821895152762316\n",
      "Loss: 0.776751517817594\n",
      "Loss: 0.6937144785975489\n",
      "Loss: 0.6710218650419355\n",
      "Loss: 0.61217026102946\n",
      "Loss: 0.5640893371208854\n",
      "Loss: 0.5377759983142217\n",
      "______\n",
      "Iteration t=2\n",
      "all:  cs/acc_i=64.42 cs/acc_c=64.99 os/recall_knw=63.21 os/recall_unk=72.09 total/acc_i=59.48 total/acc_c=55.13 total/h_score=61.93\n",
      "selected:  cs/acc_i=57.32 cs/acc_c=58.74 os/recall_knw=45.69 os/recall_unk=94.45 total/acc_i=59.71 total/acc_c=45.43 total/h_score=59.07\n",
      "Loss: 2.5731983293186533\n",
      "Loss: 1.3854560125957835\n",
      "Loss: 0.9349799852479588\n",
      "Loss: 0.7920274416154082\n",
      "Loss: 0.7140234076163986\n",
      "Loss: 0.6724940799854019\n",
      "Loss: 0.5940728446299379\n",
      "Loss: 0.5650070762092417\n",
      "Loss: 0.536690088767897\n",
      "Loss: 0.4998258858241818\n",
      "______\n",
      "Iteration t=3\n",
      "all:  cs/acc_i=65.01 cs/acc_c=65.37 os/recall_knw=57.88 os/recall_unk=79.40 total/acc_i=59.90 total/acc_c=52.61 total/h_score=62.31\n",
      "selected:  cs/acc_i=61.16 cs/acc_c=62.26 os/recall_knw=49.27 os/recall_unk=90.36 total/acc_i=59.40 total/acc_c=47.64 total/h_score=60.53\n",
      "Loss: 2.533569229685742\n",
      "Loss: 1.3080211579799652\n",
      "Loss: 0.903452270704767\n",
      "Loss: 0.7635105362404948\n",
      "Loss: 0.6768452727924222\n",
      "Loss: 0.6014184844882592\n",
      "Loss: 0.5723935017119284\n",
      "Loss: 0.529585402880026\n",
      "Loss: 0.4955599128552105\n",
      "Loss: 0.46896371060739395\n",
      "______\n",
      "Iteration t=4\n",
      "all:  cs/acc_i=66.58 cs/acc_c=66.96 os/recall_knw=56.62 os/recall_unk=80.98 total/acc_i=59.96 total/acc_c=52.07 total/h_score=62.30\n",
      "selected:  cs/acc_i=64.93 cs/acc_c=65.81 os/recall_knw=52.83 os/recall_unk=86.05 total/acc_i=59.68 total/acc_c=50.07 total/h_score=61.85\n",
      "Loss: 2.5335934066972814\n",
      "Loss: 1.263196403739833\n",
      "Loss: 0.8620583552773259\n",
      "Loss: 0.7190680675396398\n",
      "Loss: 0.6629294740552661\n",
      "Loss: 0.5847240373367021\n",
      "Loss: 0.5549308231272617\n",
      "Loss: 0.5191923550823155\n",
      "Loss: 0.47842728531285494\n",
      "Loss: 0.454746456018516\n",
      "______\n",
      "Iteration t=5\n",
      "all:  cs/acc_i=66.61 cs/acc_c=66.91 os/recall_knw=56.31 os/recall_unk=81.15 total/acc_i=59.90 total/acc_c=51.91 total/h_score=62.22\n",
      "selected:  cs/acc_i=66.06 cs/acc_c=66.67 os/recall_knw=54.95 os/recall_unk=83.58 total/acc_i=59.96 total/acc_c=51.41 total/h_score=62.41\n",
      "Loss: 2.505065114044946\n",
      "Loss: 1.2354105839059373\n",
      "Loss: 0.8556326978709087\n",
      "Loss: 0.733949503130164\n",
      "Loss: 0.6248328776891566\n",
      "Loss: 0.5692097785428536\n",
      "Loss: 0.5522146291476636\n",
      "Loss: 0.5158747028836534\n",
      "Loss: 0.46209014465739906\n",
      "Loss: 0.4380409204639679\n",
      "______\n",
      "Iteration t=6\n",
      "all:  cs/acc_i=67.12 cs/acc_c=67.45 os/recall_knw=56.23 os/recall_unk=81.15 total/acc_i=59.88 total/acc_c=51.88 total/h_score=62.19\n",
      "selected:  cs/acc_i=67.10 cs/acc_c=67.48 os/recall_knw=55.99 os/recall_unk=81.42 total/acc_i=59.90 total/acc_c=51.84 total/h_score=62.23\n",
      "Loss: 2.480313745810061\n",
      "Loss: 1.2210501308343849\n",
      "Loss: 0.8455354935052444\n",
      "Loss: 0.7191173620369969\n",
      "Loss: 0.6515317376170839\n",
      "Loss: 0.5763869414524156\n",
      "Loss: 0.5124563850918594\n",
      "Loss: 0.5092678237934501\n",
      "Loss: 0.46136220389482924\n",
      "Loss: 0.44780126889141236\n",
      "______\n",
      "Iteration t=7\n",
      "all:  cs/acc_i=67.20 cs/acc_c=67.65 os/recall_knw=56.23 os/recall_unk=81.15 total/acc_i=59.88 total/acc_c=51.88 total/h_score=62.19\n",
      "selected:  cs/acc_i=67.23 cs/acc_c=67.67 os/recall_knw=56.21 os/recall_unk=81.15 total/acc_i=59.89 total/acc_c=51.89 total/h_score=62.20\n",
      "Loss: 2.4927216685884366\n",
      "Loss: 1.2073224320159694\n",
      "Loss: 0.8482582767804464\n",
      "Loss: 0.7165470286840345\n",
      "Loss: 0.6341318459045596\n",
      "Loss: 0.5768662750478682\n",
      "Loss: 0.5450235305399429\n",
      "Loss: 0.5011710945547112\n",
      "Loss: 0.46368727499876566\n",
      "Loss: 0.4291494310023339\n",
      "______\n",
      "Iteration t=8\n",
      "all:  cs/acc_i=67.79 cs/acc_c=68.27 os/recall_knw=56.23 os/recall_unk=81.15 total/acc_i=59.88 total/acc_c=51.88 total/h_score=62.19\n",
      "selected:  cs/acc_i=67.79 cs/acc_c=68.27 os/recall_knw=56.23 os/recall_unk=81.15 total/acc_i=59.88 total/acc_c=51.88 total/h_score=62.19\n",
      "Loss: 2.5212084108251864\n",
      "Loss: 1.2217994514035015\n",
      "Loss: 0.8464519449365817\n",
      "Loss: 0.693688897097983\n",
      "Loss: 0.647636842739776\n",
      "Loss: 0.5802457437403803\n",
      "Loss: 0.5316137103893892\n",
      "Loss: 0.49936449382363296\n",
      "Loss: 0.4701421282034579\n",
      "Loss: 0.44300628023418953\n",
      "______\n",
      "Iteration t=9\n",
      "all:  cs/acc_i=67.40 cs/acc_c=67.58 os/recall_knw=56.23 os/recall_unk=81.15 total/acc_i=59.88 total/acc_c=51.88 total/h_score=62.19\n",
      "selected:  cs/acc_i=67.40 cs/acc_c=67.58 os/recall_knw=56.23 os/recall_unk=81.15 total/acc_i=59.88 total/acc_c=51.88 total/h_score=62.19\n",
      "tensor(0)\n",
      "all:  cs/acc_i=67.40 cs/acc_c=67.58 os/recall_knw=56.23 os/recall_unk=81.15 total/acc_i=59.88 total/acc_c=51.88 total/h_score=62.19\n",
      "sketch -> painting lr= 0.001 seed= 4\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19]\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20]\n",
      "Loss: 2.666938613370522\n",
      "Loss: 1.5753031127231638\n",
      "Loss: 1.1193820745060123\n",
      "Loss: 0.9281479326105609\n",
      "Loss: 0.8620489984750748\n",
      "Loss: 0.7836045347845432\n",
      "Loss: 0.7120245175877797\n",
      "Loss: 0.6956580227490553\n",
      "Loss: 0.6205892366232332\n",
      "Loss: 0.6088014893310586\n",
      "tensor(True) tensor(True)\n",
      "______\n",
      "Iteration t=1\n",
      "all:  cs/acc_i=64.62 cs/acc_c=65.19 os/recall_knw=92.71 os/recall_unk=15.70 total/acc_i=47.68 total/acc_c=61.11 total/h_score=25.16\n",
      "selected:  cs/acc_i=73.32 cs/acc_c=74.42 os/recall_knw=68.79 os/recall_unk=92.65 total/acc_i=72.38 total/acc_c=68.21 total/h_score=77.76\n",
      "Loss: 2.6253594540167544\n",
      "Loss: 1.452380469167866\n",
      "Loss: 1.019555466186597\n",
      "Loss: 0.8471084041295996\n",
      "Loss: 0.7715340131434841\n",
      "Loss: 0.6938744459463202\n",
      "Loss: 0.6438650578116449\n",
      "Loss: 0.604274736078465\n",
      "Loss: 0.5543507998404296\n",
      "Loss: 0.5621899154739104\n",
      "______\n",
      "Iteration t=2\n",
      "all:  cs/acc_i=66.14 cs/acc_c=66.34 os/recall_knw=64.69 os/recall_unk=70.51 total/acc_i=59.61 total/acc_c=55.71 total/h_score=61.78\n",
      "selected:  cs/acc_i=60.59 cs/acc_c=61.61 os/recall_knw=46.69 os/recall_unk=94.23 total/acc_i=60.79 total/acc_c=46.87 total/h_score=60.45\n",
      "Loss: 2.59081380313093\n",
      "Loss: 1.3793189246546138\n",
      "Loss: 0.9591301955960013\n",
      "Loss: 0.7921247598799792\n",
      "Loss: 0.7228788317604499\n",
      "Loss: 0.6389709807255052\n",
      "Loss: 0.6139518976211548\n",
      "Loss: 0.5668777007270943\n",
      "Loss: 0.5186837603422728\n",
      "Loss: 0.513136307082393\n",
      "______\n",
      "Iteration t=3\n",
      "all:  cs/acc_i=66.58 cs/acc_c=66.84 os/recall_knw=56.58 os/recall_unk=79.24 total/acc_i=59.56 total/acc_c=52.10 total/h_score=61.87\n",
      "selected:  cs/acc_i=63.41 cs/acc_c=64.58 os/recall_knw=49.20 os/recall_unk=90.00 total/acc_i=59.27 total/acc_c=47.77 total/h_score=60.58\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 2.5422564455957124\n",
      "Loss: 1.280914386887571\n",
      "Loss: 0.8906836736769903\n",
      "Loss: 0.7645831582866189\n",
      "Loss: 0.6913158599432413\n",
      "Loss: 0.599507877256447\n",
      "Loss: 0.567379085984065\n",
      "Loss: 0.530321641401811\n",
      "Loss: 0.49370195306998826\n",
      "Loss: 0.47104173118159887\n",
      "______\n",
      "Iteration t=4\n",
      "all:  cs/acc_i=67.75 cs/acc_c=68.05 os/recall_knw=55.92 os/recall_unk=79.90 total/acc_i=59.58 total/acc_c=51.87 total/h_score=61.86\n",
      "selected:  cs/acc_i=66.50 cs/acc_c=67.35 os/recall_knw=52.83 os/recall_unk=85.51 total/acc_i=59.69 total/acc_c=50.40 total/h_score=62.01\n",
      "Loss: 2.4967338532960714\n",
      "Loss: 1.2437703589431377\n",
      "Loss: 0.8591286350949472\n",
      "Loss: 0.7333391713244575\n",
      "Loss: 0.6447146846717146\n",
      "Loss: 0.6006371527910233\n",
      "Loss: 0.5464256660652762\n",
      "Loss: 0.515123159131583\n",
      "Loss: 0.48331297627266717\n",
      "Loss: 0.4452666612107213\n",
      "______\n",
      "Iteration t=5\n",
      "all:  cs/acc_i=67.24 cs/acc_c=67.60 os/recall_knw=55.80 os/recall_unk=80.15 total/acc_i=59.61 total/acc_c=51.82 total/h_score=61.89\n",
      "selected:  cs/acc_i=66.91 cs/acc_c=67.48 os/recall_knw=54.81 os/recall_unk=82.55 total/acc_i=59.84 total/acc_c=51.50 total/h_score=62.23\n",
      "Loss: 2.5043557538907715\n",
      "Loss: 1.2237514097994737\n",
      "Loss: 0.849064905334402\n",
      "Loss: 0.731192020967664\n",
      "Loss: 0.6259198166092728\n",
      "Loss: 0.5860419237196691\n",
      "Loss: 0.5361316757805553\n",
      "Loss: 0.5065764018292289\n",
      "Loss: 0.4663320429653788\n",
      "Loss: 0.4350659581123556\n",
      "______\n",
      "Iteration t=6\n",
      "all:  cs/acc_i=68.10 cs/acc_c=68.54 os/recall_knw=55.76 os/recall_unk=80.15 total/acc_i=59.61 total/acc_c=51.82 total/h_score=61.89\n",
      "selected:  cs/acc_i=68.04 cs/acc_c=68.50 os/recall_knw=55.62 os/recall_unk=80.96 total/acc_i=59.74 total/acc_c=51.78 total/h_score=62.06\n",
      "Loss: 2.4862351086674903\n",
      "Loss: 1.2256382998155089\n",
      "Loss: 0.8289142469970547\n",
      "Loss: 0.7381837764564826\n",
      "Loss: 0.618994842682566\n",
      "Loss: 0.5808434216343626\n",
      "Loss: 0.543483090583159\n",
      "Loss: 0.4993485476897687\n",
      "Loss: 0.4622050708653975\n",
      "Loss: 0.43863914362630063\n",
      "______\n",
      "Iteration t=7\n",
      "all:  cs/acc_i=68.38 cs/acc_c=68.68 os/recall_knw=55.76 os/recall_unk=80.15 total/acc_i=59.61 total/acc_c=51.82 total/h_score=61.89\n",
      "selected:  cs/acc_i=68.38 cs/acc_c=68.68 os/recall_knw=55.76 os/recall_unk=80.15 total/acc_i=59.61 total/acc_c=51.82 total/h_score=61.89\n",
      "Loss: 2.49052185450143\n",
      "Loss: 1.2229888337414438\n",
      "Loss: 0.8511692164390068\n",
      "Loss: 0.6917634629379443\n",
      "Loss: 0.6429038756504292\n",
      "Loss: 0.571881096598094\n",
      "Loss: 0.543570782837829\n",
      "Loss: 0.5017364449132748\n",
      "Loss: 0.4739434306577938\n",
      "Loss: 0.44644378077208513\n",
      "______\n",
      "Iteration t=8\n",
      "all:  cs/acc_i=68.30 cs/acc_c=68.64 os/recall_knw=55.76 os/recall_unk=80.15 total/acc_i=59.61 total/acc_c=51.82 total/h_score=61.89\n",
      "selected:  cs/acc_i=68.30 cs/acc_c=68.64 os/recall_knw=55.76 os/recall_unk=80.15 total/acc_i=59.61 total/acc_c=51.82 total/h_score=61.89\n",
      "Loss: 2.4842586527025796\n",
      "Loss: 1.2063630019746177\n",
      "Loss: 0.8396116183782981\n",
      "Loss: 0.718956477758361\n",
      "Loss: 0.6327539827159749\n",
      "Loss: 0.5820492667153598\n",
      "Loss: 0.5440005583128309\n",
      "Loss: 0.4956801905016589\n",
      "Loss: 0.4855151969666888\n",
      "Loss: 0.45721395701412265\n",
      "______\n",
      "Iteration t=9\n",
      "all:  cs/acc_i=67.71 cs/acc_c=68.07 os/recall_knw=55.76 os/recall_unk=80.15 total/acc_i=59.61 total/acc_c=51.82 total/h_score=61.89\n",
      "selected:  cs/acc_i=67.71 cs/acc_c=68.07 os/recall_knw=55.76 os/recall_unk=80.15 total/acc_i=59.61 total/acc_c=51.82 total/h_score=61.89\n",
      "tensor(0)\n",
      "all:  cs/acc_i=67.71 cs/acc_c=68.07 os/recall_knw=55.76 os/recall_unk=80.15 total/acc_i=59.61 total/acc_c=51.82 total/h_score=61.89\n",
      "sketch -> painting lr= 0.001 seed= 0\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19]\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20]\n",
      "Loss: 2.681846787634584\n",
      "Loss: 1.6266439544785882\n",
      "Loss: 1.1311097283338762\n",
      "Loss: 0.9229639619588852\n",
      "Loss: 0.8244871216029236\n",
      "Loss: 0.75177110931308\n",
      "Loss: 0.7159966668210078\n",
      "Loss: 0.6484911904199836\n",
      "Loss: 0.6381740534735709\n",
      "Loss: 0.5940503897433428\n",
      "tensor(True) tensor(True)\n",
      "______\n",
      "Iteration t=1\n",
      "all:  cs/acc_i=65.36 cs/acc_c=66.01 os/recall_knw=81.70 os/recall_unk=39.20 total/acc_i=53.78 total/acc_c=60.36 total/h_score=47.86\n",
      "selected:  cs/acc_i=58.32 cs/acc_c=60.01 os/recall_knw=47.11 os/recall_unk=97.72 total/acc_i=63.47 total/acc_c=49.59 total/h_score=63.64\n",
      "Loss: 2.6223937106017328\n",
      "Loss: 1.4602581778010308\n",
      "Loss: 1.0020783733630525\n",
      "Loss: 0.8592501577835728\n",
      "Loss: 0.7676600046491854\n",
      "Loss: 0.6840926266234854\n",
      "Loss: 0.6603635805816466\n",
      "Loss: 0.5774900771425542\n",
      "Loss: 0.5945281163937803\n",
      "Loss: 0.5300001263042579\n",
      "______\n",
      "Iteration t=2\n",
      "all:  cs/acc_i=66.77 cs/acc_c=67.24 os/recall_knw=60.89 os/recall_unk=74.50 total/acc_i=60.04 total/acc_c=55.04 total/h_score=62.66\n",
      "selected:  cs/acc_i=60.07 cs/acc_c=61.69 os/recall_knw=44.03 os/recall_unk=94.72 total/acc_i=59.41 total/acc_c=45.37 total/h_score=59.06\n",
      "Loss: 2.5730094080621546\n",
      "Loss: 1.3725981836969203\n",
      "Loss: 0.9605678842826323\n",
      "Loss: 0.7952004806561903\n",
      "Loss: 0.6992000819607215\n",
      "Loss: 0.6589203675362196\n",
      "Loss: 0.6076469482346014\n",
      "Loss: 0.5428302642973987\n",
      "Loss: 0.5194341018118641\n",
      "Loss: 0.4924310095608234\n",
      "______\n",
      "Iteration t=3\n",
      "all:  cs/acc_i=66.97 cs/acc_c=67.27 os/recall_knw=58.27 os/recall_unk=79.15 total/acc_i=60.54 total/acc_c=53.81 total/h_score=63.16\n",
      "selected:  cs/acc_i=63.62 cs/acc_c=64.98 os/recall_knw=50.33 os/recall_unk=90.50 total/acc_i=60.34 total/acc_c=49.44 total/h_score=62.21\n",
      "Loss: 2.5340212000396862\n",
      "Loss: 1.2755203430270736\n",
      "Loss: 0.8930855263105203\n",
      "Loss: 0.7610369478211259\n",
      "Loss: 0.6719551176090777\n",
      "Loss: 0.5845784335941463\n",
      "Loss: 0.5893524555545865\n",
      "Loss: 0.5265992452829947\n",
      "Loss: 0.47953143673928783\n",
      "Loss: 0.4807909700003537\n",
      "______\n",
      "Iteration t=4\n",
      "all:  cs/acc_i=67.91 cs/acc_c=68.27 os/recall_knw=57.29 os/recall_unk=80.56 total/acc_i=60.68 total/acc_c=53.39 total/h_score=63.23\n",
      "selected:  cs/acc_i=66.51 cs/acc_c=67.46 os/recall_knw=53.74 os/recall_unk=85.92 total/acc_i=60.63 total/acc_c=51.67 total/h_score=63.18\n",
      "Loss: 2.531481947858962\n",
      "Loss: 1.2561267138026249\n",
      "Loss: 0.8665912135126201\n",
      "Loss: 0.7099019732934162\n",
      "Loss: 0.6334814102579859\n",
      "Loss: 0.588183776292342\n",
      "Loss: 0.5480065247254392\n",
      "Loss: 0.4896603612595522\n",
      "Loss: 0.49919625867360806\n",
      "Loss: 0.4412331107894746\n",
      "______\n",
      "Iteration t=5\n",
      "all:  cs/acc_i=68.50 cs/acc_c=68.71 os/recall_knw=56.97 os/recall_unk=80.73 total/acc_i=60.65 total/acc_c=53.29 total/h_score=63.19\n",
      "selected:  cs/acc_i=67.76 cs/acc_c=68.36 os/recall_knw=55.47 os/recall_unk=83.43 total/acc_i=60.62 total/acc_c=52.66 total/h_score=63.40\n",
      "Loss: 2.5018599764309792\n",
      "Loss: 1.2460712449540816\n",
      "Loss: 0.8504443926575743\n",
      "Loss: 0.7326806136119512\n",
      "Loss: 0.6398431677141307\n",
      "Loss: 0.5867275717695064\n",
      "Loss: 0.5397424268011203\n",
      "Loss: 0.5002817879488439\n",
      "Loss: 0.4883113995255757\n",
      "Loss: 0.4465787241488327\n",
      "______\n",
      "Iteration t=6\n",
      "all:  cs/acc_i=68.89 cs/acc_c=69.38 os/recall_knw=56.97 os/recall_unk=80.81 total/acc_i=60.68 total/acc_c=53.29 total/h_score=63.22\n",
      "selected:  cs/acc_i=68.65 cs/acc_c=69.24 os/recall_knw=56.65 os/recall_unk=81.97 total/acc_i=60.75 total/acc_c=53.14 total/h_score=63.40\n",
      "Loss: 2.485681637031276\n",
      "Loss: 1.2265898456903008\n",
      "Loss: 0.8483609237321993\n",
      "Loss: 0.7085879080421557\n",
      "Loss: 0.6453671571685047\n",
      "Loss: 0.5579283806245502\n",
      "Loss: 0.5484714416287294\n",
      "Loss: 0.49493514522304377\n",
      "Loss: 0.4663938532272975\n",
      "Loss: 0.43862262943653557\n",
      "______\n",
      "Iteration t=7\n",
      "all:  cs/acc_i=69.08 cs/acc_c=69.32 os/recall_knw=56.97 os/recall_unk=80.81 total/acc_i=60.68 total/acc_c=53.29 total/h_score=63.22\n",
      "selected:  cs/acc_i=69.05 cs/acc_c=69.29 os/recall_knw=56.92 os/recall_unk=80.88 total/acc_i=60.66 total/acc_c=53.26 total/h_score=63.21\n",
      "Loss: 2.489879744255591\n",
      "Loss: 1.2073837726222358\n",
      "Loss: 0.8311154771188975\n",
      "Loss: 0.711335100143062\n",
      "Loss: 0.6078146488560356\n",
      "Loss: 0.5841923159385017\n",
      "Loss: 0.5259808877460387\n",
      "Loss: 0.5079148929973363\n",
      "Loss: 0.45021707700331687\n",
      "Loss: 0.44450227361217687\n",
      "______\n",
      "Iteration t=8\n",
      "all:  cs/acc_i=68.69 cs/acc_c=69.15 os/recall_knw=56.97 os/recall_unk=80.81 total/acc_i=60.68 total/acc_c=53.29 total/h_score=63.22\n",
      "selected:  cs/acc_i=68.69 cs/acc_c=69.15 os/recall_knw=56.97 os/recall_unk=80.81 total/acc_i=60.68 total/acc_c=53.29 total/h_score=63.22\n",
      "Loss: 2.482753984841258\n",
      "Loss: 1.2090343203139209\n",
      "Loss: 0.854241024868691\n",
      "Loss: 0.711201016236896\n",
      "Loss: 0.6509612807136799\n",
      "Loss: 0.5558249589040695\n",
      "Loss: 0.5202850332023644\n",
      "Loss: 0.5062646477931907\n",
      "Loss: 0.4652842855163914\n",
      "Loss: 0.4510190173199302\n",
      "______\n",
      "Iteration t=9\n",
      "all:  cs/acc_i=68.61 cs/acc_c=69.29 os/recall_knw=56.97 os/recall_unk=80.81 total/acc_i=60.68 total/acc_c=53.29 total/h_score=63.22\n",
      "selected:  cs/acc_i=68.61 cs/acc_c=69.29 os/recall_knw=56.97 os/recall_unk=80.81 total/acc_i=60.68 total/acc_c=53.29 total/h_score=63.22\n",
      "tensor(0)\n",
      "all:  cs/acc_i=68.61 cs/acc_c=69.29 os/recall_knw=56.97 os/recall_unk=80.81 total/acc_i=60.68 total/acc_c=53.29 total/h_score=63.22\n",
      "sketch -> painting lr= 0.001 seed= 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19]\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20]\n",
      "Loss: 2.678762985873468\n",
      "Loss: 1.6004630554582655\n",
      "Loss: 1.1341367093558163\n",
      "Loss: 0.9469283845314046\n",
      "Loss: 0.8444225041522193\n",
      "Loss: 0.764655842455392\n",
      "Loss: 0.7039793122982242\n",
      "Loss: 0.6708756688329363\n",
      "Loss: 0.6304097363014811\n",
      "Loss: 0.6100357244770551\n",
      "tensor(True) tensor(True)\n",
      "______\n",
      "Iteration t=1\n",
      "all:  cs/acc_i=65.32 cs/acc_c=65.74 os/recall_knw=81.15 os/recall_unk=38.04 total/acc_i=53.30 total/acc_c=59.89 total/h_score=46.85\n",
      "selected:  cs/acc_i=57.37 cs/acc_c=59.69 os/recall_knw=45.89 os/recall_unk=96.22 total/acc_i=61.90 total/acc_c=48.91 total/h_score=62.74\n",
      "Loss: 2.631253445206057\n",
      "Loss: 1.4452815176784128\n",
      "Loss: 1.004220666948724\n",
      "Loss: 0.846004725654344\n",
      "Loss: 0.7811021898391742\n",
      "Loss: 0.7005097771036453\n",
      "Loss: 0.6499428111285979\n",
      "Loss: 0.6240385995394941\n",
      "Loss: 0.5618426048957207\n",
      "Loss: 0.5321630543268822\n",
      "______\n",
      "Iteration t=2\n",
      "all:  cs/acc_i=65.79 cs/acc_c=66.34 os/recall_knw=63.60 os/recall_unk=70.85 total/acc_i=59.64 total/acc_c=55.91 total/h_score=62.03\n",
      "selected:  cs/acc_i=59.43 cs/acc_c=60.98 os/recall_knw=45.61 os/recall_unk=94.15 total/acc_i=60.29 total/acc_c=46.77 total/h_score=60.35\n",
      "Loss: 2.581913676587018\n",
      "Loss: 1.3523018403486773\n",
      "Loss: 0.9280736730857329\n",
      "Loss: 0.7679184782234105\n",
      "Loss: 0.6835322474891489\n",
      "Loss: 0.6448869616470554\n",
      "Loss: 0.6047856114127419\n",
      "Loss: 0.5712579024786298\n",
      "Loss: 0.528702395951206\n",
      "Loss: 0.5011760883033276\n",
      "______\n",
      "Iteration t=3\n",
      "all:  cs/acc_i=66.58 cs/acc_c=67.05 os/recall_knw=55.96 os/recall_unk=80.23 total/acc_i=59.77 total/acc_c=52.25 total/h_score=62.25\n",
      "selected:  cs/acc_i=62.95 cs/acc_c=64.20 os/recall_knw=47.94 os/recall_unk=89.20 total/acc_i=58.76 total/acc_c=47.22 total/h_score=59.93\n",
      "Loss: 2.5294874383055643\n",
      "Loss: 1.2926548309948134\n",
      "Loss: 0.9078241494686707\n",
      "Loss: 0.7589285529178121\n",
      "Loss: 0.6695923177444416\n",
      "Loss: 0.620659550246985\n",
      "Loss: 0.596072001107361\n",
      "Loss: 0.5361328110746716\n",
      "Loss: 0.5036591023854587\n",
      "Loss: 0.4617566236335298\n",
      "______\n",
      "Iteration t=4\n",
      "all:  cs/acc_i=66.93 cs/acc_c=67.20 os/recall_knw=55.05 os/recall_unk=81.56 total/acc_i=59.80 total/acc_c=51.73 total/h_score=62.18\n",
      "selected:  cs/acc_i=65.57 cs/acc_c=66.23 os/recall_knw=51.73 os/recall_unk=86.60 total/acc_i=59.72 total/acc_c=49.91 total/h_score=61.83\n",
      "Loss: 2.4977471677562857\n",
      "Loss: 1.262021556433746\n",
      "Loss: 0.8636000229336541\n",
      "Loss: 0.7299009517526828\n",
      "Loss: 0.6650592931212252\n",
      "Loss: 0.6173457992479268\n",
      "Loss: 0.5358341665081837\n",
      "Loss: 0.5213911705630742\n",
      "Loss: 0.48461681334026757\n",
      "Loss: 0.45984606774924675\n",
      "______\n",
      "Iteration t=5\n",
      "all:  cs/acc_i=68.30 cs/acc_c=68.57 os/recall_knw=55.02 os/recall_unk=81.81 total/acc_i=59.88 total/acc_c=51.74 total/h_score=62.25\n",
      "selected:  cs/acc_i=67.90 cs/acc_c=68.31 os/recall_knw=53.93 os/recall_unk=83.69 total/acc_i=59.91 total/acc_c=51.23 total/h_score=62.29\n",
      "Loss: 2.4903862604424973\n",
      "Loss: 1.2163623150222558\n",
      "Loss: 0.8406091249925046\n",
      "Loss: 0.7287310668505913\n",
      "Loss: 0.6524396970991261\n",
      "Loss: 0.5960271422528038\n",
      "Loss: 0.5501288596140451\n",
      "Loss: 0.5111345181718838\n",
      "Loss: 0.47152684413450807\n",
      "Loss: 0.44533727564348663\n",
      "______\n",
      "Iteration t=6\n",
      "all:  cs/acc_i=67.63 cs/acc_c=68.28 os/recall_knw=55.02 os/recall_unk=81.81 total/acc_i=59.88 total/acc_c=51.74 total/h_score=62.25\n",
      "selected:  cs/acc_i=67.60 cs/acc_c=68.26 os/recall_knw=54.75 os/recall_unk=82.15 total/acc_i=59.90 total/acc_c=51.66 total/h_score=62.27\n",
      "Loss: 2.497772342357479\n",
      "Loss: 1.2193610265118178\n",
      "Loss: 0.8467066242802338\n",
      "Loss: 0.7252930590852362\n",
      "Loss: 0.6275133634688425\n",
      "Loss: 0.5771357470237818\n",
      "Loss: 0.5387999084396441\n",
      "Loss: 0.5081678236239269\n",
      "Loss: 0.45567450247949265\n",
      "Loss: 0.44942951440566875\n",
      "______\n",
      "Iteration t=7\n",
      "all:  cs/acc_i=67.95 cs/acc_c=68.12 os/recall_knw=54.94 os/recall_unk=81.81 total/acc_i=59.88 total/acc_c=51.74 total/h_score=62.25\n",
      "selected:  cs/acc_i=67.93 cs/acc_c=68.11 os/recall_knw=54.92 os/recall_unk=81.81 total/acc_i=59.87 total/acc_c=51.74 total/h_score=62.25\n",
      "Loss: 2.4868548388383824\n",
      "Loss: 1.2227675447658617\n",
      "Loss: 0.8582570155056155\n",
      "Loss: 0.7158196476041054\n",
      "Loss: 0.649162454690252\n",
      "Loss: 0.5910924238209821\n",
      "Loss: 0.5160446903535298\n",
      "Loss: 0.4954276065437161\n",
      "Loss: 0.490834393002549\n",
      "Loss: 0.4571364767089182\n",
      "______\n",
      "Iteration t=8\n",
      "all:  cs/acc_i=68.38 cs/acc_c=68.86 os/recall_knw=54.94 os/recall_unk=81.81 total/acc_i=59.88 total/acc_c=51.74 total/h_score=62.25\n",
      "selected:  cs/acc_i=68.38 cs/acc_c=68.86 os/recall_knw=54.94 os/recall_unk=81.81 total/acc_i=59.88 total/acc_c=51.74 total/h_score=62.25\n",
      "Loss: 2.493009694741697\n",
      "Loss: 1.2200191495369892\n",
      "Loss: 0.8432078963639785\n",
      "Loss: 0.7236105816704886\n",
      "Loss: 0.6264247396770789\n",
      "Loss: 0.6067464728136451\n",
      "Loss: 0.5371502913382589\n",
      "Loss: 0.5227237930711435\n",
      "Loss: 0.44939410212088604\n",
      "Loss: 0.44096982509505994\n",
      "______\n",
      "Iteration t=9\n",
      "all:  cs/acc_i=68.73 cs/acc_c=69.16 os/recall_knw=54.94 os/recall_unk=81.81 total/acc_i=59.88 total/acc_c=51.74 total/h_score=62.25\n",
      "selected:  cs/acc_i=68.73 cs/acc_c=69.16 os/recall_knw=54.94 os/recall_unk=81.81 total/acc_i=59.88 total/acc_c=51.74 total/h_score=62.25\n",
      "tensor(0)\n",
      "all:  cs/acc_i=68.73 cs/acc_c=69.16 os/recall_knw=54.94 os/recall_unk=81.81 total/acc_i=59.88 total/acc_c=51.74 total/h_score=62.25\n",
      "sketch -> painting lr= 0.001 seed= 2\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19]\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20]\n",
      "Loss: 2.681812741707281\n",
      "Loss: 1.5918174343010814\n",
      "Loss: 1.1365719311630602\n",
      "Loss: 0.9605437730698242\n",
      "Loss: 0.8085713086976218\n",
      "Loss: 0.7594153344938436\n",
      "Loss: 0.6981405459113956\n",
      "Loss: 0.6540192440920269\n",
      "Loss: 0.6453872157126358\n",
      "Loss: 0.5959491837270481\n",
      "tensor(True) tensor(True)\n",
      "______\n",
      "Iteration t=1\n",
      "all:  cs/acc_i=65.20 cs/acc_c=65.89 os/recall_knw=81.62 os/recall_unk=39.04 total/acc_i=53.94 total/acc_c=60.69 total/h_score=47.84\n",
      "selected:  cs/acc_i=56.88 cs/acc_c=58.55 os/recall_knw=46.64 os/recall_unk=96.51 total/acc_i=63.10 total/acc_c=49.35 total/h_score=63.21\n",
      "Loss: 2.6238671760052297\n",
      "Loss: 1.4848957525359259\n",
      "Loss: 1.0373545781425808\n",
      "Loss: 0.8536997474909981\n",
      "Loss: 0.7709343424741772\n",
      "Loss: 0.6958810603561033\n",
      "Loss: 0.6717209148666133\n",
      "Loss: 0.5945428391729576\n",
      "Loss: 0.5671904418203566\n",
      "Loss: 0.5373052972670339\n",
      "______\n",
      "Iteration t=2\n",
      "all:  cs/acc_i=66.73 cs/acc_c=67.14 os/recall_knw=66.38 os/recall_unk=65.12 total/acc_i=58.41 total/acc_c=56.40 total/h_score=60.19\n",
      "selected:  cs/acc_i=62.43 cs/acc_c=63.56 os/recall_knw=47.84 os/recall_unk=94.12 total/acc_i=61.26 total/acc_c=48.78 total/h_score=62.26\n",
      "Loss: 2.567192938111045\n",
      "Loss: 1.368510772694241\n",
      "Loss: 0.9412754642692479\n",
      "Loss: 0.7885490580038591\n",
      "Loss: 0.6911382818763906\n",
      "Loss: 0.6869578949429772\n",
      "Loss: 0.5956283713606271\n",
      "Loss: 0.5537628737362948\n",
      "Loss: 0.5423118398270824\n",
      "Loss: 0.5110931955955246\n",
      "______\n",
      "Iteration t=3\n",
      "all:  cs/acc_i=67.12 cs/acc_c=67.47 os/recall_knw=62.46 os/recall_unk=71.10 total/acc_i=59.42 total/acc_c=55.38 total/h_score=61.76\n",
      "selected:  cs/acc_i=64.88 cs/acc_c=65.80 os/recall_knw=52.81 os/recall_unk=88.80 total/acc_i=61.32 total/acc_c=51.82 total/h_score=63.95\n",
      "Loss: 2.528449942023207\n",
      "Loss: 1.319962357545828\n",
      "Loss: 0.9021093503479317\n",
      "Loss: 0.7505499626392926\n",
      "Loss: 0.6863104000494078\n",
      "Loss: 0.6434297881601176\n",
      "Loss: 0.5843167823630494\n",
      "Loss: 0.5350051668363732\n",
      "Loss: 0.50499966263255\n",
      "Loss: 0.480284439794945\n",
      "______\n",
      "Iteration t=4\n",
      "all:  cs/acc_i=66.89 cs/acc_c=67.35 os/recall_knw=60.78 os/recall_unk=73.17 total/acc_i=59.48 total/acc_c=54.65 total/h_score=61.96\n",
      "selected:  cs/acc_i=65.60 cs/acc_c=66.38 os/recall_knw=56.13 os/recall_unk=81.42 total/acc_i=60.17 total/acc_c=52.73 total/h_score=62.94\n",
      "Loss: 2.502451990544796\n",
      "Loss: 1.2531436135371525\n",
      "Loss: 0.8717997976889212\n",
      "Loss: 0.7241350979854663\n",
      "Loss: 0.651523394882679\n",
      "Loss: 0.576492034830153\n",
      "Loss: 0.5367426861698429\n",
      "Loss: 0.49914240197589\n",
      "Loss: 0.47884161279847226\n",
      "Loss: 0.46996200292681656\n",
      "______\n",
      "Iteration t=5\n",
      "all:  cs/acc_i=67.24 cs/acc_c=67.83 os/recall_knw=59.60 os/recall_unk=74.00 total/acc_i=59.35 total/acc_c=54.11 total/h_score=61.85\n",
      "selected:  cs/acc_i=66.65 cs/acc_c=67.50 os/recall_knw=57.66 os/recall_unk=77.82 total/acc_i=59.66 total/acc_c=53.40 total/h_score=62.47\n",
      "Loss: 2.475534677505493\n",
      "Loss: 1.207131121459046\n",
      "Loss: 0.8508938089376543\n",
      "Loss: 0.7012070772366795\n",
      "Loss: 0.6519673269211761\n",
      "Loss: 0.5824219867950533\n",
      "Loss: 0.5479677638750735\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.49670686657593505\n",
      "Loss: 0.4751929966354273\n",
      "Loss: 0.43895049205398173\n",
      "______\n",
      "Iteration t=6\n",
      "all:  cs/acc_i=68.22 cs/acc_c=68.53 os/recall_knw=59.52 os/recall_unk=74.17 total/acc_i=59.37 total/acc_c=54.09 total/h_score=61.88\n",
      "selected:  cs/acc_i=68.16 cs/acc_c=68.58 os/recall_knw=59.14 os/recall_unk=75.11 total/acc_i=59.51 total/acc_c=54.07 total/h_score=62.16\n",
      "Loss: 2.4841355333328248\n",
      "Loss: 1.2393912284374238\n",
      "Loss: 0.8420493328571319\n",
      "Loss: 0.7077124919891358\n",
      "Loss: 0.6351994297504425\n",
      "Loss: 0.5839650220870972\n",
      "Loss: 0.5236057014465332\n",
      "Loss: 0.4905362875759602\n",
      "Loss: 0.45871498823165896\n",
      "Loss: 0.44118745481967925\n",
      "______\n",
      "Iteration t=7\n",
      "all:  cs/acc_i=68.03 cs/acc_c=68.49 os/recall_knw=59.52 os/recall_unk=74.25 total/acc_i=59.40 total/acc_c=54.10 total/h_score=61.91\n",
      "selected:  cs/acc_i=68.01 cs/acc_c=68.48 os/recall_knw=59.51 os/recall_unk=74.44 total/acc_i=59.43 total/acc_c=54.10 total/h_score=61.97\n",
      "Loss: 2.489732061724264\n",
      "Loss: 1.2109968234818296\n",
      "Loss: 0.8553059793326009\n",
      "Loss: 0.6912386191793647\n",
      "Loss: 0.6350771850086303\n",
      "Loss: 0.5827088233721683\n",
      "Loss: 0.5159708144536531\n",
      "Loss: 0.49643676457889524\n",
      "Loss: 0.4643044376159569\n",
      "Loss: 0.4399851559405308\n",
      "______\n",
      "Iteration t=8\n",
      "all:  cs/acc_i=68.22 cs/acc_c=68.96 os/recall_knw=59.52 os/recall_unk=74.25 total/acc_i=59.40 total/acc_c=54.10 total/h_score=61.91\n",
      "selected:  cs/acc_i=68.22 cs/acc_c=68.96 os/recall_knw=59.52 os/recall_unk=74.25 total/acc_i=59.40 total/acc_c=54.10 total/h_score=61.91\n",
      "Loss: 2.483971641833089\n",
      "Loss: 1.1984054980524983\n",
      "Loss: 0.8309636233574841\n",
      "Loss: 0.6933384594689327\n",
      "Loss: 0.621153763506517\n",
      "Loss: 0.5794933997539885\n",
      "Loss: 0.561644273747011\n",
      "Loss: 0.4900192152931396\n",
      "Loss: 0.4490098879631772\n",
      "Loss: 0.4344553968227242\n",
      "______\n",
      "Iteration t=9\n",
      "all:  cs/acc_i=68.42 cs/acc_c=68.90 os/recall_knw=59.52 os/recall_unk=74.25 total/acc_i=59.40 total/acc_c=54.10 total/h_score=61.91\n",
      "selected:  cs/acc_i=68.42 cs/acc_c=68.90 os/recall_knw=59.52 os/recall_unk=74.25 total/acc_i=59.40 total/acc_c=54.10 total/h_score=61.91\n",
      "tensor(0)\n",
      "all:  cs/acc_i=68.42 cs/acc_c=68.90 os/recall_knw=59.52 os/recall_unk=74.25 total/acc_i=59.40 total/acc_c=54.10 total/h_score=61.91\n",
      "sketch -> painting lr= 0.001 seed= 3\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19]\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20]\n",
      "Loss: 2.6873654987394193\n",
      "Loss: 1.6019013053977613\n",
      "Loss: 1.105458831664213\n",
      "Loss: 0.9471853357000449\n",
      "Loss: 0.8291583958360338\n",
      "Loss: 0.7429131227977497\n",
      "Loss: 0.7070281250575154\n",
      "Loss: 0.6538492877458789\n",
      "Loss: 0.6389789783309415\n",
      "Loss: 0.5857023300276589\n",
      "tensor(True) tensor(True)\n",
      "______\n",
      "Iteration t=1\n",
      "all:  cs/acc_i=64.38 cs/acc_c=64.99 os/recall_knw=81.35 os/recall_unk=38.46 total/acc_i=53.38 total/acc_c=60.10 total/h_score=47.23\n",
      "selected:  cs/acc_i=54.76 cs/acc_c=56.46 os/recall_knw=46.03 os/recall_unk=95.46 total/acc_i=61.81 total/acc_c=48.14 total/h_score=61.88\n",
      "Loss: 2.637858964394832\n",
      "Loss: 1.462021467190434\n",
      "Loss: 1.0224315727102584\n",
      "Loss: 0.8834501208314574\n",
      "Loss: 0.7677613395999595\n",
      "Loss: 0.698529369013321\n",
      "Loss: 0.6481491704493905\n",
      "Loss: 0.614914467441287\n",
      "Loss: 0.5492832007759435\n",
      "Loss: 0.5355308112026989\n",
      "______\n",
      "Iteration t=2\n",
      "all:  cs/acc_i=65.60 cs/acc_c=65.97 os/recall_knw=60.89 os/recall_unk=74.75 total/acc_i=59.66 total/acc_c=54.33 total/h_score=62.24\n",
      "selected:  cs/acc_i=58.73 cs/acc_c=59.92 os/recall_knw=43.81 os/recall_unk=94.44 total/acc_i=59.00 total/acc_c=44.28 total/h_score=57.93\n",
      "Loss: 2.5807832143523477\n",
      "Loss: 1.3742171509699388\n",
      "Loss: 0.9696033374829726\n",
      "Loss: 0.8000483641570265\n",
      "Loss: 0.7109174739230762\n",
      "Loss: 0.6442620032212951\n",
      "Loss: 0.6067428400570696\n",
      "Loss: 0.5550114941190589\n",
      "Loss: 0.5218893914060159\n",
      "Loss: 0.4951170968061144\n",
      "______\n",
      "Iteration t=3\n",
      "all:  cs/acc_i=66.03 cs/acc_c=66.43 os/recall_knw=57.76 os/recall_unk=78.99 total/acc_i=60.01 total/acc_c=53.06 total/h_score=62.54\n",
      "selected:  cs/acc_i=62.28 cs/acc_c=63.65 os/recall_knw=49.48 os/recall_unk=89.80 total/acc_i=59.44 total/acc_c=48.28 total/h_score=61.02\n",
      "Loss: 2.5405722115350806\n",
      "Loss: 1.2899791766767916\n",
      "Loss: 0.9058247240989105\n",
      "Loss: 0.7725253591071004\n",
      "Loss: 0.6663546205862708\n",
      "Loss: 0.6171011041040005\n",
      "Loss: 0.5714837746775668\n",
      "Loss: 0.5262421749856161\n",
      "Loss: 0.4747050132440484\n",
      "Loss: 0.4809523047960323\n",
      "______\n",
      "Iteration t=4\n",
      "all:  cs/acc_i=66.58 cs/acc_c=67.01 os/recall_knw=56.70 os/recall_unk=80.90 total/acc_i=60.22 total/acc_c=52.62 total/h_score=62.71\n",
      "selected:  cs/acc_i=64.94 cs/acc_c=65.95 os/recall_knw=53.38 os/recall_unk=85.44 total/acc_i=59.89 total/acc_c=50.74 total/h_score=62.28\n",
      "Loss: 2.5275247895069204\n",
      "Loss: 1.2722875443462547\n",
      "Loss: 0.8670749000924401\n",
      "Loss: 0.7102195222756853\n",
      "Loss: 0.6460581097642747\n",
      "Loss: 0.5876616812837174\n",
      "Loss: 0.5563194070899836\n",
      "Loss: 0.5175742227662059\n",
      "Loss: 0.4709948299444869\n",
      "Loss: 0.4584229332258512\n",
      "______\n",
      "Iteration t=5\n",
      "all:  cs/acc_i=67.75 cs/acc_c=68.16 os/recall_knw=56.35 os/recall_unk=81.23 total/acc_i=60.12 total/acc_c=52.32 total/h_score=62.56\n",
      "selected:  cs/acc_i=67.27 cs/acc_c=67.92 os/recall_knw=55.26 os/recall_unk=83.45 total/acc_i=60.19 total/acc_c=51.81 total/h_score=62.71\n",
      "Loss: 2.498874533323594\n",
      "Loss: 1.2277280732437417\n",
      "Loss: 0.858981343576447\n",
      "Loss: 0.7331384523415271\n",
      "Loss: 0.6441670380256794\n",
      "Loss: 0.5832137924162939\n",
      "Loss: 0.5376113645824385\n",
      "Loss: 0.4930306890741788\n",
      "Loss: 0.4568249408477618\n",
      "Loss: 0.4384977789634049\n",
      "______\n",
      "Iteration t=6\n",
      "all:  cs/acc_i=67.20 cs/acc_c=67.56 os/recall_knw=56.23 os/recall_unk=81.48 total/acc_i=60.17 total/acc_c=52.29 total/h_score=62.61\n",
      "selected:  cs/acc_i=67.14 cs/acc_c=67.56 os/recall_knw=55.99 os/recall_unk=82.30 total/acc_i=60.29 total/acc_c=52.26 total/h_score=62.79\n",
      "Loss: 2.503723317749646\n",
      "Loss: 1.2190229608088123\n",
      "Loss: 0.8591194503161372\n",
      "Loss: 0.715594655396987\n",
      "Loss: 0.6431580766123168\n",
      "Loss: 0.5705464375870568\n",
      "Loss: 0.5280158225370913\n",
      "Loss: 0.48054261475193255\n",
      "Loss: 0.4620857185855204\n",
      "Loss: 0.4332826981130911\n",
      "______\n",
      "Iteration t=7\n",
      "all:  cs/acc_i=67.55 cs/acc_c=67.84 os/recall_knw=56.19 os/recall_unk=81.48 total/acc_i=60.17 total/acc_c=52.29 total/h_score=62.61\n",
      "selected:  cs/acc_i=67.55 cs/acc_c=67.84 os/recall_knw=56.19 os/recall_unk=81.55 total/acc_i=60.19 total/acc_c=52.30 total/h_score=62.63\n",
      "Loss: 2.478687895991938\n",
      "Loss: 1.226550464223071\n",
      "Loss: 0.8429365076912128\n",
      "Loss: 0.7218189503603835\n",
      "Loss: 0.6321794211379881\n",
      "Loss: 0.5712973082332107\n",
      "Loss: 0.5464207325887874\n",
      "Loss: 0.4988830649271244\n",
      "Loss: 0.4580072630348244\n",
      "Loss: 0.44617416591542525\n",
      "______\n",
      "Iteration t=8\n",
      "all:  cs/acc_i=67.79 cs/acc_c=68.29 os/recall_knw=56.19 os/recall_unk=81.48 total/acc_i=60.17 total/acc_c=52.29 total/h_score=62.61\n",
      "selected:  cs/acc_i=67.79 cs/acc_c=68.29 os/recall_knw=56.19 os/recall_unk=81.48 total/acc_i=60.17 total/acc_c=52.29 total/h_score=62.61\n",
      "Loss: 2.4823071888791834\n",
      "Loss: 1.2051213839189794\n",
      "Loss: 0.8504890107769307\n",
      "Loss: 0.7062343483775612\n",
      "Loss: 0.638869726682097\n",
      "Loss: 0.5913404875654515\n",
      "Loss: 0.5385535486587664\n",
      "Loss: 0.48833028857058625\n",
      "Loss: 0.46902882852932304\n",
      "Loss: 0.43542981644471485\n",
      "______\n",
      "Iteration t=9\n",
      "all:  cs/acc_i=67.83 cs/acc_c=68.26 os/recall_knw=56.19 os/recall_unk=81.48 total/acc_i=60.17 total/acc_c=52.29 total/h_score=62.61\n",
      "selected:  cs/acc_i=67.83 cs/acc_c=68.26 os/recall_knw=56.19 os/recall_unk=81.48 total/acc_i=60.17 total/acc_c=52.29 total/h_score=62.61\n",
      "tensor(0)\n",
      "all:  cs/acc_i=67.83 cs/acc_c=68.26 os/recall_knw=56.19 os/recall_unk=81.48 total/acc_i=60.17 total/acc_c=52.29 total/h_score=62.61\n",
      "sketch -> painting lr= 0.001 seed= 4\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19]\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20]\n",
      "Loss: 2.6688000645834147\n",
      "Loss: 1.575663354593454\n",
      "Loss: 1.1183016693469174\n",
      "Loss: 0.9263536297168928\n",
      "Loss: 0.8592048162959286\n",
      "Loss: 0.7819119811672526\n",
      "Loss: 0.710277493467036\n",
      "Loss: 0.6927452783301934\n",
      "Loss: 0.6182282722948753\n",
      "Loss: 0.6059146062614992\n",
      "tensor(True) tensor(True)\n",
      "______\n",
      "Iteration t=1\n",
      "all:  cs/acc_i=64.85 cs/acc_c=65.57 os/recall_knw=81.47 os/recall_unk=38.70 total/acc_i=52.96 total/acc_c=59.46 total/h_score=47.21\n",
      "selected:  cs/acc_i=59.41 cs/acc_c=61.25 os/recall_knw=46.67 os/recall_unk=97.08 total/acc_i=62.98 total/acc_c=49.40 total/h_score=63.36\n",
      "Loss: 2.6231893732927847\n",
      "Loss: 1.4303248205046724\n",
      "Loss: 1.0137535117674565\n",
      "Loss: 0.8594282050639535\n",
      "Loss: 0.7525867049532812\n",
      "Loss: 0.695633327903379\n",
      "Loss: 0.6538064377607354\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.6031508487491792\n",
      "Loss: 0.5682481667701749\n",
      "Loss: 0.5420629117943815\n",
      "______\n",
      "Iteration t=2\n",
      "all:  cs/acc_i=66.81 cs/acc_c=67.29 os/recall_knw=62.97 os/recall_unk=70.76 total/acc_i=59.19 total/acc_c=55.22 total/h_score=61.54\n",
      "selected:  cs/acc_i=60.98 cs/acc_c=62.05 os/recall_knw=45.12 os/recall_unk=94.56 total/acc_i=59.78 total/acc_c=45.70 total/h_score=59.36\n",
      "Loss: 2.58169250163165\n",
      "Loss: 1.3832142269069498\n",
      "Loss: 0.9354226044633172\n",
      "Loss: 0.8070674889466979\n",
      "Loss: 0.7055267747152936\n",
      "Loss: 0.6306847889992324\n",
      "Loss: 0.6074622005224228\n",
      "Loss: 0.5741414532742717\n",
      "Loss: 0.5401097618720748\n",
      "Loss: 0.5064931490204551\n",
      "______\n",
      "Iteration t=3\n",
      "all:  cs/acc_i=66.73 cs/acc_c=67.03 os/recall_knw=60.07 os/recall_unk=75.42 total/acc_i=59.82 total/acc_c=54.18 total/h_score=62.33\n",
      "selected:  cs/acc_i=63.27 cs/acc_c=64.08 os/recall_knw=51.08 os/recall_unk=89.19 total/acc_i=60.05 total/acc_c=49.34 total/h_score=61.86\n",
      "Loss: 2.5436847158324665\n",
      "Loss: 1.2636122938358423\n",
      "Loss: 0.9019293907658879\n",
      "Loss: 0.7486986489523024\n",
      "Loss: 0.6730935970942179\n",
      "Loss: 0.5994983999244062\n",
      "Loss: 0.5519075004053322\n",
      "Loss: 0.530126541143372\n",
      "Loss: 0.5013015086387659\n",
      "Loss: 0.4445087572325876\n",
      "______\n",
      "Iteration t=4\n",
      "all:  cs/acc_i=67.83 cs/acc_c=68.04 os/recall_knw=59.60 os/recall_unk=75.91 total/acc_i=59.90 total/acc_c=54.07 total/h_score=62.40\n",
      "selected:  cs/acc_i=66.70 cs/acc_c=67.51 os/recall_knw=55.46 os/recall_unk=83.78 total/acc_i=60.57 total/acc_c=52.62 total/h_score=63.45\n",
      "Loss: 2.481467833121618\n",
      "Loss: 1.2487087925275167\n",
      "Loss: 0.867805594826738\n",
      "Loss: 0.7412364219625791\n",
      "Loss: 0.6388058713947733\n",
      "Loss: 0.602741973909239\n",
      "Loss: 0.5540302716195583\n",
      "Loss: 0.5048036103447279\n",
      "Loss: 0.46972607790182036\n",
      "Loss: 0.4588160072763761\n",
      "______\n",
      "Iteration t=5\n",
      "all:  cs/acc_i=67.83 cs/acc_c=68.15 os/recall_knw=58.70 os/recall_unk=77.41 total/acc_i=60.04 total/acc_c=53.68 total/h_score=62.56\n",
      "selected:  cs/acc_i=67.21 cs/acc_c=67.98 os/recall_knw=57.07 os/recall_unk=80.14 total/acc_i=60.09 total/acc_c=53.15 total/h_score=62.93\n",
      "Loss: 2.502123681866393\n",
      "Loss: 1.2212004192021428\n",
      "Loss: 0.8582891274471672\n",
      "Loss: 0.704743144828446\n",
      "Loss: 0.6345775269732183\n",
      "Loss: 0.577063113390183\n",
      "Loss: 0.5340599740038112\n",
      "Loss: 0.508657228277654\n",
      "Loss: 0.4790923546163403\n",
      "Loss: 0.44445845460405153\n",
      "______\n",
      "Iteration t=6\n",
      "all:  cs/acc_i=68.42 cs/acc_c=68.71 os/recall_knw=58.62 os/recall_unk=77.82 total/acc_i=60.12 total/acc_c=53.60 total/h_score=62.62\n",
      "selected:  cs/acc_i=68.26 cs/acc_c=68.65 os/recall_knw=58.26 os/recall_unk=78.87 total/acc_i=60.22 total/acc_c=53.50 total/h_score=62.84\n",
      "Loss: 2.4840982388104162\n",
      "Loss: 1.209975299094954\n",
      "Loss: 0.8329048561713388\n",
      "Loss: 0.7125344984233379\n",
      "Loss: 0.6249877993137606\n",
      "Loss: 0.5687126775662745\n",
      "Loss: 0.5346371348226263\n",
      "Loss: 0.479940133830232\n",
      "Loss: 0.4591490894916557\n",
      "Loss: 0.43004778805639476\n",
      "______\n",
      "Iteration t=7\n",
      "all:  cs/acc_i=68.42 cs/acc_c=68.77 os/recall_knw=58.58 os/recall_unk=77.82 total/acc_i=60.12 total/acc_c=53.60 total/h_score=62.62\n",
      "selected:  cs/acc_i=68.42 cs/acc_c=68.77 os/recall_knw=58.53 os/recall_unk=77.95 total/acc_i=60.14 total/acc_c=53.60 total/h_score=62.66\n",
      "Loss: 2.481406698743981\n",
      "Loss: 1.2051042607989177\n",
      "Loss: 0.8503635850058023\n",
      "Loss: 0.7279541381750719\n",
      "Loss: 0.613918865899963\n",
      "Loss: 0.5774696749376963\n",
      "Loss: 0.5239170583855196\n",
      "Loss: 0.49059632528259095\n",
      "Loss: 0.48523444613539074\n",
      "Loss: 0.425566456463921\n",
      "______\n",
      "Iteration t=8\n",
      "all:  cs/acc_i=68.22 cs/acc_c=68.69 os/recall_knw=58.58 os/recall_unk=77.82 total/acc_i=60.12 total/acc_c=53.60 total/h_score=62.62\n",
      "selected:  cs/acc_i=68.22 cs/acc_c=68.69 os/recall_knw=58.58 os/recall_unk=77.82 total/acc_i=60.12 total/acc_c=53.60 total/h_score=62.62\n",
      "Loss: 2.4741110184106483\n",
      "Loss: 1.1966910350274849\n",
      "Loss: 0.8438952921863541\n",
      "Loss: 0.7106385112526905\n",
      "Loss: 0.6344418766268765\n",
      "Loss: 0.5961873231523008\n",
      "Loss: 0.5302166707783817\n",
      "Loss: 0.5054387814668287\n",
      "Loss: 0.4735906749485008\n",
      "Loss: 0.42886244370994797\n",
      "______\n",
      "Iteration t=9\n",
      "all:  cs/acc_i=67.99 cs/acc_c=68.31 os/recall_knw=58.58 os/recall_unk=77.82 total/acc_i=60.12 total/acc_c=53.60 total/h_score=62.62\n",
      "selected:  cs/acc_i=67.99 cs/acc_c=68.31 os/recall_knw=58.58 os/recall_unk=77.82 total/acc_i=60.12 total/acc_c=53.60 total/h_score=62.62\n",
      "tensor(0)\n",
      "all:  cs/acc_i=67.99 cs/acc_c=68.31 os/recall_knw=58.58 os/recall_unk=77.82 total/acc_i=60.12 total/acc_c=53.60 total/h_score=62.62\n",
      "sketch -> painting lr= 0.001 seed= 0\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19]\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20]\n",
      "Loss: 2.6823198893635545\n",
      "Loss: 1.6268889473885606\n",
      "Loss: 1.1324717989287425\n",
      "Loss: 0.9246724612012351\n",
      "Loss: 0.8267483050675736\n",
      "Loss: 0.7543061040725905\n",
      "Loss: 0.7182298944782965\n",
      "Loss: 0.6521555206824824\n",
      "Loss: 0.6394772703192898\n",
      "Loss: 0.5959144490434951\n",
      "tensor(True) tensor(True)\n",
      "______\n",
      "Iteration t=1\n",
      "all:  cs/acc_i=65.87 cs/acc_c=66.41 os/recall_knw=81.11 os/recall_unk=37.96 total/acc_i=53.09 total/acc_c=59.81 total/h_score=46.77\n",
      "selected:  cs/acc_i=60.02 cs/acc_c=61.30 os/recall_knw=46.02 os/recall_unk=97.23 total/acc_i=62.29 total/acc_c=48.44 total/h_score=62.45\n",
      "Loss: 2.634740407916083\n",
      "Loss: 1.4557122550724786\n",
      "Loss: 1.004133635385025\n",
      "Loss: 0.8491547775729267\n",
      "Loss: 0.7409565221284322\n",
      "Loss: 0.6928563951582148\n",
      "Loss: 0.6428637247586596\n",
      "Loss: 0.576209664704719\n",
      "Loss: 0.5958347485405235\n",
      "Loss: 0.5578859099299436\n",
      "______\n",
      "Iteration t=2\n",
      "all:  cs/acc_i=66.89 cs/acc_c=67.34 os/recall_knw=60.38 os/recall_unk=73.26 total/acc_i=59.40 total/acc_c=54.64 total/h_score=61.98\n",
      "selected:  cs/acc_i=60.24 cs/acc_c=61.93 os/recall_knw=43.71 os/recall_unk=94.23 total/acc_i=58.78 total/acc_c=45.01 total/h_score=58.62\n",
      "Loss: 2.5795350459488957\n",
      "Loss: 1.395694546807896\n",
      "Loss: 0.9484755801883611\n",
      "Loss: 0.7948721286925402\n",
      "Loss: 0.718977251784368\n",
      "Loss: 0.6581335335969924\n",
      "Loss: 0.6170158621939745\n",
      "Loss: 0.5507129542529583\n",
      "Loss: 0.5331175999885256\n",
      "Loss: 0.49773743470961396\n",
      "______\n",
      "Iteration t=3\n",
      "all:  cs/acc_i=67.40 cs/acc_c=67.72 os/recall_knw=57.01 os/recall_unk=79.32 total/acc_i=60.12 total/acc_c=53.17 total/h_score=62.72\n",
      "selected:  cs/acc_i=64.29 cs/acc_c=65.47 os/recall_knw=49.19 os/recall_unk=89.92 total/acc_i=59.80 total/acc_c=48.74 total/h_score=61.46\n",
      "Loss: 2.5391021120599855\n",
      "Loss: 1.2832680824515108\n",
      "Loss: 0.9086436711864554\n",
      "Loss: 0.7590009857823838\n",
      "Loss: 0.655623602531689\n",
      "Loss: 0.6086626746953824\n",
      "Loss: 0.5803840928650522\n",
      "Loss: 0.5113372211848503\n",
      "Loss: 0.48792259724109205\n",
      "Loss: 0.46169354627916825\n",
      "______\n",
      "Iteration t=4\n",
      "all:  cs/acc_i=67.40 cs/acc_c=67.59 os/recall_knw=56.15 os/recall_unk=80.81 total/acc_i=60.33 total/acc_c=52.84 total/h_score=62.86\n",
      "selected:  cs/acc_i=65.98 cs/acc_c=66.61 os/recall_knw=52.64 os/recall_unk=85.80 total/acc_i=60.19 total/acc_c=50.97 total/h_score=62.56\n",
      "Loss: 2.522862704361186\n",
      "Loss: 1.2479460795386499\n",
      "Loss: 0.8900516527790984\n",
      "Loss: 0.716482589475247\n",
      "Loss: 0.6404851148484134\n",
      "Loss: 0.5886044989363486\n",
      "Loss: 0.5526078992656299\n",
      "Loss: 0.4995269436984002\n",
      "Loss: 0.4938371224688883\n",
      "Loss: 0.4476443738246164\n",
      "______\n",
      "Iteration t=5\n",
      "all:  cs/acc_i=68.46 cs/acc_c=68.89 os/recall_knw=56.03 os/recall_unk=81.15 total/acc_i=60.44 total/acc_c=52.85 total/h_score=62.96\n",
      "selected:  cs/acc_i=68.09 cs/acc_c=68.75 os/recall_knw=54.90 os/recall_unk=83.22 total/acc_i=60.54 total/acc_c=52.46 total/h_score=63.19\n",
      "Loss: 2.490310676794484\n",
      "Loss: 1.2673572115446805\n",
      "Loss: 0.8364791996439789\n",
      "Loss: 0.7479876986256352\n",
      "Loss: 0.6263061355906749\n",
      "Loss: 0.593146941053524\n",
      "Loss: 0.530325490444776\n",
      "Loss: 0.5176527038400556\n",
      "Loss: 0.45642014957749794\n",
      "Loss: 0.44511127839853737\n",
      "______\n",
      "Iteration t=6\n",
      "all:  cs/acc_i=68.57 cs/acc_c=68.92 os/recall_knw=55.92 os/recall_unk=81.23 total/acc_i=60.41 total/acc_c=52.78 total/h_score=62.92\n",
      "selected:  cs/acc_i=68.47 cs/acc_c=68.88 os/recall_knw=55.66 os/recall_unk=81.64 total/acc_i=60.40 total/acc_c=52.68 total/h_score=62.95\n",
      "Loss: 2.489904170620198\n",
      "Loss: 1.2477490276706462\n",
      "Loss: 0.8650084240095955\n",
      "Loss: 0.7157770297965225\n",
      "Loss: 0.6094386055153244\n",
      "Loss: 0.5789877564931403\n",
      "Loss: 0.558464339497138\n",
      "Loss: 0.49303112765964197\n",
      "Loss: 0.46904684810005887\n",
      "Loss: 0.43953373690648956\n",
      "______\n",
      "Iteration t=7\n",
      "all:  cs/acc_i=68.57 cs/acc_c=68.90 os/recall_knw=55.92 os/recall_unk=81.23 total/acc_i=60.41 total/acc_c=52.78 total/h_score=62.92\n",
      "selected:  cs/acc_i=68.56 cs/acc_c=68.89 os/recall_knw=55.90 os/recall_unk=81.23 total/acc_i=60.40 total/acc_c=52.76 total/h_score=62.91\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 2.4858486506997086\n",
      "Loss: 1.205375197941695\n",
      "Loss: 0.8336476742978988\n",
      "Loss: 0.7385428431557446\n",
      "Loss: 0.6416122488132338\n",
      "Loss: 0.5819161382874822\n",
      "Loss: 0.5277009401621857\n",
      "Loss: 0.4958694827992742\n",
      "Loss: 0.4716021401610801\n",
      "Loss: 0.44460301588827034\n",
      "______\n",
      "Iteration t=8\n",
      "all:  cs/acc_i=68.38 cs/acc_c=68.59 os/recall_knw=55.92 os/recall_unk=81.23 total/acc_i=60.41 total/acc_c=52.78 total/h_score=62.92\n",
      "selected:  cs/acc_i=68.38 cs/acc_c=68.59 os/recall_knw=55.92 os/recall_unk=81.23 total/acc_i=60.41 total/acc_c=52.78 total/h_score=62.92\n",
      "Loss: 2.470781833660312\n",
      "Loss: 1.2115269053757676\n",
      "Loss: 0.8361761682644123\n",
      "Loss: 0.7266143195755114\n",
      "Loss: 0.6397290234037531\n",
      "Loss: 0.6025737997114173\n",
      "Loss: 0.5386277056806456\n",
      "Loss: 0.5106239254639401\n",
      "Loss: 0.47812070091807746\n",
      "Loss: 0.45048733855166084\n",
      "______\n",
      "Iteration t=9\n",
      "all:  cs/acc_i=69.04 cs/acc_c=69.49 os/recall_knw=55.92 os/recall_unk=81.23 total/acc_i=60.41 total/acc_c=52.78 total/h_score=62.92\n",
      "selected:  cs/acc_i=69.04 cs/acc_c=69.49 os/recall_knw=55.92 os/recall_unk=81.23 total/acc_i=60.41 total/acc_c=52.78 total/h_score=62.92\n",
      "tensor(0)\n",
      "all:  cs/acc_i=69.04 cs/acc_c=69.49 os/recall_knw=55.92 os/recall_unk=81.23 total/acc_i=60.41 total/acc_c=52.78 total/h_score=62.92\n",
      "sketch -> painting lr= 0.001 seed= 1\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19]\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20]\n",
      "Loss: 2.677400797298274\n",
      "Loss: 1.5988022857105608\n",
      "Loss: 1.1332930778105235\n",
      "Loss: 0.9454334459661209\n",
      "Loss: 0.8433631939679077\n",
      "Loss: 0.7633781688115031\n",
      "Loss: 0.7016979231662357\n",
      "Loss: 0.6680504458466756\n",
      "Loss: 0.6275965082891208\n",
      "Loss: 0.6071507936132323\n",
      "tensor(True) tensor(True)\n",
      "______\n",
      "Iteration t=1\n",
      "all:  cs/acc_i=65.20 cs/acc_c=65.47 os/recall_knw=81.47 os/recall_unk=38.70 total/acc_i=53.38 total/acc_c=59.72 total/h_score=47.29\n",
      "selected:  cs/acc_i=58.16 cs/acc_c=59.49 os/recall_knw=46.37 os/recall_unk=96.08 total/acc_i=62.47 total/acc_c=48.87 total/h_score=62.68\n",
      "Loss: 2.6376734707090588\n",
      "Loss: 1.4622367974640667\n",
      "Loss: 1.0121669449668\n",
      "Loss: 0.8690430028139106\n",
      "Loss: 0.7691302891226782\n",
      "Loss: 0.6980201849614941\n",
      "Loss: 0.6669555937034496\n",
      "Loss: 0.6197981493196626\n",
      "Loss: 0.5712432077397471\n",
      "Loss: 0.5173227178733706\n",
      "______\n",
      "Iteration t=2\n",
      "all:  cs/acc_i=66.58 cs/acc_c=66.79 os/recall_knw=62.30 os/recall_unk=73.67 total/acc_i=59.90 total/acc_c=54.91 total/h_score=62.30\n",
      "selected:  cs/acc_i=60.39 cs/acc_c=61.60 os/recall_knw=44.93 os/recall_unk=94.56 total/acc_i=59.81 total/acc_c=45.50 total/h_score=59.16\n",
      "Loss: 2.584809202497656\n",
      "Loss: 1.3354385107755662\n",
      "Loss: 0.9462034000591798\n",
      "Loss: 0.7945607315410267\n",
      "Loss: 0.6957912321795117\n",
      "Loss: 0.6423393388363448\n",
      "Loss: 0.5825804147530685\n",
      "Loss: 0.5604462589729916\n",
      "Loss: 0.5314201585948467\n",
      "Loss: 0.4927698368375952\n",
      "______\n",
      "Iteration t=3\n",
      "all:  cs/acc_i=66.30 cs/acc_c=66.73 os/recall_knw=56.11 os/recall_unk=80.90 total/acc_i=60.06 total/acc_c=52.43 total/h_score=62.56\n",
      "selected:  cs/acc_i=62.64 cs/acc_c=63.88 os/recall_knw=48.15 os/recall_unk=90.69 total/acc_i=59.28 total/acc_c=47.55 total/h_score=60.50\n",
      "Loss: 2.537439729338107\n",
      "Loss: 1.3119865510774695\n",
      "Loss: 0.9087518242390259\n",
      "Loss: 0.7794848892999732\n",
      "Loss: 0.6758760216443435\n",
      "Loss: 0.6105659947447155\n",
      "Loss: 0.5808499830572501\n",
      "Loss: 0.5392737766970759\n",
      "Loss: 0.5089027327039968\n",
      "Loss: 0.44839904016774634\n",
      "______\n",
      "Iteration t=4\n",
      "all:  cs/acc_i=66.77 cs/acc_c=66.96 os/recall_knw=55.05 os/recall_unk=82.06 total/acc_i=59.93 total/acc_c=51.69 total/h_score=62.27\n",
      "selected:  cs/acc_i=65.25 cs/acc_c=65.88 os/recall_knw=51.75 os/recall_unk=86.82 total/acc_i=59.69 total/acc_c=49.78 total/h_score=61.76\n",
      "Loss: 2.507623242929515\n",
      "Loss: 1.254192858054165\n",
      "Loss: 0.8643460740268482\n",
      "Loss: 0.733412139903644\n",
      "Loss: 0.6540560538129967\n",
      "Loss: 0.6113301740668494\n",
      "Loss: 0.5521619516082957\n",
      "Loss: 0.5102280260767111\n",
      "Loss: 0.5045343943663287\n",
      "Loss: 0.46459060731316415\n",
      "______\n",
      "Iteration t=5\n",
      "all:  cs/acc_i=67.36 cs/acc_c=67.51 os/recall_knw=55.02 os/recall_unk=82.14 total/acc_i=59.96 total/acc_c=51.69 total/h_score=62.29\n",
      "selected:  cs/acc_i=66.84 cs/acc_c=67.29 os/recall_knw=53.63 os/recall_unk=84.39 total/acc_i=59.98 total/acc_c=51.15 total/h_score=62.39\n",
      "Loss: 2.5051225255633787\n",
      "Loss: 1.228826205760117\n",
      "Loss: 0.8641534215187137\n",
      "Loss: 0.7186585785937013\n",
      "Loss: 0.6470568292615819\n",
      "Loss: 0.5871405574914331\n",
      "Loss: 0.5526264723529459\n",
      "Loss: 0.4930049556295901\n",
      "Loss: 0.46616476866961515\n",
      "Loss: 0.44357660242754393\n",
      "______\n",
      "Iteration t=6\n",
      "all:  cs/acc_i=67.71 cs/acc_c=68.03 os/recall_knw=54.94 os/recall_unk=82.14 total/acc_i=59.93 total/acc_c=51.65 total/h_score=62.26\n",
      "selected:  cs/acc_i=67.73 cs/acc_c=68.10 os/recall_knw=54.80 os/recall_unk=82.97 total/acc_i=60.12 total/acc_c=51.70 total/h_score=62.51\n",
      "Loss: 2.4829001822432533\n",
      "Loss: 1.2287771850824356\n",
      "Loss: 0.8451746683873114\n",
      "Loss: 0.7143337726593018\n",
      "Loss: 0.6245808289309994\n",
      "Loss: 0.5951770995361884\n",
      "Loss: 0.5477245690636947\n",
      "Loss: 0.5071974906032203\n",
      "Loss: 0.4726121964268997\n",
      "Loss: 0.44808271924247506\n",
      "______\n",
      "Iteration t=7\n",
      "all:  cs/acc_i=68.06 cs/acc_c=68.50 os/recall_knw=54.94 os/recall_unk=82.14 total/acc_i=59.93 total/acc_c=51.65 total/h_score=62.26\n",
      "selected:  cs/acc_i=68.06 cs/acc_c=68.50 os/recall_knw=54.94 os/recall_unk=82.14 total/acc_i=59.93 total/acc_c=51.65 total/h_score=62.26\n",
      "Loss: 2.483013619695391\n",
      "Loss: 1.2222119404345142\n",
      "Loss: 0.8489299004175225\n",
      "Loss: 0.7140410699406449\n",
      "Loss: 0.6197747322977806\n",
      "Loss: 0.5772039657344623\n",
      "Loss: 0.5286203975580177\n",
      "Loss: 0.5059542190663668\n",
      "Loss: 0.46681387977940697\n",
      "Loss: 0.44788847024343453\n",
      "______\n",
      "Iteration t=8\n",
      "all:  cs/acc_i=68.22 cs/acc_c=68.43 os/recall_knw=54.94 os/recall_unk=82.14 total/acc_i=59.93 total/acc_c=51.65 total/h_score=62.26\n",
      "selected:  cs/acc_i=68.22 cs/acc_c=68.43 os/recall_knw=54.94 os/recall_unk=82.14 total/acc_i=59.93 total/acc_c=51.65 total/h_score=62.26\n",
      "Loss: 2.511050049139529\n",
      "Loss: 1.2353647373160537\n",
      "Loss: 0.8469003816040195\n",
      "Loss: 0.6985111100333078\n",
      "Loss: 0.6323226585680125\n",
      "Loss: 0.5975412947790963\n",
      "Loss: 0.5260501375003737\n",
      "Loss: 0.4880255360384377\n",
      "Loss: 0.45478854583842415\n",
      "Loss: 0.43829113105121925\n",
      "______\n",
      "Iteration t=9\n",
      "all:  cs/acc_i=68.42 cs/acc_c=68.76 os/recall_knw=54.94 os/recall_unk=82.14 total/acc_i=59.93 total/acc_c=51.65 total/h_score=62.26\n",
      "selected:  cs/acc_i=68.42 cs/acc_c=68.76 os/recall_knw=54.94 os/recall_unk=82.14 total/acc_i=59.93 total/acc_c=51.65 total/h_score=62.26\n",
      "tensor(0)\n",
      "all:  cs/acc_i=68.42 cs/acc_c=68.76 os/recall_knw=54.94 os/recall_unk=82.14 total/acc_i=59.93 total/acc_c=51.65 total/h_score=62.26\n",
      "sketch -> painting lr= 0.001 seed= 2\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19]\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20]\n",
      "Loss: 2.682220117333009\n",
      "Loss: 1.5919785456559092\n",
      "Loss: 1.1363445016526685\n",
      "Loss: 0.9600056443632263\n",
      "Loss: 0.80821391325636\n",
      "Loss: 0.7593720538407257\n",
      "Loss: 0.6979976198107926\n",
      "Loss: 0.6533542986690384\n",
      "Loss: 0.6460596432851762\n",
      "Loss: 0.5965126711375934\n",
      "tensor(True) tensor(True)\n",
      "______\n",
      "Iteration t=1\n",
      "all:  cs/acc_i=64.93 cs/acc_c=65.67 os/recall_knw=81.15 os/recall_unk=38.04 total/acc_i=53.33 total/acc_c=60.16 total/h_score=46.94\n",
      "selected:  cs/acc_i=56.28 cs/acc_c=57.78 os/recall_knw=46.08 os/recall_unk=96.62 total/acc_i=62.08 total/acc_c=48.27 total/h_score=62.20\n",
      "Loss: 2.6257558600338187\n",
      "Loss: 1.4778328209683516\n",
      "Loss: 1.0317200715991035\n",
      "Loss: 0.8788994523350168\n",
      "Loss: 0.7904168620777591\n",
      "Loss: 0.6759734633176223\n",
      "Loss: 0.6512904069273944\n",
      "Loss: 0.6140625882839811\n",
      "Loss: 0.5812413000686157\n",
      "Loss: 0.5186542333036229\n",
      "______\n",
      "Iteration t=2\n",
      "all:  cs/acc_i=66.22 cs/acc_c=66.53 os/recall_knw=63.40 os/recall_unk=69.85 total/acc_i=59.50 total/acc_c=56.06 total/h_score=61.77\n",
      "selected:  cs/acc_i=59.99 cs/acc_c=61.25 os/recall_knw=45.60 os/recall_unk=94.71 total/acc_i=60.46 total/acc_c=47.09 total/h_score=60.74\n",
      "Loss: 2.5580455790866505\n",
      "Loss: 1.3663257029923526\n",
      "Loss: 0.9615702138705687\n",
      "Loss: 0.8075414171273058\n",
      "Loss: 0.7046798515048894\n",
      "Loss: 0.6668192065574906\n",
      "Loss: 0.6018096044659614\n",
      "Loss: 0.559926951541142\n",
      "Loss: 0.5373297406868501\n",
      "Loss: 0.5165850919078697\n",
      "______\n",
      "Iteration t=3\n",
      "all:  cs/acc_i=66.89 cs/acc_c=67.11 os/recall_knw=58.50 os/recall_unk=77.57 total/acc_i=60.17 total/acc_c=53.76 total/h_score=62.67\n",
      "selected:  cs/acc_i=63.64 cs/acc_c=64.71 os/recall_knw=50.00 os/recall_unk=89.72 total/acc_i=60.18 total/acc_c=49.32 total/h_score=61.94\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 2.530342556082684\n",
      "Loss: 1.3151827032151429\n",
      "Loss: 0.8968459116375964\n",
      "Loss: 0.7572255135878273\n",
      "Loss: 0.6702948767205943\n",
      "Loss: 0.618255947465482\n",
      "Loss: 0.5903256998113964\n",
      "Loss: 0.5308831880921903\n",
      "Loss: 0.49949334412813184\n",
      "Loss: 0.469758553252272\n",
      "______\n",
      "Iteration t=4\n",
      "all:  cs/acc_i=68.06 cs/acc_c=68.42 os/recall_knw=56.74 os/recall_unk=79.65 total/acc_i=60.12 total/acc_c=52.85 total/h_score=62.56\n",
      "selected:  cs/acc_i=66.85 cs/acc_c=67.69 os/recall_knw=53.55 os/recall_unk=84.42 total/acc_i=60.06 total/acc_c=51.31 total/h_score=62.53\n",
      "Loss: 2.507444814658065\n",
      "Loss: 1.225111517447308\n",
      "Loss: 0.8834787857831772\n",
      "Loss: 0.7472853826429056\n",
      "Loss: 0.6615714703269583\n",
      "Loss: 0.5920516691447302\n",
      "Loss: 0.5527787981048289\n",
      "Loss: 0.520566217944213\n",
      "Loss: 0.469740205884728\n",
      "Loss: 0.46582763464381005\n",
      "______\n",
      "Iteration t=5\n",
      "all:  cs/acc_i=67.52 cs/acc_c=67.93 os/recall_knw=56.50 os/recall_unk=79.98 total/acc_i=60.17 total/acc_c=52.80 total/h_score=62.61\n",
      "selected:  cs/acc_i=66.82 cs/acc_c=67.52 os/recall_knw=54.91 os/recall_unk=82.17 total/acc_i=60.04 total/acc_c=52.08 total/h_score=62.61\n",
      "Loss: 2.506028187127761\n",
      "Loss: 1.2085231309565005\n",
      "Loss: 0.8540202859988428\n",
      "Loss: 0.7137688277557553\n",
      "Loss: 0.646093848801444\n",
      "Loss: 0.5792303732883783\n",
      "Loss: 0.5589616009850561\n",
      "Loss: 0.5026647066505848\n",
      "Loss: 0.4746816119662038\n",
      "Loss: 0.43404024707559696\n",
      "______\n",
      "Iteration t=6\n",
      "all:  cs/acc_i=68.22 cs/acc_c=68.61 os/recall_knw=56.50 os/recall_unk=79.98 total/acc_i=60.17 total/acc_c=52.80 total/h_score=62.61\n",
      "selected:  cs/acc_i=68.11 cs/acc_c=68.54 os/recall_knw=56.30 os/recall_unk=80.65 total/acc_i=60.23 total/acc_c=52.72 total/h_score=62.73\n",
      "Loss: 2.4798741985142714\n",
      "Loss: 1.2137841676793448\n",
      "Loss: 0.8664037925683385\n",
      "Loss: 0.7206790496905645\n",
      "Loss: 0.6430820365989112\n",
      "Loss: 0.5841654718406801\n",
      "Loss: 0.527679991249631\n",
      "Loss: 0.4977243314913618\n",
      "Loss: 0.47388708791354806\n",
      "Loss: 0.42708995306818953\n",
      "______\n",
      "Iteration t=7\n",
      "all:  cs/acc_i=67.95 cs/acc_c=68.35 os/recall_knw=56.47 os/recall_unk=79.98 total/acc_i=60.14 total/acc_c=52.76 total/h_score=62.58\n",
      "selected:  cs/acc_i=67.93 cs/acc_c=68.34 os/recall_knw=56.45 os/recall_unk=80.12 total/acc_i=60.17 total/acc_c=52.76 total/h_score=62.61\n",
      "Loss: 2.484405292728083\n",
      "Loss: 1.2253834154547714\n",
      "Loss: 0.8491455326235391\n",
      "Loss: 0.7171674737843071\n",
      "Loss: 0.6245917618516984\n",
      "Loss: 0.5928564174630777\n",
      "Loss: 0.5407933385633841\n",
      "Loss: 0.48473892167089433\n",
      "Loss: 0.46885865629930806\n",
      "Loss: 0.4529346940902675\n",
      "______\n",
      "Iteration t=8\n",
      "all:  cs/acc_i=69.32 cs/acc_c=69.56 os/recall_knw=56.47 os/recall_unk=79.98 total/acc_i=60.14 total/acc_c=52.76 total/h_score=62.58\n",
      "selected:  cs/acc_i=69.32 cs/acc_c=69.56 os/recall_knw=56.47 os/recall_unk=79.98 total/acc_i=60.14 total/acc_c=52.76 total/h_score=62.58\n",
      "Loss: 2.476885550417881\n",
      "Loss: 1.1986298146035508\n",
      "Loss: 0.8731174781496226\n",
      "Loss: 0.7099164850436724\n",
      "Loss: 0.6187161255461967\n",
      "Loss: 0.5857772963491046\n",
      "Loss: 0.5207026344441209\n",
      "Loss: 0.5063900276716904\n",
      "Loss: 0.4601443605987649\n",
      "Loss: 0.4378507850684135\n",
      "______\n",
      "Iteration t=9\n",
      "all:  cs/acc_i=67.95 cs/acc_c=68.54 os/recall_knw=56.47 os/recall_unk=79.98 total/acc_i=60.14 total/acc_c=52.76 total/h_score=62.58\n",
      "selected:  cs/acc_i=67.95 cs/acc_c=68.54 os/recall_knw=56.47 os/recall_unk=79.98 total/acc_i=60.14 total/acc_c=52.76 total/h_score=62.58\n",
      "tensor(0)\n",
      "all:  cs/acc_i=67.95 cs/acc_c=68.54 os/recall_knw=56.47 os/recall_unk=79.98 total/acc_i=60.14 total/acc_c=52.76 total/h_score=62.58\n",
      "sketch -> painting lr= 0.001 seed= 3\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19]\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20]\n",
      "Loss: 2.686736007326657\n",
      "Loss: 1.6012449713097405\n",
      "Loss: 1.1058875869229896\n",
      "Loss: 0.9477710733094167\n",
      "Loss: 0.8293407863562869\n",
      "Loss: 0.7432845302463806\n",
      "Loss: 0.7074923052922967\n",
      "Loss: 0.6549106948461729\n",
      "Loss: 0.6398418561853084\n",
      "Loss: 0.586406519425284\n",
      "tensor(True) tensor(True)\n",
      "______\n",
      "Iteration t=1\n",
      "all:  cs/acc_i=63.75 cs/acc_c=64.43 os/recall_knw=81.15 os/recall_unk=38.04 total/acc_i=52.82 total/acc_c=59.54 total/h_score=46.75\n",
      "selected:  cs/acc_i=54.74 cs/acc_c=56.84 os/recall_knw=45.71 os/recall_unk=95.82 total/acc_i=61.73 total/acc_c=48.36 total/h_score=62.15\n",
      "Loss: 2.629312292965138\n",
      "Loss: 1.4691725730320107\n",
      "Loss: 1.017895065355992\n",
      "Loss: 0.8583475611923973\n",
      "Loss: 0.7659884528549397\n",
      "Loss: 0.702181036921515\n",
      "Loss: 0.6549257821794869\n",
      "Loss: 0.6119563503253863\n",
      "Loss: 0.5613119892308102\n",
      "Loss: 0.5644703327457686\n",
      "______\n",
      "Iteration t=2\n",
      "all:  cs/acc_i=65.60 cs/acc_c=66.14 os/recall_knw=62.38 os/recall_unk=70.35 total/acc_i=58.73 total/acc_c=54.82 total/h_score=61.13\n",
      "selected:  cs/acc_i=58.78 cs/acc_c=59.95 os/recall_knw=44.89 os/recall_unk=94.11 total/acc_i=58.89 total/acc_c=44.93 total/h_score=58.53\n",
      "Loss: 2.583586065877568\n",
      "Loss: 1.3612305868755687\n",
      "Loss: 0.9464686499400572\n",
      "Loss: 0.7880603844469244\n",
      "Loss: 0.6944546237587929\n",
      "Loss: 0.6623611494898796\n",
      "Loss: 0.5957308611409231\n",
      "Loss: 0.5342991277575493\n",
      "Loss: 0.5232125285674225\n",
      "Loss: 0.48661432713270186\n",
      "______\n",
      "Iteration t=3\n",
      "all:  cs/acc_i=65.28 cs/acc_c=65.62 os/recall_knw=56.07 os/recall_unk=79.40 total/acc_i=59.16 total/acc_c=51.69 total/h_score=61.59\n",
      "selected:  cs/acc_i=61.72 cs/acc_c=62.87 os/recall_knw=47.74 os/recall_unk=89.35 total/acc_i=58.48 total/acc_c=46.89 total/h_score=59.65\n",
      "Loss: 2.532477767571159\n",
      "Loss: 1.2931487650974938\n",
      "Loss: 0.8957151086434074\n",
      "Loss: 0.7528209828812144\n",
      "Loss: 0.6539378012004106\n",
      "Loss: 0.5954846352986668\n",
      "Loss: 0.5695880144834519\n",
      "Loss: 0.5218469846507777\n",
      "Loss: 0.4877805731218794\n",
      "Loss: 0.47778930152240007\n",
      "______\n",
      "Iteration t=4\n",
      "all:  cs/acc_i=66.22 cs/acc_c=66.53 os/recall_knw=55.45 os/recall_unk=79.98 total/acc_i=59.08 total/acc_c=51.31 total/h_score=61.44\n",
      "selected:  cs/acc_i=64.72 cs/acc_c=65.65 os/recall_knw=51.78 os/recall_unk=85.00 total/acc_i=58.87 total/acc_c=49.56 total/h_score=61.18\n",
      "Loss: 2.5429695316507845\n",
      "Loss: 1.2691154432196154\n",
      "Loss: 0.8865481778539183\n",
      "Loss: 0.7374756458187908\n",
      "Loss: 0.6471391743999996\n",
      "Loss: 0.5821538571944217\n",
      "Loss: 0.5465910239813196\n",
      "Loss: 0.5169179555861759\n",
      "Loss: 0.49904313142792583\n",
      "Loss: 0.4487258881204742\n",
      "______\n",
      "Iteration t=5\n",
      "all:  cs/acc_i=66.34 cs/acc_c=66.63 os/recall_knw=55.29 os/recall_unk=80.48 total/acc_i=59.19 total/acc_c=51.26 total/h_score=61.52\n",
      "selected:  cs/acc_i=65.81 cs/acc_c=66.43 os/recall_knw=54.10 os/recall_unk=82.19 total/acc_i=59.10 total/acc_c=50.80 total/h_score=61.58\n",
      "Loss: 2.496095045113269\n",
      "Loss: 1.2390100924075875\n",
      "Loss: 0.843349387984217\n",
      "Loss: 0.7268521287804278\n",
      "Loss: 0.6480193845774411\n",
      "Loss: 0.5567594377837554\n",
      "Loss: 0.5520455271250917\n",
      "Loss: 0.5096934006047347\n",
      "Loss: 0.45671535433565147\n",
      "Loss: 0.43613313058766806\n",
      "______\n",
      "Iteration t=6\n",
      "all:  cs/acc_i=66.89 cs/acc_c=67.13 os/recall_knw=55.29 os/recall_unk=80.48 total/acc_i=59.19 total/acc_c=51.26 total/h_score=61.52\n",
      "selected:  cs/acc_i=66.76 cs/acc_c=67.03 os/recall_knw=55.11 os/recall_unk=80.95 total/acc_i=59.19 total/acc_c=51.12 total/h_score=61.53\n",
      "Loss: 2.4851205110549928\n",
      "Loss: 1.244719045746083\n",
      "Loss: 0.8632570517306425\n",
      "Loss: 0.7277260921439346\n",
      "Loss: 0.624468130968055\n",
      "Loss: 0.5834670526640756\n",
      "Loss: 0.5425535902685049\n",
      "Loss: 0.5043309220854117\n",
      "Loss: 0.47166019650746366\n",
      "Loss: 0.4415074970649213\n",
      "______\n",
      "Iteration t=7\n",
      "all:  cs/acc_i=67.63 cs/acc_c=67.93 os/recall_knw=55.29 os/recall_unk=80.48 total/acc_i=59.19 total/acc_c=51.26 total/h_score=61.52\n",
      "selected:  cs/acc_i=67.62 cs/acc_c=67.93 os/recall_knw=55.27 os/recall_unk=80.48 total/acc_i=59.17 total/acc_c=51.24 total/h_score=61.51\n",
      "Loss: 2.498282614532782\n",
      "Loss: 1.2203288105069374\n",
      "Loss: 0.8761609427782954\n",
      "Loss: 0.7326797512112831\n",
      "Loss: 0.63260951881506\n",
      "Loss: 0.5872718485034242\n",
      "Loss: 0.5554679404716103\n",
      "Loss: 0.4979795629880866\n",
      "Loss: 0.4775333071545679\n",
      "Loss: 0.44661302116452434\n",
      "______\n",
      "Iteration t=8\n",
      "all:  cs/acc_i=67.52 cs/acc_c=67.96 os/recall_knw=55.29 os/recall_unk=80.48 total/acc_i=59.19 total/acc_c=51.26 total/h_score=61.52\n",
      "selected:  cs/acc_i=67.52 cs/acc_c=67.96 os/recall_knw=55.29 os/recall_unk=80.48 total/acc_i=59.19 total/acc_c=51.26 total/h_score=61.52\n",
      "Loss: 2.4932147313137443\n",
      "Loss: 1.2216181436363531\n",
      "Loss: 0.8623736353553071\n",
      "Loss: 0.7050231612458521\n",
      "Loss: 0.6387847535464228\n",
      "Loss: 0.5786746494015869\n",
      "Loss: 0.5471060311307713\n",
      "Loss: 0.5002830292497362\n",
      "Loss: 0.4593751257171436\n",
      "Loss: 0.45430832049068137\n",
      "______\n",
      "Iteration t=9\n",
      "all:  cs/acc_i=67.40 cs/acc_c=67.74 os/recall_knw=55.29 os/recall_unk=80.48 total/acc_i=59.19 total/acc_c=51.26 total/h_score=61.52\n",
      "selected:  cs/acc_i=67.40 cs/acc_c=67.74 os/recall_knw=55.29 os/recall_unk=80.48 total/acc_i=59.19 total/acc_c=51.26 total/h_score=61.52\n",
      "tensor(0)\n",
      "all:  cs/acc_i=67.40 cs/acc_c=67.74 os/recall_knw=55.29 os/recall_unk=80.48 total/acc_i=59.19 total/acc_c=51.26 total/h_score=61.52\n",
      "sketch -> painting lr= 0.001 seed= 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19]\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20]\n",
      "Loss: 2.669263820058292\n",
      "Loss: 1.5767671103330003\n",
      "Loss: 1.1184257041547716\n",
      "Loss: 0.9269224260885691\n",
      "Loss: 0.8605115470505252\n",
      "Loss: 0.78285037826017\n",
      "Loss: 0.7117484466931254\n",
      "Loss: 0.6953229314273166\n",
      "Loss: 0.6198408762665139\n",
      "Loss: 0.6077392940054235\n",
      "tensor(True) tensor(True)\n",
      "______\n",
      "Iteration t=1\n",
      "all:  cs/acc_i=64.77 cs/acc_c=65.51 os/recall_knw=81.90 os/recall_unk=39.62 total/acc_i=53.22 total/acc_c=59.47 total/h_score=47.87\n",
      "selected:  cs/acc_i=60.00 cs/acc_c=61.81 os/recall_knw=47.20 os/recall_unk=97.35 total/acc_i=63.81 total/acc_c=49.72 total/h_score=63.70\n",
      "Loss: 2.627461568744862\n",
      "Loss: 1.4462781251916563\n",
      "Loss: 1.0281908892203069\n",
      "Loss: 0.8531685586712786\n",
      "Loss: 0.7669018819424265\n",
      "Loss: 0.6960551432077435\n",
      "Loss: 0.654493530591329\n",
      "Loss: 0.6095174484782748\n",
      "Loss: 0.5853533700180514\n",
      "Loss: 0.5309027095779705\n",
      "______\n",
      "Iteration t=2\n",
      "all:  cs/acc_i=66.34 cs/acc_c=66.62 os/recall_knw=63.71 os/recall_unk=71.51 total/acc_i=59.80 total/acc_c=55.77 total/h_score=62.17\n",
      "selected:  cs/acc_i=60.25 cs/acc_c=61.02 os/recall_knw=45.63 os/recall_unk=94.93 total/acc_i=60.50 total/acc_c=46.42 total/h_score=60.12\n",
      "Loss: 2.575983762741089\n",
      "Loss: 1.3676134380427274\n",
      "Loss: 0.9406326148997654\n",
      "Loss: 0.8152002052827315\n",
      "Loss: 0.7183178124102679\n",
      "Loss: 0.6269762049344453\n",
      "Loss: 0.6063341272825544\n",
      "Loss: 0.5485460447994146\n",
      "Loss: 0.5199871392412619\n",
      "Loss: 0.5071979368274863\n",
      "______\n",
      "Iteration t=3\n",
      "all:  cs/acc_i=66.61 cs/acc_c=67.03 os/recall_knw=57.01 os/recall_unk=80.81 total/acc_i=60.41 total/acc_c=52.87 total/h_score=62.89\n",
      "selected:  cs/acc_i=63.09 cs/acc_c=64.30 os/recall_knw=49.26 os/recall_unk=91.19 total/acc_i=59.86 total/acc_c=48.03 total/h_score=61.04\n",
      "Loss: 2.5464745158734527\n",
      "Loss: 1.2701504639957262\n",
      "Loss: 0.8848802926747695\n",
      "Loss: 0.7290953629690667\n",
      "Loss: 0.6722312531393507\n",
      "Loss: 0.6112616632295691\n",
      "Loss: 0.5650237412556358\n",
      "Loss: 0.5207754712389863\n",
      "Loss: 0.49682429679062057\n",
      "Loss: 0.472017575022967\n",
      "______\n",
      "Iteration t=4\n",
      "all:  cs/acc_i=67.91 cs/acc_c=68.18 os/recall_knw=56.03 os/recall_unk=81.64 total/acc_i=60.28 total/acc_c=52.37 total/h_score=62.71\n",
      "selected:  cs/acc_i=66.85 cs/acc_c=67.45 os/recall_knw=53.03 os/recall_unk=86.61 total/acc_i=60.39 total/acc_c=50.92 total/h_score=62.70\n",
      "Loss: 2.49500426875443\n",
      "Loss: 1.2668975476457291\n",
      "Loss: 0.885755701851444\n",
      "Loss: 0.7400721688480938\n",
      "Loss: 0.6595087216681793\n",
      "Loss: 0.6024277376777986\n",
      "Loss: 0.5483471138888046\n",
      "Loss: 0.5064319641399784\n",
      "Loss: 0.4740422880198775\n",
      "Loss: 0.45248998047298744\n",
      "______\n",
      "Iteration t=5\n",
      "all:  cs/acc_i=68.03 cs/acc_c=68.47 os/recall_knw=55.84 os/recall_unk=81.81 total/acc_i=60.28 total/acc_c=52.29 total/h_score=62.69\n",
      "selected:  cs/acc_i=67.64 cs/acc_c=68.21 os/recall_knw=54.92 os/recall_unk=83.69 total/acc_i=60.35 total/acc_c=51.82 total/h_score=62.78\n",
      "Loss: 2.4895312403455194\n",
      "Loss: 1.2193415702125172\n",
      "Loss: 0.8593294622966782\n",
      "Loss: 0.7401244089681915\n",
      "Loss: 0.6200329192258693\n",
      "Loss: 0.5745355098703762\n",
      "Loss: 0.5357426609154101\n",
      "Loss: 0.4944684392937417\n",
      "Loss: 0.47285820476312207\n",
      "Loss: 0.45464035451657486\n",
      "______\n",
      "Iteration t=6\n",
      "all:  cs/acc_i=68.65 cs/acc_c=69.01 os/recall_knw=55.76 os/recall_unk=81.81 total/acc_i=60.28 total/acc_c=52.29 total/h_score=62.69\n",
      "selected:  cs/acc_i=68.61 cs/acc_c=68.98 os/recall_knw=55.64 os/recall_unk=82.63 total/acc_i=60.42 total/acc_c=52.26 total/h_score=62.88\n",
      "Loss: 2.489225977294299\n",
      "Loss: 1.2505212131811647\n",
      "Loss: 0.8564660359402092\n",
      "Loss: 0.7425801803871077\n",
      "Loss: 0.6170150342036267\n",
      "Loss: 0.5789307145439848\n",
      "Loss: 0.5359732352349222\n",
      "Loss: 0.5059593968245448\n",
      "Loss: 0.46438862100547673\n",
      "Loss: 0.44119874558278493\n",
      "______\n",
      "Iteration t=7\n",
      "all:  cs/acc_i=68.42 cs/acc_c=68.72 os/recall_knw=55.72 os/recall_unk=81.81 total/acc_i=60.25 total/acc_c=52.25 total/h_score=62.66\n",
      "selected:  cs/acc_i=68.42 cs/acc_c=68.72 os/recall_knw=55.72 os/recall_unk=81.81 total/acc_i=60.25 total/acc_c=52.25 total/h_score=62.66\n",
      "Loss: 2.502019208304736\n",
      "Loss: 1.2154166542753881\n",
      "Loss: 0.8382088522521817\n",
      "Loss: 0.7292334826625123\n",
      "Loss: 0.6409547811868239\n",
      "Loss: 0.5754805140349329\n",
      "Loss: 0.5310660011306101\n",
      "Loss: 0.5101196100517195\n",
      "Loss: 0.45786460528568346\n",
      "Loss: 0.46839156759028533\n",
      "______\n",
      "Iteration t=8\n",
      "all:  cs/acc_i=68.03 cs/acc_c=68.37 os/recall_knw=55.72 os/recall_unk=81.81 total/acc_i=60.25 total/acc_c=52.25 total/h_score=62.66\n",
      "selected:  cs/acc_i=68.03 cs/acc_c=68.37 os/recall_knw=55.72 os/recall_unk=81.81 total/acc_i=60.25 total/acc_c=52.25 total/h_score=62.66\n",
      "Loss: 2.5013325535521216\n",
      "Loss: 1.2330550826325708\n",
      "Loss: 0.8669119180465231\n",
      "Loss: 0.7029629105207872\n",
      "Loss: 0.6450493038917074\n",
      "Loss: 0.5753272442793359\n",
      "Loss: 0.551633642279372\n",
      "Loss: 0.5091639061363376\n",
      "Loss: 0.46930470782883316\n",
      "Loss: 0.4523277651898715\n",
      "______\n",
      "Iteration t=9\n",
      "all:  cs/acc_i=67.83 cs/acc_c=68.13 os/recall_knw=55.72 os/recall_unk=81.81 total/acc_i=60.25 total/acc_c=52.25 total/h_score=62.66\n",
      "selected:  cs/acc_i=67.83 cs/acc_c=68.13 os/recall_knw=55.72 os/recall_unk=81.81 total/acc_i=60.25 total/acc_c=52.25 total/h_score=62.66\n",
      "tensor(0)\n",
      "all:  cs/acc_i=67.83 cs/acc_c=68.13 os/recall_knw=55.72 os/recall_unk=81.81 total/acc_i=60.25 total/acc_c=52.25 total/h_score=62.66\n",
      "sketch -> painting lr= 0.001 seed= 0\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19]\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20]\n",
      "Loss: 2.6835349890374647\n",
      "Loss: 1.628038213425076\n",
      "Loss: 1.1319951018721788\n",
      "Loss: 0.9240758125622248\n",
      "Loss: 0.8252398207322839\n",
      "Loss: 0.7523815080369871\n",
      "Loss: 0.7162917692636707\n",
      "Loss: 0.6499202855161785\n",
      "Loss: 0.6378076247026011\n",
      "Loss: 0.5932214560428846\n",
      "tensor(True) tensor(True)\n",
      "______\n",
      "Iteration t=1\n",
      "all:  cs/acc_i=65.40 cs/acc_c=65.99 os/recall_knw=81.27 os/recall_unk=38.29 total/acc_i=53.25 total/acc_c=59.94 total/h_score=47.05\n",
      "selected:  cs/acc_i=58.90 cs/acc_c=60.27 os/recall_knw=46.47 os/recall_unk=97.88 total/acc_i=62.83 total/acc_c=49.05 total/h_score=63.15\n",
      "Loss: 2.6201422531247713\n",
      "Loss: 1.4544978680242087\n",
      "Loss: 1.0073486258442275\n",
      "Loss: 0.8528748121526506\n",
      "Loss: 0.7416915284550708\n",
      "Loss: 0.6775225196483631\n",
      "Loss: 0.6364328066507975\n",
      "Loss: 0.6038097561413539\n",
      "Loss: 0.5779194601492029\n",
      "Loss: 0.5475432867013313\n",
      "______\n",
      "Iteration t=2\n",
      "all:  cs/acc_i=66.73 cs/acc_c=67.23 os/recall_knw=63.64 os/recall_unk=71.51 total/acc_i=60.06 total/acc_c=56.23 total/h_score=62.47\n",
      "selected:  cs/acc_i=60.53 cs/acc_c=62.36 os/recall_knw=45.57 os/recall_unk=94.20 total/acc_i=60.52 total/acc_c=47.24 total/h_score=60.81\n",
      "Loss: 2.5671344431963834\n",
      "Loss: 1.3753076155077328\n",
      "Loss: 0.9311475741592321\n",
      "Loss: 0.820113887570121\n",
      "Loss: 0.7242857006463137\n",
      "Loss: 0.6503355236216025\n",
      "Loss: 0.6075127071277662\n",
      "Loss: 0.5585294744507833\n",
      "Loss: 0.5445154528048906\n",
      "Loss: 0.48588145531036636\n",
      "______\n",
      "Iteration t=3\n",
      "all:  cs/acc_i=66.89 cs/acc_c=67.31 os/recall_knw=61.01 os/recall_unk=74.50 total/acc_i=60.28 total/acc_c=55.40 total/h_score=62.91\n",
      "selected:  cs/acc_i=63.75 cs/acc_c=64.92 os/recall_knw=51.98 os/recall_unk=89.34 total/acc_i=61.05 total/acc_c=51.29 total/h_score=63.61\n",
      "Loss: 2.530593103144592\n",
      "Loss: 1.2729123735324646\n",
      "Loss: 0.9019418718752923\n",
      "Loss: 0.7619940211504569\n",
      "Loss: 0.6775531149529791\n",
      "Loss: 0.6261225591103236\n",
      "Loss: 0.5761653762875181\n",
      "Loss: 0.5270046611755957\n",
      "Loss: 0.4836801462746286\n",
      "Loss: 0.4719699404456399\n",
      "______\n",
      "Iteration t=4\n",
      "all:  cs/acc_i=67.67 cs/acc_c=68.09 os/recall_knw=58.46 os/recall_unk=78.16 total/acc_i=60.44 total/acc_c=53.99 total/h_score=63.01\n",
      "selected:  cs/acc_i=66.03 cs/acc_c=67.00 os/recall_knw=54.70 os/recall_unk=83.94 total/acc_i=60.33 total/acc_c=52.06 total/h_score=63.04\n",
      "Loss: 2.5199705213308334\n",
      "Loss: 1.2434597509602705\n",
      "Loss: 0.8579283059885104\n",
      "Loss: 0.7092704477409522\n",
      "Loss: 0.6401907271395127\n",
      "Loss: 0.5799799722308914\n",
      "Loss: 0.5432219197973609\n",
      "Loss: 0.5018151657655835\n",
      "Loss: 0.47986731852094333\n",
      "Loss: 0.4662881943086783\n",
      "______\n",
      "Iteration t=5\n",
      "all:  cs/acc_i=67.75 cs/acc_c=67.95 os/recall_knw=57.84 os/recall_unk=78.74 total/acc_i=60.22 total/acc_c=53.44 total/h_score=62.76\n",
      "selected:  cs/acc_i=67.13 cs/acc_c=67.60 os/recall_knw=56.33 os/recall_unk=81.58 total/acc_i=60.31 total/acc_c=52.79 total/h_score=63.03\n",
      "Loss: 2.4951018231814026\n",
      "Loss: 1.2465210916077505\n",
      "Loss: 0.8593505937300745\n",
      "Loss: 0.7185723044466777\n",
      "Loss: 0.6208240741589031\n",
      "Loss: 0.5775998014895642\n",
      "Loss: 0.5142962511812077\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.5085731283379872\n",
      "Loss: 0.47045640259614735\n",
      "Loss: 0.4545795260394206\n",
      "______\n",
      "Iteration t=6\n",
      "all:  cs/acc_i=67.95 cs/acc_c=68.31 os/recall_knw=57.84 os/recall_unk=78.74 total/acc_i=60.22 total/acc_c=53.44 total/h_score=62.76\n",
      "selected:  cs/acc_i=67.88 cs/acc_c=68.34 os/recall_knw=57.54 os/recall_unk=79.93 total/acc_i=60.43 total/acc_c=53.43 total/h_score=63.09\n",
      "Loss: 2.4860139761859106\n",
      "Loss: 1.2305879310557717\n",
      "Loss: 0.8537324903464993\n",
      "Loss: 0.7047583580258404\n",
      "Loss: 0.6051913273599949\n",
      "Loss: 0.5783573241248304\n",
      "Loss: 0.5386326572431727\n",
      "Loss: 0.4813408986759572\n",
      "Loss: 0.4660923311464217\n",
      "Loss: 0.4211027865950395\n",
      "______\n",
      "Iteration t=7\n",
      "all:  cs/acc_i=69.08 cs/acc_c=69.38 os/recall_knw=57.84 os/recall_unk=78.82 total/acc_i=60.25 total/acc_c=53.44 total/h_score=62.79\n",
      "selected:  cs/acc_i=69.07 cs/acc_c=69.37 os/recall_knw=57.82 os/recall_unk=78.82 total/acc_i=60.24 total/acc_c=53.43 total/h_score=62.78\n",
      "Loss: 2.47862104398589\n",
      "Loss: 1.2091687302435599\n",
      "Loss: 0.8508721817164652\n",
      "Loss: 0.730829622716673\n",
      "Loss: 0.6213609302236188\n",
      "Loss: 0.5576395552845732\n",
      "Loss: 0.5318663195376435\n",
      "Loss: 0.48847966460931685\n",
      "Loss: 0.4692944842841356\n",
      "Loss: 0.4512004315132095\n",
      "______\n",
      "Iteration t=8\n",
      "all:  cs/acc_i=68.26 cs/acc_c=68.65 os/recall_knw=57.84 os/recall_unk=78.82 total/acc_i=60.25 total/acc_c=53.44 total/h_score=62.79\n",
      "selected:  cs/acc_i=68.26 cs/acc_c=68.65 os/recall_knw=57.84 os/recall_unk=78.82 total/acc_i=60.25 total/acc_c=53.44 total/h_score=62.79\n",
      "Loss: 2.487409923345812\n",
      "Loss: 1.205610967211185\n",
      "Loss: 0.8422060598048472\n",
      "Loss: 0.7035002971608793\n",
      "Loss: 0.6330970656727591\n",
      "Loss: 0.5857037645314009\n",
      "Loss: 0.5303609735302387\n",
      "Loss: 0.5065722679418903\n",
      "Loss: 0.4520915795357958\n",
      "Loss: 0.4402075454352363\n",
      "______\n",
      "Iteration t=9\n",
      "all:  cs/acc_i=68.61 cs/acc_c=69.07 os/recall_knw=57.84 os/recall_unk=78.82 total/acc_i=60.25 total/acc_c=53.44 total/h_score=62.79\n",
      "selected:  cs/acc_i=68.61 cs/acc_c=69.07 os/recall_knw=57.84 os/recall_unk=78.82 total/acc_i=60.25 total/acc_c=53.44 total/h_score=62.79\n",
      "tensor(0)\n",
      "all:  cs/acc_i=68.61 cs/acc_c=69.07 os/recall_knw=57.84 os/recall_unk=78.82 total/acc_i=60.25 total/acc_c=53.44 total/h_score=62.79\n",
      "sketch -> painting lr= 0.001 seed= 1\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19]\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20]\n",
      "Loss: 2.678344701983265\n",
      "Loss: 1.598374278275008\n",
      "Loss: 1.1330528293073792\n",
      "Loss: 0.9463215774482059\n",
      "Loss: 0.8438416736334869\n",
      "Loss: 0.7641404364834127\n",
      "Loss: 0.7028194427797475\n",
      "Loss: 0.669293831611417\n",
      "Loss: 0.6293852972922865\n",
      "Loss: 0.6083110472590653\n",
      "tensor(True) tensor(True)\n",
      "______\n",
      "Iteration t=1\n",
      "all:  cs/acc_i=65.48 cs/acc_c=65.86 os/recall_knw=81.11 os/recall_unk=37.96 total/acc_i=53.25 total/acc_c=59.87 total/h_score=46.78\n",
      "selected:  cs/acc_i=57.72 cs/acc_c=59.86 os/recall_knw=45.66 os/recall_unk=96.01 total/acc_i=61.70 total/acc_c=48.48 total/h_score=62.30\n",
      "Loss: 2.6404793273999494\n",
      "Loss: 1.4564929204286585\n",
      "Loss: 1.0069535717296139\n",
      "Loss: 0.8511451564837194\n",
      "Loss: 0.7675355157414496\n",
      "Loss: 0.7021152518221722\n",
      "Loss: 0.6497377494826985\n",
      "Loss: 0.6063645841274861\n",
      "Loss: 0.5707492678637666\n",
      "Loss: 0.5449818808963334\n",
      "______\n",
      "Iteration t=2\n",
      "all:  cs/acc_i=65.87 cs/acc_c=66.30 os/recall_knw=62.62 os/recall_unk=71.93 total/acc_i=59.82 total/acc_c=55.65 total/h_score=62.23\n",
      "selected:  cs/acc_i=59.11 cs/acc_c=60.64 os/recall_knw=44.98 os/recall_unk=93.93 total/acc_i=59.90 total/acc_c=46.18 total/h_score=59.74\n",
      "Loss: 2.586132766441865\n",
      "Loss: 1.3751814208247446\n",
      "Loss: 0.9368486301465468\n",
      "Loss: 0.7873601026155732\n",
      "Loss: 0.7140831357376142\n",
      "Loss: 0.6444841594858604\n",
      "Loss: 0.5980611350725997\n",
      "Loss: 0.5702085015448657\n",
      "Loss: 0.5126139573414218\n",
      "Loss: 0.49874672429128125\n",
      "______\n",
      "Iteration t=3\n",
      "all:  cs/acc_i=66.58 cs/acc_c=67.01 os/recall_knw=58.66 os/recall_unk=77.57 total/acc_i=60.06 total/acc_c=53.65 total/h_score=62.59\n",
      "selected:  cs/acc_i=63.42 cs/acc_c=64.59 os/recall_knw=50.07 os/recall_unk=89.38 total/acc_i=60.07 total/acc_c=49.18 total/h_score=61.75\n",
      "Loss: 2.5386074244718015\n",
      "Loss: 1.302440374960631\n",
      "Loss: 0.8971235032205458\n",
      "Loss: 0.7708182121381099\n",
      "Loss: 0.6760799358417462\n",
      "Loss: 0.6205974709548991\n",
      "Loss: 0.5577952039964271\n",
      "Loss: 0.5437586482340123\n",
      "Loss: 0.5092001932782012\n",
      "Loss: 0.45910788911245604\n",
      "______\n",
      "Iteration t=4\n",
      "all:  cs/acc_i=66.81 cs/acc_c=67.03 os/recall_knw=56.94 os/recall_unk=79.24 total/acc_i=60.06 total/acc_c=52.97 total/h_score=62.54\n",
      "selected:  cs/acc_i=65.07 cs/acc_c=65.85 os/recall_knw=53.29 os/recall_unk=85.10 total/acc_i=59.93 total/acc_c=51.01 total/h_score=62.43\n",
      "Loss: 2.506487173693521\n",
      "Loss: 1.2602746153579039\n",
      "Loss: 0.8601826249050493\n",
      "Loss: 0.7394533233732736\n",
      "Loss: 0.6418340969361177\n",
      "Loss: 0.592726624312521\n",
      "Loss: 0.5547637130532946\n",
      "Loss: 0.5078739946504601\n",
      "Loss: 0.47782190932947044\n",
      "Loss: 0.4450968156466965\n",
      "______\n",
      "Iteration t=5\n",
      "all:  cs/acc_i=67.99 cs/acc_c=68.15 os/recall_knw=56.90 os/recall_unk=79.57 total/acc_i=60.14 total/acc_c=52.96 total/h_score=62.62\n",
      "selected:  cs/acc_i=67.63 cs/acc_c=68.11 os/recall_knw=55.32 os/recall_unk=81.95 total/acc_i=60.29 total/acc_c=52.52 total/h_score=62.91\n",
      "Loss: 2.5004013045825095\n",
      "Loss: 1.2313553845440899\n",
      "Loss: 0.8483302901065889\n",
      "Loss: 0.7298827975865745\n",
      "Loss: 0.6392764835445969\n",
      "Loss: 0.5806460237061536\n",
      "Loss: 0.542528127385265\n",
      "Loss: 0.5037125600463569\n",
      "Loss: 0.4741377909610301\n",
      "Loss: 0.4525923988640063\n",
      "______\n",
      "Iteration t=6\n",
      "all:  cs/acc_i=67.44 cs/acc_c=67.97 os/recall_knw=56.78 os/recall_unk=79.65 total/acc_i=60.17 total/acc_c=52.96 total/h_score=62.65\n",
      "selected:  cs/acc_i=67.39 cs/acc_c=68.04 os/recall_knw=56.40 os/recall_unk=80.39 total/acc_i=60.27 total/acc_c=52.95 total/h_score=62.84\n",
      "Loss: 2.4856384711536936\n",
      "Loss: 1.2182521173139897\n",
      "Loss: 0.8403008753448967\n",
      "Loss: 0.71934580415245\n",
      "Loss: 0.6232780046700462\n",
      "Loss: 0.574894560485836\n",
      "Loss: 0.5360461845388257\n",
      "Loss: 0.49628655127878113\n",
      "Loss: 0.46276655054189325\n",
      "Loss: 0.4469847439871571\n",
      "______\n",
      "Iteration t=7\n",
      "all:  cs/acc_i=68.14 cs/acc_c=68.29 os/recall_knw=56.78 os/recall_unk=79.65 total/acc_i=60.17 total/acc_c=52.96 total/h_score=62.65\n",
      "selected:  cs/acc_i=68.16 cs/acc_c=68.31 os/recall_knw=56.69 os/recall_unk=79.78 total/acc_i=60.20 total/acc_c=52.97 total/h_score=62.69\n",
      "Loss: 2.497637551805751\n",
      "Loss: 1.2229770926328807\n",
      "Loss: 0.8390490483899831\n",
      "Loss: 0.7300403260509012\n",
      "Loss: 0.6371864071983074\n",
      "Loss: 0.5722440280895001\n",
      "Loss: 0.5187079849754751\n",
      "Loss: 0.48512883080162017\n",
      "Loss: 0.4523474483596169\n",
      "Loss: 0.45089936545985915\n",
      "______\n",
      "Iteration t=8\n",
      "all:  cs/acc_i=68.46 cs/acc_c=68.82 os/recall_knw=56.78 os/recall_unk=79.65 total/acc_i=60.17 total/acc_c=52.96 total/h_score=62.65\n",
      "selected:  cs/acc_i=68.46 cs/acc_c=68.82 os/recall_knw=56.78 os/recall_unk=79.65 total/acc_i=60.17 total/acc_c=52.96 total/h_score=62.65\n",
      "Loss: 2.476657873223185\n",
      "Loss: 1.215015400276493\n",
      "Loss: 0.8245197435622273\n",
      "Loss: 0.7129815255823405\n",
      "Loss: 0.6301076671613856\n",
      "Loss: 0.5872606758164008\n",
      "Loss: 0.5330388073617147\n",
      "Loss: 0.4950129202744256\n",
      "Loss: 0.4610180512432627\n",
      "Loss: 0.4394294369799888\n",
      "______\n",
      "Iteration t=9\n",
      "all:  cs/acc_i=68.30 cs/acc_c=68.65 os/recall_knw=56.78 os/recall_unk=79.65 total/acc_i=60.17 total/acc_c=52.96 total/h_score=62.65\n",
      "selected:  cs/acc_i=68.30 cs/acc_c=68.65 os/recall_knw=56.78 os/recall_unk=79.65 total/acc_i=60.17 total/acc_c=52.96 total/h_score=62.65\n",
      "tensor(0)\n",
      "all:  cs/acc_i=68.30 cs/acc_c=68.65 os/recall_knw=56.78 os/recall_unk=79.65 total/acc_i=60.17 total/acc_c=52.96 total/h_score=62.65\n",
      "sketch -> painting lr= 0.001 seed= 2\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19]\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20]\n",
      "Loss: 2.6827922893553664\n",
      "Loss: 1.5904709113012885\n",
      "Loss: 1.1362762577140455\n",
      "Loss: 0.9601826707726901\n",
      "Loss: 0.8081903708042558\n",
      "Loss: 0.7591862374359799\n",
      "Loss: 0.69847411547125\n",
      "Loss: 0.6542565836427138\n",
      "Loss: 0.6456470720700382\n",
      "Loss: 0.5976435254836819\n",
      "tensor(True) tensor(True)\n",
      "______\n",
      "Iteration t=1\n",
      "all:  cs/acc_i=65.09 cs/acc_c=65.83 os/recall_knw=81.74 os/recall_unk=39.29 total/acc_i=53.99 total/acc_c=60.52 total/h_score=47.97\n",
      "selected:  cs/acc_i=56.96 cs/acc_c=58.95 os/recall_knw=46.80 os/recall_unk=96.33 total/acc_i=63.35 total/acc_c=49.59 total/h_score=63.40\n",
      "Loss: 2.62593480527113\n",
      "Loss: 1.4908917399420254\n",
      "Loss: 1.0290489778426535\n",
      "Loss: 0.8570260201099414\n",
      "Loss: 0.7862155387079083\n",
      "Loss: 0.6907223296050288\n",
      "Loss: 0.6640469703985297\n",
      "Loss: 0.6126922275421124\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.5878066225472279\n",
      "Loss: 0.5255038177477565\n",
      "______\n",
      "Iteration t=2\n",
      "all:  cs/acc_i=67.12 cs/acc_c=67.23 os/recall_knw=64.66 os/recall_unk=69.93 total/acc_i=59.82 total/acc_c=56.18 total/h_score=61.88\n",
      "selected:  cs/acc_i=61.48 cs/acc_c=62.59 os/recall_knw=46.47 os/recall_unk=94.61 total/acc_i=60.97 total/acc_c=47.36 total/h_score=60.98\n",
      "Loss: 2.578081954067404\n",
      "Loss: 1.3708654804663225\n",
      "Loss: 0.9387236702171239\n",
      "Loss: 0.8095121966166929\n",
      "Loss: 0.7059829233722253\n",
      "Loss: 0.6734464297917756\n",
      "Loss: 0.6038542936471376\n",
      "Loss: 0.5627989426932551\n",
      "Loss: 0.55102877183394\n",
      "Loss: 0.506673989309506\n",
      "______\n",
      "Iteration t=3\n",
      "all:  cs/acc_i=66.73 cs/acc_c=66.95 os/recall_knw=59.68 os/recall_unk=77.57 total/acc_i=60.52 total/acc_c=54.11 total/h_score=62.93\n",
      "selected:  cs/acc_i=63.49 cs/acc_c=64.70 os/recall_knw=50.69 os/recall_unk=90.07 total/acc_i=60.66 total/acc_c=49.75 total/h_score=62.40\n",
      "Loss: 2.543487993530605\n",
      "Loss: 1.3100071005199267\n",
      "Loss: 0.8809536415597666\n",
      "Loss: 0.7589851418267126\n",
      "Loss: 0.6643690531668456\n",
      "Loss: 0.6273966600713523\n",
      "Loss: 0.584791668407295\n",
      "Loss: 0.5359009973380877\n",
      "Loss: 0.4964881945239461\n",
      "Loss: 0.4614061168354491\n",
      "______\n",
      "Iteration t=4\n",
      "all:  cs/acc_i=67.99 cs/acc_c=68.26 os/recall_knw=57.25 os/recall_unk=80.32 total/acc_i=60.68 total/acc_c=53.21 total/h_score=63.02\n",
      "selected:  cs/acc_i=66.26 cs/acc_c=67.08 os/recall_knw=53.57 os/recall_unk=85.58 total/acc_i=60.37 total/acc_c=51.14 total/h_score=62.65\n",
      "Loss: 2.505283470915145\n",
      "Loss: 1.249334101917363\n",
      "Loss: 0.8800045829109785\n",
      "Loss: 0.729005794439997\n",
      "Loss: 0.6333686644915774\n",
      "Loss: 0.593152115324966\n",
      "Loss: 0.5520570790316878\n",
      "Loss: 0.5235717979048481\n",
      "Loss: 0.4720499725276683\n",
      "Loss: 0.46850725109962854\n",
      "______\n",
      "Iteration t=5\n",
      "all:  cs/acc_i=67.55 cs/acc_c=67.77 os/recall_knw=56.58 os/recall_unk=80.98 total/acc_i=60.57 total/acc_c=52.79 total/h_score=62.87\n",
      "selected:  cs/acc_i=66.86 cs/acc_c=67.29 os/recall_knw=55.27 os/recall_unk=83.26 total/acc_i=60.50 total/acc_c=52.07 total/h_score=62.88\n",
      "Loss: 2.5112279707512246\n",
      "Loss: 1.2181012767823145\n",
      "Loss: 0.8546605167810809\n",
      "Loss: 0.7278961335680613\n",
      "Loss: 0.6307183681937402\n",
      "Loss: 0.5885995037148519\n",
      "Loss: 0.5231212167214955\n",
      "Loss: 0.4997651968227983\n",
      "Loss: 0.46744840325396736\n",
      "Loss: 0.4390578081087811\n",
      "______\n",
      "Iteration t=6\n",
      "all:  cs/acc_i=68.53 cs/acc_c=68.70 os/recall_knw=56.54 os/recall_unk=80.98 total/acc_i=60.54 total/acc_c=52.75 total/h_score=62.84\n",
      "selected:  cs/acc_i=68.54 cs/acc_c=68.74 os/recall_knw=56.39 os/recall_unk=81.52 total/acc_i=60.66 total/acc_c=52.76 total/h_score=62.99\n",
      "Loss: 2.488766392072042\n",
      "Loss: 1.2262098055060318\n",
      "Loss: 0.8431518490963835\n",
      "Loss: 0.7115546764154744\n",
      "Loss: 0.6269632181743297\n",
      "Loss: 0.5830511085507346\n",
      "Loss: 0.5346216918007145\n",
      "Loss: 0.49705424832134715\n",
      "Loss: 0.46868240754536494\n",
      "Loss: 0.4401267453180096\n",
      "______\n",
      "Iteration t=7\n",
      "all:  cs/acc_i=68.06 cs/acc_c=68.72 os/recall_knw=56.54 os/recall_unk=80.98 total/acc_i=60.54 total/acc_c=52.75 total/h_score=62.84\n",
      "selected:  cs/acc_i=68.06 cs/acc_c=68.72 os/recall_knw=56.54 os/recall_unk=80.98 total/acc_i=60.54 total/acc_c=52.75 total/h_score=62.84\n",
      "Loss: 2.495404876829163\n",
      "Loss: 1.215437336665828\n",
      "Loss: 0.8461478323471255\n",
      "Loss: 0.7277370349057322\n",
      "Loss: 0.6453347673139921\n",
      "Loss: 0.5853204610265368\n",
      "Loss: 0.5553478433228121\n",
      "Loss: 0.4880041861073758\n",
      "Loss: 0.4647800880597859\n",
      "Loss: 0.45948742675345117\n",
      "______\n",
      "Iteration t=8\n",
      "all:  cs/acc_i=68.65 cs/acc_c=68.94 os/recall_knw=56.54 os/recall_unk=80.98 total/acc_i=60.54 total/acc_c=52.75 total/h_score=62.84\n",
      "selected:  cs/acc_i=68.65 cs/acc_c=68.94 os/recall_knw=56.54 os/recall_unk=80.98 total/acc_i=60.54 total/acc_c=52.75 total/h_score=62.84\n",
      "Loss: 2.503648360570272\n",
      "Loss: 1.2314022590474385\n",
      "Loss: 0.8584964637591587\n",
      "Loss: 0.704563195022141\n",
      "Loss: 0.6296817526463571\n",
      "Loss: 0.5782871045232788\n",
      "Loss: 0.5243241427753998\n",
      "Loss: 0.5039566068387613\n",
      "Loss: 0.4774969262260247\n",
      "Loss: 0.43631089993608674\n",
      "______\n",
      "Iteration t=9\n",
      "all:  cs/acc_i=68.65 cs/acc_c=69.13 os/recall_knw=56.54 os/recall_unk=80.98 total/acc_i=60.54 total/acc_c=52.75 total/h_score=62.84\n",
      "selected:  cs/acc_i=68.65 cs/acc_c=69.13 os/recall_knw=56.54 os/recall_unk=80.98 total/acc_i=60.54 total/acc_c=52.75 total/h_score=62.84\n",
      "tensor(0)\n",
      "all:  cs/acc_i=68.65 cs/acc_c=69.13 os/recall_knw=56.54 os/recall_unk=80.98 total/acc_i=60.54 total/acc_c=52.75 total/h_score=62.84\n",
      "sketch -> painting lr= 0.001 seed= 3\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19]\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20]\n",
      "Loss: 2.6870766036289253\n",
      "Loss: 1.6009634404452806\n",
      "Loss: 1.1047913164822096\n",
      "Loss: 0.9470068385306093\n",
      "Loss: 0.8303406264671346\n",
      "Loss: 0.7436686734256056\n",
      "Loss: 0.7080337371408325\n",
      "Loss: 0.6561921805757838\n",
      "Loss: 0.6405046036870209\n",
      "Loss: 0.587008525262174\n",
      "tensor(True) tensor(True)\n",
      "______\n",
      "Iteration t=1\n",
      "all:  cs/acc_i=64.50 cs/acc_c=65.14 os/recall_knw=81.50 os/recall_unk=38.79 total/acc_i=53.30 total/acc_c=59.89 total/h_score=47.40\n",
      "selected:  cs/acc_i=56.09 cs/acc_c=57.71 os/recall_knw=46.30 os/recall_unk=96.29 total/acc_i=62.24 total/acc_c=48.47 total/h_score=62.33\n",
      "Loss: 2.617139774820079\n",
      "Loss: 1.4597748564061335\n",
      "Loss: 1.0191076968027197\n",
      "Loss: 0.8690009324446969\n",
      "Loss: 0.762462571191327\n",
      "Loss: 0.7056997438559786\n",
      "Loss: 0.663124800592229\n",
      "Loss: 0.5992667290611543\n",
      "Loss: 0.5615953281881728\n",
      "Loss: 0.5299969649545236\n",
      "______\n",
      "Iteration t=2\n",
      "all:  cs/acc_i=65.87 cs/acc_c=66.38 os/recall_knw=62.54 os/recall_unk=70.35 total/acc_i=58.73 total/acc_c=54.87 total/h_score=61.16\n",
      "selected:  cs/acc_i=59.32 cs/acc_c=60.38 os/recall_knw=44.84 os/recall_unk=94.22 total/acc_i=59.00 total/acc_c=45.07 total/h_score=58.69\n",
      "Loss: 2.5810369166460903\n",
      "Loss: 1.3721717596054077\n",
      "Loss: 0.9340854858810251\n",
      "Loss: 0.7826239615678787\n",
      "Loss: 0.6913224644281647\n",
      "Loss: 0.665342332151803\n",
      "Loss: 0.5924201340160586\n",
      "Loss: 0.5663592155006799\n",
      "Loss: 0.5294826357879422\n",
      "Loss: 0.49625683000141924\n",
      "______\n",
      "Iteration t=3\n",
      "all:  cs/acc_i=65.16 cs/acc_c=65.50 os/recall_knw=57.88 os/recall_unk=77.33 total/acc_i=59.13 total/acc_c=52.56 total/h_score=61.70\n",
      "selected:  cs/acc_i=61.48 cs/acc_c=62.49 os/recall_knw=48.88 os/recall_unk=89.52 total/acc_i=58.89 total/acc_c=47.61 total/h_score=60.35\n",
      "Loss: 2.5175233301909072\n",
      "Loss: 1.2965006724647854\n",
      "Loss: 0.9113720606202664\n",
      "Loss: 0.7626418142215066\n",
      "Loss: 0.6915981489679087\n",
      "Loss: 0.620595139912937\n",
      "Loss: 0.5552507292317308\n",
      "Loss: 0.5285944483850313\n",
      "Loss: 0.493841949817927\n",
      "Loss: 0.4794793872729592\n",
      "______\n",
      "Iteration t=4\n",
      "all:  cs/acc_i=66.50 cs/acc_c=66.74 os/recall_knw=56.43 os/recall_unk=79.90 total/acc_i=59.56 total/acc_c=52.13 total/h_score=62.07\n",
      "selected:  cs/acc_i=64.77 cs/acc_c=65.37 os/recall_knw=52.46 os/recall_unk=85.06 total/acc_i=59.22 total/acc_c=49.83 total/h_score=61.42\n",
      "Loss: 2.520094008505845\n",
      "Loss: 1.2634189196494447\n",
      "Loss: 0.8633545428013601\n",
      "Loss: 0.7090747937434861\n",
      "Loss: 0.6507851671771843\n",
      "Loss: 0.5993080726441216\n",
      "Loss: 0.5529390145249727\n",
      "Loss: 0.5154508575170982\n",
      "Loss: 0.485240444916637\n",
      "Loss: 0.46165032014876856\n",
      "______\n",
      "Iteration t=5\n",
      "all:  cs/acc_i=66.89 cs/acc_c=67.28 os/recall_knw=56.39 os/recall_unk=79.90 total/acc_i=59.56 total/acc_c=52.13 total/h_score=62.07\n",
      "selected:  cs/acc_i=66.47 cs/acc_c=66.94 os/recall_knw=55.19 os/recall_unk=82.15 total/acc_i=59.67 total/acc_c=51.56 total/h_score=62.19\n",
      "Loss: 2.5011683025477844\n",
      "Loss: 1.2550792988435722\n",
      "Loss: 0.8604932048438508\n",
      "Loss: 0.7195398714316725\n",
      "Loss: 0.6450528758788796\n",
      "Loss: 0.5875049188671779\n",
      "Loss: 0.5348869395354157\n",
      "Loss: 0.5099925540479613\n",
      "Loss: 0.4574583161147043\n",
      "Loss: 0.4358477851858846\n",
      "______\n",
      "Iteration t=6\n",
      "all:  cs/acc_i=67.63 cs/acc_c=68.00 os/recall_knw=56.31 os/recall_unk=79.90 total/acc_i=59.53 total/acc_c=52.09 total/h_score=62.03\n",
      "selected:  cs/acc_i=67.58 cs/acc_c=67.98 os/recall_knw=56.14 os/recall_unk=80.17 total/acc_i=59.54 total/acc_c=52.02 total/h_score=62.05\n",
      "Loss: 2.4861272219719925\n",
      "Loss: 1.2122359021407803\n",
      "Loss: 0.8720835550286905\n",
      "Loss: 0.7215406863185448\n",
      "Loss: 0.6379819302781811\n",
      "Loss: 0.5898066783339028\n",
      "Loss: 0.5242204276647994\n",
      "Loss: 0.4900617102781932\n",
      "Loss: 0.45361167028909777\n",
      "Loss: 0.45124544265369576\n",
      "______\n",
      "Iteration t=7\n",
      "all:  cs/acc_i=67.71 cs/acc_c=68.11 os/recall_knw=56.31 os/recall_unk=79.90 total/acc_i=59.53 total/acc_c=52.09 total/h_score=62.03\n",
      "selected:  cs/acc_i=67.71 cs/acc_c=68.11 os/recall_knw=56.31 os/recall_unk=79.90 total/acc_i=59.53 total/acc_c=52.09 total/h_score=62.03\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 2.481375641939117\n",
      "Loss: 1.2120185250916131\n",
      "Loss: 0.8731727620692757\n",
      "Loss: 0.7127244724490778\n",
      "Loss: 0.6380603378865777\n",
      "Loss: 0.5638091393360277\n",
      "Loss: 0.5343390340969815\n",
      "Loss: 0.4987383917943249\n",
      "Loss: 0.4682611560191565\n",
      "Loss: 0.4352555463347978\n",
      "______\n",
      "Iteration t=8\n",
      "all:  cs/acc_i=67.91 cs/acc_c=68.12 os/recall_knw=56.31 os/recall_unk=79.90 total/acc_i=59.53 total/acc_c=52.09 total/h_score=62.03\n",
      "selected:  cs/acc_i=67.91 cs/acc_c=68.12 os/recall_knw=56.31 os/recall_unk=79.90 total/acc_i=59.53 total/acc_c=52.09 total/h_score=62.03\n",
      "Loss: 2.48270826271879\n",
      "Loss: 1.2310545044701273\n",
      "Loss: 0.8499781169542452\n",
      "Loss: 0.7092316527434481\n",
      "Loss: 0.6270047402599963\n",
      "Loss: 0.5664213852184575\n",
      "Loss: 0.5510018781675556\n",
      "Loss: 0.4949737236933495\n",
      "Loss: 0.47575753578931335\n",
      "Loss: 0.44949637177756163\n",
      "______\n",
      "Iteration t=9\n",
      "all:  cs/acc_i=67.79 cs/acc_c=68.12 os/recall_knw=56.31 os/recall_unk=79.90 total/acc_i=59.53 total/acc_c=52.09 total/h_score=62.03\n",
      "selected:  cs/acc_i=67.79 cs/acc_c=68.12 os/recall_knw=56.31 os/recall_unk=79.90 total/acc_i=59.53 total/acc_c=52.09 total/h_score=62.03\n",
      "tensor(0)\n",
      "all:  cs/acc_i=67.79 cs/acc_c=68.12 os/recall_knw=56.31 os/recall_unk=79.90 total/acc_i=59.53 total/acc_c=52.09 total/h_score=62.03\n",
      "sketch -> painting lr= 0.001 seed= 4\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19]\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20]\n",
      "Loss: 2.670072133393632\n",
      "Loss: 1.5753809904929288\n",
      "Loss: 1.117822550313989\n",
      "Loss: 0.9262535080467302\n",
      "Loss: 0.8595299594795581\n",
      "Loss: 0.7807536125183105\n",
      "Loss: 0.7101216171820139\n",
      "Loss: 0.6936783114659417\n",
      "Loss: 0.6174205583088177\n",
      "Loss: 0.6063168173291019\n",
      "tensor(True) tensor(True)\n",
      "______\n",
      "Iteration t=1\n",
      "all:  cs/acc_i=64.93 cs/acc_c=65.60 os/recall_knw=81.62 os/recall_unk=39.04 total/acc_i=53.33 total/acc_c=59.83 total/h_score=47.57\n",
      "selected:  cs/acc_i=58.64 cs/acc_c=60.43 os/recall_knw=46.70 os/recall_unk=96.91 total/acc_i=63.15 total/acc_c=49.28 total/h_score=63.21\n",
      "Loss: 2.618898934788174\n",
      "Loss: 1.451563679077775\n",
      "Loss: 1.0070880438394592\n",
      "Loss: 0.8582916842854541\n",
      "Loss: 0.7868439797042073\n",
      "Loss: 0.6903386369419559\n",
      "Loss: 0.6196423892813604\n",
      "Loss: 0.6047846349541116\n",
      "Loss: 0.5614187123550884\n",
      "Loss: 0.5465107696211856\n",
      "______\n",
      "Iteration t=2\n",
      "all:  cs/acc_i=66.14 cs/acc_c=66.71 os/recall_knw=62.85 os/recall_unk=69.85 total/acc_i=58.84 total/acc_c=55.18 total/h_score=61.19\n",
      "selected:  cs/acc_i=60.09 cs/acc_c=61.97 os/recall_knw=45.01 os/recall_unk=94.28 total/acc_i=59.56 total/acc_c=46.17 total/h_score=59.78\n",
      "Loss: 2.5834177591583947\n",
      "Loss: 1.3613455628806894\n",
      "Loss: 0.9568492718718269\n",
      "Loss: 0.7745459763841196\n",
      "Loss: 0.70764198100025\n",
      "Loss: 0.6269220104271715\n",
      "Loss: 0.6052369497039102\n",
      "Loss: 0.5698991092091257\n",
      "Loss: 0.5243696527724916\n",
      "Loss: 0.498818851871924\n",
      "______\n",
      "Iteration t=3\n",
      "all:  cs/acc_i=65.67 cs/acc_c=66.21 os/recall_knw=60.19 os/recall_unk=76.25 total/acc_i=60.09 total/acc_c=54.31 total/h_score=62.68\n",
      "selected:  cs/acc_i=62.30 cs/acc_c=63.59 os/recall_knw=51.27 os/recall_unk=89.56 total/acc_i=60.45 total/acc_c=49.87 total/h_score=62.41\n",
      "Loss: 2.550271159126645\n",
      "Loss: 1.2716776839582435\n",
      "Loss: 0.9019291911806379\n",
      "Loss: 0.7331650942176967\n",
      "Loss: 0.6854904961018335\n",
      "Loss: 0.5994877677201192\n",
      "Loss: 0.56867250174413\n",
      "Loss: 0.515794271772558\n",
      "Loss: 0.5065055441159707\n",
      "Loss: 0.4631917881114142\n",
      "______\n",
      "Iteration t=4\n",
      "all:  cs/acc_i=67.24 cs/acc_c=67.48 os/recall_knw=59.29 os/recall_unk=77.33 total/acc_i=60.22 total/acc_c=54.04 total/h_score=62.80\n",
      "selected:  cs/acc_i=65.70 cs/acc_c=66.39 os/recall_knw=54.83 os/recall_unk=84.33 total/acc_i=60.43 total/acc_c=51.99 total/h_score=63.07\n",
      "Loss: 2.5197212536464675\n",
      "Loss: 1.2645888834817638\n",
      "Loss: 0.8724054588184197\n",
      "Loss: 0.7182114659243548\n",
      "Loss: 0.6413334091836937\n",
      "Loss: 0.5855988216699417\n",
      "Loss: 0.5561488132970602\n",
      "Loss: 0.5171149624940242\n",
      "Loss: 0.4830459411797663\n",
      "Loss: 0.45284059487875533\n",
      "______\n",
      "Iteration t=5\n",
      "all:  cs/acc_i=66.93 cs/acc_c=67.23 os/recall_knw=58.70 os/recall_unk=77.82 total/acc_i=60.09 total/acc_c=53.60 total/h_score=62.62\n",
      "selected:  cs/acc_i=66.30 cs/acc_c=67.01 os/recall_knw=56.94 os/recall_unk=81.34 total/acc_i=60.33 total/acc_c=53.08 total/h_score=63.19\n",
      "Loss: 2.4927242969880337\n",
      "Loss: 1.2232213655456168\n",
      "Loss: 0.8507109505475544\n",
      "Loss: 0.7029881104826927\n",
      "Loss: 0.6415202817345251\n",
      "Loss: 0.5808713477043832\n",
      "Loss: 0.5455976266597138\n",
      "Loss: 0.500058075810065\n",
      "Loss: 0.47419519227792006\n",
      "Loss: 0.46369957777320364\n",
      "______\n",
      "Iteration t=6\n",
      "all:  cs/acc_i=68.14 cs/acc_c=68.64 os/recall_knw=58.42 os/recall_unk=78.07 total/acc_i=60.09 total/acc_c=53.52 total/h_score=62.64\n",
      "selected:  cs/acc_i=68.00 cs/acc_c=68.56 os/recall_knw=58.13 os/recall_unk=79.06 total/acc_i=60.19 total/acc_c=53.42 total/h_score=62.84\n",
      "Loss: 2.484868075097761\n",
      "Loss: 1.2031687553371153\n",
      "Loss: 0.8193251078407611\n",
      "Loss: 0.6871962057005975\n",
      "Loss: 0.6228833035115273\n",
      "Loss: 0.5725574836495423\n",
      "Loss: 0.5273746639009445\n",
      "Loss: 0.5085517946750887\n",
      "Loss: 0.45925191201029286\n",
      "Loss: 0.4425182683213103\n",
      "______\n",
      "Iteration t=7\n",
      "all:  cs/acc_i=68.26 cs/acc_c=68.80 os/recall_knw=58.39 os/recall_unk=78.16 total/acc_i=60.12 total/acc_c=53.53 total/h_score=62.66\n",
      "selected:  cs/acc_i=68.24 cs/acc_c=68.78 os/recall_knw=58.35 os/recall_unk=78.22 total/acc_i=60.11 total/acc_c=53.51 total/h_score=62.66\n",
      "Loss: 2.4696296151862085\n",
      "Loss: 1.203055790629253\n",
      "Loss: 0.832716800960671\n",
      "Loss: 0.7058011342483352\n",
      "Loss: 0.6189865218587669\n",
      "Loss: 0.5692458556119697\n",
      "Loss: 0.5277508064565888\n",
      "Loss: 0.5009857689640129\n",
      "Loss: 0.4794750562513688\n",
      "Loss: 0.4363535559141492\n",
      "______\n",
      "Iteration t=8\n",
      "all:  cs/acc_i=68.14 cs/acc_c=68.60 os/recall_knw=58.39 os/recall_unk=78.16 total/acc_i=60.12 total/acc_c=53.53 total/h_score=62.66\n",
      "selected:  cs/acc_i=68.14 cs/acc_c=68.60 os/recall_knw=58.39 os/recall_unk=78.16 total/acc_i=60.12 total/acc_c=53.53 total/h_score=62.66\n",
      "Loss: 2.481298147435169\n",
      "Loss: 1.2081356970181905\n",
      "Loss: 0.8527511402545683\n",
      "Loss: 0.7200785971070868\n",
      "Loss: 0.6115806063255632\n",
      "Loss: 0.5773448444992663\n",
      "Loss: 0.5287849792993691\n",
      "Loss: 0.5110110407732577\n",
      "Loss: 0.4739467466332348\n",
      "Loss: 0.43316844662269915\n",
      "______\n",
      "Iteration t=9\n",
      "all:  cs/acc_i=68.57 cs/acc_c=68.86 os/recall_knw=58.39 os/recall_unk=78.16 total/acc_i=60.12 total/acc_c=53.53 total/h_score=62.66\n",
      "selected:  cs/acc_i=68.57 cs/acc_c=68.86 os/recall_knw=58.39 os/recall_unk=78.16 total/acc_i=60.12 total/acc_c=53.53 total/h_score=62.66\n",
      "tensor(0)\n",
      "all:  cs/acc_i=68.57 cs/acc_c=68.86 os/recall_knw=58.39 os/recall_unk=78.16 total/acc_i=60.12 total/acc_c=53.53 total/h_score=62.66\n",
      "sketch -> painting lr= 0.001 seed= 0\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19]\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20]\n",
      "Loss: 2.6830400271514026\n",
      "Loss: 1.6269770172453417\n",
      "Loss: 1.131378944387141\n",
      "Loss: 0.9235868647540968\n",
      "Loss: 0.8249871114787367\n",
      "Loss: 0.7524485832329878\n",
      "Loss: 0.7151402680529761\n",
      "Loss: 0.6493152568942493\n",
      "Loss: 0.6383042201092562\n",
      "Loss: 0.5937626257385176\n",
      "tensor(True) tensor(True)\n",
      "______\n",
      "Iteration t=1\n",
      "all:  cs/acc_i=66.07 cs/acc_c=66.64 os/recall_knw=81.94 os/recall_unk=39.70 total/acc_i=54.10 total/acc_c=60.52 total/h_score=48.27\n",
      "selected:  cs/acc_i=60.39 cs/acc_c=62.42 os/recall_knw=47.37 os/recall_unk=97.75 total/acc_i=64.10 total/acc_c=50.41 total/h_score=64.42\n",
      "Loss: 2.617607693741287\n",
      "Loss: 1.4539505971802607\n",
      "Loss: 1.0055200552594834\n",
      "Loss: 0.8681945816618233\n",
      "Loss: 0.7576630800818476\n",
      "Loss: 0.7108941484908551\n",
      "Loss: 0.652137779959158\n",
      "Loss: 0.5828284742895532\n",
      "Loss: 0.5944493195572913\n",
      "Loss: 0.553456951526628\n",
      "______\n",
      "Iteration t=2\n",
      "all:  cs/acc_i=66.50 cs/acc_c=66.89 os/recall_knw=61.60 os/recall_unk=73.75 total/acc_i=59.96 total/acc_c=55.09 total/h_score=62.46\n",
      "selected:  cs/acc_i=60.01 cs/acc_c=61.10 os/recall_knw=44.57 os/recall_unk=95.07 total/acc_i=59.81 total/acc_c=45.43 total/h_score=59.17\n",
      "Loss: 2.5670227337967266\n",
      "Loss: 1.356291894208301\n",
      "Loss: 0.9287019832567736\n",
      "Loss: 0.7888247381557117\n",
      "Loss: 0.7226284482262352\n",
      "Loss: 0.6389363723045046\n",
      "Loss: 0.6018577516078949\n",
      "Loss: 0.5673105946995995\n",
      "Loss: 0.5398652468892661\n",
      "Loss: 0.49432417083192953\n",
      "______\n",
      "Iteration t=3\n",
      "all:  cs/acc_i=67.36 cs/acc_c=67.68 os/recall_knw=58.23 os/recall_unk=79.40 total/acc_i=60.41 total/acc_c=53.46 total/h_score=62.96\n",
      "selected:  cs/acc_i=64.33 cs/acc_c=65.28 os/recall_knw=50.09 os/recall_unk=89.43 total/acc_i=60.03 total/acc_c=48.87 total/h_score=61.48\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 2.561079726074681\n",
      "Loss: 1.2837187103378824\n",
      "Loss: 0.9063423782974095\n",
      "Loss: 0.7509966779064823\n",
      "Loss: 0.667102397262276\n",
      "Loss: 0.6167773975954427\n",
      "Loss: 0.5992457626056877\n",
      "Loss: 0.5190226067325253\n",
      "Loss: 0.4831751099912635\n",
      "Loss: 0.46244022082456776\n",
      "______\n",
      "Iteration t=4\n",
      "all:  cs/acc_i=67.83 cs/acc_c=67.91 os/recall_knw=56.54 os/recall_unk=81.06 total/acc_i=60.33 total/acc_c=52.63 total/h_score=62.77\n",
      "selected:  cs/acc_i=66.68 cs/acc_c=67.22 os/recall_knw=53.58 os/recall_unk=85.46 total/acc_i=60.27 total/acc_c=51.11 total/h_score=62.60\n",
      "Loss: 2.5150367216086287\n",
      "Loss: 1.2391736567269809\n",
      "Loss: 0.8783539503688094\n",
      "Loss: 0.7279385156212491\n",
      "Loss: 0.6516952899335319\n",
      "Loss: 0.5722798176390357\n",
      "Loss: 0.5559431855648631\n",
      "Loss: 0.49844749733244526\n",
      "Loss: 0.4784858753616341\n",
      "Loss: 0.4522155043532659\n",
      "______\n",
      "Iteration t=5\n",
      "all:  cs/acc_i=67.87 cs/acc_c=68.03 os/recall_knw=56.43 os/recall_unk=81.40 total/acc_i=60.38 total/acc_c=52.58 total/h_score=62.81\n",
      "selected:  cs/acc_i=67.40 cs/acc_c=67.74 os/recall_knw=55.31 os/recall_unk=83.19 total/acc_i=60.37 total/acc_c=52.04 total/h_score=62.83\n",
      "Loss: 2.4817104472054377\n",
      "Loss: 1.264903013107708\n",
      "Loss: 0.86275597192623\n",
      "Loss: 0.7288525651511832\n",
      "Loss: 0.628501503555863\n",
      "Loss: 0.5867595385622095\n",
      "Loss: 0.5259383827938464\n",
      "Loss: 0.4996346084117399\n",
      "Loss: 0.4596681801809205\n",
      "Loss: 0.45400282915359663\n",
      "______\n",
      "Iteration t=6\n",
      "all:  cs/acc_i=68.42 cs/acc_c=68.83 os/recall_knw=56.35 os/recall_unk=81.40 total/acc_i=60.36 total/acc_c=52.53 total/h_score=62.77\n",
      "selected:  cs/acc_i=68.31 cs/acc_c=68.78 os/recall_knw=56.14 os/recall_unk=81.80 total/acc_i=60.35 total/acc_c=52.44 total/h_score=62.80\n",
      "Loss: 2.508803858075823\n",
      "Loss: 1.233312210014888\n",
      "Loss: 0.8503143780085505\n",
      "Loss: 0.7262742583848992\n",
      "Loss: 0.6156766224880608\n",
      "Loss: 0.5659725914196092\n",
      "Loss: 0.5381769744109134\n",
      "Loss: 0.49431269843967596\n",
      "Loss: 0.4537796941946964\n",
      "Loss: 0.4350506298091947\n",
      "______\n",
      "Iteration t=7\n",
      "all:  cs/acc_i=68.53 cs/acc_c=68.59 os/recall_knw=56.31 os/recall_unk=81.48 total/acc_i=60.36 total/acc_c=52.50 total/h_score=62.77\n",
      "selected:  cs/acc_i=68.53 cs/acc_c=68.59 os/recall_knw=56.31 os/recall_unk=81.48 total/acc_i=60.36 total/acc_c=52.50 total/h_score=62.77\n",
      "Loss: 2.5016831590877318\n",
      "Loss: 1.22114507381509\n",
      "Loss: 0.8569337095671553\n",
      "Loss: 0.7160555995334454\n",
      "Loss: 0.6303631419815668\n",
      "Loss: 0.5627737326350638\n",
      "Loss: 0.5259520524158711\n",
      "Loss: 0.5044426188115182\n",
      "Loss: 0.4615021274099505\n",
      "Loss: 0.45797914296873216\n",
      "______\n",
      "Iteration t=8\n",
      "all:  cs/acc_i=68.97 cs/acc_c=69.28 os/recall_knw=56.31 os/recall_unk=81.48 total/acc_i=60.36 total/acc_c=52.50 total/h_score=62.77\n",
      "selected:  cs/acc_i=68.97 cs/acc_c=69.28 os/recall_knw=56.31 os/recall_unk=81.48 total/acc_i=60.36 total/acc_c=52.50 total/h_score=62.77\n",
      "Loss: 2.4956125951394803\n",
      "Loss: 1.2438648493309332\n",
      "Loss: 0.8501546315061368\n",
      "Loss: 0.7158149757036348\n",
      "Loss: 0.6495185186707877\n",
      "Loss: 0.5682565743724505\n",
      "Loss: 0.5349648951636097\n",
      "Loss: 0.499838992771579\n",
      "Loss: 0.46775093129495293\n",
      "Loss: 0.44543415211080534\n",
      "______\n",
      "Iteration t=9\n",
      "all:  cs/acc_i=68.65 cs/acc_c=69.12 os/recall_knw=56.31 os/recall_unk=81.48 total/acc_i=60.36 total/acc_c=52.50 total/h_score=62.77\n",
      "selected:  cs/acc_i=68.65 cs/acc_c=69.12 os/recall_knw=56.31 os/recall_unk=81.48 total/acc_i=60.36 total/acc_c=52.50 total/h_score=62.77\n",
      "tensor(0)\n",
      "all:  cs/acc_i=68.65 cs/acc_c=69.12 os/recall_knw=56.31 os/recall_unk=81.48 total/acc_i=60.36 total/acc_c=52.50 total/h_score=62.77\n",
      "sketch -> painting lr= 0.001 seed= 1\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19]\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20]\n",
      "Loss: 2.6778744428428176\n",
      "Loss: 1.5990503703810506\n",
      "Loss: 1.133637801273582\n",
      "Loss: 0.9468013548973909\n",
      "Loss: 0.8443455914246667\n",
      "Loss: 0.7644336223602295\n",
      "Loss: 0.7031165018831331\n",
      "Loss: 0.6700369419203591\n",
      "Loss: 0.630388739182777\n",
      "Loss: 0.6087715568923459\n",
      "tensor(True) tensor(True)\n",
      "______\n",
      "Iteration t=1\n",
      "all:  cs/acc_i=65.05 cs/acc_c=65.42 os/recall_knw=81.50 os/recall_unk=38.79 total/acc_i=53.83 total/acc_c=60.23 total/h_score=47.51\n",
      "selected:  cs/acc_i=56.07 cs/acc_c=58.02 os/recall_knw=46.42 os/recall_unk=96.49 total/acc_i=62.71 total/acc_c=49.29 total/h_score=63.14\n",
      "Loss: 2.6366069599050252\n",
      "Loss: 1.47039500641938\n",
      "Loss: 1.0202603276800994\n",
      "Loss: 0.8511281589379057\n",
      "Loss: 0.782604851440531\n",
      "Loss: 0.6902333402979202\n",
      "Loss: 0.6507286878599636\n",
      "Loss: 0.6063575193213956\n",
      "Loss: 0.5622707469307858\n",
      "Loss: 0.5438016014542557\n",
      "______\n",
      "Iteration t=2\n",
      "all:  cs/acc_i=66.42 cs/acc_c=66.88 os/recall_knw=63.95 os/recall_unk=71.18 total/acc_i=59.98 total/acc_c=56.05 total/h_score=62.24\n",
      "selected:  cs/acc_i=60.29 cs/acc_c=61.70 os/recall_knw=46.04 os/recall_unk=94.49 total/acc_i=60.72 total/acc_c=47.13 total/h_score=60.75\n",
      "Loss: 2.583342043919997\n",
      "Loss: 1.3612595999782735\n",
      "Loss: 0.9279635873707858\n",
      "Loss: 0.7871810583905741\n",
      "Loss: 0.6900719280947338\n",
      "Loss: 0.6458699523047967\n",
      "Loss: 0.5922897660596804\n",
      "Loss: 0.5554443682459268\n",
      "Loss: 0.5207345099611715\n",
      "Loss: 0.4897345309230414\n",
      "______\n",
      "Iteration t=3\n",
      "all:  cs/acc_i=66.34 cs/acc_c=66.66 os/recall_knw=56.19 os/recall_unk=81.31 total/acc_i=60.04 total/acc_c=52.01 total/h_score=62.34\n",
      "selected:  cs/acc_i=62.97 cs/acc_c=63.86 os/recall_knw=47.93 os/recall_unk=90.15 total/acc_i=59.20 total/acc_c=46.98 total/h_score=59.88\n",
      "Loss: 2.536540461419451\n",
      "Loss: 1.3114021417875998\n",
      "Loss: 0.9296979289908597\n",
      "Loss: 0.7734686399130842\n",
      "Loss: 0.6873080627626728\n",
      "Loss: 0.6224629861428748\n",
      "Loss: 0.594282703888989\n",
      "Loss: 0.5602189607625445\n",
      "Loss: 0.5003186277557148\n",
      "Loss: 0.4727053157822534\n",
      "______\n",
      "Iteration t=4\n",
      "all:  cs/acc_i=67.01 cs/acc_c=67.31 os/recall_knw=54.78 os/recall_unk=82.56 total/acc_i=59.90 total/acc_c=51.37 total/h_score=62.14\n",
      "selected:  cs/acc_i=65.64 cs/acc_c=66.31 os/recall_knw=51.82 os/recall_unk=86.81 total/acc_i=59.66 total/acc_c=49.58 total/h_score=61.59\n",
      "Loss: 2.502759997351763\n",
      "Loss: 1.2427385879468313\n",
      "Loss: 0.8942695916453495\n",
      "Loss: 0.7329528231158036\n",
      "Loss: 0.6660938181203125\n",
      "Loss: 0.606554814343211\n",
      "Loss: 0.5473416885243186\n",
      "Loss: 0.5070141703519138\n",
      "Loss: 0.4899268587933311\n",
      "Loss: 0.460754364980424\n",
      "______\n",
      "Iteration t=5\n",
      "all:  cs/acc_i=67.87 cs/acc_c=68.04 os/recall_knw=54.70 os/recall_unk=82.56 total/acc_i=59.85 total/acc_c=51.30 total/h_score=62.08\n",
      "selected:  cs/acc_i=67.52 cs/acc_c=67.81 os/recall_knw=53.65 os/recall_unk=84.38 total/acc_i=59.91 total/acc_c=50.82 total/h_score=62.11\n",
      "Loss: 2.4978968343458887\n",
      "Loss: 1.231315464027657\n",
      "Loss: 0.8842616428521054\n",
      "Loss: 0.7328082101404174\n",
      "Loss: 0.6384436932723384\n",
      "Loss: 0.6034864770972039\n",
      "Loss: 0.5433148582242737\n",
      "Loss: 0.5062922404324712\n",
      "Loss: 0.48464755270599336\n",
      "Loss: 0.43039483521595473\n",
      "______\n",
      "Iteration t=6\n",
      "all:  cs/acc_i=67.87 cs/acc_c=68.15 os/recall_knw=54.58 os/recall_unk=82.64 total/acc_i=59.85 total/acc_c=51.27 total/h_score=62.08\n",
      "selected:  cs/acc_i=67.85 cs/acc_c=68.15 os/recall_knw=54.44 os/recall_unk=83.33 total/acc_i=59.98 total/acc_c=51.26 total/h_score=62.23\n",
      "Loss: 2.4923030157638677\n",
      "Loss: 1.2575758558241918\n",
      "Loss: 0.852600233299742\n",
      "Loss: 0.6978405309925354\n",
      "Loss: 0.6409791451668052\n",
      "Loss: 0.574963240405169\n",
      "Loss: 0.5433858822525284\n",
      "Loss: 0.5070392761088203\n",
      "Loss: 0.48167067778453904\n",
      "Loss: 0.46475283191405203\n",
      "______\n",
      "Iteration t=7\n",
      "all:  cs/acc_i=68.65 cs/acc_c=68.76 os/recall_knw=54.58 os/recall_unk=82.64 total/acc_i=59.85 total/acc_c=51.27 total/h_score=62.08\n",
      "selected:  cs/acc_i=68.65 cs/acc_c=68.76 os/recall_knw=54.58 os/recall_unk=82.64 total/acc_i=59.85 total/acc_c=51.27 total/h_score=62.08\n",
      "Loss: 2.4974538512894364\n",
      "Loss: 1.2330133717079632\n",
      "Loss: 0.8528461602867626\n",
      "Loss: 0.7250386475295317\n",
      "Loss: 0.6243668805624618\n",
      "Loss: 0.5738536425423427\n",
      "Loss: 0.5325558873840043\n",
      "Loss: 0.492288901638545\n",
      "Loss: 0.46990108190745605\n",
      "Loss: 0.44200427976788065\n",
      "______\n",
      "Iteration t=8\n",
      "all:  cs/acc_i=68.77 cs/acc_c=69.12 os/recall_knw=54.58 os/recall_unk=82.64 total/acc_i=59.85 total/acc_c=51.27 total/h_score=62.08\n",
      "selected:  cs/acc_i=68.77 cs/acc_c=69.12 os/recall_knw=54.58 os/recall_unk=82.64 total/acc_i=59.85 total/acc_c=51.27 total/h_score=62.08\n",
      "Loss: 2.491987882578959\n",
      "Loss: 1.2265206067288508\n",
      "Loss: 0.8597522980121316\n",
      "Loss: 0.7247426843301195\n",
      "Loss: 0.6200491390267356\n",
      "Loss: 0.5892063221726261\n",
      "Loss: 0.5509473581905248\n",
      "Loss: 0.5030345561929414\n",
      "Loss: 0.4658609582569267\n",
      "Loss: 0.45363070617323037\n",
      "______\n",
      "Iteration t=9\n",
      "all:  cs/acc_i=68.03 cs/acc_c=68.56 os/recall_knw=54.58 os/recall_unk=82.64 total/acc_i=59.85 total/acc_c=51.27 total/h_score=62.08\n",
      "selected:  cs/acc_i=68.03 cs/acc_c=68.56 os/recall_knw=54.58 os/recall_unk=82.64 total/acc_i=59.85 total/acc_c=51.27 total/h_score=62.08\n",
      "tensor(0)\n",
      "all:  cs/acc_i=68.03 cs/acc_c=68.56 os/recall_knw=54.58 os/recall_unk=82.64 total/acc_i=59.85 total/acc_c=51.27 total/h_score=62.08\n",
      "sketch -> painting lr= 0.001 seed= 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19]\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20]\n",
      "Loss: 2.680974315122231\n",
      "Loss: 1.5903894206912248\n",
      "Loss: 1.137612421795265\n",
      "Loss: 0.9610049062475716\n",
      "Loss: 0.8090056801579663\n",
      "Loss: 0.7600589174892485\n",
      "Loss: 0.6991563686697754\n",
      "Loss: 0.6555561146785304\n",
      "Loss: 0.6472147124790654\n",
      "Loss: 0.597991328878501\n",
      "tensor(True) tensor(True)\n",
      "______\n",
      "Iteration t=1\n",
      "all:  cs/acc_i=65.01 cs/acc_c=65.67 os/recall_knw=81.78 os/recall_unk=39.37 total/acc_i=53.75 total/acc_c=60.19 total/h_score=47.92\n",
      "selected:  cs/acc_i=57.67 cs/acc_c=58.81 os/recall_knw=46.80 os/recall_unk=96.73 total/acc_i=63.34 total/acc_c=49.26 total/h_score=63.16\n",
      "Loss: 2.6186220035460837\n",
      "Loss: 1.4773788112373167\n",
      "Loss: 1.0286256319658769\n",
      "Loss: 0.8600234164707903\n",
      "Loss: 0.7764996628542453\n",
      "Loss: 0.7096467306072586\n",
      "Loss: 0.6530070490595223\n",
      "Loss: 0.6321680951809537\n",
      "Loss: 0.5894582578957369\n",
      "Loss: 0.528064637368428\n",
      "______\n",
      "Iteration t=2\n",
      "all:  cs/acc_i=66.97 cs/acc_c=67.34 os/recall_knw=64.85 os/recall_unk=69.68 total/acc_i=59.77 total/acc_c=56.30 total/h_score=61.87\n",
      "selected:  cs/acc_i=61.72 cs/acc_c=62.86 os/recall_knw=46.77 os/recall_unk=95.02 total/acc_i=61.37 total/acc_c=47.76 total/h_score=61.44\n",
      "Loss: 2.5561985319310967\n",
      "Loss: 1.3604643645611676\n",
      "Loss: 0.9288690674034032\n",
      "Loss: 0.7967783998359333\n",
      "Loss: 0.6926607802510262\n",
      "Loss: 0.6614401084455577\n",
      "Loss: 0.5948930463330312\n",
      "Loss: 0.5573061307722872\n",
      "Loss: 0.5302207352085547\n",
      "Loss: 0.49882888814265075\n",
      "______\n",
      "Iteration t=3\n",
      "all:  cs/acc_i=67.55 cs/acc_c=67.99 os/recall_knw=60.03 os/recall_unk=77.16 total/acc_i=60.54 total/acc_c=54.32 total/h_score=62.97\n",
      "selected:  cs/acc_i=64.87 cs/acc_c=66.02 os/recall_knw=51.31 os/recall_unk=91.08 total/acc_i=61.28 total/acc_c=50.20 total/h_score=63.00\n",
      "Loss: 2.542558183359063\n",
      "Loss: 1.2985870537550552\n",
      "Loss: 0.883868540369946\n",
      "Loss: 0.7423257788886195\n",
      "Loss: 0.6741297680398692\n",
      "Loss: 0.63608302720215\n",
      "Loss: 0.578000998561797\n",
      "Loss: 0.5428580470059229\n",
      "Loss: 0.5088178318479787\n",
      "Loss: 0.467493551256864\n",
      "______\n",
      "Iteration t=4\n",
      "all:  cs/acc_i=67.75 cs/acc_c=68.01 os/recall_knw=58.42 os/recall_unk=79.07 total/acc_i=60.60 total/acc_c=53.67 total/h_score=63.03\n",
      "selected:  cs/acc_i=66.54 cs/acc_c=67.38 os/recall_knw=54.83 os/recall_unk=85.00 total/acc_i=60.82 total/acc_c=52.19 total/h_score=63.39\n",
      "Loss: 2.4922675213554415\n",
      "Loss: 1.249121769202803\n",
      "Loss: 0.8777434071486964\n",
      "Loss: 0.7531946442366644\n",
      "Loss: 0.6370696737177701\n",
      "Loss: 0.5987473001789348\n",
      "Loss: 0.5320344112782299\n",
      "Loss: 0.5233822170660586\n",
      "Loss: 0.48711217559531145\n",
      "Loss: 0.46246326649288755\n",
      "______\n",
      "Iteration t=5\n",
      "all:  cs/acc_i=68.14 cs/acc_c=68.45 os/recall_knw=57.92 os/recall_unk=79.57 total/acc_i=60.60 total/acc_c=53.48 total/h_score=63.03\n",
      "selected:  cs/acc_i=67.65 cs/acc_c=68.31 os/recall_knw=56.47 os/recall_unk=82.23 total/acc_i=60.74 total/acc_c=53.02 total/h_score=63.38\n",
      "Loss: 2.4897188617557777\n",
      "Loss: 1.2149543505711633\n",
      "Loss: 0.8542283520591064\n",
      "Loss: 0.7146587947108707\n",
      "Loss: 0.6477284917577368\n",
      "Loss: 0.5762514364523966\n",
      "Loss: 0.5514408297470359\n",
      "Loss: 0.5054565654059903\n",
      "Loss: 0.4756471571497253\n",
      "Loss: 0.4423742389275891\n",
      "______\n",
      "Iteration t=6\n",
      "all:  cs/acc_i=68.42 cs/acc_c=68.73 os/recall_knw=57.84 os/recall_unk=79.57 total/acc_i=60.57 total/acc_c=53.43 total/h_score=62.99\n",
      "selected:  cs/acc_i=68.27 cs/acc_c=68.66 os/recall_knw=57.54 os/recall_unk=80.30 total/acc_i=60.61 total/acc_c=53.32 total/h_score=63.10\n",
      "Loss: 2.4986659051918307\n",
      "Loss: 1.2186537068865078\n",
      "Loss: 0.8489399374979227\n",
      "Loss: 0.7191586072145686\n",
      "Loss: 0.6220712526003841\n",
      "Loss: 0.5539513381748546\n",
      "Loss: 0.5383923434414845\n",
      "Loss: 0.4923464570209565\n",
      "Loss: 0.46228387306335\n",
      "Loss: 0.4468198778778918\n",
      "______\n",
      "Iteration t=7\n",
      "all:  cs/acc_i=68.38 cs/acc_c=68.77 os/recall_knw=57.84 os/recall_unk=79.57 total/acc_i=60.57 total/acc_c=53.43 total/h_score=62.99\n",
      "selected:  cs/acc_i=68.38 cs/acc_c=68.77 os/recall_knw=57.84 os/recall_unk=79.57 total/acc_i=60.57 total/acc_c=53.43 total/h_score=62.99\n",
      "Loss: 2.4906360434909023\n",
      "Loss: 1.22546222830011\n",
      "Loss: 0.84160370680113\n",
      "Loss: 0.7158664235424611\n",
      "Loss: 0.6344066736919265\n",
      "Loss: 0.5760822141723286\n",
      "Loss: 0.5308686288734598\n",
      "Loss: 0.5060273770603442\n",
      "Loss: 0.46838478233304714\n",
      "Loss: 0.435973392859582\n",
      "______\n",
      "Iteration t=8\n",
      "all:  cs/acc_i=67.99 cs/acc_c=68.26 os/recall_knw=57.84 os/recall_unk=79.57 total/acc_i=60.57 total/acc_c=53.43 total/h_score=62.99\n",
      "selected:  cs/acc_i=67.99 cs/acc_c=68.26 os/recall_knw=57.84 os/recall_unk=79.57 total/acc_i=60.57 total/acc_c=53.43 total/h_score=62.99\n",
      "Loss: 2.4939294197866992\n",
      "Loss: 1.1880147762356266\n",
      "Loss: 0.8362910069765583\n",
      "Loss: 0.7031472879311731\n",
      "Loss: 0.615214362980858\n",
      "Loss: 0.5929246908955036\n",
      "Loss: 0.5260261524949343\n",
      "Loss: 0.48415331085843427\n",
      "Loss: 0.4635187333389636\n",
      "Loss: 0.43044285755604506\n",
      "______\n",
      "Iteration t=9\n",
      "all:  cs/acc_i=68.73 cs/acc_c=69.14 os/recall_knw=57.84 os/recall_unk=79.57 total/acc_i=60.60 total/acc_c=53.48 total/h_score=63.02\n",
      "selected:  cs/acc_i=68.73 cs/acc_c=69.14 os/recall_knw=57.84 os/recall_unk=79.57 total/acc_i=60.60 total/acc_c=53.48 total/h_score=63.02\n",
      "tensor(0)\n",
      "all:  cs/acc_i=68.73 cs/acc_c=69.14 os/recall_knw=57.84 os/recall_unk=79.57 total/acc_i=60.60 total/acc_c=53.48 total/h_score=63.02\n",
      "sketch -> painting lr= 0.001 seed= 3\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19]\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20]\n",
      "Loss: 2.687432246724355\n",
      "Loss: 1.6030740820869958\n",
      "Loss: 1.106426864247961\n",
      "Loss: 0.9477300677717346\n",
      "Loss: 0.8299447417873698\n",
      "Loss: 0.7431274386718101\n",
      "Loss: 0.7074527483932751\n",
      "Loss: 0.655001725271805\n",
      "Loss: 0.6401810624550298\n",
      "Loss: 0.5862281552909576\n",
      "tensor(True) tensor(True)\n",
      "______\n",
      "Iteration t=1\n",
      "all:  cs/acc_i=64.69 cs/acc_c=65.35 os/recall_knw=81.97 os/recall_unk=39.78 total/acc_i=53.91 total/acc_c=60.29 total/h_score=48.26\n",
      "selected:  cs/acc_i=56.17 cs/acc_c=58.35 os/recall_knw=46.94 os/recall_unk=96.18 total/acc_i=63.08 total/acc_c=49.64 total/h_score=63.43\n",
      "Loss: 2.6301753780116206\n",
      "Loss: 1.469965129946741\n",
      "Loss: 1.02773667504822\n",
      "Loss: 0.878106082983063\n",
      "Loss: 0.7640939822807404\n",
      "Loss: 0.6935275444661938\n",
      "Loss: 0.6557527578971236\n",
      "Loss: 0.6271679340209362\n",
      "Loss: 0.5622294306899038\n",
      "Loss: 0.5252598500338154\n",
      "______\n",
      "Iteration t=2\n",
      "all:  cs/acc_i=65.71 cs/acc_c=66.10 os/recall_knw=62.34 os/recall_unk=72.43 total/acc_i=59.50 total/acc_c=54.99 total/h_score=61.95\n",
      "selected:  cs/acc_i=58.88 cs/acc_c=59.98 os/recall_knw=44.58 os/recall_unk=93.76 total/acc_i=59.27 total/acc_c=45.02 total/h_score=58.57\n",
      "Loss: 2.5870291265574368\n",
      "Loss: 1.372462959452109\n",
      "Loss: 0.9403017752549865\n",
      "Loss: 0.8078654023734007\n",
      "Loss: 0.711466184258461\n",
      "Loss: 0.6441186680035158\n",
      "Loss: 0.5979955712502653\n",
      "Loss: 0.5634320607916875\n",
      "Loss: 0.5374265109950845\n",
      "Loss: 0.49704192287542603\n",
      "______\n",
      "Iteration t=3\n",
      "all:  cs/acc_i=66.50 cs/acc_c=66.88 os/recall_knw=59.87 os/recall_unk=76.16 total/acc_i=59.96 total/acc_c=54.13 total/h_score=62.53\n",
      "selected:  cs/acc_i=62.77 cs/acc_c=63.87 os/recall_knw=50.56 os/recall_unk=88.94 total/acc_i=59.80 total/acc_c=49.07 total/h_score=61.57\n",
      "Loss: 2.538929752163265\n",
      "Loss: 1.2852905983510226\n",
      "Loss: 0.8913439964470656\n",
      "Loss: 0.7701771384995917\n",
      "Loss: 0.6682870814333791\n",
      "Loss: 0.601976967635362\n",
      "Loss: 0.5448148693079534\n",
      "Loss: 0.5124971720835437\n",
      "Loss: 0.48038344448027404\n",
      "Loss: 0.4788868814058926\n",
      "______\n",
      "Iteration t=4\n",
      "all:  cs/acc_i=66.65 cs/acc_c=66.81 os/recall_knw=58.86 os/recall_unk=76.91 total/acc_i=59.90 total/acc_c=53.71 total/h_score=62.44\n",
      "selected:  cs/acc_i=64.93 cs/acc_c=65.52 os/recall_knw=54.76 os/recall_unk=83.73 total/acc_i=59.99 total/acc_c=51.61 total/h_score=62.61\n",
      "Loss: 2.529059511348293\n",
      "Loss: 1.282811273840182\n",
      "Loss: 0.8528058876801734\n",
      "Loss: 0.7125190556298738\n",
      "Loss: 0.6506791808116386\n",
      "Loss: 0.5987597019976652\n",
      "Loss: 0.5416193553967455\n",
      "Loss: 0.5242315690387742\n",
      "Loss: 0.4814842779766067\n",
      "Loss: 0.45539217308225993\n",
      "______\n",
      "Iteration t=5\n",
      "all:  cs/acc_i=67.44 cs/acc_c=67.60 os/recall_knw=58.62 os/recall_unk=77.57 total/acc_i=59.98 total/acc_c=53.54 total/h_score=62.51\n",
      "selected:  cs/acc_i=66.82 cs/acc_c=67.17 os/recall_knw=57.11 os/recall_unk=80.10 total/acc_i=60.01 total/acc_c=52.85 total/h_score=62.68\n",
      "Loss: 2.4946472430715754\n",
      "Loss: 1.2485753944941929\n",
      "Loss: 0.8496485093418433\n",
      "Loss: 0.7370472974923192\n",
      "Loss: 0.6326319531518586\n",
      "Loss: 0.5794803416242404\n",
      "Loss: 0.5289905824223343\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.49749425686135584\n",
      "Loss: 0.4564200506830702\n",
      "Loss: 0.44537140179653556\n",
      "______\n",
      "Iteration t=6\n",
      "all:  cs/acc_i=67.32 cs/acc_c=67.70 os/recall_knw=58.62 os/recall_unk=77.66 total/acc_i=60.01 total/acc_c=53.55 total/h_score=62.54\n",
      "selected:  cs/acc_i=67.18 cs/acc_c=67.61 os/recall_knw=58.24 os/recall_unk=78.37 total/acc_i=60.05 total/acc_c=53.38 total/h_score=62.62\n",
      "Loss: 2.484122005681838\n",
      "Loss: 1.2115757782613077\n",
      "Loss: 0.8488386004201828\n",
      "Loss: 0.6948819572646772\n",
      "Loss: 0.6358779590697058\n",
      "Loss: 0.5772925560633021\n",
      "Loss: 0.5392591575340878\n",
      "Loss: 0.4850277528166771\n",
      "Loss: 0.4642150536660225\n",
      "Loss: 0.4444373811204587\n",
      "______\n",
      "Iteration t=7\n",
      "all:  cs/acc_i=68.61 cs/acc_c=69.05 os/recall_knw=58.54 os/recall_unk=77.74 total/acc_i=60.01 total/acc_c=53.52 total/h_score=62.54\n",
      "selected:  cs/acc_i=68.61 cs/acc_c=69.05 os/recall_knw=58.54 os/recall_unk=77.87 total/acc_i=60.04 total/acc_c=53.53 total/h_score=62.58\n",
      "Loss: 2.4780596499462204\n",
      "Loss: 1.2115030020595077\n",
      "Loss: 0.8561366202840843\n",
      "Loss: 0.7140886149253233\n",
      "Loss: 0.625110984506856\n",
      "Loss: 0.5727772037666964\n",
      "Loss: 0.5148606074742045\n",
      "Loss: 0.4990480580483096\n",
      "Loss: 0.4520966328650593\n",
      "Loss: 0.4444542074179554\n",
      "______\n",
      "Iteration t=8\n",
      "all:  cs/acc_i=68.14 cs/acc_c=68.49 os/recall_knw=58.54 os/recall_unk=77.74 total/acc_i=60.01 total/acc_c=53.52 total/h_score=62.54\n",
      "selected:  cs/acc_i=68.14 cs/acc_c=68.49 os/recall_knw=58.54 os/recall_unk=77.74 total/acc_i=60.01 total/acc_c=53.52 total/h_score=62.54\n",
      "Loss: 2.4872006824217645\n",
      "Loss: 1.2186515927314758\n",
      "Loss: 0.8301732742403406\n",
      "Loss: 0.7055599822337368\n",
      "Loss: 0.6302751610317383\n",
      "Loss: 0.5636693522274254\n",
      "Loss: 0.5158290673331564\n",
      "Loss: 0.4830603364660558\n",
      "Loss: 0.46672630310058594\n",
      "Loss: 0.4263286253055894\n",
      "______\n",
      "Iteration t=9\n",
      "all:  cs/acc_i=68.42 cs/acc_c=69.02 os/recall_knw=58.54 os/recall_unk=77.74 total/acc_i=60.01 total/acc_c=53.52 total/h_score=62.54\n",
      "selected:  cs/acc_i=68.42 cs/acc_c=69.02 os/recall_knw=58.54 os/recall_unk=77.74 total/acc_i=60.01 total/acc_c=53.52 total/h_score=62.54\n",
      "tensor(0)\n",
      "all:  cs/acc_i=68.42 cs/acc_c=69.02 os/recall_knw=58.54 os/recall_unk=77.74 total/acc_i=60.01 total/acc_c=53.52 total/h_score=62.54\n",
      "sketch -> painting lr= 0.001 seed= 4\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19]\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20]\n",
      "Loss: 2.6692282582066724\n",
      "Loss: 1.5765549260930918\n",
      "Loss: 1.1198473938347138\n",
      "Loss: 0.9281133579224655\n",
      "Loss: 0.8616877886437878\n",
      "Loss: 0.7837415150145894\n",
      "Loss: 0.7123620404103368\n",
      "Loss: 0.6952745321485185\n",
      "Loss: 0.6204206018718248\n",
      "Loss: 0.6083297982197446\n",
      "tensor(True) tensor(True)\n",
      "______\n",
      "Iteration t=1\n",
      "all:  cs/acc_i=64.97 cs/acc_c=65.65 os/recall_knw=81.90 os/recall_unk=39.62 total/acc_i=53.73 total/acc_c=60.14 total/h_score=48.09\n",
      "selected:  cs/acc_i=58.35 cs/acc_c=59.94 os/recall_knw=47.14 os/recall_unk=97.35 total/acc_i=63.78 total/acc_c=49.67 total/h_score=63.65\n",
      "Loss: 2.622541128149355\n",
      "Loss: 1.457261697969575\n",
      "Loss: 1.0268501506911383\n",
      "Loss: 0.8578327766075227\n",
      "Loss: 0.7871784379228878\n",
      "Loss: 0.6920087704623955\n",
      "Loss: 0.6460378836606435\n",
      "Loss: 0.6167169108195005\n",
      "Loss: 0.5582147034038092\n",
      "Loss: 0.5438279651357356\n",
      "______\n",
      "Iteration t=2\n",
      "all:  cs/acc_i=66.77 cs/acc_c=67.33 os/recall_knw=63.44 os/recall_unk=70.68 total/acc_i=59.42 total/acc_c=55.63 total/h_score=61.78\n",
      "selected:  cs/acc_i=60.80 cs/acc_c=62.55 os/recall_knw=45.66 os/recall_unk=94.66 total/acc_i=60.09 total/acc_c=46.63 total/h_score=60.29\n",
      "Loss: 2.5881651970473203\n",
      "Loss: 1.3888713105158372\n",
      "Loss: 0.9659007599407976\n",
      "Loss: 0.7883448721332984\n",
      "Loss: 0.720080414685336\n",
      "Loss: 0.6260091063651172\n",
      "Loss: 0.6045758862387051\n",
      "Loss: 0.5673882942985404\n",
      "Loss: 0.5354528358036822\n",
      "Loss: 0.5013507757674563\n",
      "______\n",
      "Iteration t=3\n",
      "all:  cs/acc_i=67.16 cs/acc_c=67.53 os/recall_knw=57.95 os/recall_unk=77.57 total/acc_i=59.74 total/acc_c=53.07 total/h_score=62.15\n",
      "selected:  cs/acc_i=64.05 cs/acc_c=65.38 os/recall_knw=49.65 os/recall_unk=89.89 total/acc_i=59.78 total/acc_c=48.82 total/h_score=61.53\n",
      "Loss: 2.5340494871139527\n",
      "Loss: 1.2883326149505117\n",
      "Loss: 0.890612486652706\n",
      "Loss: 0.7761310753615006\n",
      "Loss: 0.6773043818447901\n",
      "Loss: 0.5993697447621305\n",
      "Loss: 0.5697229240899501\n",
      "Loss: 0.5302148502805959\n",
      "Loss: 0.4985169739826866\n",
      "Loss: 0.4491400922770086\n",
      "______\n",
      "Iteration t=4\n",
      "all:  cs/acc_i=68.06 cs/acc_c=68.44 os/recall_knw=57.37 os/recall_unk=78.41 total/acc_i=59.93 total/acc_c=53.03 total/h_score=62.36\n",
      "selected:  cs/acc_i=66.74 cs/acc_c=67.67 os/recall_knw=53.60 os/recall_unk=85.20 total/acc_i=60.21 total/acc_c=51.42 total/h_score=62.80\n",
      "Loss: 2.51289055678023\n",
      "Loss: 1.2573110075557934\n",
      "Loss: 0.8800295731600594\n",
      "Loss: 0.721922182360617\n",
      "Loss: 0.6496122155119392\n",
      "Loss: 0.58914803006068\n",
      "Loss: 0.5434964455100668\n",
      "Loss: 0.5134584300157403\n",
      "Loss: 0.4905519017151424\n",
      "Loss: 0.4361295977748242\n",
      "______\n",
      "Iteration t=5\n",
      "all:  cs/acc_i=68.22 cs/acc_c=68.39 os/recall_knw=57.09 os/recall_unk=78.82 total/acc_i=59.93 total/acc_c=52.85 total/h_score=62.34\n",
      "selected:  cs/acc_i=67.60 cs/acc_c=68.02 os/recall_knw=55.65 os/recall_unk=81.46 total/acc_i=59.96 total/acc_c=52.19 total/h_score=62.52\n",
      "Loss: 2.4833404744257694\n",
      "Loss: 1.208553638614592\n",
      "Loss: 0.8668160068451382\n",
      "Loss: 0.7108263995070927\n",
      "Loss: 0.6280879942608661\n",
      "Loss: 0.5656831043421245\n",
      "Loss: 0.5258010564158198\n",
      "Loss: 0.4987514753077851\n",
      "Loss: 0.458116424682199\n",
      "Loss: 0.4602663504173521\n",
      "______\n",
      "Iteration t=6\n",
      "all:  cs/acc_i=68.18 cs/acc_c=68.55 os/recall_knw=56.94 os/recall_unk=78.99 total/acc_i=59.90 total/acc_c=52.75 total/h_score=62.30\n",
      "selected:  cs/acc_i=68.02 cs/acc_c=68.41 os/recall_knw=56.61 os/recall_unk=79.38 total/acc_i=59.85 total/acc_c=52.55 total/h_score=62.25\n",
      "Loss: 2.473520011071734\n",
      "Loss: 1.2198075821042544\n",
      "Loss: 0.8571133269713476\n",
      "Loss: 0.7268359142276439\n",
      "Loss: 0.626858957684957\n",
      "Loss: 0.5858237937032452\n",
      "Loss: 0.5443906272471193\n",
      "Loss: 0.5091029337422568\n",
      "Loss: 0.4603334783542494\n",
      "Loss: 0.4266963579394074\n",
      "______\n",
      "Iteration t=7\n",
      "all:  cs/acc_i=69.00 cs/acc_c=69.49 os/recall_knw=56.90 os/recall_unk=78.99 total/acc_i=59.90 total/acc_c=52.75 total/h_score=62.30\n",
      "selected:  cs/acc_i=68.99 cs/acc_c=69.48 os/recall_knw=56.88 os/recall_unk=79.05 total/acc_i=59.91 total/acc_c=52.74 total/h_score=62.31\n",
      "Loss: 2.4740970694584403\n",
      "Loss: 1.23633039045913\n",
      "Loss: 0.8685697729770954\n",
      "Loss: 0.7096632801086796\n",
      "Loss: 0.6190659238500633\n",
      "Loss: 0.5743672799484932\n",
      "Loss: 0.5353035275270099\n",
      "Loss: 0.49622928444673176\n",
      "Loss: 0.45814261292880365\n",
      "Loss: 0.4390815013212714\n",
      "______\n",
      "Iteration t=8\n",
      "all:  cs/acc_i=68.10 cs/acc_c=68.67 os/recall_knw=56.90 os/recall_unk=78.99 total/acc_i=59.90 total/acc_c=52.75 total/h_score=62.30\n",
      "selected:  cs/acc_i=68.10 cs/acc_c=68.67 os/recall_knw=56.90 os/recall_unk=78.99 total/acc_i=59.90 total/acc_c=52.75 total/h_score=62.30\n",
      "Loss: 2.482586721659672\n",
      "Loss: 1.2188788652420044\n",
      "Loss: 0.8398480736292325\n",
      "Loss: 0.7201732120774536\n",
      "Loss: 0.6235333361365052\n",
      "Loss: 0.593833401497559\n",
      "Loss: 0.5487977710330052\n",
      "Loss: 0.510130951067938\n",
      "Loss: 0.48100307601907477\n",
      "Loss: 0.44407706565943805\n",
      "______\n",
      "Iteration t=9\n",
      "all:  cs/acc_i=68.14 cs/acc_c=68.63 os/recall_knw=56.90 os/recall_unk=78.99 total/acc_i=59.90 total/acc_c=52.75 total/h_score=62.30\n",
      "selected:  cs/acc_i=68.14 cs/acc_c=68.63 os/recall_knw=56.90 os/recall_unk=78.99 total/acc_i=59.90 total/acc_c=52.75 total/h_score=62.30\n",
      "tensor(0)\n",
      "all:  cs/acc_i=68.14 cs/acc_c=68.63 os/recall_knw=56.90 os/recall_unk=78.99 total/acc_i=59.90 total/acc_c=52.75 total/h_score=62.30\n"
     ]
    }
   ],
   "source": [
    "results = pd.DataFrame({'source': [], 'target': [], 'desc': [], 'lr': [], 'seed': [], 'epochs': [], 'weights': []})\n",
    "for (source, target), (common, tgt_private) in config.items():\n",
    "    for epochs in [10]:\n",
    "        for lr in [1e-3]:\n",
    "            for n_r in [0.1, 0.25]:\n",
    "                for weights in [[0.33, 0.33, 0.33], [0.2, 0.4, 0.4], [0.4, 0.2, 0.4], [0.4, 0.4, 0.2]]:\n",
    "                    for seed in range(5):\n",
    "                        set_seed(seed)\n",
    "                        print(source, '->', target, 'lr=', lr, 'seed=', seed)\n",
    "                        params = Params(pca_dim=512, proj_dim=128, T=10, n_r=1200, n_r_ratio=None,\n",
    "                                  dataset='DomainNet_DCC', source=source, target=target,\n",
    "                                  num_common=len(common), num_src_priv=0, num_tgt_priv=len(tgt_private))\n",
    "                        (feats_S, lbls_S), (feats_T, lbls_T) = create_datasets_sub(params.dataset, \n",
    "                                                                                   params.source, \n",
    "                                                                                   params.target, \n",
    "                                                                                   common, \n",
    "                                                                                   tgt_private)\n",
    "                        params.n_r = int(len(lbls_T) * n_r)\n",
    "                        num_src_classes = params.num_common + params.num_src_priv\n",
    "\n",
    "                        # l2 normalization and pca\n",
    "                        feats_S, feats_T = do_l2_normalization(feats_S, feats_T)\n",
    "                        feats_S, feats_T = do_pca(feats_S, feats_T, params.pca_dim)\n",
    "                        feats_S, feats_T = do_l2_normalization(feats_S, feats_T)\n",
    "\n",
    "                        # initial\n",
    "                        feats_S, feats_T = torch.tensor(feats_S), torch.tensor(feats_T)\n",
    "                        lbls_S, lbls_T = torch.tensor(lbls_S), torch.tensor(lbls_T)\n",
    "                        feats_all = torch.cat((feats_S, feats_T), dim=0)\n",
    "                        pseudo_labels = -torch.ones_like(lbls_T)\n",
    "                        rejected = torch.zeros_like(pseudo_labels)\n",
    "\n",
    "                        t = 1\n",
    "\n",
    "                        model = train_initial_NN(feats_S, lbls_S, epochs, params, balanced=True, lr=lr)\n",
    "                        feats_S_2, preds_S_2 = predict_NN(model, feats_S, lbls_S)\n",
    "                        feats_T_2, preds_T_2 = predict_NN(model, feats_T, lbls_T)\n",
    "                        print((feats_S_2 == feats_S).all(), (feats_T_2 == feats_T).all())\n",
    "                        assert (feats_S_2 == feats_S).all() and (feats_T_2 == feats_T).all()\n",
    "\n",
    "                        confs, cs_pseudo_labels = preds_T_2.max(dim=1)\n",
    "                        selected = select_closed_set_pseudo_labels_weighted(cs_pseudo_labels.numpy(), confs.numpy(), t, params.T, preds_T_2, weights)\n",
    "                        selected = torch.tensor(selected)\n",
    "                        rejected = select_initial_rejected_weighted(confs, params.n_r, preds_T_2, weights)\n",
    "\n",
    "                        rejected = torch.tensor(rejected)\n",
    "                        selected = selected * (1 - rejected)\n",
    "\n",
    "                        pseudo_labels = cs_pseudo_labels.clone()\n",
    "                        pseudo_labels[rejected == 1] = num_src_classes\n",
    "                        pseudo_labels[(rejected == 0) * (selected == 0)] = -1\n",
    "\n",
    "                        metrics = evaluate_T(params.num_common, params.num_src_priv, params.num_tgt_priv, \n",
    "                                lbls_T.numpy(), cs_pseudo_labels.numpy(), rejected.numpy())\n",
    "                        where = torch.where((selected == 1) + (rejected == 1))[0]\n",
    "                        metrics_selected = evaluate_T(params.num_common, params.num_src_priv, params.num_tgt_priv, lbls_T[where].numpy(), cs_pseudo_labels[where].numpy(), rejected[where].numpy())\n",
    "                        print('______')\n",
    "                        print(f'Iteration t={t}')\n",
    "                        print('all: ', fmeasures(metrics))\n",
    "                        print('selected: ', fmeasures(metrics_selected))\n",
    "\n",
    "                        for t in range(2, params.T):\n",
    "                            model = train_NN(feats_all, torch.cat((lbls_S, pseudo_labels), axis=0), epochs, params, balanced=True, lr=lr)\n",
    "                            feats_S_2, preds_S_2 = predict_NN(model, feats_S, lbls_S)\n",
    "                            feats_T_2, preds_T_2 = predict_NN(model, feats_T, lbls_T)\n",
    "                            assert (feats_S_2 == feats_S).all() and (feats_T_2 == feats_T).all()\n",
    "\n",
    "                            confs, cs_pseudo_labels = preds_T_2.max(dim=1)\n",
    "                            selected = torch.tensor(select_closed_set_pseudo_labels_weighted(cs_pseudo_labels.numpy(), confs.numpy(), t, params.T, preds_T_2, weights))\n",
    "                            selected = selected * (1 - rejected)\n",
    "\n",
    "                            scores = get_weighted_scores(confs, preds_T_2, weights)\n",
    "\n",
    "                            rejected_new = (scores < min(scores[rejected == 1].max().item(), scores[selected == 1].min().item())).int()\n",
    "\n",
    "\n",
    "\n",
    "                            rejected[rejected_new == 1] = 1\n",
    "                            selected = selected * (1 - rejected)\n",
    "\n",
    "                            pseudo_labels = cs_pseudo_labels.clone()\n",
    "                            pseudo_labels[rejected == 1] = num_src_classes\n",
    "                            pseudo_labels[(rejected == 0) * (selected == 0)] = -1\n",
    "\n",
    "                            metrics = evaluate_T(params.num_common, params.num_src_priv, params.num_tgt_priv, lbls_T.numpy(), cs_pseudo_labels.numpy(), rejected.numpy())\n",
    "                            where = torch.where((selected == 1) + (rejected == 1))[0]\n",
    "                            metrics_selected = evaluate_T(params.num_common, params.num_src_priv, params.num_tgt_priv, lbls_T[where].numpy(), cs_pseudo_labels[where].numpy(), rejected[where].numpy())\n",
    "                            print('______')\n",
    "                            print(f'Iteration t={t}')\n",
    "                            print('all: ', fmeasures(metrics))\n",
    "                            print('selected: ', fmeasures(metrics_selected))\n",
    "\n",
    "                        print((pseudo_labels == -1).sum())\n",
    "\n",
    "                        _rejected = rejected\n",
    "                        metrics = evaluate_T(params.num_common, params.num_src_priv, params.num_tgt_priv, lbls_T.numpy(), cs_pseudo_labels.numpy(), _rejected.numpy())\n",
    "                        print('all: ', fmeasures(metrics))\n",
    "\n",
    "                        results = results.append({'weights': str(weights), 'source': source, 'target': target, 'desc': fmeasures(metrics), 'lr': lr, 'seed': seed, 'n_r': n_r, 'epochs': epochs}, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.to_csv('results_weighted_scores/dcc__conf__small__NEW__weighted__nn_raw.csv', header=True, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# df = pd.read_csv('office_home_oslpp_nn_raw.csv')\n",
    "# df['h_score'] = df['desc'].apply(lambda x: float(x.split()[-1].split('=')[-1]))\n",
    "# import matplotlib.pyplot as plt\n",
    "# for n, gr in df.groupby(['source', 'target']):\n",
    "#     stat = gr.groupby(['lr', 'n_r'])['h_score'].mean()\n",
    "#     exps = np.array(list(stat.index))\n",
    "#     fig, ax = plt.subplots()\n",
    "#     ax.scatter(exps[:, 0], exps[:, 1], c=stat.values)\n",
    "#     for i, txt in enumerate(stat.values):\n",
    "#         ax.annotate(round(txt, 2), (exps[i][0], exps[i][1]))\n",
    "#     plt.title(n)\n",
    "#     plt.xlabel('lr')\n",
    "#     plt.ylabel('n_r')\n",
    "#     plt.xticks(exps[:, 0])\n",
    "#     plt.yticks(exps[:, 1])\n",
    "#     fig.colorbar(ax.get_children()[0])\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>target</th>\n",
       "      <th>desc</th>\n",
       "      <th>lr</th>\n",
       "      <th>seed</th>\n",
       "      <th>epochs</th>\n",
       "      <th>weights</th>\n",
       "      <th>n_r</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>painting</td>\n",
       "      <td>sketch</td>\n",
       "      <td>cs/acc_i=50.87 cs/acc_c=52.71 os/recall_knw=58...</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>[0.33, 0.33, 0.33]</td>\n",
       "      <td>0.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>painting</td>\n",
       "      <td>sketch</td>\n",
       "      <td>cs/acc_i=51.02 cs/acc_c=52.77 os/recall_knw=55...</td>\n",
       "      <td>0.001</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>[0.33, 0.33, 0.33]</td>\n",
       "      <td>0.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>painting</td>\n",
       "      <td>sketch</td>\n",
       "      <td>cs/acc_i=50.38 cs/acc_c=51.95 os/recall_knw=59...</td>\n",
       "      <td>0.001</td>\n",
       "      <td>2.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>[0.33, 0.33, 0.33]</td>\n",
       "      <td>0.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>painting</td>\n",
       "      <td>sketch</td>\n",
       "      <td>cs/acc_i=51.70 cs/acc_c=53.25 os/recall_knw=59...</td>\n",
       "      <td>0.001</td>\n",
       "      <td>3.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>[0.33, 0.33, 0.33]</td>\n",
       "      <td>0.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>painting</td>\n",
       "      <td>sketch</td>\n",
       "      <td>cs/acc_i=51.06 cs/acc_c=52.63 os/recall_knw=57...</td>\n",
       "      <td>0.001</td>\n",
       "      <td>4.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>[0.33, 0.33, 0.33]</td>\n",
       "      <td>0.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235</th>\n",
       "      <td>sketch</td>\n",
       "      <td>painting</td>\n",
       "      <td>cs/acc_i=68.65 cs/acc_c=69.12 os/recall_knw=56...</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>[0.4, 0.4, 0.2]</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>236</th>\n",
       "      <td>sketch</td>\n",
       "      <td>painting</td>\n",
       "      <td>cs/acc_i=68.03 cs/acc_c=68.56 os/recall_knw=54...</td>\n",
       "      <td>0.001</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>[0.4, 0.4, 0.2]</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>237</th>\n",
       "      <td>sketch</td>\n",
       "      <td>painting</td>\n",
       "      <td>cs/acc_i=68.73 cs/acc_c=69.14 os/recall_knw=57...</td>\n",
       "      <td>0.001</td>\n",
       "      <td>2.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>[0.4, 0.4, 0.2]</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238</th>\n",
       "      <td>sketch</td>\n",
       "      <td>painting</td>\n",
       "      <td>cs/acc_i=68.42 cs/acc_c=69.02 os/recall_knw=58...</td>\n",
       "      <td>0.001</td>\n",
       "      <td>3.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>[0.4, 0.4, 0.2]</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239</th>\n",
       "      <td>sketch</td>\n",
       "      <td>painting</td>\n",
       "      <td>cs/acc_i=68.14 cs/acc_c=68.63 os/recall_knw=56...</td>\n",
       "      <td>0.001</td>\n",
       "      <td>4.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>[0.4, 0.4, 0.2]</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>240 rows  8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       source    target                                               desc  \\\n",
       "0    painting    sketch  cs/acc_i=50.87 cs/acc_c=52.71 os/recall_knw=58...   \n",
       "1    painting    sketch  cs/acc_i=51.02 cs/acc_c=52.77 os/recall_knw=55...   \n",
       "2    painting    sketch  cs/acc_i=50.38 cs/acc_c=51.95 os/recall_knw=59...   \n",
       "3    painting    sketch  cs/acc_i=51.70 cs/acc_c=53.25 os/recall_knw=59...   \n",
       "4    painting    sketch  cs/acc_i=51.06 cs/acc_c=52.63 os/recall_knw=57...   \n",
       "..        ...       ...                                                ...   \n",
       "235    sketch  painting  cs/acc_i=68.65 cs/acc_c=69.12 os/recall_knw=56...   \n",
       "236    sketch  painting  cs/acc_i=68.03 cs/acc_c=68.56 os/recall_knw=54...   \n",
       "237    sketch  painting  cs/acc_i=68.73 cs/acc_c=69.14 os/recall_knw=57...   \n",
       "238    sketch  painting  cs/acc_i=68.42 cs/acc_c=69.02 os/recall_knw=58...   \n",
       "239    sketch  painting  cs/acc_i=68.14 cs/acc_c=68.63 os/recall_knw=56...   \n",
       "\n",
       "        lr  seed  epochs             weights   n_r  \n",
       "0    0.001   0.0    10.0  [0.33, 0.33, 0.33]  0.10  \n",
       "1    0.001   1.0    10.0  [0.33, 0.33, 0.33]  0.10  \n",
       "2    0.001   2.0    10.0  [0.33, 0.33, 0.33]  0.10  \n",
       "3    0.001   3.0    10.0  [0.33, 0.33, 0.33]  0.10  \n",
       "4    0.001   4.0    10.0  [0.33, 0.33, 0.33]  0.10  \n",
       "..     ...   ...     ...                 ...   ...  \n",
       "235  0.001   0.0    10.0     [0.4, 0.4, 0.2]  0.25  \n",
       "236  0.001   1.0    10.0     [0.4, 0.4, 0.2]  0.25  \n",
       "237  0.001   2.0    10.0     [0.4, 0.4, 0.2]  0.25  \n",
       "238  0.001   3.0    10.0     [0.4, 0.4, 0.2]  0.25  \n",
       "239  0.001   4.0    10.0     [0.4, 0.4, 0.2]  0.25  \n",
       "\n",
       "[240 rows x 8 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "results['epoch'] = pd.Series(results.index).apply(lambda i: epochs[(i // 9) % 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.read_csv('results_weighted_scores/dcc__conf__small__NEW__weighted__nn_raw.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "wd = results.copy()\n",
    "wd['h_score'] = wd['desc'].apply(lambda x: float(x.split()[-1].split('=')[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>target</th>\n",
       "      <th>desc</th>\n",
       "      <th>lr</th>\n",
       "      <th>seed</th>\n",
       "      <th>epochs</th>\n",
       "      <th>weights</th>\n",
       "      <th>n_r</th>\n",
       "      <th>h_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>painting</td>\n",
       "      <td>sketch</td>\n",
       "      <td>cs/acc_i=50.23 cs/acc_c=51.69 os/recall_knw=56...</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>[0.33, 0.33, 0.33]</td>\n",
       "      <td>0.10</td>\n",
       "      <td>48.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>painting</td>\n",
       "      <td>sketch</td>\n",
       "      <td>cs/acc_i=52.11 cs/acc_c=53.79 os/recall_knw=58...</td>\n",
       "      <td>0.001</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>[0.33, 0.33, 0.33]</td>\n",
       "      <td>0.10</td>\n",
       "      <td>50.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>painting</td>\n",
       "      <td>sketch</td>\n",
       "      <td>cs/acc_i=51.06 cs/acc_c=52.70 os/recall_knw=58...</td>\n",
       "      <td>0.001</td>\n",
       "      <td>2.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>[0.33, 0.33, 0.33]</td>\n",
       "      <td>0.10</td>\n",
       "      <td>49.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>painting</td>\n",
       "      <td>sketch</td>\n",
       "      <td>cs/acc_i=50.15 cs/acc_c=51.65 os/recall_knw=57...</td>\n",
       "      <td>0.001</td>\n",
       "      <td>3.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>[0.33, 0.33, 0.33]</td>\n",
       "      <td>0.10</td>\n",
       "      <td>49.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>painting</td>\n",
       "      <td>sketch</td>\n",
       "      <td>cs/acc_i=50.79 cs/acc_c=52.41 os/recall_knw=56...</td>\n",
       "      <td>0.001</td>\n",
       "      <td>4.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>[0.33, 0.33, 0.33]</td>\n",
       "      <td>0.10</td>\n",
       "      <td>49.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235</th>\n",
       "      <td>sketch</td>\n",
       "      <td>painting</td>\n",
       "      <td>cs/acc_i=68.61 cs/acc_c=68.97 os/recall_knw=58...</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>[0.4, 0.4, 0.2]</td>\n",
       "      <td>0.25</td>\n",
       "      <td>63.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>236</th>\n",
       "      <td>sketch</td>\n",
       "      <td>painting</td>\n",
       "      <td>cs/acc_i=68.69 cs/acc_c=68.92 os/recall_knw=53...</td>\n",
       "      <td>0.001</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>[0.4, 0.4, 0.2]</td>\n",
       "      <td>0.25</td>\n",
       "      <td>62.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>237</th>\n",
       "      <td>sketch</td>\n",
       "      <td>painting</td>\n",
       "      <td>cs/acc_i=69.12 cs/acc_c=69.16 os/recall_knw=59...</td>\n",
       "      <td>0.001</td>\n",
       "      <td>2.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>[0.4, 0.4, 0.2]</td>\n",
       "      <td>0.25</td>\n",
       "      <td>62.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238</th>\n",
       "      <td>sketch</td>\n",
       "      <td>painting</td>\n",
       "      <td>cs/acc_i=67.63 cs/acc_c=67.95 os/recall_knw=55...</td>\n",
       "      <td>0.001</td>\n",
       "      <td>3.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>[0.4, 0.4, 0.2]</td>\n",
       "      <td>0.25</td>\n",
       "      <td>61.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239</th>\n",
       "      <td>sketch</td>\n",
       "      <td>painting</td>\n",
       "      <td>cs/acc_i=67.95 cs/acc_c=68.42 os/recall_knw=57...</td>\n",
       "      <td>0.001</td>\n",
       "      <td>4.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>[0.4, 0.4, 0.2]</td>\n",
       "      <td>0.25</td>\n",
       "      <td>62.72</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>240 rows  9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       source    target                                               desc  \\\n",
       "0    painting    sketch  cs/acc_i=50.23 cs/acc_c=51.69 os/recall_knw=56...   \n",
       "1    painting    sketch  cs/acc_i=52.11 cs/acc_c=53.79 os/recall_knw=58...   \n",
       "2    painting    sketch  cs/acc_i=51.06 cs/acc_c=52.70 os/recall_knw=58...   \n",
       "3    painting    sketch  cs/acc_i=50.15 cs/acc_c=51.65 os/recall_knw=57...   \n",
       "4    painting    sketch  cs/acc_i=50.79 cs/acc_c=52.41 os/recall_knw=56...   \n",
       "..        ...       ...                                                ...   \n",
       "235    sketch  painting  cs/acc_i=68.61 cs/acc_c=68.97 os/recall_knw=58...   \n",
       "236    sketch  painting  cs/acc_i=68.69 cs/acc_c=68.92 os/recall_knw=53...   \n",
       "237    sketch  painting  cs/acc_i=69.12 cs/acc_c=69.16 os/recall_knw=59...   \n",
       "238    sketch  painting  cs/acc_i=67.63 cs/acc_c=67.95 os/recall_knw=55...   \n",
       "239    sketch  painting  cs/acc_i=67.95 cs/acc_c=68.42 os/recall_knw=57...   \n",
       "\n",
       "        lr  seed  epochs             weights   n_r  h_score  \n",
       "0    0.001   0.0    10.0  [0.33, 0.33, 0.33]  0.10    48.68  \n",
       "1    0.001   1.0    10.0  [0.33, 0.33, 0.33]  0.10    50.19  \n",
       "2    0.001   2.0    10.0  [0.33, 0.33, 0.33]  0.10    49.43  \n",
       "3    0.001   3.0    10.0  [0.33, 0.33, 0.33]  0.10    49.93  \n",
       "4    0.001   4.0    10.0  [0.33, 0.33, 0.33]  0.10    49.27  \n",
       "..     ...   ...     ...                 ...   ...      ...  \n",
       "235  0.001   0.0    10.0     [0.4, 0.4, 0.2]  0.25    63.69  \n",
       "236  0.001   1.0    10.0     [0.4, 0.4, 0.2]  0.25    62.27  \n",
       "237  0.001   2.0    10.0     [0.4, 0.4, 0.2]  0.25    62.99  \n",
       "238  0.001   3.0    10.0     [0.4, 0.4, 0.2]  0.25    61.61  \n",
       "239  0.001   4.0    10.0     [0.4, 0.4, 0.2]  0.25    62.72  \n",
       "\n",
       "[240 rows x 9 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>target</th>\n",
       "      <th>lr</th>\n",
       "      <th>n_r</th>\n",
       "      <th>epochs</th>\n",
       "      <th>weights</th>\n",
       "      <th>h_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>sketch</td>\n",
       "      <td>real</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.1</td>\n",
       "      <td>10.0</td>\n",
       "      <td>[0.33, 0.33, 0.33]</td>\n",
       "      <td>80.042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>painting</td>\n",
       "      <td>real</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.1</td>\n",
       "      <td>10.0</td>\n",
       "      <td>[0.4, 0.2, 0.4]</td>\n",
       "      <td>78.174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>real</td>\n",
       "      <td>painting</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.1</td>\n",
       "      <td>10.0</td>\n",
       "      <td>[0.4, 0.2, 0.4]</td>\n",
       "      <td>64.244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>sketch</td>\n",
       "      <td>painting</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.1</td>\n",
       "      <td>10.0</td>\n",
       "      <td>[0.4, 0.4, 0.2]</td>\n",
       "      <td>62.856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>real</td>\n",
       "      <td>sketch</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.1</td>\n",
       "      <td>10.0</td>\n",
       "      <td>[0.4, 0.4, 0.2]</td>\n",
       "      <td>55.742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>painting</td>\n",
       "      <td>sketch</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.1</td>\n",
       "      <td>10.0</td>\n",
       "      <td>[0.2, 0.4, 0.4]</td>\n",
       "      <td>49.892</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      source    target     lr  n_r  epochs             weights  h_score\n",
       "41    sketch      real  0.001  0.1    10.0  [0.33, 0.33, 0.33]   80.042\n",
       "2   painting      real  0.001  0.1    10.0     [0.4, 0.2, 0.4]   78.174\n",
       "18      real  painting  0.001  0.1    10.0     [0.4, 0.2, 0.4]   64.244\n",
       "35    sketch  painting  0.001  0.1    10.0     [0.4, 0.4, 0.2]   62.856\n",
       "27      real    sketch  0.001  0.1    10.0     [0.4, 0.4, 0.2]   55.742\n",
       "8   painting    sketch  0.001  0.1    10.0     [0.2, 0.4, 0.4]   49.892"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wd.groupby(['source', 'target', 'lr', 'n_r', 'epochs', 'weights'])['h_score'].mean().to_frame(name = 'h_score').reset_index().sort_values(by='h_score', ascending=False).drop_duplicates(['source', 'target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "wd['name'] = wd['source'].apply(lambda x: x[0].upper()) + wd['target'].apply(lambda x: x[0].upper())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"6\" halign=\"left\">&lt;lambda&gt;</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>PR</th>\n",
       "      <th>PS</th>\n",
       "      <th>RP</th>\n",
       "      <th>RS</th>\n",
       "      <th>SP</th>\n",
       "      <th>SR</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>n_r</th>\n",
       "      <th>lr</th>\n",
       "      <th>epochs</th>\n",
       "      <th>weights</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">0.25</th>\n",
       "      <th rowspan=\"4\" valign=\"top\">0.001</th>\n",
       "      <th rowspan=\"4\" valign=\"top\">10.0</th>\n",
       "      <th>[0.4, 0.4, 0.2]</th>\n",
       "      <td>77.12</td>\n",
       "      <td>49.62</td>\n",
       "      <td>64.09</td>\n",
       "      <td>54.61</td>\n",
       "      <td>62.66</td>\n",
       "      <td>77.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>[0.4, 0.2, 0.4]</th>\n",
       "      <td>77.31</td>\n",
       "      <td>49.79</td>\n",
       "      <td>64.19</td>\n",
       "      <td>54.69</td>\n",
       "      <td>62.37</td>\n",
       "      <td>77.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>[0.33, 0.33, 0.33]</th>\n",
       "      <td>77.46</td>\n",
       "      <td>49.25</td>\n",
       "      <td>63.90</td>\n",
       "      <td>55.06</td>\n",
       "      <td>62.69</td>\n",
       "      <td>78.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>[0.2, 0.4, 0.4]</th>\n",
       "      <td>77.27</td>\n",
       "      <td>49.43</td>\n",
       "      <td>63.96</td>\n",
       "      <td>54.76</td>\n",
       "      <td>62.39</td>\n",
       "      <td>78.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">0.10</th>\n",
       "      <th rowspan=\"4\" valign=\"top\">0.001</th>\n",
       "      <th rowspan=\"4\" valign=\"top\">10.0</th>\n",
       "      <th>[0.4, 0.4, 0.2]</th>\n",
       "      <td>78.10</td>\n",
       "      <td>49.70</td>\n",
       "      <td>63.82</td>\n",
       "      <td>55.74</td>\n",
       "      <td>62.86</td>\n",
       "      <td>80.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>[0.4, 0.2, 0.4]</th>\n",
       "      <td>78.17</td>\n",
       "      <td>49.38</td>\n",
       "      <td>64.24</td>\n",
       "      <td>55.57</td>\n",
       "      <td>62.60</td>\n",
       "      <td>79.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>[0.33, 0.33, 0.33]</th>\n",
       "      <td>78.03</td>\n",
       "      <td>49.50</td>\n",
       "      <td>63.74</td>\n",
       "      <td>55.45</td>\n",
       "      <td>62.65</td>\n",
       "      <td>80.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>[0.2, 0.4, 0.4]</th>\n",
       "      <td>78.03</td>\n",
       "      <td>49.89</td>\n",
       "      <td>63.98</td>\n",
       "      <td>55.41</td>\n",
       "      <td>62.68</td>\n",
       "      <td>79.97</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     <lambda>                              \\\n",
       "name                                       PR     PS     RP     RS     SP   \n",
       "n_r  lr    epochs weights                                                   \n",
       "0.25 0.001 10.0   [0.4, 0.4, 0.2]       77.12  49.62  64.09  54.61  62.66   \n",
       "                  [0.4, 0.2, 0.4]       77.31  49.79  64.19  54.69  62.37   \n",
       "                  [0.33, 0.33, 0.33]    77.46  49.25  63.90  55.06  62.69   \n",
       "                  [0.2, 0.4, 0.4]       77.27  49.43  63.96  54.76  62.39   \n",
       "0.10 0.001 10.0   [0.4, 0.4, 0.2]       78.10  49.70  63.82  55.74  62.86   \n",
       "                  [0.4, 0.2, 0.4]       78.17  49.38  64.24  55.57  62.60   \n",
       "                  [0.33, 0.33, 0.33]    78.03  49.50  63.74  55.45  62.65   \n",
       "                  [0.2, 0.4, 0.4]       78.03  49.89  63.98  55.41  62.68   \n",
       "\n",
       "                                             \n",
       "name                                     SR  \n",
       "n_r  lr    epochs weights                    \n",
       "0.25 0.001 10.0   [0.4, 0.4, 0.2]     77.54  \n",
       "                  [0.4, 0.2, 0.4]     77.29  \n",
       "                  [0.33, 0.33, 0.33]  78.31  \n",
       "                  [0.2, 0.4, 0.4]     78.08  \n",
       "0.10 0.001 10.0   [0.4, 0.4, 0.2]     80.03  \n",
       "                  [0.4, 0.2, 0.4]     79.44  \n",
       "                  [0.33, 0.33, 0.33]  80.04  \n",
       "                  [0.2, 0.4, 0.4]     79.97  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wd.pivot_table(index=['n_r', 'lr', 'epochs', 'weights'], columns='name', values='h_score', aggfunc=[lambda x: round(np.mean(x), 2)]).sort_index(key=lambda x: x, ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wd.set_index(['lr', 'epoch', 'n_r']).head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "wd = pd.read_csv('results/dcc__entropy__StepLR__50_epochs__nn_raw.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "wd['h_score'] = wd['desc'].apply(lambda x: float(x.split()[-1].split('=')[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>target</th>\n",
       "      <th>desc</th>\n",
       "      <th>lr</th>\n",
       "      <th>seed</th>\n",
       "      <th>n_r</th>\n",
       "      <th>h_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>painting_train</td>\n",
       "      <td>real_train</td>\n",
       "      <td>cs/acc_i=59.98 cs/acc_c=60.09 os/recall_knw=71...</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.15</td>\n",
       "      <td>54.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>painting_train</td>\n",
       "      <td>sketch_train</td>\n",
       "      <td>cs/acc_i=26.40 cs/acc_c=25.41 os/recall_knw=53...</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.15</td>\n",
       "      <td>30.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>real_train</td>\n",
       "      <td>painting_train</td>\n",
       "      <td>cs/acc_i=39.74 cs/acc_c=39.39 os/recall_knw=65...</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.15</td>\n",
       "      <td>40.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>real_train</td>\n",
       "      <td>sketch_train</td>\n",
       "      <td>cs/acc_i=24.48 cs/acc_c=23.68 os/recall_knw=51...</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.15</td>\n",
       "      <td>29.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sketch_train</td>\n",
       "      <td>painting_train</td>\n",
       "      <td>cs/acc_i=37.51 cs/acc_c=34.45 os/recall_knw=70...</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.15</td>\n",
       "      <td>35.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>sketch_train</td>\n",
       "      <td>real_train</td>\n",
       "      <td>cs/acc_i=56.05 cs/acc_c=57.00 os/recall_knw=71...</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.15</td>\n",
       "      <td>48.56</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           source          target  \\\n",
       "0  painting_train      real_train   \n",
       "1  painting_train    sketch_train   \n",
       "2      real_train  painting_train   \n",
       "3      real_train    sketch_train   \n",
       "4    sketch_train  painting_train   \n",
       "5    sketch_train      real_train   \n",
       "\n",
       "                                                desc      lr  seed   n_r  \\\n",
       "0  cs/acc_i=59.98 cs/acc_c=60.09 os/recall_knw=71...  0.0005   0.0  0.15   \n",
       "1  cs/acc_i=26.40 cs/acc_c=25.41 os/recall_knw=53...  0.0005   0.0  0.15   \n",
       "2  cs/acc_i=39.74 cs/acc_c=39.39 os/recall_knw=65...  0.0005   0.0  0.15   \n",
       "3  cs/acc_i=24.48 cs/acc_c=23.68 os/recall_knw=51...  0.0005   0.0  0.15   \n",
       "4  cs/acc_i=37.51 cs/acc_c=34.45 os/recall_knw=70...  0.0005   0.0  0.15   \n",
       "5  cs/acc_i=56.05 cs/acc_c=57.00 os/recall_knw=71...  0.0005   0.0  0.15   \n",
       "\n",
       "   h_score  \n",
       "0    54.40  \n",
       "1    30.42  \n",
       "2    40.83  \n",
       "3    29.29  \n",
       "4    35.06  \n",
       "5    48.56  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "87c3e150e0f22e62286b0675a541f4baa4e53a56f1434145374688b05f7921a7"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
