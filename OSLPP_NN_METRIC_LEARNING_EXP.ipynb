{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "% load_ext autoreload\n",
    "% autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "from modules.logging.format_utils import format_measures\n",
    "from modules.collecting.results_collector import DataFrameCollector\n",
    "from modules.logging.logger import DefaultLogger\n",
    "from modules.algorithms.base.OSLPP import Params\n",
    "from modules.selection.uncertanties import SelectRejectMode\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('experiments/configs/small_datasets.pkl', 'rb') as f:\n",
    "    config = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class MlInfoParams:\n",
    "    oslpp_params: Params\n",
    "    tau: float\n",
    "    lr: float\n",
    "    batch_size: int\n",
    "    num_layers: int\n",
    "    pairwise_distance_fn: str  # Callable[[torch.Tensor, torch.Tensor], torch.Tensor]\n",
    "    pos: int\n",
    "    neg: int\n",
    "    epochs: int\n",
    "\n",
    "@dataclass\n",
    "class MlTripletParams:\n",
    "    oslpp_params: Params\n",
    "    margin: float\n",
    "    lr: float\n",
    "    batch_size: int\n",
    "    num_layers: int\n",
    "    normalize: bool\n",
    "    distance_fn: str # Callable[[torch.Tensor, torch.Tensor], torch.Tensor]\n",
    "    pairwise_distance_fn: str # Callable[[torch.Tensor, torch.Tensor], torch.Tensor]\n",
    "    epochs: int"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from modules.algorithms.base.OSLPP import get_l2_normalized\n",
    "from modules.algorithms.nn.OSLPP_NN_UTILS import predict_NN\n",
    "import math\n",
    "\n",
    "\n",
    "def create_model(params: MlTripletParams):\n",
    "    if params.num_layers == 1:\n",
    "        return nn.Linear(params.oslpp_params.pca_dim, params.oslpp_params.proj_dim)\n",
    "    else:\n",
    "        mid_dim = int(math.sqrt(params.oslpp_params.pca_dim * params.oslpp_params.proj_dim))\n",
    "        layers = [nn.Linear(params.oslpp_params.pca_dim, mid_dim)]\n",
    "        for _ in range(1, (params.num_layers - 1)):\n",
    "            layers += [nn.ReLU(), nn.Linear(mid_dim, mid_dim)]\n",
    "        layers += [nn.ReLU(), nn.Linear(mid_dim, params.oslpp_params.proj_dim)]\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "\n",
    "def predict(model, features, labels):\n",
    "    model = model.eval()\n",
    "    preds = predict_NN(model, features, labels)\n",
    "    return get_l2_normalized(preds)  # l2 norm"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from modules.loaders.balanced_sampling import create_train_dataloader\n",
    "from modules.metric_learning.ml import TripletLoss, get_euclidian_distances, \\\n",
    "    get_cosine_distances, TripletDataset, get_pairwise_euclidian_distances, get_pairwise_cosine_distances\n",
    "\n",
    "\n",
    "def get_distance_fn(name):\n",
    "    if name == 'eucl': return get_euclidian_distances\n",
    "    elif name == 'cos': return get_cosine_distances\n",
    "    else: raise Exception(f'Unsupported distance function name {name}')\n",
    "\n",
    "def get_distance_fn_pairwise(name):\n",
    "    if name == 'eucl': return get_pairwise_euclidian_distances\n",
    "    elif name == 'cos': return get_pairwise_cosine_distances\n",
    "    else: raise Exception(f'Unsupported pairwise distance function name {name}')\n",
    "\n",
    "def train_model(features, labels, params: MlTripletParams):\n",
    "    # train model for N classes (remove -1 and -2 and num_src_classes labels)\n",
    "    num_src_classes = params.oslpp_params.num_common + params.oslpp_params.num_src_priv\n",
    "    features, labels = features[labels >= 0], labels[labels >= 0]\n",
    "    # feats, lbls = feats[lbls < num_src_classes], lbls[lbls < num_src_classes]\n",
    "\n",
    "    model = create_model(params).cuda().train()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=params.lr)\n",
    "    distance_fn = get_distance_fn(params.distance_fn)\n",
    "    loss_fn = TripletLoss(distance_fn, params.margin)\n",
    "\n",
    "    ds = TripletDataset(features, labels)\n",
    "    dl = create_train_dataloader(ds, batch_size=params.batch_size, balanced=True)\n",
    "    for ep in range(params.epochs):\n",
    "        for batch in dl:\n",
    "            anchor, pos, neg = batch['anchor'][0], batch['pos'][0], batch['neg'][0]\n",
    "            anchor, pos, neg = model(anchor.cuda()), model(pos.cuda()), model(neg.cuda())\n",
    "            loss = loss_fn(anchor, pos, neg)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "    return model.eval()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from modules import metric_learning\n",
    "\n",
    "\n",
    "def get_centroids(predictions, labels):\n",
    "    centroids = metric_learning.ml.get_centroids(predictions, labels)\n",
    "    return metric_learning.ml.get_l2_normalized(centroids)  # l2 norm"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from modules.selection.uncertanties import select_initial_rejected, get_new_rejected\n",
    "import torch\n",
    "import numpy as np\n",
    "from modules.algorithms.base.OSLPP import do_l2_normalization, do_pca, select_closed_set_pseudo_labels, evaluate_T\n",
    "from modules.loaders.osda import create_datasets_sub\n",
    "from modules.loaders.common import set_seed\n",
    "from torch import nn\n",
    "\n",
    "\n",
    "def train(params: MlTripletParams,\n",
    "          select_reject_mode, seed,\n",
    "          common, tgt_private, logger):\n",
    "    set_seed(seed)\n",
    "    print(params.oslpp_params.source, '->', params.oslpp_params.target, 'lr=', params.lr, 'seed=', seed)\n",
    "\n",
    "    (feats_S, labels_S), (feats_T, labels_T) = create_datasets_sub(params.oslpp_params.dataset,\n",
    "                                                                   params.oslpp_params.source,\n",
    "                                                                   params.oslpp_params.target,\n",
    "                                                                   common,\n",
    "                                                                   tgt_private, None)\n",
    "\n",
    "    params.oslpp_params.n_r = int(len(labels_T) * params.oslpp_params.n_r)\n",
    "    num_src_classes = params.oslpp_params.num_common + params.oslpp_params.num_src_priv\n",
    "\n",
    "    feats_S, feats_T = do_l2_normalization(feats_S, feats_T)\n",
    "    feats_S, feats_T = do_pca(feats_S, feats_T, params.oslpp_params.pca_dim)\n",
    "    feats_S, feats_T = do_l2_normalization(feats_S, feats_T)\n",
    "\n",
    "    rejected = np.zeros((len(feats_T),), dtype=np.int)\n",
    "    pseudo_labels = -torch.tensor(np.ones((len(feats_T),), dtype=np.int))\n",
    "    cs_pseudo_labels = pseudo_labels\n",
    "\n",
    "    # initial\n",
    "    feats_S, feats_T = torch.tensor(feats_S), torch.tensor(feats_T)\n",
    "    labels_S, labels_T = torch.tensor(labels_S), torch.tensor(labels_T)\n",
    "    feats_all = torch.cat((feats_S, feats_T), dim=0)\n",
    "\n",
    "\n",
    "    pairwise_distance_fn = get_distance_fn_pairwise(params.pairwise_distance_fn)\n",
    "\n",
    "    for t in range(1, params.oslpp_params.T):\n",
    "        model = train_model(feats_all, torch.cat([labels_S, pseudo_labels], dim=0), params)\n",
    "\n",
    "        centroids = get_centroids(predict(model, feats_S, labels_S), labels_S)\n",
    "        preds = predict(model, feats_T, labels_T)\n",
    "\n",
    "        pairwise_distances = pairwise_distance_fn(preds, centroids)\n",
    "        pairwise_distances = F.softmax(-pairwise_distances, dim=-1)\n",
    "\n",
    "        cs_pseudo_probs, cs_pseudo_labels = pairwise_distances.max(dim=-1)\n",
    "        selected = torch.tensor(\n",
    "            select_closed_set_pseudo_labels(cs_pseudo_labels.numpy(), torch.tensor([preds]),\n",
    "                                            t, params.oslpp_params.T,\n",
    "                                            mode=select_reject_mode,\n",
    "                                            uniform_ratio=None, balanced=False,\n",
    "                                            weights=None, tops=None, aug_preds=None))\n",
    "\n",
    "        if t == 1:\n",
    "            rejected = torch.tensor(select_initial_rejected(torch.tensor([preds]), params.oslpp_params.n_r,\n",
    "                                                            mode=select_reject_mode, weights=None,\n",
    "                                                            tops=None, aug_preds=None))\n",
    "        else:\n",
    "            selected = selected * (1 - rejected)\n",
    "            rejected_new = get_new_rejected(torch.tensor([preds]), selected, rejected, mode=select_reject_mode,\n",
    "                                            weights=None, tops=None, aug_preds=None)\n",
    "            rejected[rejected_new == 1] = 1\n",
    "        selected = selected * (1 - rejected)\n",
    "\n",
    "        pseudo_labels = cs_pseudo_labels.clone()\n",
    "        pseudo_labels[rejected == 1] = num_src_classes\n",
    "        pseudo_labels[(rejected == 0) * (selected == 0)] = -1\n",
    "\n",
    "        metrics = evaluate_T(params.oslpp_params.num_common, params.oslpp_params.num_src_priv,\n",
    "                             params.oslpp_params.num_tgt_priv,\n",
    "                             labels_T.numpy(), cs_pseudo_labels.numpy(), rejected.numpy())\n",
    "        where = torch.where((selected == 1) + (rejected == 1))[0]\n",
    "        metrics_selected = evaluate_T(params.oslpp_params.num_common, params.oslpp_params.num_src_priv,\n",
    "                                      params.oslpp_params.num_tgt_priv,\n",
    "                                      labels_T[where].numpy(), cs_pseudo_labels[where].numpy(),\n",
    "                                      rejected[where].numpy())\n",
    "        logger.log(t, metrics, metrics_selected)\n",
    "\n",
    "    assert (pseudo_labels == -1).sum() == 0\n",
    "\n",
    "    _rejected = rejected\n",
    "    metrics = evaluate_T(params.oslpp_params.num_common, params.oslpp_params.num_src_priv,\n",
    "                         params.oslpp_params.num_tgt_priv, labels_T.numpy(),\n",
    "                         cs_pseudo_labels.numpy(), _rejected.numpy())\n",
    "    logger.log_res(metrics)\n",
    "    return metrics"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "results = DataFrameCollector({'source': [], 'target': [], 'desc': [], 'lr': [], 'seed': [], 'epochs': []})\n",
    "select_reject_mode = SelectRejectMode.CONFIDENCE\n",
    "logger = DefaultLogger()\n",
    "for (source, target), (common, tgt_private) in config.items():\n",
    "    for epochs in [10]:\n",
    "        for lr in [1e-3]:\n",
    "            for n_r in [0.15]:\n",
    "                for seed in range(1):\n",
    "                    params = Params(pca_dim=512, proj_dim=128, T=10, n_r=n_r, n_r_ratio=None,\n",
    "                                    dataset='DomainNet_DCC', source=source, target=target,\n",
    "                                    num_common=len(common), num_src_priv=0, num_tgt_priv=len(tgt_private))\n",
    "                    ml_params = MlTripletParams(oslpp_params=params,\n",
    "                                         margin=0.5, lr=1e-4, batch_size=32, num_layers=1, epochs=100,\n",
    "                                        normalize=False, distance_fn='cos', pairwise_distance_fn='cos')\n",
    "                    metrics = train(ml_params, select_reject_mode, seed, common, tgt_private, logger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "87c3e150e0f22e62286b0675a541f4baa4e53a56f1434145374688b05f7921a7"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}