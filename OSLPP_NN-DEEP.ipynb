{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from collections import Counter\n",
    "import os\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import ConcatDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('small_datasets.pkl', 'rb') as f:\n",
    "    config = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from modules.deep.DEEPNN import get_simple_deep_nn\n",
    "\n",
    "\n",
    "def get_model(n_classes):\n",
    "    return get_simple_deep_nn(n_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from modules.loaders.balanced_sampling import create_train_dataloader\n",
    "from modules.loaders.resnet_features.features_dataset import FeaturesDataset\n",
    "from modules.deep.DEEPNN import fix_batch_normalization_layers\n",
    "\n",
    "\n",
    "def train_initial_NN(feats_S, lbls_S, num_epochs, params, balanced, lr):\n",
    "    num_src_classes = params.num_common + params.num_src_priv\n",
    "    assert (lbls_S.unique() == torch.arange(num_src_classes)).all()\n",
    "    model = get_model(num_src_classes).cuda().train()\n",
    "    model.apply(fix_batch_normalization_layers)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    loss_fn = nn.CrossEntropyLoss().cuda()\n",
    "    ds = FeaturesDataset(feats_S, lbls_S)\n",
    "    dl = create_train_dataloader(ds, 32, balanced)\n",
    "    print('CLASSES:', num_src_classes)\n",
    "    for ep in (pbar := tqdm(range(num_epochs))):\n",
    "        avg_loss = 0\n",
    "        for f,l in dl:\n",
    "            optimizer.zero_grad()\n",
    "            preds = model(f.cuda())\n",
    "            loss = loss_fn(preds, l.cuda())\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            avg_loss += loss.item()\n",
    "        pbar.set_description('Loss: ' + str(avg_loss / len(dl)))\n",
    "    return model.eval()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from torch.utils.data import Subset\n",
    "\n",
    "\n",
    "def train_NN(feats, lbls, num_epochs, params, balanced, lr):\n",
    "    num_src_classes = params.num_common + params.num_src_priv\n",
    "    feats, lbls = Subset(feats, np.arange(0, len(lbls))[lbls >= 0]), lbls[lbls >= 0]\n",
    "    feats, lbls = Subset(feats, np.arange(0, len(lbls))[lbls < num_src_classes]), lbls[lbls < num_src_classes]\n",
    "    model = get_model(num_src_classes).cuda().train()\n",
    "    model.apply(fix_batch_normalization_layers)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    loss_fn = nn.CrossEntropyLoss().cuda()\n",
    "    ds = FeaturesDataset(feats, lbls)\n",
    "    dl = create_train_dataloader(ds, 32, balanced)\n",
    "    for ep in (pbar := tqdm(range(num_epochs))):\n",
    "        avg_loss = 0\n",
    "        for f,l in dl:\n",
    "            optimizer.zero_grad()\n",
    "            loss = loss_fn(model(f.cuda()), l.cuda())\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            avg_loss += loss.item()\n",
    "        pbar.set_description('Loss: ' + str(avg_loss / len(dl)))\n",
    "    return model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_NN(model, feats, lbls):\n",
    "    ds = FeaturesDataset(feats, lbls)\n",
    "    dl = torch.utils.data.DataLoader(ds, batch_size=32, shuffle=False)\n",
    "    model = model.eval()\n",
    "    preds = []\n",
    "    with torch.no_grad():\n",
    "        for f,l in dl:\n",
    "            out = model(f.cuda())\n",
    "            preds.append(F.softmax(out, dim=1).detach().cpu())\n",
    "    preds = torch.cat(preds, dim=0)\n",
    "    return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Input \u001B[1;32mIn [1]\u001B[0m, in \u001B[0;36m<cell line: 7>\u001B[1;34m()\u001B[0m\n\u001B[0;32m      4\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mmodules\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mloaders\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mcommon\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m set_seed\n\u001B[0;32m      5\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mmodules\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mselection\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01muncertanties\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m SelectRejectMode, select_initial_rejected, get_new_rejected\n\u001B[1;32m----> 7\u001B[0m results \u001B[38;5;241m=\u001B[39m \u001B[43mpd\u001B[49m\u001B[38;5;241m.\u001B[39mDataFrame({\u001B[38;5;124m'\u001B[39m\u001B[38;5;124msource\u001B[39m\u001B[38;5;124m'\u001B[39m: [], \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtarget\u001B[39m\u001B[38;5;124m'\u001B[39m: [], \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mdesc\u001B[39m\u001B[38;5;124m'\u001B[39m: [], \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mlr\u001B[39m\u001B[38;5;124m'\u001B[39m: [], \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mseed\u001B[39m\u001B[38;5;124m'\u001B[39m: [], \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mepochs\u001B[39m\u001B[38;5;124m'\u001B[39m: []})\n\u001B[0;32m      8\u001B[0m select_reject_mode \u001B[38;5;241m=\u001B[39m SelectRejectMode\u001B[38;5;241m.\u001B[39mCONFIDENCE\n\u001B[0;32m      9\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m (source, target), (common, tgt_private) \u001B[38;5;129;01min\u001B[39;00m config\u001B[38;5;241m.\u001B[39mitems():\n",
      "\u001B[1;31mNameError\u001B[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "from modules.logging.format_utils import format_measures\n",
    "from modules.loaders.osda import create_datasets_sub\n",
    "from modules.algorithms.base.OSLPP import Params, select_closed_set_pseudo_labels, evaluate_T\n",
    "from modules.loaders.common import set_seed\n",
    "from modules.selection.uncertanties import SelectRejectMode, select_initial_rejected, get_new_rejected\n",
    "\n",
    "results = pd.DataFrame({'source': [], 'target': [], 'desc': [], 'lr': [], 'seed': [], 'epochs': []})\n",
    "select_reject_mode = SelectRejectMode.CONFIDENCE\n",
    "for (source, target), (common, tgt_private) in config.items():\n",
    "    for epochs in [35]:\n",
    "        for lr in [1e-3]:\n",
    "            for n_r in [0.1, 0.25]:\n",
    "                for seed in range(1):\n",
    "                    set_seed(seed)\n",
    "                    print(source, '->', target, 'lr=', lr, 'seed=', seed)\n",
    "                    params = Params(pca_dim=512, proj_dim=128, T=10, n_r=1200, n_r_ratio=None,\n",
    "                              dataset='DomainNet_DCC', source=source, target=target,\n",
    "                              num_common=len(common), num_src_priv=0, num_tgt_priv=len(tgt_private))\n",
    "                    (feats_S, labels_S), (feats_T, labels_T) = create_datasets_sub(params.dataset,\n",
    "                                                                                   params.source,\n",
    "                                                                                   params.target,\n",
    "                                                                                   common,\n",
    "                                                                                   tgt_private,\n",
    "                                                                                   is_images=True)\n",
    "                    params.n_r = int(len(labels_T) * n_r)\n",
    "                    num_src_classes = params.num_common + params.num_src_priv\n",
    "\n",
    "                    # initial\n",
    "                    labels_S, labels_T = torch.tensor(labels_S), torch.tensor(labels_T)\n",
    "                    feats_all = ConcatDataset([feats_S, feats_T])\n",
    "\n",
    "                    t = 1\n",
    "                    model = train_initial_NN(feats_S, labels_S, epochs, params, balanced=True, lr=lr)\n",
    "                    predictions_S_2 = predict_NN(model, feats_S, labels_S)\n",
    "                    predictions_T_2 = predict_NN(model, feats_T, labels_T)\n",
    "\n",
    "                    confs, cs_pseudo_labels = predictions_T_2.max(dim=1)\n",
    "                    selected = torch.tensor(select_closed_set_pseudo_labels(cs_pseudo_labels.numpy(), confs.numpy(), predictions_T_2,\n",
    "                                                                            t, params.T,\n",
    "                                                                            mode=select_reject_mode))\n",
    "                    rejected = torch.tensor(select_initial_rejected(confs, predictions_T_2, params.n_r, mode=select_reject_mode))\n",
    "\n",
    "                    rejected = torch.tensor(rejected)\n",
    "                    selected = selected * (1 - rejected)\n",
    "\n",
    "                    pseudo_labels = cs_pseudo_labels.clone()\n",
    "                    pseudo_labels[rejected == 1] = num_src_classes\n",
    "                    pseudo_labels[(rejected == 0) * (selected == 0)] = -1\n",
    "\n",
    "                    metrics = evaluate_T(params.num_common, params.num_src_priv, params.num_tgt_priv,\n",
    "                                         labels_T.numpy(), cs_pseudo_labels.numpy(), rejected.numpy())\n",
    "                    where = torch.where((selected == 1) + (rejected == 1))[0]\n",
    "                    metrics_selected = evaluate_T(params.num_common, params.num_src_priv, params.num_tgt_priv, labels_T[where].numpy(), cs_pseudo_labels[where].numpy(), rejected[where].numpy())\n",
    "                    print('______')\n",
    "                    print(f'Iteration t={t}')\n",
    "                    print('all: ', format_measures(metrics))\n",
    "                    print('selected: ', format_measures(metrics_selected))\n",
    "                    \n",
    "                    for t in range(2, params.T):\n",
    "                        print('TRAIN NN:', t)\n",
    "                        model = train_NN(feats_all, torch.cat((labels_S, pseudo_labels), axis=0), epochs, params, balanced=True, lr=lr)\n",
    "                        predictions_S_2 = predict_NN(model, feats_S, labels_S)\n",
    "                        predictions_T_2 = predict_NN(model, feats_T, labels_T)\n",
    "\n",
    "                        confs, cs_pseudo_labels = predictions_T_2.max(dim=1)\n",
    "                        selected = torch.tensor(select_closed_set_pseudo_labels(cs_pseudo_labels.numpy(), confs.numpy(), t, params.T, predictions_T_2, select_reject_mode))\n",
    "                        selected = selected * (1 - rejected)\n",
    "\n",
    "                        rejected_new = get_new_rejected(confs, predictions_T_2, selected, rejected, mode=select_reject_mode)\n",
    "\n",
    "                        rejected[rejected_new == 1] = 1\n",
    "                        selected = selected * (1 - rejected)\n",
    "\n",
    "                        pseudo_labels = cs_pseudo_labels.clone()\n",
    "                        pseudo_labels[rejected == 1] = num_src_classes\n",
    "                        pseudo_labels[(rejected == 0) * (selected == 0)] = -1\n",
    "                        \n",
    "                        print('Rejected:', len(rejected[rejected == 1]), '/', len(rejected))\n",
    "                        print('Selected:', len(selected[selected == 1]), '/', len(selected))\n",
    "\n",
    "                        metrics = evaluate_T(params.num_common, params.num_src_priv, params.num_tgt_priv, labels_T.numpy(), cs_pseudo_labels.numpy(), rejected.numpy())\n",
    "                        where = torch.where((selected == 1) + (rejected == 1))[0]\n",
    "                        metrics_selected = evaluate_T(params.num_common, params.num_src_priv, params.num_tgt_priv, labels_T[where].numpy(), cs_pseudo_labels[where].numpy(), rejected[where].numpy())\n",
    "                        print('______')\n",
    "                        print(f'Iteration t={t}')\n",
    "                        print('all: ', format_measures(metrics))\n",
    "                        print('selected: ', format_measures(metrics_selected))\n",
    "\n",
    "                    print((pseudo_labels == -1).sum())\n",
    "\n",
    "                    _rejected = rejected\n",
    "                    metrics = evaluate_T(params.num_common, params.num_src_priv, params.num_tgt_priv, labels_T.numpy(), cs_pseudo_labels.numpy(), _rejected.numpy())\n",
    "                    print('all: ', format_measures(metrics))\n",
    "\n",
    "                    results = results.append({'source': source, 'target': target, 'desc': format_measures(metrics), 'lr': lr, 'seed': seed, 'n_r': n_r, 'epochs': epochs}, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "results.to_csv('results/abacaba-deep.csv', header=True, index=False)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "87c3e150e0f22e62286b0675a541f4baa4e53a56f1434145374688b05f7921a7"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}